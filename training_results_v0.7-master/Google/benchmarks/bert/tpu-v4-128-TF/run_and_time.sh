python3 run_pretraining.py --bert_config_file=${INTERNAL_PATH} --nobinarylog --${INTERNAL}_num_eigen_threads=1 --${INTERNAL}_num_operation_threads=1 --${INTERNAL}_port=14612 --${INTERNAL}_rpc_layer=rpc2 --${INTERNAL}_run_locally --${INTERNAL}_session_gc_seconds=86400 --census_cpu_accounting_enabled --nodo_eval --do_train --noenable_profiling --eval_batch_size=3072 --gfs_user=platforms-deepsea --init_checkpoint=${INTERNAL_PATH} --input_file="${INTERNAL_PATH} --iterations_per_loop=163 --lamb_beta_1=0.9 --lamb_beta_2=0.999 --lamb_weight_decay_rate=0.01 --learning_rate=0.0015 --local_prefix=/export/ssd/mlperf_data/bert/ --log_epsilon=-6 --master=mvbn1:14678 --max_eval_steps=4 --max_predictions_per_seq=76 --max_seq_length=512 --model_dir=${INTERNAL_PATH} --num_eval_samples=10000 --num_tpu_cores=128 --num_train_steps=1141 --num_warmup_steps=100 --optimizer=lamb --norepeatable --rpclog=-1 --save_checkpoints_steps=163 --sleep_after_init=200 --start_warmup_step=0 --stop_steps=1141 --stop_threshold=0.712 --train_batch_size=3072 --use_bfloat16_activation --use_bfloat16_all_reduce --use_tpu --xprof_port=14613