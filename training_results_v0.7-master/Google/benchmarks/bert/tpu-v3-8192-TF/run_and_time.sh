python3 run_pretraining.py --bert_config_file=${INTERNAL_PATH} --nobinarylog --${INTERNAL}_job_name=train --${INTERNAL}_jobs=tpu_worker|${INTERNAL_PATH} --${INTERNAL}_num_eigen_threads=1 --${INTERNAL}_num_operation_threads=1 --${INTERNAL}_port=26097 --${INTERNAL}_rpc_layer=rpc2 --${INTERNAL}_session_gc_seconds=86400 --${INTERNAL}_task=0 --census_cpu_accounting_enabled --nodo_eval --do_train --noenable_profiling --eval_batch_size=8192 --gfs_user=staging-${INTERNAL}-gpu-dedicated --init_checkpoint=${INTERNAL_PATH} --input_file=${INTERNAL_PATH} --iterations_per_loop=62 --lamb_beta_1=0.88 --lamb_beta_2=0.88 --lamb_weight_decay_rate=0.0166629 --learning_rate=0.00288293 --log_epsilon=-6 --master=${INTERNAL_PATH} --max_eval_steps=2 --max_predictions_per_seq=76 --max_seq_length=512 --model_dir=${INTERNAL_PATH} --num_eval_samples=10000 --num_partitions=1 --num_tpu_cores=8192 --num_train_steps=560 --num_warmup_steps=287 --optimizer=lamb --norepeatable --replicas_per_host=16 --rpclog=-1 --save_checkpoints_steps=62 --sleep_after_init=900 --start_warmup_step=-76 --stop_steps=560 --stop_threshold=0.712 --train_batch_size=8192 --use_bfloat16_activation --use_bfloat16_all_reduce --use_tpu --xprof_port=26098