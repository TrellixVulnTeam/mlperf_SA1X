python3 trainer.py --EXPERIMENTAL_${INTERNAL}_session_device_filters=/job:ps,/job:trainer/replica:0 --nobinarylog --no${INTERNAL}_collect_cpu_allocator_stats --${INTERNAL}_port=14208 --${INTERNAL}_rpc_layer=rpc2 --${INTERNAL}_run_locally --${INTERNAL}_session_gc_seconds=86400 --${INTERNAL}_timeline_step=100 --no${INTERNAL}_use_bfloat16_for_sendrecv --no${INTERNAL}_use_gpuprof --census_cpu_accounting_enabled --nocluster_placer_in_executor --controller_gpus=0 --controller_job="" --disable_meta_optimizer_in_executor --disable_py_utils_debug --noenable_asserts --noenable_check_numerics --gfs_user=platforms-deepsea --job=executor_tpu --logdir=${INTERNAL_PATH} --mode=sync --model=mt.mlperf.WmtEnDeMlPerfTpuExecutorOneShotPfcTwoCube --model_spec_path="" --model_task_name="" --nono_identity_on_vars --ps_gpus=0 --ps_job=/job:trainer --ps_replicas=1 --pythreadz_port=14209 --norpc_dependency_configuration_enable_enforcement --rpclog=-1 --streamz_announce_roots --streamz_default_root_labels=babelfish_job_category:string:experimental --task=0 --tf_master=mvbn2:14678 --undefok=model_spec_path --nouse_lingvo_cluster --worker_job=/job:trainer --worker_num_tpu_hosts=2 --worker_replicas=1 --worker_split_size=1 --worker_tpus=16 --nowrite_inference_graph --xla_device=tpu