+ echo 'Beginning trial 4 of 4'
Beginning trial 4 of 4
+ docker exec -it translation python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.TRANSFORMER)'
:::MLLOG {"namespace": "", "time_ms": 1593126519389, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "transformer", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 84}}
:::MLLOG {"namespace": "", "time_ms": 1593126519428, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell EMC", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 89}}
:::MLLOG {"namespace": "", "time_ms": 1593126519428, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 93}}
:::MLLOG {"namespace": "", "time_ms": 1593126519428, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1593126519428, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/translation/mlperf_log_utils.py", "lineno": 101}}
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it translation python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1593126522574, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ export SEED=29819
+ SEED=29819
+ docker exec -it --env=EXTRA_PARAMS --env=HT --env=LEARNING_RATE --env=MAX_TOKENS --env=NCCL_SOCKET_IFNAME --env=NGPU --env=NNODES --env=NSOCKET --env=SOCKETCORES --env=WALLTIME --env=WARMUP_UPDATES --env=SEED translation ./run_and_time.sh
Run vars: id 14093 gpus  mparams 
+ SEED=29819
+ MAX_TOKENS=15360
+ DATASET_DIR=/data
+ MODE=TRAIN
+ NUMEPOCHS=30
+ case "$MODE" in
+ source run_training.sh
+++ date +%s
++ START=1593126523
+++ date '+%Y-%m-%d %r'
++ START_FMT='2020-06-25 11:08:43 PM'
++ echo 'STARTING TIMING RUN AT 2020-06-25 11:08:43 PM'
STARTING TIMING RUN AT 2020-06-25 11:08:43 PM
++ [[ '' -ne 1 ]]
++ DISTRIBUTED_INIT_METHOD='--distributed-init-method env://'
++ export SYSTEM
++ export SLURM_NTASKS_PER_NODE
++ export SLURM_NNODES
++ declare -a CMD
++ '[' -n '' ']'
++ HTFLAG=
++ [[ 1 == 1 ]]
++ HTFLAG=--no_hyperthreads
++ CMD=('python' '-u' '-m' 'bind_launch' ${HTFLAG} "--nsockets_per_node=${NSOCKET}" "--ncores_per_socket=${SOCKETCORES}" "--nproc_per_node=${NGPU}")
++ python -u -m bind_launch --no_hyperthreads --nsockets_per_node=2 --ncores_per_socket=20 --nproc_per_node=4 train.py /data --seed 29819 --arch transformer_wmt_en_de_big_t2t --share-all-embeddings --optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-9 --clip-norm 0.0 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0 --warmup-updates 2000 --lr 1.976e-3 --min-lr 0.0 --dropout 0.1 --weight-decay 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 15360 --max-epoch 30 --target-bleu 25.0 --ignore-case --no-save --update-freq 1 --fp16 --seq-len-multiple 2 --source_lang en --target_lang de --bucket_growth_factor 1.035 --batching_scheme v0p5_better --batch_multiple_strategy dynamic --fast-xentropy --max-len-a 1 --max-len-b 50 --lenpen 0.6 --no-progress-bar --dataloader-num-workers 2 --enable-dataloader-pin-memory --multihead-attn-impl fast_with_lyrnrm_and_dropoutadd --distributed-init-method env:// --distributed-weight-update 2 --dwu-num-blocks 4 --dwu-num-rs-pg 2 --dwu-num-ar-pg 2 --dwu-num-ag-pg 0 --dwu-overlap-reductions --dwu-num-chunks 1 --dwu-flat-mt --dwu-compute-L2-grad-norm --max-source-positions 64 --max-target-positions 64 --adam-betas '(0.9,0.98)'
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 4, RANK: 2
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 4, RANK: 3
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 4, RANK: 1
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 4, RANK: 0
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| initialized host node010 as rank 0 and device id 0
:::MLLOG {"namespace": "", "time_ms": 1593126527396, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1593126527408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1593126527408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1593126527412, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 116}}
Namespace(adam_betas='(0.9,0.98)', adam_eps=1e-09, adaptive_softmax_cutoff=None, arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, batch_multiple_strategy='dynamic', batching_scheme='v0p5_better', beam=4, bucket_growth_factor=1.035, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', data='/data', dataloader_num_workers=2, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, device_id=0, distributed_backend='nccl', distributed_init_method='env://', distributed_port=-1, distributed_rank=0, distributed_weight_update=2, distributed_world_size=4, dropout=0.1, dwu_compute_L2_grad_norm=True, dwu_do_not_flatten_model=False, dwu_e5m2_allgather=False, dwu_flat_mt=True, dwu_full_pipeline=False, dwu_group_size=0, dwu_num_ag_pg=0, dwu_num_ar_pg=2, dwu_num_blocks=4, dwu_num_chunks=1, dwu_num_rs_pg=2, dwu_overlap_reductions=True, enable_dataloader_pin_memory=True, enable_global_stats=False, enable_parallel_backward_allred_opt=False, enable_parallel_backward_allred_opt_correctness_check=False, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, fast_xentropy=True, fp16=True, gen_subset='test', ignore_case=True, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', lenpen=0.6, local_rank=0, log_format=None, log_interval=1000, log_translations=False, lr=[0.001976], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=30, max_len_a=1.0, max_len_b=50, max_sentences=None, max_sentences_valid=None, max_source_positions=64, max_target_positions=64, max_tokens=15360, max_update=0, min_len=1, min_loss_scale=0.0001, min_lr=0.0, model_overrides='{}', momentum=0.99, multihead_attn_impl='fast_with_lyrnrm_and_dropoutadd', nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_progress_bar=True, no_save=True, no_token_positional_embeddings=False, num_shards=1, online_eval=False, optimizer='adam', parallel_backward_allred_cuda_nstreams=1, parallel_backward_allred_opt_threshold=0, path=None, prefix_size=0, print_alignment=False, profile=None, quiet=False, raw_text=False, relu_dropout=0.1, remove_bpe=None, replace_unk=None, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, seed=29819, sentence_avg=False, seq_len_multiple=2, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_bleu=25.0, target_lang='de', task='translation', time_step=False, train_subset='train', uniform_n_seq_in_dataset=None, uniform_n_seq_per_batch=None, uniform_seq_len_per_batch=None, unkpen=0, unnormalized=False, update_freq=[1], valid_subset='valid', validate_interval=1, warmup_init_lr=0.0, warmup_updates=2000, weight_decay=0.0)
:::MLLOG {"namespace": "", "time_ms": 1593126527466, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 61440, "metadata": {"file": "/workspace/translation/train.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/translation/train.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.001976, "metadata": {"file": "/workspace/translation/train.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 2000, "metadata": {"file": "/workspace/translation/train.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "max_sequence_length", "value": 64, "metadata": {"file": "/workspace/translation/train.py", "lineno": 139, "method": "discard"}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "opt_adam_beta_1", "value": 0.9, "metadata": {"file": "/workspace/translation/train.py", "lineno": 140}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "opt_adam_beta_2", "value": 0.98, "metadata": {"file": "/workspace/translation/train.py", "lineno": 141}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "opt_adam_epsilon", "value": 1e-09, "metadata": {"file": "/workspace/translation/train.py", "lineno": 142}}
:::MLLOG {"namespace": "", "time_ms": 1593126527467, "event_type": "POINT_IN_TIME", "key": "seed", "value": 29819, "metadata": {"file": "/workspace/translation/train.py", "lineno": 143}}
Using master seed from command line: 29819
Worker 0 is using worker seed: 654134935
| [en] dictionary: 33712 types
| [de] dictionary: 33712 types
| model transformer_wmt_en_de_big_t2t, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 210808832
| training on 4 GPUs
| max tokens per GPU = 15360 and max sentences per GPU = None
DistributedFusedAdam {'distributed_weight_update': 2, 'dwu_group_size': 0, 'dwu_num_blocks': 4, 'dwu_num_chunks': 1, 'dwu_num_rs_pg': 2, 'dwu_num_ar_pg': 2, 'dwu_num_ag_pg': 0, 'overlap_reductions': True, 'full_pipeline': False, 'compute_L2_grad_norm': True, 'flat_mt': True, 'e5m2_allgather': False, 'do_not_flatten_model': False}
self._net_total_param_size=210808832, self._total_param_size=210808832, dwu_min_page_size=4096, self._block_size=52702208, self._chunk_size=52702208, self._shard_size=13175552
[0, 15, 55, 104]
model_param_fragment.size()=torch.Size([13175552]), new_param_packed_fragment.size()=torch.Size([13175552]), master_param_fragment.size()=torch.Size([13175552])
model_param_fragment.size()=torch.Size([2801664]), new_param_packed_fragment.size()=torch.Size([2801664]), master_param_fragment.size()=torch.Size([2801664])
model_param_fragment.size()=torch.Size([4096]), new_param_packed_fragment.size()=torch.Size([4096]), master_param_fragment.size()=torch.Size([4096])
model_param_fragment.size()=torch.Size([4194304]), new_param_packed_fragment.size()=torch.Size([4194304]), master_param_fragment.size()=torch.Size([4194304])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([3145728]), new_param_packed_fragment.size()=torch.Size([3145728]), master_param_fragment.size()=torch.Size([3145728])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1976064]), new_param_packed_fragment.size()=torch.Size([1976064]), master_param_fragment.size()=torch.Size([1976064])
model_param_fragment.size()=torch.Size([467968]), new_param_packed_fragment.size()=torch.Size([467968]), master_param_fragment.size()=torch.Size([467968])
model_param_fragment.size()=torch.Size([4096]), new_param_packed_fragment.size()=torch.Size([4096]), master_param_fragment.size()=torch.Size([4096])
model_param_fragment.size()=torch.Size([4194304]), new_param_packed_fragment.size()=torch.Size([4194304]), master_param_fragment.size()=torch.Size([4194304])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([3145728]), new_param_packed_fragment.size()=torch.Size([3145728]), master_param_fragment.size()=torch.Size([3145728])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([2097152]), new_param_packed_fragment.size()=torch.Size([2097152]), master_param_fragment.size()=torch.Size([2097152])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([111360]), new_param_packed_fragment.size()=torch.Size([111360]), master_param_fragment.size()=torch.Size([111360])
model_param_fragment.size()=torch.Size([2331648]), new_param_packed_fragment.size()=torch.Size([2331648]), master_param_fragment.size()=torch.Size([2331648])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([3145728]), new_param_packed_fragment.size()=torch.Size([3145728]), master_param_fragment.size()=torch.Size([3145728])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([2097152]), new_param_packed_fragment.size()=torch.Size([2097152]), master_param_fragment.size()=torch.Size([2097152])
model_param_fragment.size()=torch.Size([1048576]), new_param_packed_fragment.size()=torch.Size([1048576]), master_param_fragment.size()=torch.Size([1048576])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([1024]), new_param_packed_fragment.size()=torch.Size([1024]), master_param_fragment.size()=torch.Size([1024])
model_param_fragment.size()=torch.Size([2448128]), new_param_packed_fragment.size()=torch.Size([2448128]), master_param_fragment.size()=torch.Size([2448128])
:::MLLOG {"namespace": "", "time_ms": 1593126540412, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 212}}
:::MLLOG {"namespace": "", "time_ms": 1593126540412, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 214}}
filename: /data/train.en-de.en
raw_text: False
| /data train 4590101 examples
filename: /data/train1.en-de.en
raw_text: False
filename: /data/train1.de-en.en
raw_text: False
srcline: tensor([ 9093,    73,   156,    10,  3977,   165,     7,   147,   273, 10881,     2])
| Sentences are being padded to multiples of: 2
filename: /data/test.en-de.en
raw_text: False
| /data test 3003 examples
srcline: tensor([ 7549,  4344,    64, 32364,  1259,    20, 13504,  8959,  3868,     2])
| Sentences are being padded to multiples of: 2
filename: /data/test1.en-de.en
raw_text: False
filename: /data/test1.de-en.en
raw_text: False
:::MLLOG {"namespace": "", "time_ms": 1593126541608, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4590101, "metadata": {"file": "/workspace/translation/train.py", "lineno": 224}}
:::MLLOG {"namespace": "", "time_ms": 1593126541609, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 3003, "metadata": {"file": "/workspace/translation/train.py", "lineno": 227}}
self.dataset.src_sizes 4590101
self.dataset.tgt_sizes 4590101
generated 8733 batches in 2.070107s
got epoch iterator 2.0704433917999268
:::MLLOG {"namespace": "", "time_ms": 1593126543679, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593126543680, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 1}}
| WARNING: overflow detected, setting loss scale to: 64.0
| WARNING: overflow detected, setting loss scale to: 32.0
| WARNING: overflow detected, setting loss scale to: 16.0
| WARNING: overflow detected, setting loss scale to: 8.0
| WARNING: overflow detected, setting loss scale to: 4.0
| epoch 001:   1000 / 2184 loss=80147.959, nll_loss=0.000, ppl=1.00, wps=176604, ups=3.1, wpb=56011, bsz=488, num_updates=996, lr=0.000984048, gnorm=74180.885, clip=100%, oom=0, loss_scale=4.000, wall=323
| WARNING: overflow detected, setting loss scale to: 4.0
| epoch 001:   2000 / 2184 loss=66191.385, nll_loss=0.000, ppl=1.00, wps=177320, ups=3.1, wpb=56113, bsz=490, num_updates=1995, lr=0.00197106, gnorm=53025.453, clip=100%, oom=0, loss_scale=4.000, wall=638
| epoch 001 | loss 64716.392 | nll_loss 0.000 | ppl 1.00 | wps 177171 | ups 3.1 | wpb 56059 | bsz 490 | num_updates 2178 | lr 0.00189353 | gnorm 51503.038 | clip 100% | oom 0 | loss_scale 4.000 | wall 696
epoch time  689.634514093399
:::MLLOG {"namespace": "", "time_ms": 1593127233314, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593127233315, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 1}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 51 batches in 0.000875s
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
/workspace/translation/fairseq/sequence_generator.py:356: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:66.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams)
| Translated 816 sentences (22581 tokens) in 11.5s (71.20 sentences/s, 1970.22 tokens/s)
| Generate test with beam=4: bleu_score=19.2222
| Eval completed in: 15.04s
:::MLLOG {"namespace": "", "time_ms": 1593127248353, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593127248356, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1922219842672348, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 1}}
validation and scoring  15.04153847694397
:::MLLOG {"namespace": "", "time_ms": 1593127248356, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593127248358, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593127248359, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 2}}
| epoch 002:   1000 / 2184 loss=46769.738, nll_loss=0.000, ppl=1.00, wps=177624, ups=3.0, wpb=56071, bsz=494, num_updates=3179, lr=0.00156732, gnorm=57847.331, clip=100%, oom=0, loss_scale=8.000, wall=1027
| WARNING: overflow detected, setting loss scale to: 4.0
| WARNING: overflow detected, setting loss scale to: 2.0
| epoch 002:   2000 / 2184 loss=45841.254, nll_loss=0.000, ppl=1.00, wps=177683, ups=3.1, wpb=56100, bsz=488, num_updates=4177, lr=0.00136732, gnorm=52575.392, clip=100%, oom=0, loss_scale=2.000, wall=1342
| epoch 002 | loss 45631.510 | nll_loss 0.000 | ppl 1.00 | wps 177640 | ups 3.1 | wpb 56063 | bsz 489 | num_updates 4360 | lr 0.00133832 | gnorm 51302.294 | clip 100% | oom 0 | loss_scale 2.000 | wall 1400
epoch time  688.6933324337006
:::MLLOG {"namespace": "", "time_ms": 1593127937052, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1593127937052, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 2}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 51 batches in 0.000850s
| Translated 816 sentences (22789 tokens) in 11.3s (72.24 sentences/s, 2017.41 tokens/s)
| Generate test with beam=4: bleu_score=23.8253
| Eval completed in: 14.94s
:::MLLOG {"namespace": "", "time_ms": 1593127951988, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1593127951991, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.23825326561927795, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 2}}
validation and scoring  14.93917465209961
:::MLLOG {"namespace": "", "time_ms": 1593127951991, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1593127951992, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593127951992, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 3}}
| WARNING: overflow detected, setting loss scale to: 2.0
| epoch 003:   1000 / 2184 loss=42599.811, nll_loss=0.000, ppl=1.00, wps=177828, ups=3.0, wpb=56147, bsz=480, num_updates=5360, lr=0.00120703, gnorm=47795.847, clip=100%, oom=0, loss_scale=2.000, wall=1731
| epoch 003:   2000 / 2184 loss=42439.835, nll_loss=0.000, ppl=1.00, wps=177946, ups=3.1, wpb=56118, bsz=481, num_updates=6360, lr=0.00110809, gnorm=45099.810, clip=100%, oom=0, loss_scale=4.000, wall=2046
| epoch 003 | loss 42547.689 | nll_loss 0.000 | ppl 1.00 | wps 177854 | ups 3.1 | wpb 56065 | bsz 480 | num_updates 6543 | lr 0.00109248 | gnorm 45298.764 | clip 100% | oom 0 | loss_scale 4.000 | wall 2103
epoch time  688.2089245319366
:::MLLOG {"namespace": "", "time_ms": 1593128640201, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1593128640202, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 3}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 51 batches in 0.000867s
| Translated 816 sentences (23312 tokens) in 11.7s (69.83 sentences/s, 1994.99 tokens/s)
| Generate test with beam=4: bleu_score=24.6975
| Eval completed in: 15.27s
:::MLLOG {"namespace": "", "time_ms": 1593128655472, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1593128655475, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.24697525799274445, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 3}}
validation and scoring  15.27373480796814
:::MLLOG {"namespace": "", "time_ms": 1593128655475, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1593128655476, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 257, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1593128655476, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 258, "epoch_num": 4}}
| WARNING: overflow detected, setting loss scale to: 2.0
| epoch 004:   1000 / 2184 loss=41498.485, nll_loss=0.000, ppl=1.00, wps=178077, ups=3.0, wpb=56113, bsz=483, num_updates=7543, lr=0.00101749, gnorm=42817.611, clip=100%, oom=0, loss_scale=2.000, wall=2433
| epoch 004:   2000 / 2184 loss=41363.460, nll_loss=0.000, ppl=1.00, wps=177801, ups=3.1, wpb=56058, bsz=482, num_updates=8543, lr=0.000956086, gnorm=44239.064, clip=100%, oom=0, loss_scale=4.000, wall=2749
| WARNING: overflow detected, setting loss scale to: 4.0
| epoch 004 | loss 41291.405 | nll_loss 0.000 | ppl 1.00 | wps 177718 | ups 3.1 | wpb 56060 | bsz 481 | num_updates 8725 | lr 0.000946061 | gnorm 45286.302 | clip 100% | oom 0 | loss_scale 4.000 | wall 2807
epoch time  688.3444366455078
:::MLLOG {"namespace": "", "time_ms": 1593129343820, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 273, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1593129343821, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 640, "epoch_num": 4}}
self.dataset.src_sizes 3003
self.dataset.tgt_sizes 3003
generated 51 batches in 0.000853s
| Translated 816 sentences (22830 tokens) in 11.3s (72.37 sentences/s, 2024.65 tokens/s)
| Generate test with beam=4: bleu_score=26.1388
| Eval completed in: 14.88s
:::MLLOG {"namespace": "", "time_ms": 1593129358697, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 751, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1593129358699, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2613884508609772, "metadata": {"file": "/workspace/translation/train.py", "lineno": 280, "epoch_num": 4}}
validation and scoring  14.879521131515503
:::MLLOG {"namespace": "", "time_ms": 1593129358700, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 295, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1593129358701, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/translation/train.py", "lineno": 300, "status": "success"}}
| done training in 2818.3 seconds
++ ret_code=0
++ sleep 3
++ [[ 0 != 0 ]]
+++ date +%s
++ END=1593129362
+++ date '+%Y-%m-%d %r'
++ END_FMT='2020-06-25 11:56:02 PM'
++ echo 'ENDING TIMING RUN AT 2020-06-25 11:56:02 PM'
ENDING TIMING RUN AT 2020-06-25 11:56:02 PM
++ RESULT=2839
++ RESULT_NAME=transformer
++ echo 'RESULT,transformer,29819,2839,,2020-06-25 11:08:43 PM'
RESULT,transformer,29819,2839,,2020-06-25 11:08:43 PM
+ set +x
