:::MLL 1560879840.629908238 submission_org: {"value": "Intel_Corp", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.631584696 submission_platform: {"value": "32xCLX-8260L_CPUs", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.632980032 submission_division: {"value": "closed", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.634397790 submission_status: {"value": "onprem", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.635757501 submission_benchmark: {"value": "minigo", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.637154305 submission_poc_name: {"value": "Guokai Ma, Letian Kang, Christine Cheng, Mingxiao Huang", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.638562864 submission_poc_email: {"value": "guokai.ma@intel.com, letian.kang@intel.com, christine.cheng@intel.com, mingxiao.huang@intel.com", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879840.640052562 submission_entry: {"value": {"framework": "TensorFlow 1.13.1", "power": "none", "notes": "none", "interconnect": "OPA", "os": "Oracle Linux Server 7.6", "libraries": "MKLDNN (v0.18), MKL (v2019.0.3.20190220), IntelMPI (2018.1.163)", "compilers": "GCC6.3", "nodes": [{"num_nodes": 32, "cpu": "Intel(R) Xeon(R) Platinum 8260L CPU @ 2.40GHz", "num_cores": 48, "num_vcpus": "NA", "accelerator": "NA", "num_accelerators": 0, "sys_mem_size": "192G", "sys_storage_type": "SSD", "sys_storage_size": "800G", "cpu_accel_interconnect": "100Gb OPA", "network_card": "100Gb OPA", "num_network_cards": 1, "notes": "NA"}]}, "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879844.152983342 cache_clear: {value: true, metadata: {lineno: 0, file: manual}}
~/submission/benchmarks/minigo/implementations/tensorflow ~/submission/benchmarks/minigo/clx-8260l-2s-x32
Physical cores = 48
Virtual cores = 96
NUMA cores = 24
KMP_HW_SUBSET = 2T
Output to /lfs/lfs12/gma_akey
./run_mn.sh: line 20: ulimit: max user processes: cannot modify limit: Operation not permitted
Wiping dir /lfs/lfs12/gma_akey/results/epb269
:::MLL 1560879857.342595 init_start: {"value": null, "metadata": {'lineno': 742, 'file': 'ml_perf/reference_implementation.py'}}
Making dir /lfs/lfs12/gma_akey/results/epb269/models
Making dir /lfs/lfs12/gma_akey/results/epb269/data/selfplay
Making dir /lfs/lfs12/gma_akey/results/epb269/data/holdout
Making dir /lfs/lfs12/gma_akey/results/epb269/sgf/eval
Making dir /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks
Making dir /lfs/lfs12/gma_akey/results/epb269/work_dir
Making dir /lfs/lfs12/gma_akey/results/epb269/mpi
[2019-06-18 11:44:17] Selfplay nodes = ['epb269', 'epb307', 'epb345', 'epb212', 'epb305', 'epb147', 'epb146', 'epb145', 'epb144', 'epb143', 'epb142', 'epb141', 'epb140', 'epb229', 'epb228', 'epb227', 'epb226', 'epb225', 'epb224', 'epb223', 'epb222', 'epb221', 'epb220', 'epb199', 'epb198', 'epb197']
[2019-06-18 11:44:17] Train nodes = ['epb196', 'epb195', 'epb194', 'epb192', 'epb191', 'epb190']
[2019-06-18 11:44:17] Eval nodes = ['epb269', 'epb307', 'epb345', 'epb212', 'epb305', 'epb147', 'epb146', 'epb145', 'epb144', 'epb143', 'epb142', 'epb141', 'epb140', 'epb229', 'epb228', 'epb227', 'epb226', 'epb225', 'epb224', 'epb223', 'epb222', 'epb221', 'epb220', 'epb199', 'epb198', 'epb197']
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.53s/it]
[2019-06-18 11:47:10] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py:86: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2019-06-18 11:47:10] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
2019-06-18 11:47:10.258116: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-06-18 11:47:10.287566: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[2019-06-18 11:47:10] From ./quantize_graph.py:351: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.
Instructions for updating:
`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.
2019-06-18 11:47:10.687883: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
[2019-06-18 11:47:10] From ./dual_net.py:679: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99']
Reading tf_records from 1 inputs
[2019-06-18 11:47:14] minmax time: 4.015 seconds
2019-06-18 11:47:14.714056: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:47:14.719824: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:47:14.724559: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880035.057484 init_stop: {"value": null, "metadata": {'lineno': 614, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560880035.057856 run_start: {"value": null, "metadata": {'lineno': 615, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560880035.058255 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 11:47:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:47:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=2 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=1023779833 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=2047559664 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=3071339495 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=4095119326 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=5118899157 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=6142678988 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=7166458819 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=8190238650 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=9214018481 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=10237798312 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=11261578143 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=12285357974 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=13309137805 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=14332917636 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=15356697467 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=16380477298 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=17404257129 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=18428036960 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000001-000000 --seed=19451816791 : \
-host epb2
[2019-06-18 11:47:50] selfplay finished: 35.350 seconds
[2019-06-18 11:47:50] selfplay mn: 35.373 seconds
[2019-06-18 11:47:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-2-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779833 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559664 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339495 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119326 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899157 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678988 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458819 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238650 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018481 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798312 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578143 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357974 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137805 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917636 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697467 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477298 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257129 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036960 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816791 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596622 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376453 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156284 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:48:12] divide_golden_chunk finished: 21.823 seconds
[2019-06-18 11:48:12] generate golden chunk: 21.840 seconds
[2019-06-18 11:48:15] train finished: 60.878 seconds
:::MLL 1560880055.277846 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.278316 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.278711 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.795505 47826328925056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.213845 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.214721 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.215527 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.795499 47247718806400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.213880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.214786 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.215581 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.795506 47338751443840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.273758 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.274236 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.274680 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.795504 47770444485504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:35.797017 47338751443840 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjbk52g2_
I0618 11:47:35.798152 47338751443840 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjbk52g2_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e320d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.797430 47826328925056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz6sbtsu0
I0618 11:47:35.798522 47826328925056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz6sbtsu0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7fb7ef0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.798617 47338751443840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.797905 47770444485504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzv_avb36
W0618 11:47:35.797890 47247718806400 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx7w9f65_
I0618 11:47:35.798964 47826328925056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.798976 47770444485504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzv_avb36', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72b4f62e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.799008 47247718806400 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx7w9f65_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af900153e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.799419 47770444485504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.799462 47247718806400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880055.225016 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.225919 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.226652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.799571 46990006776704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.284180 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.284589 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.284937 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.799549 47679256777600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.284088 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.284499 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.284841 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.799574 47447599145856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.224261 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.225122 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.225948 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.799698 47258763879296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:35.801042 47679256777600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzck5v0k5
I0618 11:47:35.802132 47679256777600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzck5v0k5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d79c02e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.801468 47447599145856 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnukf53rb
I0618 11:47:35.802531 47447599145856 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnukf53rb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2789e13e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.802585 47679256777600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.801921 46990006776704 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpszp6135a
W0618 11:47:35.801950 47258763879296 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpelestbfw
I0618 11:47:35.802961 47447599145856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.803035 47258763879296 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpelestbfw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb926bbda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.803034 46990006776704 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpszp6135a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcff3fcda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.803479 47258763879296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.803493 46990006776704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.819034 47247718806400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.819098 47826328925056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.819141 47338751443840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.819209 47770444485504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.828039 47447599145856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.828129 47679256777600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.828176 47258763879296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.828172 46990006776704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880055.266797 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.267549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.268214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.835388 47921051960192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.263828 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.264658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.265497 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.835374 47395159765888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.319353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.319793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.320112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.835680 47888974119808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.315697 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.316154 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.316587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.835705 47920812602240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.268385 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.269289 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.270073 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.837553 47389535335296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.276734 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.277462 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.278221 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.837512 46996584944512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.338415 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.338895 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.339322 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.837669 47549232288640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.342244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.342675 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.343048 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.837666 46917444457344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:35.838898 47826328925056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.838867 47247718806400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.838999 47338751443840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.839062 47770444485504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.838823 46996584944512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1dfdk21f
W0618 11:47:35.839145 47921051960192 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfolfgvij
I0618 11:47:35.839868 47921051960192 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfolfgvij', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95c5ddce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.839887 46996584944512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1dfdk21f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abe8756ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.839548 47395159765888 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcrn19qry
I0618 11:47:35.840183 47921051960192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.840239 47395159765888 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcrn19qry', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b543fce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.840289 46996584944512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.840557 47395159765888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.839918 47389535335296 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_hype7dt
W0618 11:47:35.839992 47888974119808 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmc_u2uex
W0618 11:47:35.840019 47920812602240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0sqnn7bz
W0618 11:47:35.840179 47549232288640 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu57ob41u
I0618 11:47:35.840905 47389535335296 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_hype7dt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a0501cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.840203 46917444457344 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvdkc50ji
I0618 11:47:35.841023 47888974119808 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmc_u2uex', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e4de0de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.841058 47920812602240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0sqnn7bz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95b7998e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.841141 47549232288640 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu57ob41u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f33afee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.841198 46917444457344 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvdkc50ji', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac1a32ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.841295 47389535335296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.841447 47888974119808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.841481 47920812602240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.841534 47549232288640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.841614 46917444457344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.847805 47447599145856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.848000 47679256777600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.849327 47258763879296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.849426 46990006776704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.878245 47921051960192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.878216 47395159765888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.878389 47920812602240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.878496 47888974119808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.879528 47549232288640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.879551 46917444457344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.879523 47389535335296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.879582 46996584944512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.897346 47921051960192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.897459 47395159765888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.897988 47888974119808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.898015 47920812602240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.899261 47549232288640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.899284 46917444457344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.899279 47389535335296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:35.899310 46996584944512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880055.309517 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.310443 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.311295 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.901342 47365947675520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.309522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.310452 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.311325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.901382 47345506497408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.357090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.357610 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.358049 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.901445 47470397617024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.362894 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.363309 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.363661 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.901521 47353601246080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:35.902923 47365947675520 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpp5s4c703
I0618 11:47:35.903956 47365947675520 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpp5s4c703', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b148712ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.903253 47345506497408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpn7ndh2dk
I0618 11:47:35.904253 47345506497408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpn7ndh2dk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fc4aeee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.904363 47365947675520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.903691 47470397617024 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplogc07ig
W0618 11:47:35.903716 47353601246080 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpp8pb_noa
I0618 11:47:35.904681 47470397617024 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplogc07ig', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2cd8c64e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.904680 47353601246080 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpp8pb_noa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11a72b0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.904664 47345506497408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.905077 47470397617024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.905075 47353601246080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880055.386325 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.386703 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.387027 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.922488 47620066415488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.383557 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.383989 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.384316 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.922553 46930931024768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.333559 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.334497 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.335369 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.922823 47727824749440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880055.333545 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880055.334419 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880055.335321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:35.922827 47442123043712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz_0
I0618 11:47:35.923915 47727824749440 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68c8a09cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.923937 47620066415488 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp88rm4ty5
I0618 11:47:35.924991 47620066415488 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp88rm4ty5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4fb1baee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.925090 47727824749440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.924473 46930931024768 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpt6_sv7s1
I0618 11:47:35.925426 47620066415488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.925555 46930931024768 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpt6_sv7s1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf3e0f5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:35.924869 47442123043712 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjtgvbj5m
I0618 11:47:35.925906 47442123043712 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjtgvbj5m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b26437a8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:35.925986 46930931024768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:35.926328 47442123043712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:35.950300 47470397617024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.950373 47353601246080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.950349 47365947675520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.950355 47345506497408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.952212 47620066415488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.952345 47442123043712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.952364 47727824749440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.952396 46930931024768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:35.964642 47920812602240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.964702 47888974119808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.965543 47679256777600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.965502 47447599145856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.965615 46990006776704 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.965756 47258763879296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.966287 47247718806400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.966325 47338751443840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.966343 47826328925056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.966571 47770444485504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:35.968928 47920812602240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:47:35.969001 47888974119808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:47:35.969849 47679256777600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Us[2019-06-18 11:48:15] iteration time 0: 60.904 seconds
2019-06-18 11:48:16.334387: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880095.962801 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 11:48:19] minmax time: 3.217 seconds
2019-06-18 11:48:19.562060: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:48:19.567519: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:48:19.572217: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880099.583455 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 0}}
[2019-06-18 11:48:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:48:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=2 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=1023779833 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=2047559664 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=3071339495 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=4095119326 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=5118899157 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=6142678988 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=7166458819 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=8190238650 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=9214018481 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=10237798312 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=11261578143 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=12285357974 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=13309137805 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=14332917636 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=15356697467 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=16380477298 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=17404257129 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=18428036960 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=19451816791 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000001-000001 --seed=20475596622 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 11:48:30] eval finished: 10.702 seconds
[2019-06-18 11:48:30] Win rate 000001-000001 vs checkpoint: 0.730
:::MLL 1560880110.348614 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 11:48:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=3 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=1023779834 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=2047559665 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=3071339496 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=4095119327 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=5118899158 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=6142678989 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=7166458820 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=8190238651 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=9214018482 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=10237798313 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=11261578144 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=12285357975 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=13309137806 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=14332917637 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=15356697468 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=16380477299 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=17404257130 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000002-000000 --seed=18428036961 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:49:00] selfplay finished: 29.927 seconds
[2019-06-18 11:49:00] selfplay mn: 29.944 seconds
[2019-06-18 11:49:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-3-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779834 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559665 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339496 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119327 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899158 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678989 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458820 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238651 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018482 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798313 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578144 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357975 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137806 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917637 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697468 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477299 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257130 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036961 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816792 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596623 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376454 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156285 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:49:03] divide_golden_chunk finished: 3.358 seconds
[2019-06-18 11:49:03] generate golden chunk: 3.373 seconds
[2019-06-18 11:49:04] train finished: 44.448 seconds
:::MLL 1560880104.887007 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.887924 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.888740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.955662 47663571702656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.886889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.887772 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.888650 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.955752 47824838386560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:24.956750 47663571702656 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp90sxmdd1
W0618 11:48:24.956826 47824838386560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5k79_gus
I0618 11:48:24.957825 47663571702656 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp90sxmdd1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b59d2d8ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.957921 47824838386560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5k79_gus', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f5f173e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.958263 47663571702656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:24.958391 47824838386560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880104.896348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.897244 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.898120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.961664 47749819368320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.902269 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.903039 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.903742 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.961766 47980411478912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:24.962634 47749819368320 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppxz8inkr
W0618 11:48:24.962704 47980411478912 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplkb3naqk
W0618 11:48:24.963468 47663571702656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:24.963564 47824838386560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:48:24.963600 47749819368320 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppxz8inkr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6de79bde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.963670 47980411478912 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplkb3naqk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba397f83e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.963990 47749819368320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:24.964051 47980411478912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:24.968733 47980411478912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:24.968722 47749819368320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880104.951151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.951606 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.952023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.982163 47449518740352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.952027 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.952469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.952839 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.982289 47506830455680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:24.984024 47663571702656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:24.983565 47449518740352 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp23bn9hw4
W0618 11:48:24.983594 47506830455680 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdvoapx63
W0618 11:48:24.984484 47824838386560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:48:24.984651 47506830455680 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdvoapx63', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3554573e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.984656 47449518740352 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp23bn9hw4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27fc4bde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.985083 47506830455680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:24.985096 47449518740352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:24.988476 47749819368320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:24.988646 47980411478912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:24.990211 47506830455680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:24.990206 47449518740352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880104.960265 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.960652 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.960971 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.990439 47565010183040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.961573 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.961941 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.962260 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:24.990830 47109434934144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:24.991793 47565010183040 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpr1em3dan
W0618 11:48:24.991842 47109434934144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppz6ann5a
I0618 11:48:24.992764 47565010183040 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpr1em3dan', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42e01f7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.992808 47109434934144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppz6ann5a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad8cdb8de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:24.993149 47565010183040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:24.993193 47109434934144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:24.997824 47109434934144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:24.997836 47565010183040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880104.923104 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.923936 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.924625 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.000869 47794835555200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.926426 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.927188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.927886 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.000885 47364064011136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.001956 47794835555200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpneuaffo1
W0618 11:48:25.001917 47364064011136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpraax3egt
I0618 11:48:25.003009 47364064011136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpraax3egt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1416cc1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.003053 47794835555200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpneuaffo1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7862c85e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.003472 47364064011136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.003497 47794835555200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880104.931057 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.931797 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.932445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.004392 47415131415424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.927006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.927931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.928729 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.004469 47052471944064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.005468 47415131415424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphs4pm2mv
W0618 11:48:25.005536 47052471944064 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpbvu3nlgp
I0618 11:48:25.006556 47415131415424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphs4pm2mv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ffaa6fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.006607 47052471944064 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpbvu3nlgp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb8a769e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880104.938183 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.938924 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.939564 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.006761 47357244822400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.932885 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.933836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.934668 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.006839 47165200073600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:48:25.006992 47415131415424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.007022 47052471944064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.007863 47357244822400 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b128057acc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:25.007915 47165200073600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk3j4v1y6
W0618 11:48:25.008760 47794835555200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:48:25.009000 47165200073600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk3j4v1y6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5c9955e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:25.008751 47364064011136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:48:25.009077 47357244822400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.009452 47165200073600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:25.011470 47506830455680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.011660 47449518740352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.012512 47052471944064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.012521 47415131415424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.014307 47357244822400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.014647 47165200073600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880104.957713 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.958566 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.959301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.016871 47902010196864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.943950 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.944880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.945739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.016903 47225508180864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.017640 47109434934144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.017695 47565010183040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.017939 47902010196864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeoonye83
W0618 11:48:25.017970 47225508180864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvrclm94a
I0618 11:48:25.019003 47902010196864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeoonye83', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9156e38e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.019039 47225508180864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvrclm94a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3d43a0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.019451 47902010196864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.019482 47225508180864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:25.024574 47902010196864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.024592 47225508180864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880104.997818 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.998293 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.998715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.024652 47995131110272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.987580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.988031 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.988422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.025727 47261821240192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880104.993060 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880104.993488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880104.993841 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.026325 47169330365312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.026043 47995131110272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2eutoing
I0618 11:48:25.027127 47995131110272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2eutoing', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba70553fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:25.026744 47261821240192 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzznkvd4b
I0618 11:48:25.027565 47995131110272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.027717 47261821240192 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzznkvd4b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc48a75e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:25.027301 47169330365312 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpabeyoruv
I0618 11:48:25.028100 47261821240192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.028272 47169330365312 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpabeyoruv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae6bfc49dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.028663 47169330365312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880105.002658 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880105.003146 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880105.003556 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.028867 47864493245312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.030195 47794835555200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.030245 47364064011136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.029860 47864493245312 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzppd08qy
I0618 11:48:25.030873 47864493245312 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzppd08qy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b889ab44e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.031279 47864493245312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:25.031864 47663571702656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:25.032221 47824838386560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:25.032641 47261821240192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.032655 47995131110272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.033226 47169330365312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.034250 47052471944064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.034486 47415131415424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.035866 47749819368320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:25.036063 47980411478912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:25.036181 47864493245312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.036206 47663571702656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:48:25.036561 47824838386560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:48:25.036752 47357244822400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.037040 47165200073600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.040144 47749819368320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:48:25.040368 47980411478912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:48:25.041267 47663571702656 estimator.py:1111] Calling model_fn.
W0618 11:48:25.041380 47663571702656 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:48:25.041637 47824838386560 estimator.py:1111] Calling model_fn.
W0618 11:48:25.041742 47824838386560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:48:25.042740 47663571702656 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:48:25.043091 47824838386560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:48:25.044882 47902010196864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880105.015967 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880105.016405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880105.016796 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.044762 47195952640896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.044966 47225508180864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:48:25.045185 47749819368320 estimator.py:1111] Calling model_fn.
W0618 11:48:25.045291 47749819368320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:48:25.045416 47980411478912 estimator.py:1111] Calling model_fn.
W0618 11:48:25.045522 47980411478912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:48:25.046655 47749819368320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:48:25.045814 47195952640896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjcj9jah4
W0618 11:48:25.046871 47980411478912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:48:25.046872 47195952640896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjcj9jah4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aecf2944e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.047313 47195952640896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880105.019669 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880105.020172 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880105.020562 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.047856 47587842761600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880105.018720 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880105.019105 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880105.019464 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.048665 47477892576128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880105.018922 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880105.019334 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880105.019674 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:25.048694 47691459720064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:25.048838 47587842761600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplxgxkvfi
I0618 11:48:25.049857 47587842761600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplxgxkvfi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48310cfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.050273 47587842761600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:25.050070 47477892576128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_ndf2pt6
W0618 11:48:25.050099 47691459720064 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpbg0aprkv
I0618 11:48:25.051133 47477892576128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_ndf2pt6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2e97824e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.051146 47691459720064 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpbg0aprkv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60511a3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:25.051517 47477892576128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:25.051544 47691459720064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:25.052214 47195952640896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.052648 47261821240192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.053046 47169330365312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.053929 47995131110272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:25.055137 47587842761600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.056148 47477892576128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:25.056148 47691459720064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev[2019-06-18 11:49:04] moving /lfs/lfs12/gma_akey/results/epb269/models/000002-000001.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000002-000002.meta
[2019-06-18 11:49:04] moving /lfs/lfs12/gma_akey/results/epb269/models/000002-000001.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000002-000002.data-00000-of-00001
[2019-06-18 11:49:04] moving /lfs/lfs12/gma_akey/results/epb269/models/000002-000001.index --> /lfs/lfs12/gma_akey/results/epb269/models/000002-000002.index
[2019-06-18 11:49:04] moving /lfs/lfs12/gma_akey/results/epb269/models/000002-000001.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb
[2019-06-18 11:49:04] iteration time 1: 48.132 seconds
2019-06-18 11:49:04.497615: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880144.094486 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 11:49:07] minmax time: 3.275 seconds
2019-06-18 11:49:07.782793: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:49:07.788302: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:49:07.793005: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880147.803723 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 1}}
[2019-06-18 11:49:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:49:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=3 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=1023779834 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=2047559665 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=3071339496 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=4095119327 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=5118899158 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=6142678989 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=7166458820 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=8190238651 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=9214018482 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=10237798313 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=11261578144 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=12285357975 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=13309137806 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=14332917637 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=15356697468 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=16380477299 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=17404257130 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=18428036961 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=19451816792 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000002-000002 --seed=20475596623 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:49:18] eval finished: 10.763 seconds
[2019-06-18 11:49:18] Win rate 000002-000002 vs 000001-000001: 0.570
:::MLL 1560880158.625664 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 11:49:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=4 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=1023779835 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=2047559666 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=3071339497 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=4095119328 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=5118899159 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=6142678990 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=7166458821 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=8190238652 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=9214018483 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=10237798314 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=11261578145 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=12285357976 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=13309137807 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=14332917638 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=15356697469 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=16380477300 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=17404257131 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000003-000001 --seed=18428036962 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:49:48] selfplay finished: 29.743 seconds
[2019-06-18 11:49:48] selfplay mn: 29.762 seconds
[2019-06-18 11:49:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-4-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779835 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559666 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339497 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119328 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899159 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678990 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458821 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238652 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018483 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798314 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578145 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357976 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137807 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917638 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697469 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477300 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257131 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036962 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816793 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596624 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376455 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156286 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:49:51] divide_golden_chunk finished: 3.293 seconds
[2019-06-18 11:49:51] generate golden chunk: 3.308 seconds
[2019-06-18 11:49:52] train finished: 44.478 seconds
:::MLL 1560880153.061026 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.061769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.062457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.128091 47786054660992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.058648 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.059383 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.060099 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.128108 47964720751488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.129202 47786054660992 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph5qi7uny
W0618 11:49:13.129229 47964720751488 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4v6sx9pm
I0618 11:49:13.130324 47786054660992 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph5qi7uny', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7657668e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.130335 47964720751488 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4v6sx9pm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ff0babe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.130780 47786054660992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.130786 47964720751488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.136111 47964720751488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.136138 47786054660992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880153.093172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.093951 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.094652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.154051 47363658109824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.083430 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.084332 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.085169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.154391 47190932120448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.155101 47363658109824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk4uvbrdt
W0618 11:49:13.155443 47190932120448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpou3a53nm
I0618 11:49:13.156224 47363658109824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk4uvbrdt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13fe9a9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.156540 47190932120448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpou3a53nm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebc7553e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.156671 47363658109824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.156962 47190932120448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.157717 47786054660992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.158030 47964720751488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.161750 47363658109824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.161893 47190932120448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880153.102171 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.102908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.103620 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.172448 47721403487104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.099108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.099862 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.100561 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.172496 47504049337216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.139004 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.139443 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.139822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.172857 47633826284416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.140658 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.141042 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.141457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.173009 47764899390336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.173515 47721403487104 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpl6kkvhqr
W0618 11:49:13.173570 47504049337216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpq8uowyi8
I0618 11:49:13.174625 47721403487104 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpl6kkvhqr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6749e3eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.174625 47504049337216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpq8uowyi8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34ae92bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:49:13.173911 47633826284416 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4e7tbntv
W0618 11:49:13.174030 47764899390336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp29sbpsz8
I0618 11:49:13.174995 47633826284416 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4e7tbntv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52e5e1ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.175100 47764899390336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp29sbpsz8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b716a72ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.175048 47504049337216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.175051 47721403487104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.175434 47633826284416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.175547 47764899390336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.180255 47633826284416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.180356 47764899390336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.180418 47504049337216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.180455 47721403487104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.182415 47190932120448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.182478 47363658109824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880153.109218 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.110103 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.110977 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.186095 47629030282112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.122829 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.123586 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.124371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.186164 46985328776064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.187235 47629030282112 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1zdtmp_6
W0618 11:49:13.187203 46985328776064 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjx_dz5y9
I0618 11:49:13.188352 46985328776064 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjx_dz5y9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abbe86b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.188364 47629030282112 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1zdtmp_6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51c804ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.188791 46985328776064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.188815 47629030282112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.194176 46985328776064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.194230 47629030282112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880153.161296 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.161730 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.162054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.194400 47739458106240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.160964 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.161364 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.161739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.194423 47257772708736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.124884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.125664 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.126366 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.195469 47981975200640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.116801 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.117712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.118608 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.195534 47867775349632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.195475 47257772708736 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwox_kus_
W0618 11:49:13.195508 47739458106240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9jubge7u
I0618 11:49:13.196553 47257772708736 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwox_kus_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb57579e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.196588 47739458106240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9jubge7u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b7e078e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880153.118731 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.119528 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.120237 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.196567 47378751243136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.113090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.114000 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.114901 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.196869 47248592339840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 11:49:13.196995 47257772708736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.197027 47739458106240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.196534 47981975200640 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8olx5iic
W0618 11:49:13.196606 47867775349632 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmndc5cij
I0618 11:49:13.197625 47981975200640 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8olx5iic', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3f52cbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.197726 47867775349632 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmndc5cij', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b895e553da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.198034 47981975200640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.198143 47867775349632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.197908 47378751243136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjlgj9qhg
I0618 11:49:13.197980 47248592339840 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af934265d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.199007 47378751243136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjlgj9qhg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1782399e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.199226 47248592339840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.199452 47378751243136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.200233 47633826284416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.200262 47764899390336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.202122 47257772708736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.202168 47739458106240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.202841 47504049337216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.203233 47721403487104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.203225 47981975200640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.203289 47867775349632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.204507 47248592339840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.204617 47378751243136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.206906 47964720751488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:13.207174 47786054660992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:13.211397 47964720751488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:49:13.211725 47786054660992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880153.180779 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.181150 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.181466 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.213832 47685880861568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.179850 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.180220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.180562 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.213865 47137512244096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.215327 47629030282112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.214934 47685880861568 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp29po2qzc
W0618 11:49:13.214962 47137512244096 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp924l1bzr
W0618 11:49:13.215995 46985328776064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:49:13.215973 47685880861568 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp29po2qzc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5f04939e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.215990 47137512244096 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp924l1bzr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf57429e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.216390 47685880861568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.216407 47137512244096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.216585 47964720751488 estimator.py:1111] Calling model_fn.
W0618 11:49:13.216710 47964720751488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:49:13.216979 47786054660992 estimator.py:1111] Calling model_fn.
W0618 11:49:13.217092 47786054660992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880153.185064 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.185603 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.186080 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.216976 47106299564928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.218156 47964720751488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:49:13.218518 47786054660992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880153.172969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.173442 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.173859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.218519 47231546790784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880153.177088 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.177630 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.177960 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.218524 47274705945472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.218024 47106299564928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpby0a5xat
I0618 11:49:13.219087 47106299564928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpby0a5xat', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad812d6ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.219527 47106299564928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.219533 47231546790784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvyizthdo
W0618 11:49:13.219564 47274705945472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7ol4ba1m
I0618 11:49:13.220559 47231546790784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvyizthdo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af53c27edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.220607 47274705945472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7ol4ba1m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff48a45e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.220969 47231546790784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:13.221022 47274705945472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.221273 47685880861568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.221287 47137512244096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880153.192206 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.192645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.193043 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.222870 47150940877696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.223119 47257772708736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.223460 47739458106240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.224225 47981975200640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.224353 47867775349632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.224691 47106299564928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.223990 47150940877696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpe89k9sgw
I0618 11:49:13.225051 47150940877696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpe89k9sgw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae277ab4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.225451 47150940877696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880153.193271 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.193707 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.194076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.225533 47080769090432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:13.225792 47231546790784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.225871 47274705945472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.226709 47248592339840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.226910 47378751243136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.226601 47080769090432 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdk0fngwv
:::MLL 1560880153.195642 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880153.196125 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880153.196536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:13.227351 47624481158016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 11:49:13.227653 47080769090432 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdk0fngwv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad2211ace48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.228077 47080769090432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.228341 47624481158016 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8y7vd8wn
I0618 11:49:13.229363 47624481158016 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8y7vd8wn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50b8de8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:13.229782 47624481158016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:13.230137 47150940877696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.230107 47190932120448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:13.230865 47363658109824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:13.233086 47080769090432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.234416 47190932120448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:49:13.234684 47624481158016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:13.235220 47363658109824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:49:13.239489 47190932120448 estimator.py:1111] Calling model_fn.
W0618 11:49:13.239598 47190932120448 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:49:13.240351 47363658109824 estimator.py:1111] Calling model_fn.
W0618 11:49:13.240462 47363658109824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:49:13.240938 47190932120448 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:49:13.241096 47685880861568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.241144 47137512244096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:13.241830 47363658109824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:49:13.244628 47106299564928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from[2019-06-18 11:49:52] moving /lfs/lfs12/gma_akey/results/epb269/models/000003-000002.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000003-000003.data-00000-of-00001
[2019-06-18 11:49:52] moving /lfs/lfs12/gma_akey/results/epb269/models/000003-000002.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb
[2019-06-18 11:49:52] moving /lfs/lfs12/gma_akey/results/epb269/models/000003-000002.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000003-000003.meta
[2019-06-18 11:49:52] moving /lfs/lfs12/gma_akey/results/epb269/models/000003-000002.index --> /lfs/lfs12/gma_akey/results/epb269/models/000003-000003.index
[2019-06-18 11:49:52] iteration time 2: 48.248 seconds
2019-06-18 11:49:52.789092: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880192.343039 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 11:49:56] minmax time: 3.249 seconds
2019-06-18 11:49:56.048790: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:49:56.054482: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:49:56.059188: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880196.070137 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 2}}
[2019-06-18 11:49:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:49:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=4 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=1023779835 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=2047559666 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=3071339497 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=4095119328 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=5118899159 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=6142678990 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=7166458821 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=8190238652 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=9214018483 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=10237798314 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=11261578145 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=12285357976 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=13309137807 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=14332917638 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=15356697469 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=16380477300 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=17404257131 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=18428036962 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=19451816793 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000003-000003 --seed=20475596624 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:50:09] eval finished: 13.373 seconds
[2019-06-18 11:50:09] Win rate 000003-000003 vs 000002-000002: 0.270
:::MLL 1560880209.503403 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 11:50:09] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=5 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=1023779836 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=2047559667 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=3071339498 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=4095119329 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=5118899160 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=6142678991 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=7166458822 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=8190238653 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=9214018484 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=10237798315 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=11261578146 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=12285357977 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=13309137808 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=14332917639 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=15356697470 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=16380477301 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=17404257132 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000004-000002 --seed=18428036963 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:50:39] selfplay finished: 30.201 seconds
[2019-06-18 11:50:39] selfplay mn: 30.220 seconds
[2019-06-18 11:50:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-5-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779836 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559667 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339498 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119329 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899160 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678991 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458822 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238653 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018484 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798315 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578146 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357977 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137808 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917639 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697470 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477301 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257132 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036963 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816794 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596625 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376456 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156287 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000004-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:50:40] train finished: 44.146 seconds
:::MLL 1560880201.333725 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.334629 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.335345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.410149 47928313013120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.332969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.333841 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.334673 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.410296 47309513094016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.341957 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.342696 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.343354 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.410504 47215276651392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.338496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.339364 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.340031 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.410506 47643910497152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.411250 47928313013120 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqh1owx79
W0618 11:50:01.411330 47309513094016 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4krzb531
W0618 11:50:01.411586 47215276651392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxjetr8ks
W0618 11:50:01.411559 47643910497152 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpv8gr_t04
I0618 11:50:01.412350 47928313013120 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqh1owx79', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9776a8be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.412398 47309513094016 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4krzb531', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b07634f4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.412582 47643910497152 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpv8gr_t04', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b553ef2be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.412612 47215276651392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxjetr8ks', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af172614e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.412787 47928313013120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.412839 47309513094016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.412991 47643910497152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.413032 47215276651392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.418060 47928313013120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.418084 47215276651392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.418068 47309513094016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.418158 47643910497152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880201.361992 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.362814 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.363613 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.432975 46934875689856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.362565 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.363458 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.364190 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.433019 47507580789632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.434002 46934875689856 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkm3vtlqq
W0618 11:50:01.434032 47507580789632 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1at9lnxd
I0618 11:50:01.435039 46934875689856 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkm3vtlqq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0292e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.435070 47507580789632 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1at9lnxd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3581107e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.435461 46934875689856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.435521 47507580789632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.437996 47215276651392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.438956 47643910497152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.440583 47309513094016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.440599 47928313013120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.440760 46934875689856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.440758 47507580789632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880201.403108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.403490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.403838 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.442735 47712704693120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.404723 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.405105 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.405457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.442761 47144332198784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.443801 47712704693120 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp99on7afw
W0618 11:50:01.443833 47144332198784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpw_u5edl6
I0618 11:50:01.444804 47712704693120 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp99on7afw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b654366de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.444841 47144332198784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpw_u5edl6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae0edc2dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.445204 47712704693120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.445231 47144332198784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880201.370466 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.371368 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.372226 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.446451 47630547567488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.377132 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.377874 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.378594 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.446476 47270667764608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.447526 47270667764608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0p79x7i1
W0618 11:50:01.447560 47630547567488 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzy6aax9t
I0618 11:50:01.448631 47270667764608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0p79x7i1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe57f29e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.448647 47630547567488 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzy6aax9t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5222749e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.449070 47270667764608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.449071 47630547567488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880201.414502 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.414968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.415383 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.449261 46996351705984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.413625 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.414083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.414506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.449423 46941782557568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.450096 47712704693120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.450113 47144332198784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.450301 46996351705984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnwsn1ptk
W0618 11:50:01.450475 46941782557568 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpozyh59iw
I0618 11:50:01.451366 46996351705984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnwsn1ptk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abe796fae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.451534 46941782557568 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpozyh59iw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1c4dc8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.451816 46996351705984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.451961 46941782557568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.454145 47630547567488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.454146 47270667764608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880201.383779 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.384539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.385250 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.456415 47274661049216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.379542 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.380469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.381264 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.456475 47961731769216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.456682 46996351705984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.456753 46941782557568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.457531 47961731769216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpurlxebg1
I0618 11:50:01.457555 47274661049216 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff45f73d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.458615 47961731769216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpurlxebg1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9f3e927e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.458792 47274661049216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.459051 47961731769216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.460903 47507580789632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.461336 46934875689856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.463950 47274661049216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.464343 47961731769216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.469693 47712704693120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.469711 47144332198784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880201.395213 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.395956 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.396652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.470669 47375666533248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.391822 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.392765 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.393461 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.470663 47582161855360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.471618 47582161855360 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpif3g0vdc
W0618 11:50:01.471648 47375666533248 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdqdkaqjc
I0618 11:50:01.472663 47582161855360 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpif3g0vdc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b46de711e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.472694 47375666533248 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdqdkaqjc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16ca5cae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.473110 47582161855360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.473133 47375666533248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.474359 47270667764608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.474319 47630547567488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880201.438336 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.438743 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.439089 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.474652 47904418067328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.439813 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.440222 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.440629 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.475384 47083474592640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.475694 47904418067328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3vq04ru0
I0618 11:50:01.476750 47904418067328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3vq04ru0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91e668ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.477185 47904418067328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.476425 47083474592640 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpplyhuz_k
I0618 11:50:01.477487 47083474592640 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpplyhuz_k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad2c25d7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:01.477645 46996351705984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.477750 46941782557568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:01.477915 47083474592640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.478083 47582161855360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.478103 47375666533248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880201.435348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.435750 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.436101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.479448 47409091793792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.437397 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.437807 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.438151 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.479648 46914288173952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.480439 47409091793792 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_rij4xcq
W0618 11:50:01.480576 46914288173952 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpllwnxpxg
I0618 11:50:01.481406 47409091793792 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_rij4xcq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e92a9ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.481541 46914288173952 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpllwnxpxg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab5e118e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.481793 47409091793792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880201.446936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.447410 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.447796 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.481551 47938233983872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 11:50:01.481925 46914288173952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880201.446801 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.447251 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.447653 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.481605 47123227341696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.482229 47904418067328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.482898 47083474592640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.482612 47938233983872 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp690e07yp
W0618 11:50:01.482641 47123227341696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_24ip976
I0618 11:50:01.483649 47123227341696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_24ip976', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc03d04e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.483648 47938233983872 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp690e07yp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99c5fe9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.484058 47938233983872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.484068 47123227341696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.486320 47274661049216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.486259 47215276651392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:01.486484 46914288173952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.486499 47409091793792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.486699 47643910497152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:01.486911 47961731769216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.488788 47123227341696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.488790 47938233983872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.488723 47309513094016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:01.489168 47928313013120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:01.490602 47215276651392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:01.491029 47643910497152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880201.440481 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.441004 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.441465 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.491069 47008484979584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880201.448042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880201.448582 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880201.448987 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:01.491709 47243188605824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:01.492053 47008484979584 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpofkeun23
I0618 11:50:01.493053 47008484979584 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpofkeun23', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac14ca2cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:01.493022 47309513094016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:01.492695 47243188605824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpinwck166
I0618 11:50:01.493482 47008484979584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:01.493509 47928313013120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:50:01.493737 47243188605824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpinwck166', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af7f20fee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:01.494125 47243188605824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:01.495682 47215276651392 estimator.py:1111] Calling model_fn.
W0618 11:50:01.495788 47215276651392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:01.496089 47643910497152 estimator.py:1111] Calling model_fn.
W0618 11:50:01.496193 47643910497152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:01.497144 47215276651392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:01.497569 47643910497152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:01.498159 47008484979584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:01.498073 47309513094016 estimator.py:1111] Calling model_fn.
W0618 11:50:01.498215 47375666533248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.498179 47309513094016 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:01.498263 47582161855360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:01.498597 47928313013120 estimator.py:1111] Calling model_fn.
W0618 11:50:01.498704 47928313013120 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:01.498900 47243188605824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:01.499531 47309513094016 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:01.500069 47928313013120 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:01.503288 47904418067328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.504107 47083474592640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:01.505953 46914288173952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from[2019-06-18 11:50:43] divide_golden_chunk finished: 3.327 seconds
[2019-06-18 11:50:43] generate golden chunk: 3.341 seconds
[2019-06-18 11:50:43] iteration time 3: 50.724 seconds
2019-06-18 11:50:43.555563: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880243.067047 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 11:50:46] minmax time: 3.213 seconds
2019-06-18 11:50:46.779602: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:50:46.785456: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:50:46.789943: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880246.802155 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 3}}
[2019-06-18 11:50:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:50:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=5 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=1023779836 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=2047559667 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=3071339498 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=4095119329 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=5118899160 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=6142678991 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=7166458822 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=8190238653 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=9214018484 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=10237798315 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=11261578146 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=12285357977 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=13309137808 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=14332917639 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=15356697470 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=16380477301 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=17404257132 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=18428036963 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=19451816794 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000004-000003 --seed=20475596625 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:50:58] eval finished: 11.182 seconds
[2019-06-18 11:50:58] Win rate 000004-000003 vs 000002-000002: 0.390
:::MLL 1560880258.042281 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 11:50:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=6 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=1023779837 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=2047559668 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=3071339499 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=4095119330 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=5118899161 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=6142678992 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=7166458823 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=8190238654 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=9214018485 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=10237798316 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=11261578147 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=12285357978 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=13309137809 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=14332917640 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=15356697471 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=16380477302 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=17404257133 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000005-000002 --seed=18428036964 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:51:27] selfplay finished: 29.716 seconds
[2019-06-18 11:51:27] selfplay mn: 29.736 seconds
[2019-06-18 11:51:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-6-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779837 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559668 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339499 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119330 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899161 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678992 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458823 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238654 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018485 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798316 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578147 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357978 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137809 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917640 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697471 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477302 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257133 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036964 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816795 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596626 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376457 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156288 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:51:30] train finished: 44.140 seconds
:::MLL 1560880252.067918 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.068785 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.069587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.125587 47645722813312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.052696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.053599 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.054465 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.125602 47624549426048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.126673 47645722813312 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk_ivgjn2
W0618 11:50:52.126647 47624549426048 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0sij33jx
I0618 11:50:52.127640 47624549426048 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0sij33jx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50bcf03e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.127676 47645722813312 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk_ivgjn2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55aaf86e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.128035 47624549426048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.128072 47645722813312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.133135 47645722813312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.133124 47624549426048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880252.066700 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.067619 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.068459 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.138938 47123411465088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.071227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.071981 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.072667 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.138958 46989194171264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.140034 46989194171264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzf_4b5gh
W0618 11:50:52.140066 47123411465088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpn2ofvxw5
I0618 11:50:52.141125 46989194171264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzf_4b5gh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcced05e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.141168 47123411465088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpn2ofvxw5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc0ec9ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.141580 46989194171264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.141653 47123411465088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.146864 46989194171264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.146962 47123411465088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880252.075947 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.076851 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.077686 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.147035 47843309392768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.089469 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.090209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.090927 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.147145 47748806493056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.148135 47843309392768 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpoq1l868b
W0618 11:50:52.148163 47748806493056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpycyynci4
I0618 11:50:52.149148 47843309392768 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpoq1l868b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83ac0c6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.149179 47748806493056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpycyynci4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6dab3c9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.149554 47843309392768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.149581 47748806493056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.152761 47624549426048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.153003 47645722813312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.154532 47843309392768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.154548 47748806493056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880252.096680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.097612 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.098487 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.167685 47951568024448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.101793 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.102545 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.103242 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.167728 47058330211200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.169219 46989194171264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.169415 47123411465088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.168758 47951568024448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1m8odavf
W0618 11:50:52.168785 47058330211200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxagx1q0p
I0618 11:50:52.169803 47951568024448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1m8odavf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ce0c40e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.169811 47058330211200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxagx1q0p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acce7a4ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.170222 47951568024448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.170227 47058330211200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.174015 47843309392768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.174442 47748806493056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.175051 47058330211200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.175072 47951568024448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880252.130033 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.130482 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.130862 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.175405 47629281592192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.135668 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.136040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.136365 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.175606 47255774606208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.176391 47629281592192 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpln77i_4c
W0618 11:50:52.176575 47255774606208 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4vrgh7u3
I0618 11:50:52.177360 47629281592192 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpln77i_4c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51d6ff3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.177550 47255774606208 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4vrgh7u3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afae03efda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.177777 47629281592192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.177976 47255774606208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880252.145249 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.145733 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.146117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.181901 47590747411328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.182567 47629281592192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.182770 47255774606208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.182975 47590747411328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprz9tdnqk
I0618 11:50:52.184079 47590747411328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprz9tdnqk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48de2e6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.184524 47590747411328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880252.148705 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.149161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.149551 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.188800 48005726323584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.189681 47590747411328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.189854 48005726323584 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp640elg3j
I0618 11:50:52.190819 48005726323584 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp640elg3j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba97cda0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.191204 48005726323584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880252.153047 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.153437 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.153787 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.192717 47783622914944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.154619 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.154991 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.155313 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.192800 47673324753792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.193842 47783622914944 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph6zb6v7p
W0618 11:50:52.193867 47673324753792 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5yb5unv0
W0618 11:50:52.194629 47058330211200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.194848 47951568024448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:52.194840 47783622914944 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph6zb6v7p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75c6750e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.194841 47673324753792 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5yb5unv0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c182c9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.195233 47673324753792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.195240 47783622914944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.195747 48005726323584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.199983 47783622914944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.199999 47673324753792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880252.126565 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.127451 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.128294 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.199994 46972938191744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.126535 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.127438 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.128291 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.200039 47442549097344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.201171 47624549426048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:52.201078 46972938191744 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfh16vtj8
W0618 11:50:52.201118 47442549097344 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdi93kjo3
W0618 11:50:52.202047 47645722813312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:50:52.202088 46972938191744 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfh16vtj8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab905e1de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.202088 47442549097344 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdi93kjo3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b265cdf9da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:52.202078 47629281592192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.202350 47255774606208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:52.202530 47442549097344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.202537 46972938191744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.205507 47624549426048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:52.206342 47645722813312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:52.207363 47442549097344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.207382 46972938191744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880252.169351 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.169878 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.170262 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.208266 46999044248448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.170481 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.170945 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.171267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.208485 47300904080256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.209352 47590747411328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.209228 46999044248448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyrezui3v
W0618 11:50:52.209432 47300904080256 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcrd6opy3
I0618 11:50:52.210221 46999044248448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyrezui3v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf19ec7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.210409 47300904080256 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcrd6opy3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05622c2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.210567 47624549426048 estimator.py:1111] Calling model_fn.
W0618 11:50:52.210676 47624549426048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:52.210669 46999044248448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.210825 47300904080256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.211397 47645722813312 estimator.py:1111] Calling model_fn.
W0618 11:50:52.211507 47645722813312 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:52.212037 47624549426048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:52.212876 47645722813312 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:52.215080 48005726323584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.215468 46999044248448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.215587 47300904080256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.219465 47783622914944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.219465 47673324753792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880252.146362 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.147209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.148042 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.220564 47940061062016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.220813 46989194171264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880252.146854 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.147711 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.148508 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.221043 47833291178880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.221281 47123411465088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:52.221772 47843309392768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:52.222224 47748806493056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:52.221634 47940061062016 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcibqo3d1
I0618 11:50:52.222723 47940061062016 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcibqo3d1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a32e5ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.222204 47833291178880 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8156ea9d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.223177 47940061062016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.223466 47833291178880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.225475 46989194171264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:52.225937 47123411465088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:52.226060 47843309392768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:52.226548 47748806493056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:52.227347 46972938191744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.227436 47442549097344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.228516 47940061062016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:52.228822 47833291178880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:52.230925 46989194171264 estimator.py:1111] Calling model_fn.
W0618 11:50:52.231036 46989194171264 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:52.231081 47843309392768 estimator.py:1111] Calling model_fn.
W0618 11:50:52.231184 47843309392768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:52.231424 47123411465088 estimator.py:1111] Calling model_fn.
W0618 11:50:52.231543 47123411465088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:52.231643 47748806493056 estimator.py:1111] Calling model_fn.
W0618 11:50:52.231749 47748806493056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:52.232472 46989194171264 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:52.232539 47843309392768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:52.233017 47123411465088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:52.233097 47748806493056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:52.235014 47300904080256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:52.235014 46999044248448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880252.196139 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.196621 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.196993 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.236753 47819576066944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880252.195662 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880252.196139 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880252.196558 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:52.236933 47705947550592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:50:52.237729 47819576066944 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp23156c7c
W0618 11:50:52.237924 47705947550592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsj2dc49e
I0618 11:50:52.238752 47819576066944 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp23156c7c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e256e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.238952 47705947550592 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsj2dc49e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63b0a50da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:52.239170 47819576066944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:52.239388 47705947550592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:52.242086 47058330211200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all [2019-06-18 11:51:31] divide_golden_chunk finished: 3.296 seconds
[2019-06-18 11:51:31] generate golden chunk: 3.311 seconds
[2019-06-18 11:51:31] iteration time 4: 48.024 seconds
2019-06-18 11:51:31.616468: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880291.091384 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 11:51:34] minmax time: 3.266 seconds
2019-06-18 11:51:34.893733: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:51:34.899744: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:51:34.904595: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880294.916902 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 4}}
[2019-06-18 11:51:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:51:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=6 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=1023779837 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=2047559668 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=3071339499 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=4095119330 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=5118899161 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=6142678992 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=7166458823 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=8190238654 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=9214018485 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=10237798316 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=11261578147 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=12285357978 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=13309137809 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=14332917640 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=15356697471 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=16380477302 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=17404257133 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=18428036964 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=19451816795 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000005-000003 --seed=20475596626 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:51:46] eval finished: 11.183 seconds
[2019-06-18 11:51:46] Win rate 000005-000003 vs 000002-000002: 0.580
:::MLL 1560880306.158000 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 11:51:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=7 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=1023779838 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=2047559669 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=3071339500 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=4095119331 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=5118899162 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=6142678993 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=7166458824 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=8190238655 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=9214018486 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=10237798317 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=11261578148 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=12285357979 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=13309137810 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=14332917641 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=15356697472 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=16380477303 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=17404257134 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000006-000002 --seed=18428036965 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:52:16] selfplay finished: 30.839 seconds
[2019-06-18 11:52:17] selfplay mn: 30.858 seconds
[2019-06-18 11:52:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-7-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779838 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559669 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339500 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119331 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899162 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678993 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458824 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238655 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018486 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798317 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578148 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357979 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137810 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917641 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697472 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477303 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257134 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036965 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816796 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596627 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376458 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156289 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:52:18] train finished: 43.776 seconds
:::MLL 1560880300.198151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.199047 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.199919 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.277967 47038660952960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.209236 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.209970 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.210574 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.277939 47089955021696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.207200 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.207932 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.208601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.277912 47468684575616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.201638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.202511 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.203318 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.277969 47187324928896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.278979 47089955021696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpordcx7mt
W0618 11:51:40.279005 47187324928896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpngbp7nkk
W0618 11:51:40.279066 47038660952960 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5rc5e0xv
W0618 11:51:40.279039 47468684575616 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7dyy99do
I0618 11:51:40.279977 47089955021696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpordcx7mt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad444a0fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.280004 47187324928896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpngbp7nkk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeaf053de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.280107 47038660952960 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5rc5e0xv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac853439e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.280107 47468684575616 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7dyy99do', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c72ab5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.280380 47089955021696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.280426 47187324928896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.280504 47038660952960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.280501 47468684575616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.285358 47038660952960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.285355 47468684575616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.285391 47089955021696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.285462 47187324928896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.305262 47038660952960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.305471 47468684575616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.305721 47089955021696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.305931 47187324928896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880300.241882 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.242594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.243281 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.307829 47356587520896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.231411 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.232332 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.233145 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.307865 47123075502976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.264526 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.265072 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.265505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.308165 47050816603008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.227543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.228503 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.229356 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.308186 47980551447424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.236822 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.237582 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.238269 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.308322 47410678915968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.267926 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.268370 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.268757 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.308540 47644316586880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.308954 47123075502976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpoussibvi
W0618 11:51:40.308924 47356587520896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkheozfm0
W0618 11:51:40.309128 47050816603008 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjagfif2_
I0618 11:51:40.310009 47356587520896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkheozfm0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b125929fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.310033 47123075502976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpoussibvi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbfac36e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.310094 47050816603008 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjagfif2_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb27cc1da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:40.309264 47980551447424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpghrsb7cm
W0618 11:51:40.309491 47644316586880 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppgj5ooer
I0618 11:51:40.310433 47356587520896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.309479 47410678915968 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcvsr3cc5
I0618 11:51:40.310452 47123075502976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.310486 47644316586880 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppgj5ooer', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5557272e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.310347 47980551447424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpghrsb7cm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3a04ffda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.310500 47050816603008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.310628 47410678915968 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcvsr3cc5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ef1430e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.310790 47980551447424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.310885 47644316586880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.311107 47410678915968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880300.271095 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.271526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.271902 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.312985 47449473520512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.273062 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.273504 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.273905 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.313362 47306098037632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.313965 47449473520512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpc38hr4q3
I0618 11:51:40.314940 47449473520512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpc38hr4q3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27f999ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:40.314315 47306098037632 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsvt_e3nw
W0618 11:51:40.315186 47050816603008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:40.315271 47306098037632 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsvt_e3nw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0697c19e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.315336 47449473520512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.315461 47644316586880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:40.315673 47306098037632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.315739 47123075502976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.315755 47356587520896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.316103 47980551447424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.316525 47410678915968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.320114 47449473520512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.320371 47306098037632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880300.248190 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.249124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.249987 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.323434 47252058821504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.259085 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.259942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.260711 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.323396 47349689754496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.324454 47349689754496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpt3876n40
W0618 11:51:40.324486 47252058821504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_i0e85fi
I0618 11:51:40.325535 47349689754496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpt3876n40', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10be067e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.325555 47252058821504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_i0e85fi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa02c4ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.325973 47349689754496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.325994 47252058821504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.330989 47349689754496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.331021 47252058821504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.334836 47050816603008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.335117 47644316586880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.335637 47123075502976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.335733 47356587520896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.338580 47980551447424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.339729 47449473520512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.339710 47410678915968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.340066 47306098037632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880300.303283 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.303680 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.304072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.346780 47335456555904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.304055 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.304430 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.304755 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.346845 47514431296384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.347816 47335456555904 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplzkavpzk
W0618 11:51:40.347880 47514431296384 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_p5u47nk
I0618 11:51:40.348906 47335456555904 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplzkavpzk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d6da91e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.348962 47514431296384 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_p5u47nk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b371962eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.349313 47335456555904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.349373 47514431296384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.351258 47349689754496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.351856 47252058821504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.353060 47038660952960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.353841 47468684575616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.353778 47187324928896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.354244 47089955021696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.354139 47335456555904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.354146 47514431296384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.357381 47038660952960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:40.358199 47468684575616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:40.358084 47187324928896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:40.358640 47089955021696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:51:40.362432 47038660952960 estimator.py:1111] Calling model_fn.
W0618 11:51:40.362540 47038660952960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:40.363138 47187324928896 estimator.py:1111] Calling model_fn.
I0618 11:51:40.363292 47468684575616 estimator.py:1111] Calling model_fn.
W0618 11:51:40.363246 47187324928896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:40.363406 47468684575616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880300.322571 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.323045 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.323457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.363229 47438617502592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
I0618 11:51:40.363787 47089955021696 estimator.py:1111] Calling model_fn.
W0618 11:51:40.363898 47089955021696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:40.363894 47038660952960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:40.364595 47187324928896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:40.364763 47468684575616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:40.364300 47438617502592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4acyixd8
W0618 11:51:40.365271 47089955021696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880300.293819 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.294569 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.295275 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.365232 47570193245056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
I0618 11:51:40.365371 47438617502592 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4acyixd8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2572880e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.365832 47438617502592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880300.288480 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.289386 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.290251 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.365824 47927829504896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.366296 47570193245056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppw3zzckr
I0618 11:51:40.367362 47570193245056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppw3zzckr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44150eadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.367797 47570193245056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:40.366964 47927829504896 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9759d6dd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.368261 47927829504896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880300.330240 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.330712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.331105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.368234 47646931649408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880300.326124 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.326631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.327006 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.368868 48007983145856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.369246 47646931649408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqspufsqb
I0618 11:51:40.370297 47646931649408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqspufsqb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55f305ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.370728 47646931649408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880300.327945 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880300.328428 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880300.328920 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:40.370385 47680298886016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:40.369923 48007983145856 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf4rky_ys
W0618 11:51:40.370855 47438617502592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:40.370953 48007983145856 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf4rky_ys', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa035e7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.371381 48007983145856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.371403 47680298886016 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpatv1k8nq
I0618 11:51:40.372378 47680298886016 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpatv1k8nq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5db7dd5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:40.372769 47680298886016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:40.373165 47570193245056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.373773 47927829504896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.373885 47335456555904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.373923 47514431296384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:40.375317 47646931649408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.376090 48007983145856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.377360 47680298886016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:40.382525 47644316586880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.382518 47050816603008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.383886 47123075502976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.384055 47356587520896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:40.386826 47644316586880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:40.386834 47050816603008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:40.387102 47449473520512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops[2019-06-18 11:52:20] divide_golden_chunk finished: 3.305 seconds
[2019-06-18 11:52:20] generate golden chunk: 3.320 seconds
[2019-06-18 11:52:20] moving /lfs/lfs12/gma_akey/results/epb269/models/000006-000003.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000006-000004.data-00000-of-00001
[2019-06-18 11:52:20] moving /lfs/lfs12/gma_akey/results/epb269/models/000006-000003.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000006-000004.meta
[2019-06-18 11:52:20] moving /lfs/lfs12/gma_akey/results/epb269/models/000006-000003.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb
[2019-06-18 11:52:20] moving /lfs/lfs12/gma_akey/results/epb269/models/000006-000003.index --> /lfs/lfs12/gma_akey/results/epb269/models/000006-000004.index
[2019-06-18 11:52:20] iteration time 5: 49.286 seconds
2019-06-18 11:52:20.942155: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880340.377633 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 11:52:24] minmax time: 3.281 seconds
2019-06-18 11:52:24.233058: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:52:24.238417: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:52:24.242884: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880344.253933 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 5}}
[2019-06-18 11:52:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:52:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=7 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=1023779838 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=2047559669 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=3071339500 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=4095119331 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=5118899162 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=6142678993 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=7166458824 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=8190238655 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=9214018486 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=10237798317 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=11261578148 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=12285357979 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=13309137810 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=14332917641 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=15356697472 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=16380477303 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=17404257134 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=18428036965 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=19451816796 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000006-000004 --seed=20475596627 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:52:35] eval finished: 11.389 seconds
[2019-06-18 11:52:35] Win rate 000006-000004 vs 000005-000003: 0.630
:::MLL 1560880355.704968 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 11:52:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=8 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=1023779839 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=2047559670 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=3071339501 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=4095119332 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=5118899163 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=6142678994 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=7166458825 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=8190238656 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=9214018487 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=10237798318 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=11261578149 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=12285357980 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=13309137811 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=14332917642 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=15356697473 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=16380477304 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=17404257135 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000007-000003 --seed=18428036966 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:53:06] selfplay finished: 30.975 seconds
[2019-06-18 11:53:06] selfplay mn: 30.995 seconds
[2019-06-18 11:53:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-8-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779839 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559670 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339501 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119332 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899163 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678994 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458825 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238656 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018487 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798318 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578149 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357980 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137811 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917642 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697473 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477304 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257135 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036966 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816797 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596628 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376459 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156290 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:53:08] train finished: 43.963 seconds
:::MLL 1560880349.543138 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.543921 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.544594 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.617157 47739736204160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.546312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.547037 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.547659 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.617312 47104689931136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.618210 47739736204160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5mt9yl4o
W0618 11:52:29.618363 47104689931136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2pgmndbr
I0618 11:52:29.619250 47739736204160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5mt9yl4o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b8e9afdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.619406 47104689931136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2pgmndbr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad7b2e5cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.619717 47739736204160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.619870 47104689931136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.624787 47739736204160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.624892 47104689931136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880349.545366 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.546284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.547139 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.625660 47889977398144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.552038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.552822 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.553487 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.625786 47041735136128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.626767 47889977398144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1t5__tqi
W0618 11:52:29.626881 47041735136128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpktnaf5ug
I0618 11:52:29.627874 47889977398144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1t5__tqi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e89adae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.627996 47041735136128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpktnaf5ug', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac90a7fee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.628323 47889977398144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.628461 47041735136128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.633638 47889977398144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.633860 47041735136128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880349.571076 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.571852 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.572520 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.638967 47008318817152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.564257 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.565125 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.565926 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.639023 47043051758464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.640022 47008318817152 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx77gxqm9
W0618 11:52:29.640081 47043051758464 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyutlvkbh
I0618 11:52:29.641066 47008318817152 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx77gxqm9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac142bb5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.641119 47043051758464 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyutlvkbh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac958f9fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.641473 47008318817152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.641554 47043051758464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.645614 47104689931136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.645690 47739736204160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.646694 47043051758464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.646704 47008318817152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880349.603619 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.604140 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.604607 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.650780 47452221588352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.651859 47452221588352 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmiy_qh9e
I0618 11:52:29.652918 47452221588352 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmiy_qh9e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b289d661e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.653349 47452221588352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880349.573987 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.574773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.575544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.655559 47885913064320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.576006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.576760 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.577454 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.655616 46928448541568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.607496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.607925 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.608295 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.655972 47991827899264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.656039 47889977398144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.656566 47041735136128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.656656 47885913064320 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpv4wuipyp
W0618 11:52:29.656703 46928448541568 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmputsngepw
I0618 11:52:29.657717 47885913064320 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpv4wuipyp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d976cde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.657766 46928448541568 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmputsngepw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaeaa179da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:29.656965 47991827899264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwe_8ljcf
I0618 11:52:29.657997 47991827899264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwe_8ljcf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba64070fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.658133 47885913064320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.658181 46928448541568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.658420 47991827899264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.658414 47452221588352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880349.614405 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.614854 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.615263 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.659345 47079425450880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.660437 47079425450880 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2poaw_42
I0618 11:52:29.661507 47079425450880 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2poaw_42', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1d1047e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.661930 47079425450880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.663052 47991827899264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.663141 46928448541568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.663169 47885913064320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880349.620972 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.621404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.621792 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.663640 47332002546560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.664750 47332002546560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp16v4o25g
I0618 11:52:29.665719 47332002546560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp16v4o25g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c9fc91da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.666107 47332002546560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.666590 47043051758464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.666687 47008318817152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.666778 47079425450880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.670603 47332002546560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880349.600039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.600886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.601686 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.678271 47688209326976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.678274 47452221588352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880349.601324 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.602159 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.602860 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.678308 47798571762560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.679374 47688209326976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprk6g1zvp
I0618 11:52:29.679421 47798571762560 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79417a4d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.680492 47688209326976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprk6g1zvp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5f8f5d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.680701 47798571762560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.680931 47688209326976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880349.622170 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.622771 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.623302 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.682353 47492895929216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.609956 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.610726 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.611416 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.682385 47084962554752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.603258 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.604155 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.605001 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.682448 47791049802624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.682776 47991827899264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880349.630902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.631359 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.631794 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.682831 47864284828544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.683662 47885913064320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.683754 46928448541568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.683348 47492895929216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7o9pf2u1
W0618 11:52:29.683464 47084962554752 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0hvd1a_j
W0618 11:52:29.683505 47791049802624 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcbfujqui
I0618 11:52:29.684395 47492895929216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7o9pf2u1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3215c74e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:29.683813 47864284828544 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp843ryota
I0618 11:52:29.684557 47084962554752 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0hvd1a_j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad31b0dee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.684587 47791049802624 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcbfujqui', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7781224da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.684796 47492895929216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.684791 47864284828544 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp843ryota', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b888e47fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.684993 47084962554752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.685022 47791049802624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:29.685181 47864284828544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.685975 47798571762560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.686223 47688209326976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.686592 47079425450880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.689531 47492895929216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.689874 47864284828544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.690270 47332002546560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.690277 47791049802624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.690292 47084962554752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.693840 47104689931136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:29.694393 47739736204160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:29.698146 47104689931136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:29.698731 47739736204160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880349.659493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.659870 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.660193 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.702881 46949494076288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
I0618 11:52:29.703223 47104689931136 estimator.py:1111] Calling model_fn.
W0618 11:52:29.703330 47104689931136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:52:29.703836 47739736204160 estimator.py:1111] Calling model_fn.
W0618 11:52:29.703940 47739736204160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880349.661514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.661919 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.662320 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.703889 47736803050368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.703885 46949494076288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyr9l8wah
W0618 11:52:29.704688 47104689931136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:52:29.704849 46949494076288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyr9l8wah', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab39080fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.705240 46949494076288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.705302 47739736204160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:29.705315 47889977398144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:29.704854 47736803050368 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz1cysu5h
W0618 11:52:29.705322 47041735136128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:52:29.705808 47736803050368 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz1cysu5h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6adfc69e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:29.706194 47736803050368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.708244 47798571762560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880349.656739 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.657214 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.657637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.708375 47908939080576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880349.656757 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.657224 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.657645 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.708438 47891691275136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.708957 47688209326976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.709104 47492895929216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.709408 47864284828544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:29.709664 47889977398144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:29.709858 46949494076288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.709639 47041735136128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:29.709441 47908939080576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2p3j699d
W0618 11:52:29.709481 47891691275136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprpymjm9v
I0618 11:52:29.710448 47908939080576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2p3j699d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92f3e1ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:29.710232 47791049802624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:52:29.710472 47891691275136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprpymjm9v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8eefd55e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:29.710335 47084962554752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:52:29.710846 47908939080576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.710744 47736803050368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:29.710861 47891691275136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880349.668849 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.669398 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.669885 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.713315 47535528395648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.714653 47043051758464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:52:29.714739 47889977398144 estimator.py:1111] Calling model_fn.
I0618 11:52:29.714707 47041735136128 estimator.py:1111] Calling model_fn.
W0618 11:52:29.714816 47041735136128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:52:29.714847 47889977398144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:52:29.714394 47535528395648 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8fmp8fdh
W0618 11:52:29.715510 47008318817152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:52:29.715448 47535528395648 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8fmp8fdh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3c02df1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:29.715700 47908939080576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:29.715693 47891691275136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:29.715886 47535528395648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:29.716167 47041735136128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:29.716212 47889977398144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880349.674971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880349.675415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880349.675794 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:29.717255 47233811374976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:29.718931 47043051758464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a [2019-06-18 11:53:10] divide_golden_chunk finished: 3.328 seconds
[2019-06-18 11:53:10] generate golden chunk: 3.343 seconds
[2019-06-18 11:53:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000007-000004.index --> /lfs/lfs12/gma_akey/results/epb269/models/000007-000005.index
[2019-06-18 11:53:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000007-000004.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000007-000005.meta
[2019-06-18 11:53:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000007-000004.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb
[2019-06-18 11:53:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000007-000004.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000007-000005.data-00000-of-00001
[2019-06-18 11:53:10] iteration time 6: 49.708 seconds
2019-06-18 11:53:10.690558: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880390.085317 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 11:53:13] minmax time: 3.230 seconds
2019-06-18 11:53:13.931162: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:53:13.936739: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:53:13.941509: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880393.952593 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 6}}
[2019-06-18 11:53:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir 
[2019-06-18 11:53:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=8 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=1023779839 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=2047559670 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=3071339501 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=4095119332 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=5118899163 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=6142678994 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=7166458825 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=8190238656 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=9214018487 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=10237798318 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=11261578149 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=12285357980 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=13309137811 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=14332917642 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=15356697473 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=16380477304 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=17404257135 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=18428036966 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=19451816797 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000007-000005 --seed=20475596628 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:53:24] eval finished: 10.499 seconds
[2019-06-18 11:53:24] Win rate 000007-000005 vs 000006-000004: 0.540
:::MLL 1560880404.512431 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 11:53:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=9 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=1023779840 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=2047559671 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=3071339502 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=4095119333 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=5118899164 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=6142678995 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=7166458826 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=8190238657 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=9214018488 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=10237798319 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=11261578150 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=12285357981 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=13309137812 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=14332917643 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=15356697474 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=16380477305 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=17404257136 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000008-000004 --seed=18428036967 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/
[2019-06-18 11:53:55] selfplay finished: 30.591 seconds
[2019-06-18 11:53:55] selfplay mn: 30.609 seconds
[2019-06-18 11:53:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-9-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779840 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559671 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339502 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119333 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899164 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678995 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458826 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238657 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018488 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798319 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578150 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357981 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137812 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917643 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697474 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477305 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257136 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036967 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816798 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596629 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376460 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156291 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_
[2019-06-18 11:53:57] train finished: 44.005 seconds
:::MLL 1560880399.174938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.175718 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.176421 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.246096 47585092121472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.172038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.172773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.173445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.246104 46982232683392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.171710 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.172444 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.173145 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.246179 47220036891520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.173916 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.174675 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.175346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.246282 47932051727232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.247163 47585092121472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvxrwz8ks
W0618 11:53:19.247179 47220036891520 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpepfoipuv
W0618 11:53:19.247134 46982232683392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgaivjran
W0618 11:53:19.247229 47932051727232 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpq1h_3t2j
I0618 11:53:19.248219 46982232683392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgaivjran', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb2fe08e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.248242 47220036891520 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpepfoipuv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af28e1cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.248243 47585092121472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvxrwz8ks', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b478d198dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.248315 47932051727232 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpq1h_3t2j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b985580fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.248655 46982232683392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.248659 47220036891520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.248677 47585092121472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.248743 47932051727232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.253614 47585092121472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.253619 46982232683392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.253609 47220036891520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.253620 47932051727232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.273181 47932051727232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.273476 47585092121472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.273528 46982232683392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.273876 47220036891520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880399.248908 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.249435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.249817 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.300696 47723057890176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.253208 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.253677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.254106 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.300858 47086979781504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.225089 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.225838 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.226566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.300873 47343455740800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.252884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.253252 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.253575 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.301024 47079203427200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.227982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.228754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.229472 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.301022 47113000391552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.257203 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.257668 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.258100 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.301462 47607707120512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.301703 47723057890176 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu5gpru0d
W0618 11:53:19.301840 47086979781504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpt_mj6xlc
W0618 11:53:19.301928 47343455740800 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsiry8ow0
I0618 11:53:19.302657 47723057890176 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu5gpru0d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b67ac801e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:19.301984 47079203427200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4pecs0tn
I0618 11:53:19.302804 47086979781504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpt_mj6xlc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3934a6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:19.302048 47113000391552 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdifkztap
I0618 11:53:19.302917 47343455740800 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsiry8ow0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f4a72fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.302945 47079203427200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4pecs0tn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1c3c89dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.303049 47723057890176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.302403 47607707120512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjj4ongul
I0618 11:53:19.303061 47113000391552 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdifkztap', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad9a23d6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.303191 47086979781504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.303332 47079203427200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.303310 47343455740800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.303365 47607707120512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjj4ongul', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4cd10f0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.303476 47113000391552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.303771 47607707120512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.307655 47723057890176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.307821 47086979781504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.307952 47079203427200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.308054 47343455740800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.308250 47113000391552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.308314 47607707120512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880399.238508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.239348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.240082 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.313452 47522620285824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.237508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.238373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.239178 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.313540 47196561679232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.314558 47522620285824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsqrp1ak7
W0618 11:53:19.314615 47196561679232 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpy39_f_3d
I0618 11:53:19.315638 47522620285824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsqrp1ak7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39017cfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.315698 47196561679232 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpy39_f_3d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed16e14e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.316083 47522620285824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.316142 47196561679232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.321402 47196561679232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.321365 47932051727232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.321415 47522620285824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.321761 47220036891520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.321759 47585092121472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.321913 46982232683392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880399.245035 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.245920 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.246799 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.323071 47943997711232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.249928 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.250631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.251252 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.323105 47944106926976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.324170 47944106926976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsur8kmnq
W0618 11:53:19.324210 47943997711232 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnaa92ckj
I0618 11:53:19.325293 47944106926976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsur8kmnq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b240cbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.325308 47943997711232 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnaa92ckj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b1d8a3da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.325729 47944106926976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.325692 47932051727232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:53:19.325743 47943997711232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.326064 47220036891520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:19.326091 47585092121472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:19.326234 46982232683392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:19.327343 47086979781504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.327454 47723057890176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.327657 47079203427200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.327944 47607707120512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.328034 47343455740800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.328835 47113000391552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.330531 47944106926976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.330510 47943997711232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:53:19.330766 47932051727232 estimator.py:1111] Calling model_fn.
W0618 11:53:19.330874 47932051727232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:19.331131 47220036891520 estimator.py:1111] Calling model_fn.
W0618 11:53:19.331238 47220036891520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:19.331150 47585092121472 estimator.py:1111] Calling model_fn.
W0618 11:53:19.331265 47585092121472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:19.331326 46982232683392 estimator.py:1111] Calling model_fn.
W0618 11:53:19.331440 46982232683392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:53:19.332215 47932051727232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:19.332602 47220036891520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:19.332622 47585092121472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:19.332794 46982232683392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880399.291479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.291911 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.292292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.338112 46942846215040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.293422 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.293856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.294242 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.338956 47754786968448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.339088 46942846215040 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9bwepf92
I0618 11:53:19.340056 46942846215040 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9bwepf92', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab20442be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.340507 46942846215040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.339908 47754786968448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmc3psza8
I0618 11:53:19.340934 47754786968448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmc3psza8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6f0fb35e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.341369 47754786968448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.343925 47196561679232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.343933 47522620285824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.345241 46942846215040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.345969 47754786968448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.350495 47943997711232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.350615 47944106926976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880399.304019 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.304399 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.304723 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.351059 47916402606976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.305287 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.305666 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.305988 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.351500 47164285232000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.352040 47916402606976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptjz0akoa
I0618 11:53:19.353009 47916402606976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptjz0akoa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94b0be5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:19.352442 47164285232000 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph2s8mlbv
I0618 11:53:19.353403 47916402606976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.353415 47164285232000 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph2s8mlbv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5930dee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.353813 47164285232000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880399.270543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.271491 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.272369 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.353958 46936086700928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.278783 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.279532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.280230 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.354388 47115678339968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.355069 46936086700928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2l1sfqw4
I0618 11:53:19.356164 46936086700928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2l1sfqw4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0715cbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.355513 47115678339968 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada41db8d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.356604 46936086700928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.356754 47115678339968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.358054 47916402606976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.358325 47164285232000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.361918 46936086700928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.362210 47115678339968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880399.315636 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.316070 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.316506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.363546 47231289688960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880399.317092 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880399.317530 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880399.317903 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:19.363600 46992572691328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:19.364743 46942846215040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:19.364558 46992572691328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqoxtbm4y
W0618 11:53:19.364607 47231289688960 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpir0_k128
W0618 11:53:19.365473 47754786968448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:53:19.365542 46992572691328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqoxtbm4y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd98308e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.365554 47231289688960 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpir0_k128', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af52cd4dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:19.365937 46992572691328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:19.365943 47231289688960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:19.370656 46992572691328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.370704 47231289688960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:19.374810 47723057890176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.374922 47079203427200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.375168 47086979781504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.375254 47607707120512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.375872 47343455740800 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.376208 47113000391552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:19.377641 47916402606976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future versi[2019-06-18 11:53:58] divide_golden_chunk finished: 3.327 seconds
[2019-06-18 11:53:58] generate golden chunk: 3.342 seconds
[2019-06-18 11:53:58] moving /lfs/lfs12/gma_akey/results/epb269/models/000008-000005.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000008-000006.meta
[2019-06-18 11:53:58] moving /lfs/lfs12/gma_akey/results/epb269/models/000008-000005.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb
[2019-06-18 11:53:58] moving /lfs/lfs12/gma_akey/results/epb269/models/000008-000005.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000008-000006.data-00000-of-00001
[2019-06-18 11:53:58] moving /lfs/lfs12/gma_akey/results/epb269/models/000008-000005.index --> /lfs/lfs12/gma_akey/results/epb269/models/000008-000006.index
[2019-06-18 11:53:58] iteration time 7: 48.420 seconds
2019-06-18 11:53:59.146226: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880438.505683 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 11:54:02] minmax time: 3.201 seconds
2019-06-18 11:54:02.356885: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:54:02.362470: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:54:02.367201: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880442.378367 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 7}}
[2019-06-18 11:54:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:54:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=9 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=1023779840 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=2047559671 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=3071339502 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=4095119333 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=5118899164 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=6142678995 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=7166458826 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=8190238657 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=9214018488 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=10237798319 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=11261578150 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=12285357981 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=13309137812 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=14332917643 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=15356697474 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=16380477305 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=17404257136 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=18428036967 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=19451816798 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000008-000006 --seed=20475596629 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:54:13] eval finished: 10.719 seconds
[2019-06-18 11:54:13] Win rate 000008-000006 vs 000007-000005: 0.450
:::MLL 1560880453.155664 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 11:54:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=10 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=1023779841 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=2047559672 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=3071339503 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=4095119334 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=5118899165 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=6142678996 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=7166458827 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=8190238658 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=9214018489 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=10237798320 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=11261578151 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=12285357982 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=13309137813 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=14332917644 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=15356697475 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=16380477306 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=17404257137 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000009-000005 --seed=18428036968 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:54:44] selfplay finished: 31.102 seconds
[2019-06-18 11:54:44] selfplay mn: 31.120 seconds
[2019-06-18 11:54:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-10-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779841 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559672 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339503 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119334 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899165 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678996 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458827 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238658 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018489 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798320 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578151 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357982 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137813 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917644 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697475 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477306 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257137 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036968 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816799 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596630 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376461 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156292 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:54:46] train finished: 44.003 seconds
:::MLL 1560880447.639079 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.639889 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.640574 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.714224 47639858525056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.638034 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.638864 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.639664 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.714365 47573597475712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.715294 47639858525056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_ypyd1t5
W0618 11:54:07.715388 47573597475712 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi5cu0020
I0618 11:54:07.716391 47639858525056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_ypyd1t5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b544d6e8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.716481 47573597475712 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi5cu0020', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44dff72e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.716824 47639858525056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.716897 47573597475712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.721691 47639858525056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.721773 47573597475712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880447.656675 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.657579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.658433 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.731858 47017078752128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.677682 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.678450 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.679179 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.731868 47277878727552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.732871 47017078752128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfozyu8jf
W0618 11:54:07.732900 47277878727552 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp57doz35f
I0618 11:54:07.733993 47017078752128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfozyu8jf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac34cdd4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.734005 47277878727552 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp57doz35f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0005c0fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.734439 47017078752128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.734454 47277878727552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.739487 47277878727552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.739537 47017078752128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.741556 47573597475712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.741697 47639858525056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.759305 47277878727552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.759891 47017078752128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880447.711151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.711607 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.711995 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.760475 47010276774784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.710415 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.710871 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.711258 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.760511 47413364163456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.761453 47010276774784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwoxrhyku
W0618 11:54:07.761481 47413364163456 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpo9t7xpd0
:::MLL 1560880447.684147 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.684844 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.685541 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.762167 47400759374720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:54:07.762448 47010276774784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwoxrhyku', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1b76f6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.762450 47413364163456 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpo9t7xpd0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f9150de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880447.686783 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.687547 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.688205 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.762290 47063802434432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:54:07.762853 47010276774784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.762848 47413364163456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.763371 47063802434432 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpduoe6dbh
W0618 11:54:07.763406 47400759374720 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx9ub9dq_
I0618 11:54:07.764447 47400759374720 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx9ub9dq_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ca2030e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.764447 47063802434432 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpduoe6dbh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace2dd02e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.764841 47063802434432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.764846 47400759374720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.767592 47010276774784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.767599 47413364163456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.769728 47400759374720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.769740 47063802434432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880447.713154 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.713963 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.714760 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.780070 47185993618304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.701295 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.702213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.703076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.780074 47442589393792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.781142 47185993618304 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvu592mmg
W0618 11:54:07.781169 47442589393792 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2vu93vzz
I0618 11:54:07.782208 47442589393792 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2vu93vzz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b265f467e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.782215 47185993618304 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvu592mmg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeaa0f99e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.782606 47442589393792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.782618 47185993618304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880447.735470 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.735952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.736421 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.783050 47523963622272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.784095 47523963622272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpse_cxxz5
I0618 11:54:07.785161 47523963622272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpse_cxxz5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39518e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.785607 47523963622272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.786977 47413364163456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.787134 47010276774784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.787750 47185993618304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.787752 47442589393792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880447.742808 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.743269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.743676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.788887 47139124331392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.789594 47573597475712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.789698 47063802434432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.789776 47400759374720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.789915 47639858525056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.790471 47523963622272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.789862 47139124331392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpo5x7ek60
I0618 11:54:07.790832 47139124331392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpo5x7ek60', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adfb7591e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.791227 47139124331392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880447.740060 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.740641 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.741149 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.793825 47601854092160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.793955 47573597475712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:07.794260 47639858525056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880447.716341 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.717276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.718165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.795176 47865109435264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.794842 47601854092160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp81lp8c5o
:::MLL 1560880447.726594 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.727415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.728136 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.795408 47937641653120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:54:07.795878 47601854092160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp81lp8c5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b7430edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:07.795773 47139124331392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:07.796302 47601854092160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.796185 47865109435264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpup19hqbk
W0618 11:54:07.796350 47937641653120 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkmi0ap7u
I0618 11:54:07.797216 47865109435264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpup19hqbk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88bf6eae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.797361 47937641653120 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkmi0ap7u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99a2b06e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.797616 47865109435264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.797757 47937641653120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880447.752787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.753237 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.753624 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.798048 47528427836288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:54:07.799039 47573597475712 estimator.py:1111] Calling model_fn.
W0618 11:54:07.799149 47573597475712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:07.799323 47639858525056 estimator.py:1111] Calling model_fn.
W0618 11:54:07.799437 47639858525056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:07.799039 47528427836288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyx8vkxe5
I0618 11:54:07.800017 47528427836288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyx8vkxe5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a5ba52e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.800411 47528427836288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:07.800517 47573597475712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.800784 47639858525056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.801025 47601854092160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.802551 47865109435264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.802606 47937641653120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.805131 47528427836288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.807876 47277878727552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.808177 47017078752128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.809442 47442589393792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.809892 47523963622272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.810469 47185993618304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.812223 47277878727552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:07.812480 47017078752128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:07.815324 47139124331392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:54:07.817312 47277878727552 estimator.py:1111] Calling model_fn.
W0618 11:54:07.817427 47277878727552 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:07.817543 47017078752128 estimator.py:1111] Calling model_fn.
W0618 11:54:07.817656 47017078752128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:07.818793 47277878727552 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.819018 47017078752128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.820667 47601854092160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.822575 47937641653120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.823089 47865109435264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.824825 47528427836288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:07.834547 47413364163456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.835052 47010276774784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.837795 47063802434432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.837761 47400759374720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:07.838840 47413364163456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:07.839368 47010276774784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880447.789229 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.789653 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.790025 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.839826 47851610104704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.789181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.789612 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.789992 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.839814 47373433328512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.840813 47851610104704 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkw36zfqc
W0618 11:54:07.840841 47373433328512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptgp9rxc9
I0618 11:54:07.841803 47851610104704 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkw36zfqc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b859acf1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.841809 47373433328512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptgp9rxc9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b164540ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:07.842056 47400759374720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:07.842127 47063802434432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:54:07.842196 47851610104704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.842196 47373433328512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.843884 47413364163456 estimator.py:1111] Calling model_fn.
W0618 11:54:07.843991 47413364163456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:07.844428 47010276774784 estimator.py:1111] Calling model_fn.
W0618 11:54:07.844537 47010276774784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:07.845348 47413364163456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.845881 47010276774784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.846929 47851610104704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:07.846948 47373433328512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:07.847100 47400759374720 estimator.py:1111] Calling model_fn.
W0618 11:54:07.847208 47400759374720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:07.847203 47063802434432 estimator.py:1111] Calling model_fn.
W0618 11:54:07.847314 47063802434432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:07.848577 47400759374720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:07.848684 47063802434432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880447.802022 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.802417 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.802738 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.851627 47490224558976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.803421 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.803792 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.804120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.852084 47092355425152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.852638 47490224558976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpurpiw98s
I0618 11:54:07.853675 47490224558976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpurpiw98s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31768d6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:07.853103 47092355425152 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpil5x_rn_
I0618 11:54:07.854064 47490224558976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:07.854121 47092355425152 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpil5x_rn_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad4d3b43e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:07.854524 47092355425152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880447.766572 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.767372 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.768152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.855585 47813257057152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880447.768646 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880447.769418 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880447.770109 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:07.855783 47384524657536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:07.857078 47523963622272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating[2019-06-18 11:54:47] divide_golden_chunk finished: 3.257 seconds
[2019-06-18 11:54:47] generate golden chunk: 3.273 seconds
[2019-06-18 11:54:47] iteration time 8: 49.044 seconds
2019-06-18 11:54:48.215438: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880487.550219 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 11:54:51] minmax time: 3.232 seconds
2019-06-18 11:54:51.457587: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:54:51.462978: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:54:51.467581: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880491.480737 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 8}}
[2019-06-18 11:54:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:54:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=10 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=1023779841 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=2047559672 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=3071339503 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=4095119334 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=5118899165 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=6142678996 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=7166458827 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=8190238658 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=9214018489 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=10237798320 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=11261578151 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=12285357982 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=13309137813 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=14332917644 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=15356697475 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=16380477306 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=17404257137 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=18428036968 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=19451816799 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000009-000006 --seed=20475596630 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:55:02] eval finished: 10.850 seconds
[2019-06-18 11:55:02] Win rate 000009-000006 vs 000007-000005: 0.400
:::MLL 1560880502.390743 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 11:55:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=11 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=1023779842 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=2047559673 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=3071339504 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=4095119335 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=5118899166 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=6142678997 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=7166458828 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=8190238659 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=9214018490 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=10237798321 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=11261578152 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=12285357983 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=13309137814 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=14332917645 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=15356697476 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=16380477307 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=17404257138 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000010-000005 --seed=18428036969 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:55:32] selfplay finished: 30.167 seconds
[2019-06-18 11:55:32] selfplay mn: 30.184 seconds
[2019-06-18 11:55:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-11-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779842 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559673 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339504 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119335 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899166 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678997 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458828 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238659 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018490 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798321 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578152 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357983 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137814 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917645 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697476 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477307 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257138 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036969 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816800 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596631 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376462 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156293 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:55:35] train finished: 44.012 seconds
:::MLL 1560880496.720563 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.721284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.721947 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.794943 47339976704896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.716808 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.717689 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.718397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.795164 47230830818176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.795972 47339976704896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp82mq3ys0
W0618 11:54:56.796131 47230830818176 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp220s_5ul
I0618 11:54:56.796953 47339976704896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp82mq3ys0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e7b151e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.797118 47230830818176 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp220s_5ul', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5117b0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.797347 47339976704896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.797539 47230830818176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.802121 47339976704896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.802208 47230830818176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.822067 47339976704896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.822147 47230830818176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880496.788790 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.789193 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.789568 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.840622 47552143995776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.763920 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.764685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.765380 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.841838 46936307610496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.766864 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.767583 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.768284 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.841977 47931033035648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.841699 47552143995776 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4xdk7pj4
I0618 11:54:56.842803 47552143995776 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4xdk7pj4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fe13d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.843228 47552143995776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.842846 46936307610496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeqr7om8x
W0618 11:54:56.842984 47931033035648 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpuk1ub8vn
I0618 11:54:56.843893 46936307610496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeqr7om8x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab07e877e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.844037 47931033035648 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpuk1ub8vn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9818c8fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.844284 46936307610496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.844440 47931033035648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880496.785741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.786227 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.786604 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.846075 47871905760128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.847080 47871905760128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpo71bnixd
W0618 11:54:56.847967 47552143995776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:56.848051 47871905760128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpo71bnixd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a54865e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.848454 47871905760128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.849146 46936307610496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.849189 47931033035648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880496.772024 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.772746 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.773439 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.852410 47515543765888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.769617 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.770351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.771034 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.852535 47104820560768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.852925 47871905760128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.853432 47515543765888 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmped89bigz
W0618 11:54:56.853530 47104820560768 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpq34mb19t
I0618 11:54:56.854538 47515543765888 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmped89bigz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b375bb1de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.854644 47104820560768 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpq34mb19t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad7baaf0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.854955 47515543765888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.855032 47104820560768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.859974 47515543765888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.860120 47104820560768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880496.781672 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.782408 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.783095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.862398 47605140689792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.776017 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.776923 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.777803 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.862513 47635441894272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.863569 47605140689792 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_3z57v29
W0618 11:54:56.863599 47635441894272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4o2gubjz
I0618 11:54:56.864693 47605140689792 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_3z57v29', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c38165e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.864705 47635441894272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4o2gubjz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b53462e1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.865148 47635441894272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.865160 47605140689792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.867554 47552143995776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.868941 46936307610496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.869095 47931033035648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.869777 47339976704896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:56.869935 47230830818176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:56.870465 47605140689792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.870489 47635441894272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.872252 47871905760128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.874059 47339976704896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:56.874230 47230830818176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880496.790493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.791361 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.792104 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.876785 46980510540672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.789966 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.790752 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.791559 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.877517 46918142907264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.877797 46980510540672 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkouo99nz
I0618 11:54:56.878803 46980510540672 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkouo99nz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abac93abda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:56.878474 46918142907264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4dc9_6d5
I0618 11:54:56.879112 47339976704896 estimator.py:1111] Calling model_fn.
I0618 11:54:56.879207 46980510540672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.879219 47339976704896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:56.879264 47230830818176 estimator.py:1111] Calling model_fn.
W0618 11:54:56.879369 47230830818176 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:56.879712 46918142907264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4dc9_6d5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac43d42da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:56.879969 47515543765888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.880088 47104820560768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:54:56.880172 46918142907264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.880569 47339976704896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:56.880725 47230830818176 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:56.884192 46980510540672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.884823 46918142907264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880496.805918 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.806878 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.807740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.885965 47239457473408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.887033 47239457473408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpweilko90
I0618 11:54:56.888149 47239457473408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpweilko90', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af713ab5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.888592 47239457473408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880496.839685 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.840073 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.840397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.890096 47290191971200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.837039 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.837549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.837942 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.890124 47146417132416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.833185 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.833729 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.834198 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.890173 46977733559168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.891118 47290191971200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprvnwram1
W0618 11:54:56.891103 47146417132416 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmd78a_4s
W0618 11:54:56.891157 46977733559168 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4l7rzuq4
I0618 11:54:56.892085 47290191971200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprvnwram1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b02e3ae5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.892072 47146417132416 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmd78a_4s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae16a086e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880496.842247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.842680 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.843094 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.891991 47610856829824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 11:54:56.892137 46977733559168 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4l7rzuq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aba23b55e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.892482 47290191971200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.892468 47146417132416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.892534 46977733559168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.892715 47605140689792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.893125 47635441894272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.892940 47610856829824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmizlgx3s
I0618 11:54:56.893909 47610856829824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmizlgx3s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4d8ccbce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:54:56.894000 47239457473408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:56.894302 47610856829824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880496.844686 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.845575 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.846425 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.896185 47030934205312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.897075 47290191971200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.897115 46977733559168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.897131 47146417132416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:54:56.897334 47030934205312 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac686b6bd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.898586 47030934205312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.898787 47610856829824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880496.847149 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.847559 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.847927 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.900395 47216173589376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.843289 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.843769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.844195 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.900501 47302579757952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.901452 47216173589376 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpquu42fxq
W0618 11:54:56.901518 47302579757952 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6b9huej3
I0618 11:54:56.902484 47216173589376 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpquu42fxq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af1a7d77e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.902523 47302579757952 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6b9huej3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05c60cfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.902886 47216173589376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:56.902918 47302579757952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.903807 47030934205312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.904041 46980510540672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.904603 46918142907264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.907524 47302579757952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.907553 47216173589376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880496.849051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.849550 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.849956 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.912676 47314802123648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880496.845601 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880496.846147 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880496.846566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:56.912795 47800059876224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:54:56.913758 47314802123648 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu0e1ksxp
W0618 11:54:56.913855 47800059876224 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi4n5c6lh
I0618 11:54:56.914792 47314802123648 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu0e1ksxp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b089e8f7da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.914886 47800059876224 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi4n5c6lh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b799a2d2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:56.915193 47314802123648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.915201 47552143995776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:54:56.915277 47800059876224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:56.916603 47290191971200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.916810 46936307610496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:56.916832 46977733559168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.916916 47146417132416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.917018 47239457473408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.917040 47931033035648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:56.918209 47610856829824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.919316 47871905760128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:56.919524 47552143995776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:56.919844 47314802123648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.919855 47800059876224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:56.921303 46936307610496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:56.921540 47931033035648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:56.923709 47871905760128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:54:56.924886 47552143995776 estimator.py:1111] Calling model_fn.
W0618 11:54:56.924997 47552143995776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:56.926371 46936307610496 estimator.py:1111] Calling model_fn.
W0618 11:54:56.926488 46936307610496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:56.926397 47552143995776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:54:56.926655 47931033035648 estimator.py:1111] Calling model_fn.
W0618 11:54:56.926764 47931033035648 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:56.926774 47030934205312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.926923 47302579757952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.927059 47216173589376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:56.927847 46936307610496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:56.928118 47931033035648 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will [2019-06-18 11:55:35] divide_golden_chunk finished: 3.304 seconds
[2019-06-18 11:55:35] generate golden chunk: 3.319 seconds
[2019-06-18 11:55:35] iteration time 9: 48.345 seconds
2019-06-18 11:55:36.598190: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880535.895169 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 11:55:39] minmax time: 3.244 seconds
2019-06-18 11:55:39.852717: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:55:39.858117: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:55:39.862653: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880539.875917 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 9}}
[2019-06-18 11:55:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:55:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=11 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=1023779842 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=2047559673 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=3071339504 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=4095119335 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=5118899166 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=6142678997 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=7166458828 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=8190238659 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=9214018490 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=10237798321 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=11261578152 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=12285357983 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=13309137814 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=14332917645 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=15356697476 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=16380477307 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=17404257138 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=18428036969 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=19451816800 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000010-000006 --seed=20475596631 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:55:50] eval finished: 10.912 seconds
[2019-06-18 11:55:50] Win rate 000010-000006 vs 000007-000005: 0.840
:::MLL 1560880550.848323 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 11:55:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=12 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=1023779843 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=2047559674 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=3071339505 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=4095119336 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=5118899167 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=6142678998 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=7166458829 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=8190238660 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=9214018491 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=10237798322 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=11261578153 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=12285357984 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=13309137815 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=14332917646 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=15356697477 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=16380477308 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=17404257139 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000011-000005 --seed=18428036970 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:56:21] selfplay finished: 30.703 seconds
[2019-06-18 11:56:21] selfplay mn: 30.723 seconds
[2019-06-18 11:56:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-12-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779843 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559674 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339505 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119336 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899167 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678998 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458829 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238660 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018491 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798322 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578153 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357984 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137815 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917646 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697477 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477308 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257139 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036970 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816801 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596632 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376463 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156294 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:56:24] train finished: 44.217 seconds
:::MLL 1560880545.175083 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.175944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.176810 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.260608 47303311979392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.179779 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.180552 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.181226 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.260884 47809201853312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.261602 47303311979392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvf0l5fg0
W0618 11:55:45.261870 47809201853312 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0hbobxgz
I0618 11:55:45.262597 47303311979392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvf0l5fg0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05f1b1ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.262879 47809201853312 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0hbobxgz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bbb148e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.262996 47303311979392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.263268 47809201853312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880545.176957 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.177848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.178722 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.266001 47634251187072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.191567 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.192240 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.192919 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.265957 47634040329088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.267032 47634040329088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4eahgw72
W0618 11:55:45.267063 47634251187072 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_w14iy8t
I0618 11:55:45.268133 47634040329088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4eahgw72', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52f2a3bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.268142 47634251187072 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_w14iy8t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52ff355dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:45.268088 47303311979392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.268291 47809201853312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:55:45.268570 47634040329088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.268587 47634251187072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.273642 47634040329088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.273652 47634251187072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880545.213107 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.213866 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.214551 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.285631 47699839030144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.193367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.194314 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.195200 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.285848 47657869640576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.286633 47699839030144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwopv35cg
W0618 11:55:45.286821 47657869640576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpj9_0oypz
:::MLL 1560880545.210796 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.211548 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.212263 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.287257 47457561711488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.194232 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.195190 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.196064 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.287333 47010737992576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 11:55:45.287684 47699839030144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwopv35cg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b62448c6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880545.198251 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.199039 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.199777 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.287575 47355350733696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.183127 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.184055 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.184877 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.287637 47383622595456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 11:55:45.287895 47657869640576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpj9_0oypz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b587efa5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.288140 47699839030144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.288339 47657869640576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.288879 47303311979392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.288292 47457561711488 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf5xlgcyf
W0618 11:55:45.288356 47010737992576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp53kjbuay
W0618 11:55:45.289229 47809201853312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.288617 47355350733696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx3fipuue
W0618 11:55:45.288659 47383622595456 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqhrqw7rt
I0618 11:55:45.289361 47457561711488 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf5xlgcyf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29dbb1eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.289417 47010737992576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp53kjbuay', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1d2ed0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.289664 47355350733696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx3fipuue', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b120f721da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.289690 47383622595456 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqhrqw7rt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b18a4948e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.289808 47457561711488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.289841 47010737992576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.290083 47355350733696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.290108 47383622595456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.293006 47699839030144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.293111 47657869640576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.293662 47634040329088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.293675 47634251187072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.294842 47457561711488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.294853 47010737992576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.295096 47355350733696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.295097 47383622595456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.312782 47699839030144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.312990 47657869640576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880545.257092 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.257534 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.257944 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.313791 47910327268224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.252093 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.252601 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.253041 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.313820 47396196950912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.314406 47457561711488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.314457 47010737992576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.314906 47355350733696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.314985 47383622595456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.314768 47910327268224 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzv4xscsr
W0618 11:55:45.314801 47396196950912 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9enajfpl
I0618 11:55:45.315733 47910327268224 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzv4xscsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9346a00dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.315778 47396196950912 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9enajfpl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b9211fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.316122 47910327268224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.316167 47396196950912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.320774 47910327268224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.320778 47396196950912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880545.265242 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.265772 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.266165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.323994 47590814200704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.264027 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.264495 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.264915 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.324074 47415179989888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.252112 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.252601 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.253006 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.325177 47666414478208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.253625 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.254120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.254649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.325269 46967240340352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.325016 47590814200704 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphq28ovqg
W0618 11:55:45.325045 47415179989888 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjh5yfspv
I0618 11:55:45.326064 47590814200704 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphq28ovqg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48e2298e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.326065 47415179989888 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjh5yfspv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ffd8c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.326489 47590814200704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.326488 47415179989888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.326256 47666414478208 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkw7wic_3
W0618 11:55:45.326311 46967240340352 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpuln2zsmx
I0618 11:55:45.327273 47666414478208 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkw7wic_3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a7c4a3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.327325 46967240340352 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpuln2zsmx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab7b2438e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.327673 47666414478208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.327716 46967240340352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.331296 47415179989888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.331313 47590814200704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880545.276551 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.277021 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.277403 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.331468 47193840223104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.276551 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.277028 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.277413 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.331687 47449937077120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.332432 46967240340352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.332447 47666414478208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.332460 47193840223104 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7_9j9g0w
W0618 11:55:45.332663 47449937077120 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjm9uqkw1
:::MLL 1560880545.249684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.250447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.251211 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.333322 47212929586048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 11:55:45.333436 47193840223104 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7_9j9g0w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec74ab4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.333623 47449937077120 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjm9uqkw1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28153b2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.333843 47193840223104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.334017 47449937077120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880545.251870 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.252644 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.253359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.334163 47976378229632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.334439 47212929586048 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx890gmm9
I0618 11:55:45.335523 47212929586048 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx890gmm9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af0e67bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.335979 47212929586048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:45.335289 47976378229632 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2a791ad30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.336623 47976378229632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.338493 47193840223104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.338596 47449937077120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880545.284052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.284567 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.284996 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.338415 47224721068928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.340125 47396196950912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.340234 47910327268224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.339450 47224721068928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi8rc9ghu
I0618 11:55:45.340520 47224721068928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi8rc9ghu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3a54fada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.340939 47224721068928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.341241 47212929586048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.341657 47303311979392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.341964 47976378229632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.341955 47809201853312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880545.289906 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.290470 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.290851 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.342045 47118737826688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:45.342258 47634251187072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.342235 47634040329088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.343016 47118737826688 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3e7wk364
I0618 11:55:45.344018 47118737826688 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3e7wk364', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adaf837be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:45.344461 47118737826688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:45.345744 47224721068928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.346069 47303311979392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.346328 47809201853312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.346590 47634251187072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.346563 47634040329088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.349159 47118737826688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:45.350653 47415179989888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.350841 47590814200704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:45.351126 47303311979392 estimator.py:1111] Calling model_fn.
W0618 11:55:45.351235 47303311979392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:45.351387 47809201853312 estimator.py:1111] Calling model_fn.
W0618 11:55:45.351501 47809201853312 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:45.351673 47634251187072 estimator.py:1111] Calling model_fn.
I0618 11:55:45.351632 47634040329088 estimator.py:1111] Calling model_fn.
W0618 11:55:45.351739 47634040329088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:45.351780 47634251187072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:45.351840 46967240340352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.352020 47666414478208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.352586 47303311979392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:45.352865 47809201853312 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:45.353138 47634251187072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:45.353098 47634040329088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:45.357938 47193840223104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.358150 47449937077120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.360781 47699839030144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.361247 47657869640576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.362076 47457561711488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.362369 47010737992576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.362736 47355350733696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.362789 47383622595456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:45.363346 47212929586048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.364755 47976378229632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.365106 47699839030144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.365465 47224721068928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:45.365597 47657869640576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.366382 47457561711488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.366682 47010737992576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.367014 47355350733696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.367070 47383622595456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:45.368929 47118737826688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880545.304704 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.305126 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.305483 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.369747 47970992067456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880545.303455 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880545.303879 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880545.304236 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:45.370090 47300905333632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 11:55:45.370191 47699839030144 estimator.py:1111] Calling model_fn.
W0618 11:55:45.370298 47699839030144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:45.370671 47657869640576 estimator.py:1111] Calling model_fn.
W0618 11:55:45.370780 47657869640576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:45.371446 47457561711488 estimator.py:1111] Calling model_fn.
W0618 11:55:45.370803 4[2019-06-18 11:56:24] divide_golden_chunk finished: 3.306 seconds
[2019-06-18 11:56:24] generate golden chunk: 3.321 seconds
[2019-06-18 11:56:24] moving /lfs/lfs12/gma_akey/results/epb269/models/000011-000006.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000011-000007.meta
[2019-06-18 11:56:24] moving /lfs/lfs12/gma_akey/results/epb269/models/000011-000006.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb
[2019-06-18 11:56:24] moving /lfs/lfs12/gma_akey/results/epb269/models/000011-000006.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000011-000007.data-00000-of-00001
[2019-06-18 11:56:24] moving /lfs/lfs12/gma_akey/results/epb269/models/000011-000006.index --> /lfs/lfs12/gma_akey/results/epb269/models/000011-000007.index
[2019-06-18 11:56:24] iteration time 10: 49.040 seconds
2019-06-18 11:56:25.667080: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880584.935288 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 11:56:28] minmax time: 3.192 seconds
2019-06-18 11:56:28.869176: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:56:28.874752: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:56:28.879596: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880588.891335 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 10}}
[2019-06-18 11:56:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:56:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=12 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=1023779843 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=2047559674 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=3071339505 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=4095119336 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=5118899167 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=6142678998 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=7166458829 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=8190238660 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=9214018491 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=10237798322 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=11261578153 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=12285357984 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=13309137815 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=14332917646 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=15356697477 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=16380477308 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=17404257139 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=18428036970 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=19451816801 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000011-000007 --seed=20475596632 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:56:39] eval finished: 10.593 seconds
[2019-06-18 11:56:39] Win rate 000011-000007 vs 000010-000006: 0.410
:::MLL 1560880599.545706 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 11:56:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=13 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=1023779844 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=2047559675 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=3071339506 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=4095119337 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=5118899168 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=6142678999 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=7166458830 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=8190238661 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=9214018492 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=10237798323 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=11261578154 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=12285357985 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=13309137816 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=14332917647 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=15356697478 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=16380477309 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=17404257140 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000012-000006 --seed=18428036971 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:57:09] selfplay finished: 30.157 seconds
[2019-06-18 11:57:09] selfplay mn: 30.174 seconds
[2019-06-18 11:57:09] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-13-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779844 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559675 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339506 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119337 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899168 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142678999 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458830 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238661 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018492 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798323 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578154 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357985 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137816 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917647 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697478 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477309 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257140 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036971 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816802 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596633 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376464 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156295 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:57:13] divide_golden_chunk finished: 3.333 seconds
[2019-06-18 11:57:13] generate golden chunk: 3.348 seconds
[2019-06-18 11:57:13] train finished: 44.289 seconds
:::MLL 1560880594.129571 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.130445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.131168 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.214112 46921804747648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.133829 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.134530 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.135214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.214251 47775753929600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.215196 46921804747648 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpn2lgxamo
W0618 11:56:34.215260 47775753929600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8cjom740
I0618 11:56:34.216198 46921804747648 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpn2lgxamo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad1e176dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.216255 47775753929600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8cjom740', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b73f16dde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.216599 46921804747648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.216658 47775753929600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.221574 47775753929600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.221589 46921804747648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.241028 47775753929600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.241163 46921804747648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880594.171004 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.171842 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.172584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.241046 47857496028032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.154667 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.155580 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.156381 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.241019 47945726194560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.242119 47857496028032 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm2h3oi9t
W0618 11:56:34.242086 47945726194560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnzuf605u
I0618 11:56:34.243164 47945726194560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnzuf605u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b8490cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.243199 47857496028032 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm2h3oi9t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86f9a33e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.243596 47945726194560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.243644 47857496028032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.248826 47945726194560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.248853 47857496028032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880594.203256 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.203691 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.204057 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.265848 47533758604160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.266928 47533758604160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpa7buo6wp
I0618 11:56:34.268011 47533758604160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpa7buo6wp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b99623e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.268464 47533758604160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.269855 47945726194560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.270072 47857496028032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.273722 47533758604160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880594.180443 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.181201 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.181865 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.274034 47331159085952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.172920 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.173797 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.174607 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.274235 47184641991552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.275057 47331159085952 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpre0xj63j
W0618 11:56:34.275201 47184641991552 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkcfjekip
I0618 11:56:34.276057 47331159085952 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpre0xj63j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c6d82dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.276169 47184641991552 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkcfjekip', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea50697e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.276464 47331159085952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.276561 47184641991552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880594.206069 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.206506 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.206886 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.277260 47388793054080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.278278 47388793054080 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_uw9m_qk
I0618 11:56:34.279262 47388793054080 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_uw9m_qk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19d8c37e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.279660 47388793054080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.281373 47184641991552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.281562 47331159085952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.284279 47388793054080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.289272 47775753929600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:34.289879 46921804747648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:34.293379 47533758604160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.293546 47775753929600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:34.294200 46921804747648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:56:34.298634 47775753929600 estimator.py:1111] Calling model_fn.
W0618 11:56:34.298738 47775753929600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:56:34.299317 46921804747648 estimator.py:1111] Calling model_fn.
W0618 11:56:34.299431 46921804747648 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:34.300090 47775753929600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:34.300798 46921804747648 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:34.301180 47184641991552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.301452 47331159085952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.303572 47388793054080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880594.253996 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.254421 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.254829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.313633 47165384889216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.253973 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.254410 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.254829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.313728 47289053238144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.245134 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.245622 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.246026 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.315119 47265973592960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.240924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.241422 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.241851 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.315087 47934238196608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.314669 47289053238144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3ytx3v79
W0618 11:56:34.314634 47165384889216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjh1sf343
I0618 11:56:34.315629 47165384889216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjh1sf343', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5d4995da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.315654 47289053238144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3ytx3v79', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b029fce9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.316026 47165384889216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.316052 47289053238144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.316081 47934238196608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk42dko3p
W0618 11:56:34.316110 47265973592960 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpowk3pbdj
I0618 11:56:34.317087 47934238196608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk42dko3p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98d7d3de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.317102 47265973592960 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpowk3pbdj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd40271da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.317485 47934238196608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.317492 47265973592960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.320645 47165384889216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.320677 47289053238144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.321957 47945726194560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:34.322200 47265973592960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.322217 47934238196608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.322233 47857496028032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880594.202798 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.203718 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.204605 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.325983 47355010274176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.326236 47945726194560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880594.211386 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.212141 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.212821 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.326074 47140457665408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.326544 47857496028032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:34.326986 47355010274176 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp57a8ap2l
W0618 11:56:34.327037 47140457665408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfr72ha20
I0618 11:56:34.327994 47355010274176 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp57a8ap2l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11fb272e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.328041 47140457665408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfr72ha20', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae006d22e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.328410 47355010274176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.328441 47140457665408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880594.214845 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.215558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.216283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.329904 47467048326016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.217350 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.218122 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.218821 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.330017 47995578913664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 11:56:34.331331 47945726194560 estimator.py:1111] Calling model_fn.
W0618 11:56:34.331444 47945726194560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:34.330923 47467048326016 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6n05kwwy
I0618 11:56:34.331617 47857496028032 estimator.py:1111] Calling model_fn.
W0618 11:56:34.330991 47995578913664 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp34cvtsky
W0618 11:56:34.331725 47857496028032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:56:34.331909 47467048326016 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6n05kwwy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c11242e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.331977 47995578913664 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp34cvtsky', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba72004cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.332296 47467048326016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.332374 47995578913664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.332818 47945726194560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:34.333080 47857496028032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:34.333353 47355010274176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.333399 47140457665408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.337239 47467048326016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.337249 47995578913664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.339770 47165384889216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.340012 47289053238144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.340604 47533758604160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:34.341522 47265973592960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.341678 47934238196608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.344847 47533758604160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:34.349052 47184641991552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:34.349155 47331159085952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:56:34.349920 47533758604160 estimator.py:1111] Calling model_fn.
W0618 11:56:34.350025 47533758604160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:34.350505 47388793054080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:34.351371 47533758604160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:34.352605 47355010274176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.352960 47140457665408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.353357 47184641991552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:34.353466 47331159085952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:34.354767 47388793054080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:34.357011 47467048326016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:34.357305 47995578913664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:56:34.358430 47184641991552 estimator.py:1111] Calling model_fn.
W0618 11:56:34.358538 47184641991552 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:56:34.358547 47331159085952 estimator.py:1111] Calling model_fn.
W0618 11:56:34.358655 47331159085952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:34.359871 47184641991552 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:56:34.359844 47388793054080 estimator.py:1111] Calling model_fn.
W0618 11:56:34.359952 47388793054080 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:34.360009 47331159085952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880594.276928 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.277398 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.277809 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.360578 47518741951360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.275741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.276212 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.276635 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.360617 47157621957504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.361291 47388793054080 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:34.361547 47518741951360 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvbshykz1
W0618 11:56:34.361601 47157621957504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8_5hugpu
I0618 11:56:34.362517 47518741951360 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvbshykz1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b381a524e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.362583 47157621957504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8_5hugpu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae405e46e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.362908 47518741951360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.362974 47157621957504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880594.284361 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.284875 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.285325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.365702 47341073200000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880594.285239 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.285710 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.286123 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.365768 47930659861376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:34.366789 47930659861376 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpg5eh4th9
W0618 11:56:34.366734 47341073200000 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6cc0mrsr
W0618 11:56:34.367547 47518741951360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.367554 47157621957504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:34.367731 47341073200000 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6cc0mrsr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ebc704e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.367763 47930659861376 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpg5eh4th9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98028ace48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:34.368127 47341073200000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:34.368153 47930659861376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:34.372963 47930659861376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:34.372961 47341073200000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880594.207999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880594.208736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880594.209462 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:34.380044 47407680660352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecor[2019-06-18 11:57:13] iteration time 11: 48.267 seconds
2019-06-18 11:57:14.001358: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880633.202469 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 11:57:17] minmax time: 3.246 seconds
2019-06-18 11:57:17.257266: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:57:17.262604: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:57:17.267230: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880637.280208 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 11}}
[2019-06-18 11:57:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000013-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:57:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=13 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=1023779844 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=2047559675 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=3071339506 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=4095119337 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=5118899168 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=6142678999 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=7166458830 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=8190238661 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=9214018492 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=10237798323 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=11261578154 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=12285357985 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=13309137816 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=14332917647 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=15356697478 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=16380477309 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=17404257140 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=18428036971 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=19451816802 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000012-000007 --seed=20475596633 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:57:27] eval finished: 10.669 seconds
[2019-06-18 11:57:28] Win rate 000012-000007 vs 000010-000006: 0.550
:::MLL 1560880648.009782 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 11:57:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=14 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=1023779845 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=2047559676 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=3071339507 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=4095119338 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=5118899169 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=6142679000 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=7166458831 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=8190238662 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=9214018493 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=10237798324 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=11261578155 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=12285357986 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=13309137817 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=14332917648 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=15356697479 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=16380477310 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=17404257141 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000013-000006 --seed=18428036972 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:57:56] selfplay finished: 28.985 seconds
[2019-06-18 11:57:57] selfplay mn: 29.004 seconds
[2019-06-18 11:57:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-14-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779845 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559676 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339507 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119338 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899169 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679000 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458831 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238662 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018493 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798324 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578155 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357986 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137817 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917648 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697479 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477310 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257141 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036972 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816803 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596634 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376465 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156296 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000013-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:58:00] divide_golden_chunk finished: 3.324 seconds
[2019-06-18 11:58:00] generate golden chunk: 3.339 seconds
[2019-06-18 11:58:01] train finished: 43.787 seconds
:::MLL 1560880642.582562 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.583309 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.584001 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.667683 46920127325056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.568347 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.569286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.570160 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.667810 47074421670784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.668811 46920127325056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnb2wquuc
W0618 11:57:22.668937 47074421670784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpafav3mw4
I0618 11:57:22.669975 46920127325056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnb2wquuc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aacba1bcda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.670038 47074421670784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpafav3mw4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad0a6c4de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.670432 46920127325056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.670487 47074421670784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880642.570365 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.571141 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.571933 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.671589 47035550462848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.571983 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.572758 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.573462 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.671796 47428313846656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.672616 47035550462848 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprkjbyrzh
W0618 11:57:22.672753 47428313846656 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpr4wczr7_
I0618 11:57:22.673709 47035550462848 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprkjbyrzh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac799dd3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.673829 47428313846656 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpr4wczr7_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b230c62de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.674162 47035550462848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.674270 47428313846656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880642.585087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.585852 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.586573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.674073 47110693204864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.587663 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.588398 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.589097 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.674098 47056866886528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.675166 47056866886528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph8mwqiiz
W0618 11:57:22.675193 47110693204864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4e209ljw
W0618 11:57:22.675961 47074421670784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:57:22.676165 47056866886528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph8mwqiiz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc906c0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:22.675965 46920127325056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:57:22.676189 47110693204864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4e209ljw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad918b88e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.676568 47056866886528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.676595 47110693204864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.679066 47428313846656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.679072 47035550462848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.681657 47110693204864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.681667 47056866886528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880642.598839 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.599597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.600294 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.689006 47679653090176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.590102 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.591022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.591843 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.689068 47414810612608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.690099 47679653090176 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1iqvo27l
W0618 11:57:22.690129 47414810612608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpt2jv1omo
I0618 11:57:22.691156 47679653090176 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1iqvo27l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d915f5da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.691157 47414810612608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpt2jv1omo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1fe787ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.691560 47679653090176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.691560 47414810612608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.696604 47414810612608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.696631 47679653090176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880642.588142 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.588910 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.589552 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.698021 47888482214784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.585483 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.586230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.586962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.698076 47022771712896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.698150 47074421670784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.698428 46920127325056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.699250 47035550462848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.699205 47428313846656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.699077 47022771712896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfob6a1gx
W0618 11:57:22.699048 47888482214784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdbaui001
I0618 11:57:22.700049 47022771712896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfob6a1gx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4a030fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.700044 47888482214784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdbaui001', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e308eee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.700477 47888482214784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.700608 47022771712896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.701459 47110693204864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.701501 47056866886528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.705469 47888482214784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.705512 47022771712896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880642.621201 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.622034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.622875 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.707844 47913025442688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.621576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.622519 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.623272 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.707960 47181774259072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.642366 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.642769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.643121 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.707999 48010835096448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.639823 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.640215 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.640564 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.707994 46998911566720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
I0618 11:57:22.708996 47913025442688 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93e772ed30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880642.633571 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.634035 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.634436 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.709568 47368883110784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.709048 47181774259072 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgm8v6trg
:::MLL 1560880642.635951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.636397 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.636783 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.709657 47731971531648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.709005 48010835096448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpa43yl0jb
W0618 11:57:22.709033 46998911566720 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps4g_ovk_
I0618 11:57:22.710100 47181774259072 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgm8v6trg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae9a57b5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.710002 48010835096448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpa43yl0jb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baaad5bbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.710006 46998911566720 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps4g_ovk_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf12041e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.710284 47913025442688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.710544 47181774259072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.710390 46998911566720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.710394 48010835096448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.710570 47368883110784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeq81_et8
W0618 11:57:22.710615 47731971531648 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzg_3vjl5
I0618 11:57:22.711550 47368883110784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeq81_et8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b153609ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.711575 47731971531648 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzg_3vjl5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b69bfcb5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.711943 47368883110784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.711979 47731971531648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.715084 48010835096448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.715104 46998911566720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.715699 47913025442688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.715765 47181774259072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.716262 47414810612608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.716370 47679653090176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.716758 47731971531648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.716763 47368883110784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880642.665408 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.665958 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.666400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.723155 46972313236352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.665408 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.665950 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.666387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.723272 47601030194048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.724157 46972313236352 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4_ze16kb
W0618 11:57:22.724251 47601030194048 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz7vw0hth
I0618 11:57:22.725131 46972313236352 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4_ze16kb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab8e0a1ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.725216 47601030194048 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz7vw0hth', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b43153e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:22.725252 47888482214784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.725327 47022771712896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:57:22.725527 46972313236352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.725615 47601030194048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880642.625957 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.626439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.626908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.728484 47425416758144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.627116 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.627587 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.627990 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.728526 47172957381504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.730167 46972313236352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.730209 47601030194048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.729601 47425416758144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0jzujp4r
W0618 11:57:22.729629 47172957381504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsqa9r2qo
I0618 11:57:22.730631 47425416758144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0jzujp4r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b225fb4de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.730631 47172957381504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsqa9r2qo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae797f47e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.731021 47425416758144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.731025 47172957381504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880642.662784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.663259 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.663664 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.731361 47685038785408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560880642.664590 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.665071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.665480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.731535 47871433053056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.732374 47685038785408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpq_efz4pl
W0618 11:57:22.732537 47871433053056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpih8hev8i
I0618 11:57:22.733344 47685038785408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpq_efz4pl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ed2628e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.733497 47871433053056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpih8hev8i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a38596e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.733744 47685038785408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.733899 47871433053056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.734464 48010835096448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.734459 46998911566720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.735762 47172957381504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.735779 47425416758144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.736345 47731971531648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.736388 47368883110784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.738048 47181774259072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.738373 47913025442688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.738504 47685038785408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.738626 47871433053056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.746654 47074421670784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:22.747286 46920127325056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880642.685389 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.685851 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.686230 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.747293 47517067395968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.747416 47035550462848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880642.686036 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880642.686459 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880642.686802 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:22.747294 47828863386496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 11:57:22.747435 47428313846656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:22.748322 47828863386496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwdjosz_9
W0618 11:57:22.748353 47517067395968 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz4iqapps
I0618 11:57:22.749335 47828863386496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwdjosz_9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b804effce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:22.749382 47517067395968 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz4iqapps', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37b6829e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:22.749604 46972313236352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:57:22.749755 47828863386496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:22.749804 47517067395968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:22.749620 47601030194048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.749685 47110693204864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:22.749727 47056866886528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:22.750946 47074421670784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:22.751605 46920127325056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:22.751708 47035550462848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:22.751739 47428313846656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:22.754015 47110693204864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:22.754056 47056866886528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:22.754476 47828863386496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.754486 47517067395968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:22.755097 47425416758144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:22.755111 47172957381504 deprecation.p[2019-06-18 11:58:01] moving /lfs/lfs12/gma_akey/results/epb269/models/000013-000007.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000013-000008.meta
[2019-06-18 11:58:01] moving /lfs/lfs12/gma_akey/results/epb269/models/000013-000007.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb
[2019-06-18 11:58:01] moving /lfs/lfs12/gma_akey/results/epb269/models/000013-000007.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000013-000008.data-00000-of-00001
[2019-06-18 11:58:01] moving /lfs/lfs12/gma_akey/results/epb269/models/000013-000007.index --> /lfs/lfs12/gma_akey/results/epb269/models/000013-000008.index
[2019-06-18 11:58:01] iteration time 12: 47.936 seconds
2019-06-18 11:58:01.975728: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880681.138165 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 11:58:05] minmax time: 3.240 seconds
2019-06-18 11:58:05.225382: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:58:05.230672: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:58:05.235096: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880685.246909 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 12}}
[2019-06-18 11:58:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:58:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=14 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=1023779845 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=2047559676 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=3071339507 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=4095119338 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=5118899169 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=6142679000 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=7166458831 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=8190238662 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=9214018493 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=10237798324 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=11261578155 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=12285357986 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=13309137817 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=14332917648 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=15356697479 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=16380477310 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=17404257141 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=18428036972 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=19451816803 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000013-000008 --seed=20475596634 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:58:17] eval finished: 11.791 seconds
[2019-06-18 11:58:17] Win rate 000013-000008 vs 000012-000007: 0.400
:::MLL 1560880697.095943 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 11:58:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=15 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=1023779846 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=2047559677 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=3071339508 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=4095119339 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=5118899170 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=6142679001 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=7166458832 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=8190238663 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=9214018494 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=10237798325 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=11261578156 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=12285357987 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=13309137818 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=14332917649 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=15356697480 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=16380477311 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=17404257142 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000014-000007 --seed=18428036973 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:58:46] selfplay finished: 29.445 seconds
[2019-06-18 11:58:46] selfplay mn: 29.462 seconds
[2019-06-18 11:58:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-15-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779846 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559677 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339508 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119339 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899170 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679001 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458832 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238663 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018494 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798325 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578156 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357987 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137818 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917649 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697480 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477311 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257142 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036973 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816804 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596635 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376466 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156297 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:58:49] train finished: 43.835 seconds
:::MLL 1560880690.506423 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.507302 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.508150 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.595720 47591120761728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.511033 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.511769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.512448 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.595851 47638159418240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 11:58:10.596783 47591120761728 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphpvotdvf
W0618 11:58:10.596891 47638159418240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeqrj165h
I0618 11:58:10.597773 47591120761728 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphpvotdvf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48f46f4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.597903 47638159418240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeqrj165h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b53e8283e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.598169 47591120761728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.598310 47638159418240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.603005 47591120761728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.603142 47638159418240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880690.514852 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.515704 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.516476 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.607636 47308065313664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.515938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.516749 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.517460 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.607696 47466291299200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.512911 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.513829 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.514727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.608568 47641133482880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.518959 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.519696 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.520333 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.608758 48004341867392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 11:58:10.608690 47308065313664 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu5tqkicq
W0618 11:58:10.608726 47466291299200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpr620qnhg
I0618 11:58:10.609746 47308065313664 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu5tqkicq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b070d03de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.609784 47466291299200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpr620qnhg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2be404de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.610146 47308065313664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.610179 47466291299200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.609606 47641133482880 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprcbn7xz3
W0618 11:58:10.609761 48004341867392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1yatkebx
I0618 11:58:10.610733 47641133482880 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprcbn7xz3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b54996cddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.610845 48004341867392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1yatkebx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba92a54fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.611180 47641133482880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.611280 48004341867392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.614941 47466291299200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.614939 47308065313664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.616038 48004341867392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.616047 47641133482880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.622697 47591120761728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.623325 47638159418240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880690.536112 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.536964 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.537769 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.627991 47882061001600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.536367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.537232 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.538017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.628008 47153451930496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 11:58:10.629148 47882061001600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplwy48kk6
W0618 11:58:10.629187 47153451930496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9xo2wnum
I0618 11:58:10.630250 47882061001600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplwy48kk6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8cb1d30e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.630294 47153451930496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9xo2wnum', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae30d56ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.630691 47882061001600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.630734 47153451930496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.634666 47308065313664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.635211 47466291299200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.635569 48004341867392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.635806 47641133482880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.636025 47882061001600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.636036 47153451930496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880690.588418 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.588859 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.589230 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.648672 47975324889984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.589859 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.590292 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.590668 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.648728 47024182764416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.558608 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.559271 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.559972 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.648982 46963467494272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.556528 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.557256 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.558017 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.649302 47061148496768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.580040 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.580610 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.581089 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.649724 46992438457216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 11:58:10.649684 47975324889984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsd4ammo4
W0618 11:58:10.649712 47024182764416 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8b1bbi8q
I0618 11:58:10.650665 47975324889984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsd4ammo4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba268c8fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.650677 47024182764416 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8b1bbi8q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4f44bfdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:10.649982 46963467494272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdw1hkrsw
:::MLL 1560880690.585769 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.586243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.586684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.650702 47790655660928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
I0618 11:58:10.650964 46963467494272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdw1hkrsw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6d1626da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.651059 47975324889984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.651072 47024182764416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.650304 47061148496768 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvf6nuz1t
:::MLL 1560880690.576562 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.577152 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.577640 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.651175 47159692338048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
I0618 11:58:10.651330 47061148496768 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvf6nuz1t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd8fa04e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:10.650722 46992438457216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph4wuvzbu
I0618 11:58:10.651364 46963467494272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.651697 46992438457216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph4wuvzbu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd90304e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.651748 47061148496768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880690.594326 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.594992 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.595374 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.651892 47511831499648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
I0618 11:58:10.652086 46992438457216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.651712 47790655660928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppb2bt7y3
I0618 11:58:10.652672 47790655660928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppb2bt7y3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7769a43e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:10.652126 47159692338048 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpiijksbl3
I0618 11:58:10.653063 47790655660928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.653092 47159692338048 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpiijksbl3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4814bfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.653491 47159692338048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.652858 47511831499648 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0dyuqsup
I0618 11:58:10.653825 47511831499648 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0dyuqsup', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b367e6d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.654221 47511831499648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.655759 47975324889984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.655783 47024182764416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.656107 46963467494272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.656405 47061148496768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.656732 46992438457216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.657681 47790655660928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.658046 47159692338048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.658178 47882061001600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.658356 47153451930496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.658715 47511831499648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880690.572267 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.573197 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.574043 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.661082 47657626112896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.578464 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.579211 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.579918 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.661113 47873423991680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
I0618 11:58:10.662194 47873423991680 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8aaf04ad30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:10.662192 47657626112896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_gz9d6pw
I0618 11:58:10.663236 47657626112896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_gz9d6pw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5870766e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.663393 47873423991680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.663715 47657626112896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.668719 47873423991680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.668828 47657626112896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.670623 47591120761728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:10.671290 47638159418240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880690.606667 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.607084 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.607437 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.671016 46931130893184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.608971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.609376 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.609734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.671182 47117378282368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 11:58:10.672026 46931130893184 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjuctbht9
W0618 11:58:10.672199 47117378282368 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8m66bkeo
I0618 11:58:10.673013 46931130893184 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjuctbht9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf49f91e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.673172 47117378282368 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8m66bkeo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adaa72eae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.673410 46931130893184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.673571 47117378282368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.674914 47591120761728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:10.675089 47975324889984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.675160 47024182764416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.675623 47638159418240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:10.675848 46963467494272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.676034 46992438457216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.676318 47061148496768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.677073 47790655660928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.677470 47159692338048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.677906 47511831499648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.678057 46931130893184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:10.678154 47117378282368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:58:10.679939 47591120761728 estimator.py:1111] Calling model_fn.
W0618 11:58:10.680048 47591120761728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:10.680700 47638159418240 estimator.py:1111] Calling model_fn.
W0618 11:58:10.680808 47638159418240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:10.681405 47591120761728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:10.682175 47638159418240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:10.682102 47308065313664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:10.682698 47466291299200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:10.683569 47641133482880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:10.683620 48004341867392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:10.686410 47308065313664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:10.687012 47466291299200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:10.687884 47641133482880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:10.687959 48004341867392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:10.691214 47873423991680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.691293 47657626112896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:10.691467 47308065313664 estimator.py:1111] Calling model_fn.
W0618 11:58:10.691577 47308065313664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:10.692043 47466291299200 estimator.py:1111] Calling model_fn.
W0618 11:58:10.692152 47466291299200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:10.692929 47308065313664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:58:10.692945 47641133482880 estimator.py:1111] Calling model_fn.
W0618 11:58:10.693053 47641133482880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:10.693036 48004341867392 estimator.py:1111] Calling model_fn.
W0618 11:58:10.693143 48004341867392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:10.693502 47466291299200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880690.628807 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.629278 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.629670 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.693809 47764633412480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
:::MLL 1560880690.627987 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880690.628490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880690.628928 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:10.694017 47546693088128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000004-000002.tfrecord.zz_0_0
W0618 11:58:10.694412 47641133482880 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:10.694516 48004341867392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:10.694834 47764633412480 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyptibfkz
W0618 11:58:10.694987 47546693088128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp419qim01
I0618 11:58:10.695814 47764633412480 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyptibfkz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b715a982e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.695953 47546693088128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp419qim01', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e9c56ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:10.696221 47764633412480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:10.696346 47546693088128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:10.697314 46931130893184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:10.697700 47117378282368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel[2019-06-18 11:58:49] divide_golden_chunk finished: 3.302 seconds
[2019-06-18 11:58:49] generate golden chunk: 3.316 seconds
[2019-06-18 11:58:49] iteration time 13: 48.738 seconds
2019-06-18 11:58:50.864963: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880729.876009 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 11:58:54] minmax time: 3.242 seconds
2019-06-18 11:58:54.117021: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:58:54.122541: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:58:54.127122: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880734.140217 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 13}}
[2019-06-18 11:58:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000015-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:58:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=15 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=1023779846 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=2047559677 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=3071339508 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=4095119339 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=5118899170 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=6142679001 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=7166458832 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=8190238663 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=9214018494 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=10237798325 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=11261578156 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=12285357987 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=13309137818 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=14332917649 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=15356697480 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=16380477311 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=17404257142 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=18428036973 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=19451816804 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000014-000008 --seed=20475596635 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:59:05] eval finished: 11.082 seconds
[2019-06-18 11:59:05] Win rate 000014-000008 vs 000012-000007: 0.580
:::MLL 1560880745.281090 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 11:59:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=16 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=1023779847 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=2047559678 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=3071339509 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=4095119340 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=5118899171 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=6142679002 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=7166458833 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=8190238664 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=9214018495 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=10237798326 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=11261578157 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=12285357988 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=13309137819 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=14332917650 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=15356697481 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=16380477312 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=17404257143 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000015-000007 --seed=18428036974 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:59:37] selfplay finished: 31.769 seconds
[2019-06-18 11:59:37] selfplay mn: 31.786 seconds
[2019-06-18 11:59:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-16-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779847 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559678 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339509 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119340 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899171 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679002 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458833 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238664 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018495 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798326 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578157 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357988 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137819 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917650 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697481 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477312 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257143 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036974 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816805 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596636 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376467 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156298 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000015-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 11:59:37] train finished: 43.426 seconds
:::MLL 1560880739.354082 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.354801 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.355505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.439107 47922808345472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.350580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.351409 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.352085 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.439156 47239716356992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.440106 47922808345472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplgylr58f
W0618 11:58:59.440142 47239716356992 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgchiybdu
I0618 11:58:59.441087 47922808345472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplgylr58f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b962e8e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.441136 47239716356992 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgchiybdu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af723199e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.441490 47922808345472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.441540 47239716356992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.446292 47922808345472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.446332 47239716356992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.465789 47922808345472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.465882 47239716356992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880739.393646 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.394482 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.395254 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.480059 47377502864256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.394827 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.395620 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.396292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.480477 47550928966528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.481052 47377502864256 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp69cucfgr
I0618 11:58:59.482065 47377502864256 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp69cucfgr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1737d0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.481431 47550928966528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptikg8hg5
I0618 11:58:59.482401 47550928966528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptikg8hg5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f98d12dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.482470 47377502864256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.482799 47550928966528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.487362 47377502864256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.487572 47550928966528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880739.396540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.397280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.397968 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.495554 47632146563968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.399228 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.400014 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.400654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.495669 47548106810240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.496659 47632146563968 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjuqhrp4_
W0618 11:58:59.496741 47548106810240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpg7b0kts6
I0618 11:58:59.497739 47632146563968 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjuqhrp4_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5281c35e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.497815 47548106810240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpg7b0kts6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ef09a7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.498181 47632146563968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.498242 47548106810240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880739.428914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.429472 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.429844 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.502855 47979763766144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.428312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.428974 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.429471 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.502867 47300515574656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.503480 47548106810240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.503544 47632146563968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.503897 47300515574656 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm5croo1j
W0618 11:58:59.503929 47979763766144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpytbzmoss
I0618 11:58:59.504859 47300515574656 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm5croo1j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b054b040e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.504905 47979763766144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpytbzmoss', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3715cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.505251 47300515574656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.505302 47979763766144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.506957 47377502864256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.507297 47550928966528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.509872 47300515574656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.509922 47979763766144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.514439 47239716356992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:59.514446 47922808345472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880739.418523 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.419268 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.419966 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.517879 47600227361664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.414008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.414870 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.415732 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.517852 47149154366336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.518784 47239716356992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:59.518745 47922808345472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:59.518842 47149154366336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9cbttb5q
W0618 11:58:59.518872 47600227361664 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5mt056kc
I0618 11:58:59.519869 47149154366336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9cbttb5q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae20d2f4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.520022 47600227361664 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5mt056kc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b133afe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.520314 47149154366336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.520467 47600227361664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880739.416994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.417894 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.418705 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.520333 47617329832832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.421413 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.422120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.422802 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.520605 47990564078464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.521398 47617329832832 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpega6fh5l
I0618 11:58:59.522398 47617329832832 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpega6fh5l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f0e9dfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.521582 47990564078464 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvd6vg4zc
I0618 11:58:59.522733 47990564078464 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvd6vg4zc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5f51c8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.522797 47617329832832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.523137 47990564078464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.523775 47922808345472 estimator.py:1111] Calling model_fn.
I0618 11:58:59.523849 47239716356992 estimator.py:1111] Calling model_fn.
W0618 11:58:59.523885 47922808345472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:59.523958 47239716356992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:59.525126 47600227361664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.525128 47149154366336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.525232 47922808345472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:59.525326 47239716356992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:59.525586 47548106810240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.525706 47632146563968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.527560 47617329832832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.528016 47990564078464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.529174 47979763766144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.529130 47300515574656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880739.468773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.469203 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.469581 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.540527 46928042804096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.470936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.471348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.471708 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.540950 47327840871296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.541568 46928042804096 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxzq3l_xa
I0618 11:58:59.542553 46928042804096 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxzq3l_xa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aae91e89e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.541929 47327840871296 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvaa8wuk6
:::MLL 1560880739.480768 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.481170 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.481514 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.542703 47037032805248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 11:58:59.542898 47327840871296 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvaa8wuk6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ba7bafe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880739.481371 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.481763 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.482093 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.542785 47353491874688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 11:58:59.542964 46928042804096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.543286 47327840871296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.543752 47037032805248 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp15vxlyc3
W0618 11:58:59.543784 47353491874688 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnhutq9z5
W0618 11:58:59.544593 47600227361664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:59.544712 47037032805248 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp15vxlyc3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac7f2380e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.544647 47149154366336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:59.544767 47353491874688 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnhutq9z5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11a0a63e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.545103 47037032805248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.545166 47353491874688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.547111 47617329832832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.547630 46928042804096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.547961 47327840871296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.548711 47990564078464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.549844 47037032805248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.549922 47353491874688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880739.449491 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.450252 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.450933 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.550522 47902469137280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.452001 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.452746 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.453441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.550544 47980123513728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.551633 47902469137280 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxij9nm7k
I0618 11:58:59.551655 47980123513728 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba386ce3d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.552730 47902469137280 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxij9nm7k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b91723e7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.552894 47980123513728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.553173 47902469137280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.555128 47377502864256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:59.555254 47550928966528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880739.473453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.473931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.474339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.557230 47255643153280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.470647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.471151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.471582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.557191 47912294896512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.558258 47980123513728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.558330 47902469137280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.558235 47255643153280 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpp8njth0e
W0618 11:58:59.558205 47912294896512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptxgp5b5b
I0618 11:58:59.559188 47912294896512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptxgp5b5b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93bbe7ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:59.559205 47255643153280 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpp8njth0e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afad8691e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.559482 47377502864256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:58:59.559591 47912294896512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.559607 47255643153280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.559597 47550928966528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:59.564166 47912294896512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.564203 47255643153280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:58:59.564549 47377502864256 estimator.py:1111] Calling model_fn.
W0618 11:58:59.564661 47377502864256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:59.564667 47550928966528 estimator.py:1111] Calling model_fn.
W0618 11:58:59.564778 47550928966528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880739.485510 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.485975 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.486416 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.564665 47900099892096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560880739.486792 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880739.487273 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880739.487798 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:59.564964 47783709819776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 11:58:59.566028 47377502864256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:59.566137 47550928966528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:59.565653 47900099892096 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm5ic6ste
I0618 11:58:59.566647 47900099892096 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm5ic6ste', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b90e5069e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.565951 47783709819776 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_u5vqmgv
I0618 11:58:59.566924 47783709819776 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_u5vqmgv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75cba31e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:59.566807 46928042804096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:59.567042 47900099892096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:59.567341 47783709819776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:59.567303 47327840871296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.569086 47037032805248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.569351 47353491874688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.571820 47900099892096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.572042 47783709819776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:59.575045 47632146563968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:59.575242 47548106810240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:59.576143 47300515574656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:59.576762 47979763766144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:59.579382 47632146563968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:59.579617 47548106810240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:59.580285 47902469137280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:59.580397 47300515574656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed[2019-06-18 11:59:40] divide_golden_chunk finished: 3.311 seconds
[2019-06-18 11:59:40] generate golden chunk: 3.326 seconds
[2019-06-18 11:59:40] moving /lfs/lfs12/gma_akey/results/epb269/models/000015-000008.index --> /lfs/lfs12/gma_akey/results/epb269/models/000015-000009.index
[2019-06-18 11:59:40] moving /lfs/lfs12/gma_akey/results/epb269/models/000015-000008.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb
[2019-06-18 11:59:40] moving /lfs/lfs12/gma_akey/results/epb269/models/000015-000008.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000015-000009.meta
[2019-06-18 11:59:40] moving /lfs/lfs12/gma_akey/results/epb269/models/000015-000008.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000015-000009.data-00000-of-00001
[2019-06-18 11:59:40] iteration time 14: 50.558 seconds
2019-06-18 11:59:41.345797: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880780.433964 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 11:59:44] minmax time: 3.230 seconds
2019-06-18 11:59:44.585746: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:59:44.591061: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:59:44.595564: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880784.607154 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 14}}
[2019-06-18 11:59:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000016-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 11:59:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=16 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=1023779847 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=2047559678 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=3071339509 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=4095119340 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=5118899171 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=6142679002 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=7166458833 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=8190238664 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=9214018495 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=10237798326 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=11261578157 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=12285357988 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=13309137819 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=14332917650 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=15356697481 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=16380477312 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=17404257143 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=18428036974 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=19451816805 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000015-000009 --seed=20475596636 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:59:55] eval finished: 10.687 seconds
[2019-06-18 11:59:55] Win rate 000015-000009 vs 000014-000008: 0.750
:::MLL 1560880795.356076 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 11:59:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=17 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=1023779848 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=2047559679 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=3071339510 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=4095119341 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=5118899172 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=6142679003 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=7166458834 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=8190238665 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=9214018496 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=10237798327 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=11261578158 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=12285357989 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=13309137820 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=14332917651 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=15356697482 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=16380477313 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=17404257144 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000016-000008 --seed=18428036975 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:00:24] selfplay finished: 29.295 seconds
[2019-06-18 12:00:24] selfplay mn: 29.315 seconds
[2019-06-18 12:00:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-17-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779848 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559679 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339510 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119341 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899172 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679003 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458834 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238665 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018496 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798327 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578158 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357989 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137820 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917651 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697482 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477313 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257144 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036975 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816806 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596637 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376468 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156299 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000016-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:00:27] divide_golden_chunk finished: 3.325 seconds
[2019-06-18 12:00:28] generate golden chunk: 3.340 seconds
[2019-06-18 12:00:28] train finished: 43.801 seconds
:::MLL 1560880789.874108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.874867 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.875535 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:49.959054 47184119636864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.865050 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.865963 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.866792 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:49.959099 47297624269696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:49.960129 47184119636864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8q6dc_v7
W0618 11:59:49.960156 47297624269696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9cy0tbbn
I0618 11:59:49.961164 47184119636864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8q6dc_v7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea3146fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:49.961204 47297624269696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9cy0tbbn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b049eae3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:49.961565 47184119636864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:49.961609 47297624269696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:49.966352 47297624269696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:49.966358 47184119636864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880789.883914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.884734 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.885400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:49.970431 47196853318528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.882697 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.883519 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.884290 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:49.970684 47590757057408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:49.971555 47196853318528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpycpl8l34
W0618 11:59:49.971770 47590757057408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5xwzs9x1
I0618 11:59:49.972587 47196853318528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpycpl8l34', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed28438e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:49.972801 47590757057408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5xwzs9x1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48dec17e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:49.972981 47196853318528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:49.973197 47590757057408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:49.977723 47196853318528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:49.977826 47590757057408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:49.986022 47297624269696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:49.985980 47184119636864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880789.896329 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.897206 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.898039 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:49.988416 47039956538240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.896361 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.897266 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.898106 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:49.988447 47260062131072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:49.989590 47260062131072 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3pk5531g
W0618 11:59:49.989624 47039956538240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpl3jp_vg7
I0618 11:59:49.990692 47260062131072 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3pk5531g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afbdfcd7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:49.990719 47039956538240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpl3jp_vg7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8a07cae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:49.991137 47260062131072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:49.991158 47039956538240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:49.996513 47039956538240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:49.996523 47260062131072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:49.997058 47196853318528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:49.997104 47590757057408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880789.913736 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.914488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.915162 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.000632 47553186100096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.906719 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.907640 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.908517 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.000765 47117752730496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.001670 47553186100096 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9p4jvfqf
W0618 11:59:50.001738 47117752730496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4s0yah0k
I0618 11:59:50.002678 47553186100096 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9p4jvfqf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b401f5a4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.002732 47117752730496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4s0yah0k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adabd805da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.003084 47553186100096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.003122 47117752730496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880789.916405 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.917269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.917931 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.007975 47495367611264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.008119 47553186100096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880789.915428 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.916296 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.917129 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.008169 47453204169600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.008138 47117752730496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.009073 47495367611264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm9__xvmp
W0618 11:59:50.009186 47453204169600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm_odc0is
I0618 11:59:50.010097 47495367611264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm9__xvmp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32a91a2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.010178 47453204169600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm_odc0is', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28d7f71e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.010505 47495367611264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.010573 47453204169600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880789.946332 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.946834 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.947229 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.012521 47390978810752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.949613 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.950057 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.950444 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.013518 47218082059136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.013542 47390978810752 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpn_50u4_b
I0618 11:59:50.014531 47390978810752 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpn_50u4_b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a5b0b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.014938 47390978810752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:50.014497 47218082059136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9puc7e2u
W0618 11:59:50.015293 47495367611264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.015358 47453204169600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:59:50.015492 47218082059136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9puc7e2u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af219985e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.015908 47218082059136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880789.946070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.946597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.947059 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.017482 47769425699712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.953252 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.953695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.954074 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.018132 47874299597696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.018576 47039956538240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.018806 47260062131072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.018490 47769425699712 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_q1gpdyq
I0618 11:59:50.019473 47769425699712 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_q1gpdyq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72783cada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:50.019692 47390978810752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.019114 47874299597696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3ya8oelz
I0618 11:59:50.019882 47769425699712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.020094 47874299597696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3ya8oelz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ae3355e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:50.020505 47218082059136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:59:50.020498 47874299597696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:50.024475 47769425699712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.025003 47874299597696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.027508 47553186100096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.027569 47117752730496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.034417 47297624269696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.034425 47184119636864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.034712 47495367611264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.035135 47453204169600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.038747 47297624269696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:50.038750 47184119636864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:50.039141 47390978810752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.039963 47218082059136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.043591 47769425699712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:59:50.043856 47297624269696 estimator.py:1111] Calling model_fn.
:::MLL 1560880789.977070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.977444 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.977909 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.043651 47802345771904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
I0618 11:59:50.043818 47184119636864 estimator.py:1111] Calling model_fn.
W0618 11:59:50.043929 47184119636864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:50.043967 47297624269696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:50.044234 47874299597696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880789.979326 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.979705 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.980033 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.044193 48001285796736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.044693 47196853318528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.045034 47590757057408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.045285 47184119636864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:50.044644 47802345771904 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprse1fcrg
W0618 11:59:50.045338 47297624269696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:59:50.045633 47802345771904 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprse1fcrg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a226d2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:50.045158 48001285796736 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpa4bpenh4
I0618 11:59:50.046030 47802345771904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.046139 48001285796736 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpa4bpenh4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8742d0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.046547 48001285796736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:50.048972 47196853318528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:50.049369 47590757057408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:50.050671 47802345771904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.051055 48001285796736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880789.984433 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.984841 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.985192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.052545 47525171569536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.986678 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.987080 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.987468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.052691 47972862239616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
I0618 11:59:50.054004 47196853318528 estimator.py:1111] Calling model_fn.
W0618 11:59:50.054112 47196853318528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880789.965384 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.966083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.966792 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.054073 47080963388288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.958205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.959144 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.959988 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.054285 47340135617408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.053552 47525171569536 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2km43tjj
I0618 11:59:50.054428 47590757057408 estimator.py:1111] Calling model_fn.
W0618 11:59:50.053699 47972862239616 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpks1p30vr
W0618 11:59:50.054542 47590757057408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:59:50.054543 47525171569536 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2km43tjj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39998e7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.054659 47972862239616 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpks1p30vr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1d5fffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.054928 47525171569536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.055052 47972862239616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:50.055456 47196853318528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880789.989875 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.990405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.990819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.055311 47035454710656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880789.989952 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880789.990471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880789.990884 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:50.055561 47645296182144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 11:59:50.055146 47080963388288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps_0v3fpi
W0618 11:59:50.055900 47590757057408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:59:50.055349 47340135617408 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e848ded30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.056187 47080963388288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps_0v3fpi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad22caf5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.056521 47340135617408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.056620 47080963388288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:50.056294 47035454710656 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpscy7ikgr
W0618 11:59:50.056546 47645296182144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfrfkprjq
I0618 11:59:50.057274 47035454710656 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpscy7ikgr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac794282dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.057536 47645296182144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfrfkprjq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55918a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:50.057672 47035454710656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:50.057938 47645296182144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:50.059526 47525171569536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.059638 47972862239616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.061585 47340135617408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.061635 47080963388288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.062270 47035454710656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.062541 47645296182144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:50.068619 47260062131072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.068714 47039956538240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.069926 47802345771904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.070366 48001285796736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:50.072919 47260062131072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:50.073052 47039956538240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:50.075261 47553186100096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:50.075431 47117752730496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:59:50.077947 47260062131072 estimator.py:1111] Calling model_fn.
W0618 11:59:50.078056 47260062131072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:59:50.078119 47039956538240 estimator.py:1111] Calling model_fn.
W0618 11:59:50.078224 47039956538240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Inst[2019-06-18 12:00:28] moving /lfs/lfs12/gma_akey/results/epb269/models/000016-000009.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000016-000010.data-00000-of-00001
[2019-06-18 12:00:28] moving /lfs/lfs12/gma_akey/results/epb269/models/000016-000009.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000016-000010.meta
[2019-06-18 12:00:28] moving /lfs/lfs12/gma_akey/results/epb269/models/000016-000009.index --> /lfs/lfs12/gma_akey/results/epb269/models/000016-000010.index
[2019-06-18 12:00:28] moving /lfs/lfs12/gma_akey/results/epb269/models/000016-000009.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb
[2019-06-18 12:00:28] iteration time 15: 48.043 seconds
2019-06-18 12:00:29.426539: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880828.476856 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:00:32] minmax time: 3.286 seconds
2019-06-18 12:00:32.722454: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:00:32.727850: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:00:32.732356: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880832.744289 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 15}}
[2019-06-18 12:00:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:00:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=17 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=1023779848 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=2047559679 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=3071339510 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=4095119341 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=5118899172 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=6142679003 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=7166458834 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=8190238665 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=9214018496 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=10237798327 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=11261578158 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=12285357989 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=13309137820 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=14332917651 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=15356697482 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=16380477313 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=17404257144 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=18428036975 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=19451816806 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000016-000010 --seed=20475596637 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:00:43] eval finished: 10.541 seconds
[2019-06-18 12:00:43] Win rate 000016-000010 vs 000015-000009: 0.450
:::MLL 1560880843.346851 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 12:00:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=18 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=1023779849 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=2047559680 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=3071339511 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=4095119342 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=5118899173 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=6142679004 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=7166458835 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=8190238666 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=9214018497 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=10237798328 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=11261578159 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=12285357990 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=13309137821 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=14332917652 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=15356697483 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=16380477314 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=17404257145 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000017-000009 --seed=18428036976 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:01:14] selfplay finished: 30.786 seconds
[2019-06-18 12:01:14] selfplay mn: 30.804 seconds
[2019-06-18 12:01:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-18-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779849 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559680 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339511 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119342 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899173 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679004 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458835 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238666 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018497 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798328 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578159 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357990 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137821 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917652 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697483 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477314 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257145 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036976 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816807 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596638 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376469 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156300 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000017-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:01:16] train finished: 43.659 seconds
:::MLL 1560880837.949255 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880837.950120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880837.950960 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.041454 47261021168512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880837.953989 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880837.954684 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880837.955352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.041557 47418784306048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.042499 47261021168512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7y6i14cx
W0618 12:00:38.042577 47418784306048 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3a8j59rm
I0618 12:00:38.043632 47261021168512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7y6i14cx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc18f73e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.043678 47418784306048 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3a8j59rm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20d461add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.044070 47261021168512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.044094 47418784306048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.048852 47261021168512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.048865 47418784306048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.068264 47418784306048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.068430 47261021168512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880838.024724 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.025168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.025544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.092443 46913695478656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.024049 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.024527 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.024917 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.092528 47151877673856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.093497 46913695478656 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpg8x8jm22
W0618 12:00:38.093566 47151877673856 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphokasb8u
I0618 12:00:38.094514 46913695478656 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpg8x8jm22', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab3abdae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.094600 47151877673856 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphokasb8u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae2af81ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.094913 46913695478656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.094996 47151877673856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880838.000314 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.001210 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.002083 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.094786 47037596570496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.000306 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.001219 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.002081 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.094909 47379084178304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.000310 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.001213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.002082 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.094914 47312245654400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.004975 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.005705 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.006397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.095070 47797098894208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.095940 47312245654400 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyieluxfz
W0618 12:00:38.096033 47797098894208 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi27mf8j8
W0618 12:00:38.095882 47037596570496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyliy9qgj
I0618 12:00:38.096946 47312245654400 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyieluxfz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b08062ede10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:38.095943 47379084178304 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf32nwqqq
I0618 12:00:38.097027 47797098894208 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi27mf8j8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78e9b02e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.096996 47037596570496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyliy9qgj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac813d24e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.097020 47379084178304 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf32nwqqq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b179611be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.097352 47312245654400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.097426 47797098894208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.097437 47037596570496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.097472 47379084178304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.099446 46913695478656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.099591 47151877673856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.102300 47312245654400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.102371 47797098894208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.102707 47037596570496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.102708 47379084178304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.116244 47418784306048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.116491 47261021168512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.118684 46913695478656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.118895 47151877673856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.120542 47418784306048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:38.120770 47261021168512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:38.121878 47797098894208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.121995 47312245654400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880838.027512 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.028375 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.029192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.121864 47818587288448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.027963 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.028811 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.029562 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.122037 47122918802304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.122983 47818587288448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppn6b0tga
W0618 12:00:38.123066 47122918802304 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpddc6xjgl
I0618 12:00:38.123988 47818587288448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppn6b0tga', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7dea7efe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.124059 47122918802304 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpddc6xjgl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbf16c5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.124396 47818587288448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.124466 47122918802304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.124389 47037596570496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.124381 47379084178304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:38.125590 47418784306048 estimator.py:1111] Calling model_fn.
W0618 12:00:38.125698 47418784306048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:38.125804 47261021168512 estimator.py:1111] Calling model_fn.
W0618 12:00:38.125914 47261021168512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:38.127058 47418784306048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:38.127262 47261021168512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:38.129158 47818587288448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.129169 47122918802304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880838.031515 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.032374 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.033223 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.133781 47221047341952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.031518 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.032442 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.033277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.133897 47268534547328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.134796 47221047341952 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf68h2xw1
W0618 12:00:38.134835 47268534547328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdl4w3wzi
I0618 12:00:38.135849 47221047341952 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf68h2xw1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af2ca570e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.136046 47268534547328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdl4w3wzi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afdd8cc4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.136294 47221047341952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.136507 47268534547328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.141180 47221047341952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.141258 47268534547328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880838.071128 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.071702 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.072152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.143813 47803398886272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.066135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.066695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.067172 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.144432 47167720752000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.070844 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.071307 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.071714 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.144367 47879225533312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.070946 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.071400 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.071803 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.144429 47855992451968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.144797 47803398886272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfih8ghd4
I0618 12:00:38.145766 47803398886272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfih8ghd4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a61325da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:38.145397 47167720752000 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi84euntl
I0618 12:00:38.146166 47803398886272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.145350 47879225533312 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeidj_qiv
W0618 12:00:38.145404 47855992451968 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf_oy_tpx
I0618 12:00:38.146368 47167720752000 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi84euntl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae65fd3de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.146333 47879225533312 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeidj_qiv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c08d13e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.146373 47855992451968 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf_oy_tpx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86a0048e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.146764 47167720752000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.146729 47879225533312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.146770 47855992451968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880838.055816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.056600 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.057288 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.148139 47345298695040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880838.053932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.054661 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.055405 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.148234 47736210670464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.148757 47818587288448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.148802 47122918802304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.149244 47345298695040 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwj4xjrx5
I0618 12:00:38.149382 47736210670464 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6abc779d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.150351 47345298695040 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwj4xjrx5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fb84c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.150636 47736210670464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:38.150802 47345298695040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.150794 47803398886272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.151272 47167720752000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.151339 47879225533312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.151367 47855992451968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.156126 47736210670464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.156167 47345298695040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:38.160677 47221047341952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.160848 47268534547328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.166073 46913695478656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.166592 47151877673856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.169706 47797098894208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.170145 47803398886272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.170158 47312245654400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.170358 46913695478656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:38.170662 47167720752000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.170496 47879225533312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.170617 47855992451968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:38.170903 47151877673856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:38.172841 47379084178304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.172978 47037596570496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:38.174026 47797098894208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880838.103465 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.103967 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.104394 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.173870 47921209029504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.174485 47312245654400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:00:38.175380 46913695478656 estimator.py:1111] Calling model_fn.
W0618 12:00:38.175488 46913695478656 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:38.174888 47921209029504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpr0qzyzq2
I0618 12:00:38.175873 47921209029504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpr0qzyzq2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95cf3a7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:38.175987 47151877673856 estimator.py:1111] Calling model_fn.
W0618 12:00:38.176100 47151877673856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880838.107029 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.107483 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.107875 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.175959 47868304491392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:00:38.176288 47921209029504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.176824 46913695478656 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:38.177144 47379084178304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:38.177280 47037596570496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:38.177464 47151877673856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:38.176937 47868304491392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8jlqqz_j
I0618 12:00:38.177912 47868304491392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8jlqqz_j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b897ddf4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:38.178294 47345298695040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:38.178309 47868304491392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:38.178469 47736210670464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:38.179087 47797098894208 estimator.py:1111] Calling model_fn.
W0618 12:00:38.179197 47797098894208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:38.179608 47312245654400 estimator.py:1111] Calling model_fn.
W0618 12:00:38.179718 47312245654400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:38.180564 47797098894208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880838.102015 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.102584 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.103059 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.180554 47635772830592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.180998 47921209029504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880838.109591 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880838.110077 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880838.110521 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:38.180970 47917252531072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:38.181088 47312245654400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:38.181560 47635772830592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjhdima7q
I0618 12:00:38.182193 47379084178304 estimator.py:1111] Calling model_fn.
W0618 12:00:38.182303 47379084178304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:38.182323 47037596570496 estimator.[2019-06-18 12:01:17] divide_golden_chunk finished: 3.303 seconds
[2019-06-18 12:01:17] generate golden chunk: 3.317 seconds
[2019-06-18 12:01:17] iteration time 16: 48.993 seconds
2019-06-18 12:01:18.476076: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
Got 342800 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000009.tfrecord.zz: 13.205 seconds
Got 377347 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000004.tfrecord.zz: 14.184 seconds
Got 380116 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000005.tfrecord.zz: 15.044 seconds
Got 347710 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000006.tfrecord.zz: 13.974 seconds
Got 390823 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000000.tfrecord.zz: 15.105 seconds
Got 383197 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000002.tfrecord.zz: 14.932 seconds
Got 347566 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000007.tfrecord.zz: 14.443 seconds
Got 346341 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000008.tfrecord.zz: 13.679 seconds
Got 389066 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000003.tfrecord.zz: 14.919 seconds
Got 388250 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000000-000001.tfrecord.zz: 11.607 seconds
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/checkpoint_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/checkpointlog.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000001-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000001-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000002-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000002-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000003-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000003-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000004-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000004-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000005-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000005-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000006-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000006-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000007-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000007-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000008-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000008-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000009-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000009-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000010-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000010-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000011-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000011-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000012-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000012-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000013-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000013-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000014-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000014-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000015-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000015-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000016-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000016-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000017-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000017-000010log.txt['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880877.469651 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:01:21] minmax time: 3.230 seconds
2019-06-18 12:01:21.716895: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:01:21.722346: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:01:21.726903: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880881.740106 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 16}}
[2019-06-18 12:01:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000018-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:01:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=18 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=1023779849 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=2047559680 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=3071339511 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=4095119342 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=5118899173 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=6142679004 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=7166458835 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=8190238666 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=9214018497 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=10237798328 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=11261578159 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=12285357990 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=13309137821 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=14332917652 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=15356697483 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=16380477314 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=17404257145 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=18428036976 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=19451816807 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000017-000010 --seed=20475596638 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:01:31] eval finished: 10.099 seconds
[2019-06-18 12:01:31] Win rate 000017-000010 vs 000015-000009: 0.580
:::MLL 1560880891.898009 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:01:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=19 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=1023779850 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=2047559681 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=3071339512 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=4095119343 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=5118899174 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=6142679005 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=7166458836 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=8190238667 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=9214018498 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=10237798329 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=11261578160 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=12285357991 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=13309137822 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=14332917653 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=15356697484 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=16380477315 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=17404257146 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000018-000009 --seed=18428036977 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:02:03] selfplay finished: 31.962 seconds
[2019-06-18 12:02:03] selfplay mn: 31.980 seconds
[2019-06-18 12:02:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-19-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779850 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559681 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339512 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119343 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899174 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679005 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458836 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238667 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018498 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798329 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578160 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357991 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137822 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917653 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697484 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477315 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257146 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036977 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816808 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596639 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376470 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156301 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000018-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:02:05] train finished: 43.343 seconds
:::MLL 1560880887.024096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.024828 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.025512 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.117250 47725203436416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.020135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.021066 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.021745 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.117329 47553718100864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.118270 47725203436416 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps0_f7gre
W0618 12:01:27.118308 47553718100864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpopqqx9t4
I0618 12:01:27.119282 47725203436416 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps0_f7gre', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b682c628e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.119306 47553718100864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpopqqx9t4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b403f0fee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.119687 47725203436416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:27.119711 47553718100864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880887.029178 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.029909 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.030582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.119408 47280498553728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.019288 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.020223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.021111 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.119774 46958506435456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.120551 47280498553728 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpo69jmlvc
W0618 12:01:27.120853 46958506435456 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4glhttl3
I0618 12:01:27.121652 47280498553728 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpo69jmlvc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00a1e87e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.121960 46958506435456 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4glhttl3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab5a9aebda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.122102 47280498553728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:27.122415 46958506435456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.124678 47725203436416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.124699 47553718100864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.127436 47280498553728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.127660 46958506435456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880887.039928 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.040631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.041277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.130103 47627908371328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.032254 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.033139 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.033995 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.130218 47102459257728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.131165 47627908371328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4uf9lg19
W0618 12:01:27.131194 47102459257728 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9ghgs8al
I0618 12:01:27.132235 47627908371328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4uf9lg19', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5185259e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.132248 47102459257728 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9ghgs8al', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad72df07e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.132644 47627908371328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:27.132652 47102459257728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.137644 47627908371328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.137662 47102459257728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880887.054786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.055548 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.056235 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.138657 47910372414336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.045644 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.046554 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.047386 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.139165 47402011440000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.139680 47910372414336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpumqnja3f
I0618 12:01:27.140691 47910372414336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpumqnja3f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b934950ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:27.140170 47402011440000 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9nb3zfcd
I0618 12:01:27.141095 47910372414336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:27.141176 47402011440000 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9nb3zfcd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ceca3fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.141586 47402011440000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.143922 47553718100864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.143900 47725203436416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.146228 47910372414336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.146553 47402011440000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.149497 47280498553728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.149957 46958506435456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.157074 47102459257728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.157228 47627908371328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880887.058398 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.059134 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.059861 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.157955 47984301024128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.049587 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.050509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.051386 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.158075 47522376319872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.158963 47984301024128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx0wjbsva
W0618 12:01:27.159050 47522376319872 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpc_9jjcww
I0618 12:01:27.159970 47984301024128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx0wjbsva', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba47fcdfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.160074 47522376319872 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpc_9jjcww', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38f2f25da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.160420 47984301024128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:27.160567 47522376319872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.165370 47984301024128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.165435 47522376319872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.165602 47910372414336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.165833 47402011440000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880887.101799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.102229 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.102612 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.166725 47414951793536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.167753 47414951793536 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpno_78wlt
I0618 12:01:27.168811 47414951793536 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpno_78wlt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1feff22e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.169239 47414951793536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880887.099344 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.099867 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.100314 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.169705 47571510383488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.170707 47571510383488 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5t2806lm
I0618 12:01:27.171714 47571510383488 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5t2806lm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4463909e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.172120 47571510383488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880887.104495 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.105120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.105510 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.172217 47812418327424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.173174 47812418327424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_1oio49q
I0618 12:01:27.174151 47812418327424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_1oio49q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c7acc2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:27.174301 47414951793536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:01:27.174550 47812418327424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.176797 47571510383488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.179082 47812418327424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880887.106735 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.107155 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.107520 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.179972 47408383071104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.180944 47408383071104 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2ay7x4jv
I0618 12:01:27.181919 47408383071104 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2ay7x4jv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e686b6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.182311 47408383071104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.184633 47984301024128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.185160 47522376319872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.186875 47408383071104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880887.111927 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.112405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.112831 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.189733 47737597256576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.110990 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.111503 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.112042 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.189859 47792678699904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.190742 47737597256576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmftru1v_
W0618 12:01:27.190843 47792678699904 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp71t2j2wz
I0618 12:01:27.191741 47737597256576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmftru1v_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b0f1d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880887.117645 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.118077 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.118455 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.191527 47917127320448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:01:27.191841 47792678699904 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp71t2j2wz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77e2394e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880887.112628 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.113131 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.113573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.191475 47877287773056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:01:27.192134 47737597256576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.192118 47553718100864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:01:27.192235 47792678699904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.192142 47725203436416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:27.192488 47877287773056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpc5k1mvg1
W0618 12:01:27.192521 47917127320448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf7ys_a9y
I0618 12:01:27.193479 47877287773056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpc5k1mvg1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8b95515e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.193518 47917127320448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf7ys_a9y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94dbf09e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:27.193560 47414951793536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:01:27.193873 47877287773056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:27.193913 47917127320448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.196004 47571510383488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.196421 47553718100864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:27.196454 47725203436416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:27.196771 47737597256576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.196842 47792678699904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.197915 47812418327424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.198535 47877287773056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.198543 47917127320448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.199225 47280498553728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:27.200144 46958506435456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:01:27.201472 47553718100864 estimator.py:1111] Calling model_fn.
I0618 12:01:27.201537 47725203436416 estimator.py:1111] Calling model_fn.
W0618 12:01:27.201581 47553718100864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:27.201643 47725203436416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:27.202930 47553718100864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:27.202998 47725203436416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:27.203504 47280498553728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:27.204505 46958506435456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:27.205215 47102459257728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:27.205518 47627908371328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:27.205965 47408383071104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880887.127376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.127931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.128470 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.208046 47982962439040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:01:27.208567 47280498553728 estimator.py:1111] Calling model_fn.
W0618 12:01:27.208674 47280498553728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:27.209546 47102459257728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:01:27.209656 46958506435456 estimator.py:1111] Calling model_fn.
W0618 12:01:27.209769 46958506435456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:27.209849 47627908371328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880887.133008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.133479 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.133893 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.209671 47353618228096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.209062 47982962439040 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_q4ecvfv
I0618 12:01:27.210057 47982962439040 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_q4ecvfv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba43004ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:27.210030 47280498553728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:01:27.210466 47982962439040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.211146 46958506435456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:27.210629 47353618228096 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpg5es9q7e
I0618 12:01:27.211620 47353618228096 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpg5es9q7e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11a82e3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:27.212021 47353618228096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:27.213735 47402011440000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:27.213788 47910372414336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:01:27.214681 47102459257728 estimator.py:1111] Calling model_fn.
W0618 12:01:27.214794 47102459257728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:01:27.214945 47627908371328 estimator.py:1111] Calling model_fn.
W0618 12:01:27.215054 47627908371328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:27.215215 47982962439040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:27.215945 47737597256576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.215956 47792678699904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.216170 47102459257728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:27.216407 47627908371328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:27.216668 47353618228096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880887.106622 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.107347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.108163 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.216833 47344879850368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560880887.108574 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880887.109323 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880887.110020 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:27.216868 47300107404160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:01:27.217635 47917127320448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.217684 47877287773056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:27.218039 47402011440000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:27.218107 47910372414336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:01:[2019-06-18 12:02:07] divide_golden_chunk finished: 3.294 seconds
[2019-06-18 12:02:07] generate golden chunk: 3.308 seconds
[2019-06-18 12:02:07] moving /lfs/lfs12/gma_akey/results/epb269/models/000018-000010.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000018-000011.data-00000-of-00001
[2019-06-18 12:02:07] moving /lfs/lfs12/gma_akey/results/epb269/models/000018-000010.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000018-000011.meta
[2019-06-18 12:02:07] moving /lfs/lfs12/gma_akey/results/epb269/models/000018-000010.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb
[2019-06-18 12:02:07] moving /lfs/lfs12/gma_akey/results/epb269/models/000018-000010.index --> /lfs/lfs12/gma_akey/results/epb269/models/000018-000011.index
[2019-06-18 12:02:07] iteration time 17: 49.756 seconds
2019-06-18 12:02:08.275064: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880927.225383 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:02:11] minmax time: 3.246 seconds
2019-06-18 12:02:11.530923: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:02:11.536302: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:02:11.540934: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880931.552765 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 17}}
[2019-06-18 12:02:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:02:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=19 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=1023779850 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=2047559681 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=3071339512 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=4095119343 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=5118899174 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=6142679005 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=7166458836 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=8190238667 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=9214018498 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=10237798329 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=11261578160 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=12285357991 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=13309137822 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=14332917653 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=15356697484 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=16380477315 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=17404257146 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=18428036977 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=19451816808 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000018-000011 --seed=20475596639 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:02:22] eval finished: 10.697 seconds
[2019-06-18 12:02:22] Win rate 000018-000011 vs 000017-000010: 0.300
:::MLL 1560880942.310955 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:02:22] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=20 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=1023779851 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=2047559682 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=3071339513 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=4095119344 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=5118899175 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=6142679006 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=7166458837 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=8190238668 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=9214018499 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=10237798330 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=11261578161 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=12285357992 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=13309137823 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=14332917654 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=15356697485 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=16380477316 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=17404257147 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000019-000010 --seed=18428036978 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:02:53] selfplay finished: 30.907 seconds
[2019-06-18 12:02:53] selfplay mn: 30.927 seconds
[2019-06-18 12:02:53] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-20-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779851 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559682 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339513 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119344 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899175 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679006 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458837 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238668 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018499 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798330 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578161 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357992 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137823 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917654 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697485 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477316 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257147 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036978 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816809 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596640 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376471 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156302 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000019-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:02:54] train finished: 43.400 seconds
:::MLL 1560880936.869948 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.870668 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.871346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.963326 47746144379776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.856988 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.857872 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.858741 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.963356 47175325356928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:16.964355 47746144379776 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp05fhexj5
W0618 12:02:16.964385 47175325356928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9kk3kiug
I0618 12:02:16.965358 47746144379776 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp05fhexj5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d0c8ffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.965373 47175325356928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9kk3kiug', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae82518ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.965759 47746144379776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:16.965773 47175325356928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880936.862783 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.863528 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.864194 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.969606 47150482944896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.860014 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.860754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.861439 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.969717 47648549593984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:16.970537 47746144379776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.970501 47175325356928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.970656 47150482944896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7uo10ck_
W0618 12:02:16.970733 47648549593984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprra5s41_
I0618 12:02:16.971737 47150482944896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7uo10ck_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae25c5fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.971807 47648549593984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprra5s41_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b565375be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.972129 47150482944896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:16.972199 47648549593984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:16.976887 47150482944896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.976917 47648549593984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880936.888109 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.888868 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.889564 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.983684 47913775973248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.877038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.877942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.878842 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.983672 47087054140288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:16.984683 47913775973248 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps9snwoih
W0618 12:02:16.984713 47087054140288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpuny9lmah
I0618 12:02:16.985748 47913775973248 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps9snwoih', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94142f0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.985780 47087054140288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpuny9lmah', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad397b90e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.986208 47913775973248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:16.986232 47087054140288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880936.877600 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.878328 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.879004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.986027 47307410064256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.872519 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.873438 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.874292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.986138 47979313701760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:16.987183 47307410064256 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpoj5d439b
W0618 12:02:16.987231 47979313701760 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6zo9oh2d
I0618 12:02:16.988319 47979313701760 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6zo9oh2d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba356897e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.988326 47307410064256 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpoj5d439b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06e5f59da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:16.988765 47979313701760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:16.988778 47307410064256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:16.989848 47175325356928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:16.990304 47746144379776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:16.990978 47087054140288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.991014 47913775973248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.994068 47979313701760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.994078 47307410064256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:16.996039 47150482944896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:16.996255 47648549593984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880936.887874 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.888757 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.889609 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.999001 47365260735360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.901386 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.902108 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.902781 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:16.999151 46955013436288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.000035 47365260735360 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp91kg8mcw
W0618 12:02:17.000142 46955013436288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfb0ik3rn
I0618 12:02:17.001042 47365260735360 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp91kg8mcw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b145e20ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.001146 46955013436288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfb0ik3rn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4d97bce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.001451 47365260735360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:17.001582 46955013436288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.006430 46955013436288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.006424 47365260735360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.010365 47087054140288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.010699 47913775973248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880936.931833 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.932307 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.932732 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.011944 47055375897472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.922727 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.923267 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.923737 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.011926 46941772780416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.012977 47055375897472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpj6tqnwl2
W0618 12:02:17.013006 46941772780416 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps69ot09f
I0618 12:02:17.013963 47055375897472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpj6tqnwl2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc378d6da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.013983 46941772780416 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps69ot09f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1c4476e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.014364 47055375897472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:17.014376 46941772780416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.015909 47979313701760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.016061 47307410064256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.019029 47055375897472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.018996 46941772780416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880936.947257 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.947801 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.948288 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.022221 47417519301504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.951412 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.951814 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.952178 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.022723 46985035592576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.023231 47417519301504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpku1345no
I0618 12:02:17.024213 47417519301504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpku1345no', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2088fb2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:17.023688 46985035592576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp768sdyjl
I0618 12:02:17.024615 47417519301504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:17.024680 46985035592576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp768sdyjl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abbd6f18e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.025069 46985035592576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.025685 47365260735360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.025830 46955013436288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.029234 47417519301504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.029633 46985035592576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.037385 47175325356928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880936.954821 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.955234 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.955599 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.037188 47690081846144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560880936.955087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.955655 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.956127 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.037380 47580827370368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.037868 47746144379776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:17.037958 46941772780416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.038173 47055375897472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880936.953815 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.954235 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.954665 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.037988 47532128293760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.038215 47690081846144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp94o08dci
:::MLL 1560880936.965617 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.966063 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.966461 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.039046 47650952909696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
I0618 12:02:17.039219 47690081846144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp94o08dci', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5ffef98e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:17.038454 47580827370368 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptddi6i2f
I0618 12:02:17.039510 47580827370368 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptddi6i2f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b468ee69e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.039621 47690081846144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.038962 47532128293760 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnm_6wpme
I0618 12:02:17.039930 47580827370368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:17.039948 47532128293760 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnm_6wpme', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b3835ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.040338 47532128293760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.040079 47650952909696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpd2ajcszd
I0618 12:02:17.041131 47650952909696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpd2ajcszd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b56e2b55e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.041563 47650952909696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.041680 47175325356928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.042171 47746144379776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.043803 47150482944896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880936.966237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.966717 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.967214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.044072 47905076917120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.044375 47648549593984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:17.044314 47690081846144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.044853 47580827370368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.045050 47532128293760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.045171 47905076917120 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5rvvm54i
I0618 12:02:17.046246 47905076917120 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5rvvm54i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b920dadfdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:17.046379 47650952909696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:02:17.046682 47905076917120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:17.046735 47175325356928 estimator.py:1111] Calling model_fn.
W0618 12:02:17.046845 47175325356928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:17.047271 47746144379776 estimator.py:1111] Calling model_fn.
W0618 12:02:17.047387 47746144379776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:17.048093 47150482944896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.048192 47175325356928 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:17.048318 47417519301504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.048745 47746144379776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:17.048734 46985035592576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.048709 47648549593984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.051660 47905076917120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:02:17.053169 47150482944896 estimator.py:1111] Calling model_fn.
W0618 12:02:17.053277 47150482944896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:17.053825 47648549593984 estimator.py:1111] Calling model_fn.
W0618 12:02:17.053934 47648549593984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880936.967437 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880936.967900 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880936.968302 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:17.053900 46932129567616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:02:17.054630 47150482944896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:17.055287 47648549593984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:17.054893 46932129567616 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2bv27nzu
I0618 12:02:17.055877 46932129567616 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2bv27nzu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf857fae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:17.056269 46932129567616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:17.058198 47913775973248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:17.058320 47087054140288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:17.060918 46932129567616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:17.062460 47913775973248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.062649 47087054140288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.063581 47690081846144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.064762 47532128293760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.065494 47580827370368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.065424 47979313701760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:17.066066 47307410064256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:17.067054 47650952909696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:02:17.067495 47913775973248 estimator.py:1111] Calling model_fn.
W0618 12:02:17.067602 47913775973248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:17.067748 47087054140288 estimator.py:1111] Calling model_fn.
W0618 12:02:17.067854 47087054140288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:17.068954 47913775973248 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:17.069191 47087054140288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:17.069908 47979313701760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.070674 47307410064256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:17.071118 47905076917120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:17.073742 47365260735360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
   [2019-06-18 12:02:56] divide_golden_chunk finished: 3.315 seconds
[2019-06-18 12:02:56] generate golden chunk: 3.330 seconds
[2019-06-18 12:02:56] iteration time 18: 49.344 seconds
2019-06-18 12:02:57.658919: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880976.569551 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:03:00] minmax time: 3.238 seconds
2019-06-18 12:03:00.906856: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:03:00.912366: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:03:00.917054: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880980.930167 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 18}}
[2019-06-18 12:03:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:03:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=20 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=1023779851 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=2047559682 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=3071339513 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=4095119344 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=5118899175 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=6142679006 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=7166458837 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=8190238668 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=9214018499 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=10237798330 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=11261578161 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=12285357992 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=13309137823 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=14332917654 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=15356697485 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=16380477316 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=17404257147 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=18428036978 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=19451816809 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000019-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000019-000011 --seed=20475596640 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:03:11] eval finished: 10.442 seconds
[2019-06-18 12:03:11] Win rate 000019-000011 vs 000017-000010: 0.430
:::MLL 1560880991.432626 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:03:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=21 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=1023779852 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=2047559683 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=3071339514 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=4095119345 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=5118899176 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=6142679007 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=7166458838 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=8190238669 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=9214018500 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=10237798331 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=11261578162 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=12285357993 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=13309137824 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=14332917655 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=15356697486 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=16380477317 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=17404257148 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000020-000010 --seed=18428036979 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:03:41] selfplay finished: 30.398 seconds
[2019-06-18 12:03:41] selfplay mn: 30.416 seconds
[2019-06-18 12:03:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-21-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779852 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559683 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339514 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119345 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899176 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679007 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458838 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238669 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018500 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798331 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578162 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357993 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137824 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917655 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697486 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477317 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257148 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036979 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816810 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596641 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376472 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156303 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000020-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:03:44] train finished: 43.561 seconds
:::MLL 1560880986.205990 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.206738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.207409 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.297441 47794222273408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.194771 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.195673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.196507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.297458 47825230672768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.298531 47794222273408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1qu9gt79
W0618 12:03:06.298559 47825230672768 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi9mgt955
I0618 12:03:06.299518 47794222273408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1qu9gt79', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b783e3a5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.299536 47825230672768 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi9mgt955', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f76790e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.299921 47794222273408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.299937 47825230672768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.304930 47794222273408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.304962 47825230672768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880986.235430 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.236197 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.236931 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.323886 47528746603392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.221712 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.222616 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.223478 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.324040 47129205384064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.324199 47825230672768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.324331 47794222273408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.325028 47528746603392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx4ot8uii
W0618 12:03:06.325117 47129205384064 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpue0yviqe
I0618 12:03:06.326025 47528746603392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx4ot8uii', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a6ea52e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.326105 47129205384064 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpue0yviqe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add6821fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.326428 47528746603392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.326499 47129205384064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.331195 47129205384064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.331212 47528746603392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880986.206362 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.207125 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.207846 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.331298 47721626174336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.208298 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.209071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.209738 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.331537 47238952010624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.332324 47721626174336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpav0b00dy
W0618 12:03:06.332506 47238952010624 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxzcdarov
I0618 12:03:06.333331 47721626174336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpav0b00dy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b675729ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.333501 47238952010624 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxzcdarov', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af6f58a8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.333763 47721626174336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.333932 47238952010624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.338604 47721626174336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.338673 47238952010624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.350743 47528746603392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.350709 47129205384064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880986.275708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.276179 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.276632 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.351882 46913194681216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.277779 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.278215 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.278588 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.352239 47120632464256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.352901 46913194681216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3l8nbpqg
I0618 12:03:06.353863 46913194681216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3l8nbpqg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab1ce43dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:06.353219 47120632464256 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8mo2a1ms
I0618 12:03:06.354221 47120632464256 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8mo2a1ms', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adb69257e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.354258 46913194681216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.354620 47120632464256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880986.231038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.231902 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.232563 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.357686 47770458493824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.234779 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.235497 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.236184 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.357845 46941372011392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.358103 47721626174336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.358459 47238952010624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.358867 46913194681216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.359237 47120632464256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.358695 47770458493824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0b_pejmi
W0618 12:03:06.358850 46941372011392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp07obwtsh
I0618 12:03:06.359699 47770458493824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0b_pejmi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72b5cbee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.359838 46941372011392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp07obwtsh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1ac642e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.360094 47770458493824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.360239 46941372011392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880986.233784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.234676 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.235533 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.364094 47092259550080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.251517 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.252254 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.253006 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.364142 46934041195392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.365048 47770458493824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.365141 46941372011392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.365224 47092259550080 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgrh5y5b3
W0618 12:03:06.365337 46934041195392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpg1qbpdgv
I0618 12:03:06.366323 47092259550080 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgrh5y5b3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad4cdfd4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.366415 46934041195392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpg1qbpdgv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaff770bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.366771 47092259550080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.366863 46934041195392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.372090 47092259550080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.372113 46934041195392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.372202 47825230672768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:06.372324 47794222273408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880986.273732 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.274187 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.274593 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.376368 47264856142720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.376521 47825230672768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880986.268695 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.269238 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.269733 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.376347 47932188967808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.376658 47794222273408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:06.377853 46913194681216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.377361 47932188967808 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqg6f3v4m
W0618 12:03:06.377396 47264856142720 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_4lwim2y
I0618 12:03:06.378338 47932188967808 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqg6f3v4m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b985daf0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:06.378364 47120632464256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:03:06.378374 47264856142720 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_4lwim2y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afcfd8c4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.378741 47932188967808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.378772 47264856142720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880986.297652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.298124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.298548 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.379861 47002566509440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.296431 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.296894 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.297323 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.379924 47237041177472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
I0618 12:03:06.381580 47825230672768 estimator.py:1111] Calling model_fn.
W0618 12:03:06.381696 47825230672768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:06.381713 47794222273408 estimator.py:1111] Calling model_fn.
W0618 12:03:06.380961 47002566509440 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdm7wlzpx
W0618 12:03:06.381822 47794222273408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:06.380989 47237041177472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm_pzqkuf
I0618 12:03:06.381944 47002566509440 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdm7wlzpx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abfebde1da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.381953 47237041177472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm_pzqkuf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af683a59da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.382348 47237041177472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.382354 47002566509440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.383055 47825230672768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:06.383177 47794222273408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:06.383422 47264856142720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.383429 47932188967808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.384247 46941372011392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.384419 47770458493824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.387044 47237041177472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.387051 47002566509440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880986.301355 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.302112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.302829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.390170 47304856527744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880986.288654 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.289586 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.290490 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.390427 47369287701376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
I0618 12:03:06.391324 47304856527744 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b064dc1bd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:06.391525 47369287701376 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphvm33lwi
I0618 12:03:06.392576 47304856527744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.392659 47369287701376 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphvm33lwi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b154e276dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.393124 47369287701376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.394103 47092259550080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.394189 46934041195392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.398249 47304856527744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.398203 47129205384064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:06.398471 47528746603392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:06.398550 47369287701376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.402488 47129205384064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:06.402576 47264856142720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.402740 47932188967808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.402759 47528746603392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:06.405770 47721626174336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880986.304437 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.304981 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.305463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.405663 47966517437312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.406020 47002566509440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.406296 47238952010624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:06.406338 47237041177472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880986.308696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.309167 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.309577 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.406565 47449142223744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.406651 47966517437312 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9mn6dply
I0618 12:03:06.407510 47129205384064 estimator.py:1111] Calling model_fn.
W0618 12:03:06.407620 47129205384064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:06.407628 47966517437312 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9mn6dply', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba05bd1fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.407802 47528746603392 estimator.py:1111] Calling model_fn.
W0618 12:03:06.407912 47528746603392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:06.408021 47966517437312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880986.303564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.304044 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.304473 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.407989 47053896946560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:06.407562 47449142223744 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp424wv33f
:::MLL 1560880986.303581 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880986.304058 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880986.304482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:06.408076 47425345766272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000010-000005.tfrecord.zz_0_0
I0618 12:03:06.408536 47449142223744 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp424wv33f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27e5dabe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:06.408958 47129205384064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:03:06.408937 47449142223744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.409270 47528746603392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:06.409024 47053896946560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4_2o5i_3
W0618 12:03:06.409085 47425345766272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnx8xcect
I0618 12:03:06.410019 47053896946560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4_2o5i_3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbdf665e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:06.410080 47721626174336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:03:06.410076 47425345766272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnx8xcect', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b225b799da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:06.410413 47053896946560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:06.410472 47425345766272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:06.410642 47238952010624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:06.412780 47966517437312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.413515 47449142223744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:03:06.415128 47721626174336 estimator.py:1111] Calling model_fn.
W0618 12:03:06.415108 47053896946560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:06.415238 47721626174336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:06.415129 47425345766272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:03:06.415703 47238952010624 estimator.py:1111] Calling model_fn.
W0618 12:03:06.415810 47238952010624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:06.416588 47721626174336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:06.417160 47238952010624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:06.420432 47304856527744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:06.420570 47369287701376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.[2019-06-18 12:03:45] divide_golden_chunk finished: 3.307 seconds
[2019-06-18 12:03:45] generate golden chunk: 3.321 seconds
[2019-06-18 12:03:45] iteration time 19: 48.602 seconds
2019-06-18 12:03:46.303054: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881025.171339 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:03:49] minmax time: 3.237 seconds
2019-06-18 12:03:49.549720: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:03:49.555267: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:03:49.559887: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881029.573687 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 19}}
[2019-06-18 12:03:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000021-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:03:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=21 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=1023779852 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=2047559683 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=3071339514 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=4095119345 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=5118899176 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=6142679007 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=7166458838 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=8190238669 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=9214018500 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=10237798331 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=11261578162 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=12285357993 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=13309137824 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=14332917655 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=15356697486 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=16380477317 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=17404257148 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=18428036979 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=19451816810 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000020-000011 --seed=20475596641 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:04:00] eval finished: 10.719 seconds
[2019-06-18 12:04:00] Win rate 000020-000011 vs 000017-000010: 0.520
:::MLL 1560881040.352168 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:04:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=22 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=1023779853 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=2047559684 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=3071339515 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=4095119346 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=5118899177 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=6142679008 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=7166458839 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=8190238670 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=9214018501 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=10237798332 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=11261578163 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=12285357994 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=13309137825 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=14332917656 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=15356697487 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=16380477318 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=17404257149 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000021-000010 --seed=18428036980 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:04:29] selfplay finished: 29.577 seconds
[2019-06-18 12:04:29] selfplay mn: 29.597 seconds
[2019-06-18 12:04:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-22-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779853 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559684 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339515 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119346 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899177 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679008 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458839 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238670 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018501 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798332 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578163 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357994 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137825 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917656 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697487 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477318 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257149 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036980 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816811 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596642 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376473 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156304 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000021-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:04:33] divide_golden_chunk finished: 3.250 seconds
[2019-06-18 12:04:33] generate golden chunk: 3.266 seconds
[2019-06-18 12:04:33] train finished: 44.188 seconds
:::MLL 1560881034.855234 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.856149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.857005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:54.960072 46989071385472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.865208 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.865975 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.866639 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:54.960207 47456619135872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:54.961220 46989071385472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3ok65q66
W0618 12:03:54.961319 47456619135872 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz36nhirk
I0618 12:03:54.962310 46989071385472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3ok65q66', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcc77ede10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:54.962430 47456619135872 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz36nhirk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29a3833e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:54.962814 46989071385472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:54.962900 47456619135872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:54.968073 46989071385472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:54.968267 47456619135872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:54.989998 46989071385472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:54.990613 47456619135872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881034.896175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.897075 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.897858 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:54.999148 47376458900352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.900385 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.901091 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.901755 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:54.999114 47803125445504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.000212 47803125445504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcc4azyva
I0618 12:03:55.001200 47803125445504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcc4azyva', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a50e60e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.000253 47376458900352 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp61dwb3j1
I0618 12:03:55.001561 47376458900352 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp61dwb3j1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16f9972e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.001607 47803125445504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.002116 47376458900352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.006346 47803125445504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.008027 47376458900352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881034.937773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.938211 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.938608 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.014870 47195784180608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.015971 47195784180608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpef7hi8qw
I0618 12:03:55.016982 47195784180608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpef7hi8qw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aece889be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.017383 47195784180608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.022187 47195784180608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881034.941505 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.941882 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.942203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.024621 47360518251392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.025586 47803125445504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.025606 47360518251392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpr8v0o9au
I0618 12:03:55.026594 47360518251392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpr8v0o9au', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1343743e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.026991 47360518251392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.028148 47376458900352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.031594 47360518251392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.041501 47195784180608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.042306 46989071385472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.042602 47456619135872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.046956 46989071385472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:55.047235 47456619135872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881034.917895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.918651 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.919312 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.048104 47889388217216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.913317 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.914281 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.915117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.048566 47325377094528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.049103 47889388217216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx_j96z0o
I0618 12:03:55.050187 47889388217216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx_j96z0o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e668f7dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.049602 47325377094528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1i62y0be
I0618 12:03:55.050639 47889388217216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.050698 47325377094528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1i62y0be', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b14e0be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.050765 47360518251392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:03:55.051150 47325377094528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.052424 46989071385472 estimator.py:1111] Calling model_fn.
W0618 12:03:55.052546 46989071385472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:55.052698 47456619135872 estimator.py:1111] Calling model_fn.
W0618 12:03:55.052814 47456619135872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:55.054017 46989071385472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:55.054288 47456619135872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:55.055414 47889388217216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.055749 47325377094528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881034.976721 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.977202 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.977730 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.056629 47503432774528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.979393 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.979821 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.980206 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.057190 47126781399936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.057647 47503432774528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzotkp651
I0618 12:03:55.058621 47503432774528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzotkp651', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3489d2be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.058178 47126781399936 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_7jscmlj
I0618 12:03:55.059015 47503432774528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.059161 47126781399936 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_7jscmlj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcd7a6ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.059566 47126781399936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.063664 47503432774528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.064186 47126781399936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881034.905972 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.906883 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.907575 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.065998 47293047137152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.067102 47293047137152 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprf5cf024
I0618 12:03:55.068118 47293047137152 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprf5cf024', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b038ddcbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.068571 47293047137152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881034.905137 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.906002 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.906813 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.071128 47927995155328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.072215 47927995155328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpepg290nf
I0618 12:03:55.073250 47927995155328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpepg290nf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9763b69e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.073538 47803125445504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:03:55.073661 47927995155328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.073725 47293047137152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.074888 47889388217216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.075198 47325377094528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.075814 47376458900352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.077852 47803125445504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:55.078368 47927995155328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.080124 47376458900352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:55.082786 47503432774528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:03:55.082903 47803125445504 estimator.py:1111] Calling model_fn.
W0618 12:03:55.083014 47803125445504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:55.083330 47126781399936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.084386 47803125445504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:03:55.085205 47376458900352 estimator.py:1111] Calling model_fn.
W0618 12:03:55.085314 47376458900352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:55.086862 47376458900352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881034.936523 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.937292 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.938019 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.087658 47093218542464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.934829 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.935492 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.936306 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.087942 47134146245504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.089053 47195784180608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.088742 47093218542464 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpc36sy7_7
W0618 12:03:55.088990 47134146245504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5t9i4mfg
I0618 12:03:55.089809 47093218542464 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpc36sy7_7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad507264e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.090013 47134146245504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5t9i4mfg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade8ea17e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.090216 47093218542464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.090410 47134146245504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.093201 47293047137152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.093372 47195784180608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:55.094968 47093218542464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.095076 47134146245504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881034.995314 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.995788 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.996188 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.095988 47976388780928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.989518 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.990061 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.990540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.096454 47361878795136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.096977 47976388780928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvhbjz1de
I0618 12:03:55.097954 47976388780928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvhbjz1de', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2a832be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.097430 47361878795136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp394d13td
I0618 12:03:55.098345 47976388780928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.098225 47927995155328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.098177 47360518251392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:03:55.098402 47361878795136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp394d13td', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13948c7dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.098447 47195784180608 estimator.py:1111] Calling model_fn.
W0618 12:03:55.098564 47195784180608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:55.098800 47361878795136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:55.099933 47195784180608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:55.102513 47360518251392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:55.103020 47976388780928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.103546 47361878795136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881034.962499 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.963050 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.963482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.104516 47339131966336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881034.966135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.966658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.967096 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.104806 46991031923584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.105551 47339131966336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp21tgij93
W0618 12:03:55.105832 46991031923584 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplxj3egyg
I0618 12:03:55.106618 47339131966336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp21tgij93', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e48bb3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.106893 46991031923584 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplxj3egyg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd3c5a4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.107035 47339131966336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.107321 46991031923584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.107583 47360518251392 estimator.py:1111] Calling model_fn.
W0618 12:03:55.107689 47360518251392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:55.109043 47360518251392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:55.111833 47339131966336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.112052 46991031923584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:55.114552 47093218542464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.114575 47134146245504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.122144 47976388780928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.122786 47889388217216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.122892 47325377094528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.123043 47361878795136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.127103 47889388217216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:55.127206 47325377094528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881034.995618 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881034.996163 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881034.996637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.128570 47064462476160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881035.000264 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881035.000732 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881035.001150 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:55.128792 47278589580160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:03:55.130345 47503432774528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:55.129603 47064462476160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjxgoqzwy
W0618 12:03:55.129815 47278589580160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptqhdu8nk
I0618 12:03:55.130588 47064462476160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjxgoqzwy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace55278e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:55.130799 47278589580160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptqhdu8nk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00301fdda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:55.130913 47126781399936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:03:55.130989 47064462476160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.131197 47278589580160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:55.132203 47889388217216 estimator.py:1111] Calling model_fn.
I0618 12:03:55.132250 47325377094528 estimator.py:1111] Calling model_fn.
W0618 12:03:55.132314 47889388217216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:55.132357 47325377094528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:55.132285 47339131966336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:55.132477 46991031923584 deprecation.py:323] From ./preprocessing.py:14[2019-06-18 12:04:33] moving /lfs/lfs12/gma_akey/results/epb269/models/000021-000011.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb
[2019-06-18 12:04:33] moving /lfs/lfs12/gma_akey/results/epb269/models/000021-000011.index --> /lfs/lfs12/gma_akey/results/epb269/models/000021-000012.index
[2019-06-18 12:04:33] moving /lfs/lfs12/gma_akey/results/epb269/models/000021-000011.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000021-000012.data-00000-of-00001
[2019-06-18 12:04:33] moving /lfs/lfs12/gma_akey/results/epb269/models/000021-000011.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000021-000012.meta
[2019-06-18 12:04:33] iteration time 20: 48.660 seconds
2019-06-18 12:04:34.995758: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881073.831527 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:04:38] minmax time: 3.253 seconds
2019-06-18 12:04:38.258879: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:04:38.264350: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:04:38.268861: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881078.280782 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 20}}
[2019-06-18 12:04:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:04:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=22 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=1023779853 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=2047559684 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=3071339515 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=4095119346 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=5118899177 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=6142679008 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=7166458839 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=8190238670 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=9214018501 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=10237798332 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=11261578163 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=12285357994 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=13309137825 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=14332917656 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=15356697487 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=16380477318 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=17404257149 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=18428036980 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=19451816811 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000021-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000021-000012 --seed=20475596642 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:04:48] eval finished: 10.246 seconds
[2019-06-18 12:04:48] Win rate 000021-000012 vs 000020-000011: 0.430
:::MLL 1560881088.591799 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:04:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=23 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=1023779854 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=2047559685 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=3071339516 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=4095119347 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=5118899178 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=6142679009 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=7166458840 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=8190238671 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=9214018502 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=10237798333 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=11261578164 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=12285357995 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=13309137826 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=14332917657 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=15356697488 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=16380477319 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=17404257150 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000022-000011 --seed=18428036981 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:05:18] selfplay finished: 29.625 seconds
[2019-06-18 12:05:18] selfplay mn: 29.643 seconds
[2019-06-18 12:05:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-23-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=23 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779854 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559685 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339516 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119347 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899178 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679009 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458840 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238671 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018502 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798333 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578164 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357995 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137826 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917657 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697488 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477319 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257150 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036981 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816812 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596643 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376474 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156305 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000022-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:05:21] divide_golden_chunk finished: 3.343 seconds
[2019-06-18 12:05:21] generate golden chunk: 3.358 seconds
[2019-06-18 12:05:22] train finished: 44.045 seconds
:::MLL 1560881083.580373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.581056 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.581716 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.686729 47051758678912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.569636 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.570549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.571420 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.687554 47163976254336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.687788 47051758678912 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpotz2ntvh
I0618 12:04:43.688821 47051758678912 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpotz2ntvh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb5ff30e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.689228 47051758678912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.688534 47163976254336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjsswjk5y
I0618 12:04:43.689521 47163976254336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjsswjk5y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae580a35e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.689919 47163976254336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.694007 47051758678912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.694805 47163976254336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881083.598757 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.599700 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.600552 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.704937 47999574844288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.705934 47999574844288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpl5zo94o3
I0618 12:04:43.706948 47999574844288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpl5zo94o3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba80e31fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.707354 47999574844288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881083.618484 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.619348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.620114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.710960 47303809258368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.712387 47999574844288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.711953 47303809258368 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptvhax2so
I0618 12:04:43.712930 47303809258368 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptvhax2so', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b060f558e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:43.713258 47051758678912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:43.713335 47303809258368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.715119 47163976254336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.717903 47303809258368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.731831 47999574844288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881083.577833 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.578561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.579219 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.734440 47131870622592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.579443 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.580301 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.581148 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.734768 47133499839360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.586851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.587615 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.588305 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.734828 47818124768128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.570299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.571214 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.572006 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.735097 47828253479808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.735589 47131870622592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpao3x3e7n
I0618 12:04:43.735879 47133499839360 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade681a2d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:43.735870 47818124768128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph02_cf6t
I0618 12:04:43.736698 47131870622592 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpao3x3e7n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade06fe3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.736949 47818124768128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph02_cf6t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7dceed8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:43.736173 47828253479808 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpicuwx98w
I0618 12:04:43.737108 47133499839360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.737175 47131870622592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.737263 47303809258368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:43.737274 47828253479808 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpicuwx98w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b802aa56e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.737425 47818124768128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.737841 47828253479808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881083.648066 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.648534 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.648929 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.739691 47343489905536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.643118 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.643676 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.644183 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.739754 47252061901696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.740751 47343489905536 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmph2qdin8m
W0618 12:04:43.740782 47252061901696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnmrjb63c
I0618 12:04:43.741733 47343489905536 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmph2qdin8m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f4c7c4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.741776 47252061901696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnmrjb63c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa02f39e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.742135 47343489905536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.742178 47252061901696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.742514 47133499839360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.742640 47818124768128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.742572 47131870622592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.742981 47828253479808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.746926 47252061901696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.746927 47343489905536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881083.573843 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.574668 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.575502 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.748385 47883722396544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.574320 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.575189 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.575950 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.748372 47411582690176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.749655 47883722396544 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi3f4fe9x
W0618 12:04:43.749674 47411582690176 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5op1rtz1
I0618 12:04:43.751027 47883722396544 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi3f4fe9x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d14d9ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.751027 47411582690176 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5op1rtz1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f2721be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.751628 47883722396544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.751628 47411582690176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.758317 47883722396544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.758317 47411582690176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.761479 47051758678912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:43.763418 47133499839360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.763607 47818124768128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.764007 47131870622592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.764656 47828253479808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.765659 47163976254336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:43.765827 47051758678912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:43.765993 47252061901696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.765995 47343489905536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881083.679058 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.679536 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.680018 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.767925 47756211913600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.680209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.680694 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.681101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.768060 47447031284608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.574066 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.574794 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.575487 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.768144 47040517772160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.572348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.573076 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.573881 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.768714 47438055875456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.768952 47756211913600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprxyq3sg1
W0618 12:04:43.769046 47447031284608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwchmosg0
W0618 12:04:43.769265 47040517772160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp157s4rav
I0618 12:04:43.769937 47756211913600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprxyq3sg1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6f64a24e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.770018 47447031284608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwchmosg0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2768085da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.770269 47040517772160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp157s4rav', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8c1f05e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.770344 47756211913600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.770370 47163976254336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:43.769752 47438055875456 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxew_o83w
I0618 12:04:43.770417 47447031284608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.770672 47040517772160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.770752 47438055875456 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxew_o83w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25510e7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.770910 47051758678912 estimator.py:1111] Calling model_fn.
W0618 12:04:43.771019 47051758678912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:43.771153 47438055875456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881083.641843 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.642388 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.642872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.771449 47177912443776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.646283 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.646785 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.647198 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.771490 47562983695232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.772367 47051758678912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:43.772456 47177912443776 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5t20nw1v
W0618 12:04:43.772510 47562983695232 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpy1pksb5o
:::MLL 1560881083.646772 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.647184 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.647540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.773076 47257208230784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.642754 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.643255 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.643684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.773086 47965871498112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
I0618 12:04:43.773453 47177912443776 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5t20nw1v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8bf4cbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.773495 47562983695232 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpy1pksb5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b426755bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.773868 47177912443776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.773901 47562983695232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.774137 47257208230784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpn32i5xi8
W0618 12:04:43.774108 47965871498112 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu9g00p3c
I0618 12:04:43.775076 47965871498112 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu9g00p3c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba03551be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.775125 47257208230784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpn32i5xi8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb35b25dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:43.775128 47447031284608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.775130 47756211913600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:43.775482 47965871498112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.775403 47040517772160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:43.775527 47257208230784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881083.648515 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.648919 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.649276 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.775373 47250706260864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
I0618 12:04:43.775827 47163976254336 estimator.py:1111] Calling model_fn.
W0618 12:04:43.775832 47438055875456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.775937 47163976254336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881083.647485 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.647898 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.648248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.775677 47853158007680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.776386 47250706260864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpua8bc4xv
W0618 12:04:43.777405 47163976254336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:43.776631 47853158007680 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6gah4wcb
I0618 12:04:43.777370 47250706260864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpua8bc4xv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af9b2262e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.777613 47853158007680 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6gah4wcb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85f7124da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.777776 47250706260864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.778023 47853158007680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.778676 47562983695232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.778683 47177912443776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.780092 47965871498112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.780169 47257208230784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.780325 47999574844288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:43.782391 47250706260864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.782597 47853158007680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:43.784631 47999574844288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:43.784934 47303809258368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:43.789231 47303809258368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:04:43.789708 47999574844288 estimator.py:1111] Calling model_fn.
W0618 12:04:43.789817 47999574844288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:43.791183 47999574844288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:43.791205 47883722396544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.791205 47411582690176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:43.794272 47303809258368 estimator.py:1111] Calling model_fn.
W0618 12:04:43.794319 47756211913600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.794377 47303809258368 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:43.794385 47447031284608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.794572 47040517772160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.795242 47438055875456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881083.627517 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.627986 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.628411 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.795219 47362115818368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881083.626795 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881083.627331 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881083.627730 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:43.795215 47863963517824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:43.795723 47303809258368 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:43.796218 47362115818368 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgrqxgfh9
W0618 12:04:43.796250 47863963517824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgxgb0aaz
I0618 12:04:43.797198 47362115818368 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgrqxgfh9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13a2ad2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.797230 47863963517824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgxgb0aaz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b887b214e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:43.797594 47362115818368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:43.797633 47863963517824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:43.797813 47562983695232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.797848 47177912443776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.799110 47965871498112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.799223 47257208230784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:43.801450 4725070626086[2019-06-18 12:05:22] iteration time 21: 48.516 seconds
2019-06-18 12:05:23.591228: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881122.347300 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:05:26] minmax time: 3.240 seconds
2019-06-18 12:05:26.841699: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:05:26.847247: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:05:26.851837: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881126.865617 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 21}}
[2019-06-18 12:05:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000023-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:05:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=23 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=1023779854 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=2047559685 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=3071339516 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=4095119347 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=5118899178 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=6142679009 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=7166458840 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=8190238671 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=9214018502 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=10237798333 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=11261578164 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=12285357995 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=13309137826 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=14332917657 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=15356697488 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=16380477319 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=17404257150 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=18428036981 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=19451816812 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000020-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000022-000012 --seed=20475596643 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:05:37] eval finished: 10.238 seconds
[2019-06-18 12:05:37] Win rate 000022-000012 vs 000020-000011: 0.580
:::MLL 1560881137.164016 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:05:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=24 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=1023779855 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=2047559686 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=3071339517 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=4095119348 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=5118899179 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=6142679010 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=7166458841 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=8190238672 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=9214018503 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=10237798334 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=11261578165 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=12285357996 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=13309137827 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=14332917658 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=15356697489 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=16380477320 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=17404257151 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000023-000011 --seed=18428036982 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:06:07] selfplay finished: 30.151 seconds
[2019-06-18 12:06:07] selfplay mn: 30.169 seconds
[2019-06-18 12:06:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-24-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=24 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779855 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559686 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339517 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119348 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899179 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679010 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458841 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238672 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018503 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798334 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578165 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357996 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137827 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917658 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697489 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477320 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257151 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036982 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816813 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596644 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376475 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156306 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000023-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:06:10] train finished: 43.737 seconds
:::MLL 1560881132.193584 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.194324 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.195043 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.302754 47981242110848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.195744 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.196498 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.197190 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.302834 47149196878720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.303864 47981242110848 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpl53q_1ul
W0618 12:05:32.303892 47149196878720 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgs1_07tt
I0618 12:05:32.304982 47981242110848 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpl53q_1ul', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3c97a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881132.180821 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.181764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.182622 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.304776 47375455302528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
I0618 12:05:32.305252 47149196878720 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgs1_07tt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae20fb7ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881132.207982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.208720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.209401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.305109 47359779615616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
I0618 12:05:32.305445 47981242110848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.305708 47149196878720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.305966 47375455302528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpwxso2nl2
W0618 12:05:32.306261 47359779615616 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpo_52tqug
I0618 12:05:32.307075 47375455302528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpwxso2nl2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16bdc57e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.307362 47359779615616 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpo_52tqug', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13176d8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.307523 47375455302528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.307819 47359779615616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.310370 47981242110848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.310435 47149196878720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.312821 47375455302528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.313150 47359779615616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881132.192509 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.193259 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.193967 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.327444 47242507273088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.190559 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.191329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.192079 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.327600 46937186878336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.328499 47242507273088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpq9xorac4
W0618 12:05:32.328590 46937186878336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsctsv0lp
I0618 12:05:32.329488 47242507273088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpq9xorac4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af7c9738e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.329580 46937186878336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsctsv0lp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0b2f01dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.329889 47242507273088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.329984 46937186878336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.329911 47149196878720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.330128 47981242110848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.334693 46937186878336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.334503 47375455302528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.334722 47242507273088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.335902 47359779615616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.353964 47242507273088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.354008 46937186878336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881132.220575 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.221311 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.222010 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.357227 47324634780544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.223509 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.224254 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.224908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.358332 47479906374528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.358268 47324634780544 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpj069roj4
I0618 12:05:32.359280 47324634780544 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpj069roj4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ae8a1ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.359685 47324634780544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.359310 47479906374528 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4sq0x7l5
I0618 12:05:32.360295 47479906374528 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4sq0x7l5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f0f8a6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.360687 47479906374528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881132.279051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.279687 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.280169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.362530 48001384600448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.363527 48001384600448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfmn5yzvt
I0618 12:05:32.364516 48001384600448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfmn5yzvt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba87a109e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881132.283223 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.283673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.284059 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.364483 47234034094976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.364712 47324634780544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:05:32.364913 48001384600448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.365446 47479906374528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881132.274390 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.274925 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.275321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.365227 47054390252416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.276514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.276923 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.277277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.365282 47238872306560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.365482 47234034094976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk4zt55lb
I0618 12:05:32.366497 47234034094976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk4zt55lb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5d0691e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.366947 47234034094976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.366237 47054390252416 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1blm18wz
W0618 12:05:32.366269 47238872306560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp42cqcd88
I0618 12:05:32.367221 47054390252416 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1blm18wz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbfccdae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.367245 47238872306560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp42cqcd88', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af6f0ca6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.367620 47054390252416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.367652 47238872306560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.369610 48001384600448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.371455 47234034094976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.372338 47054390252416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.372348 47238872306560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881132.260558 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.261026 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.261503 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.373576 47100994106240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.261607 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.262083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.262496 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.373692 47123240035200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.374589 47100994106240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphk2xtxnt
W0618 12:05:32.374670 47123240035200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgr4lvyfy
I0618 12:05:32.375555 47100994106240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphk2xtxnt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6d69c0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.375648 47123240035200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgr4lvyfy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc0491ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.375952 47100994106240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.376044 47123240035200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.378203 47981242110848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.378513 47149196878720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.380589 47100994106240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.380648 47123240035200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.382471 47981242110848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:32.382848 47149196878720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:32.384123 47324634780544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.384277 47375455302528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.384696 47479906374528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.385648 47359779615616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:05:32.387472 47981242110848 estimator.py:1111] Calling model_fn.
W0618 12:05:32.387582 47981242110848 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:05:32.387942 47149196878720 estimator.py:1111] Calling model_fn.
W0618 12:05:32.388051 47149196878720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:32.388683 48001384600448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.388567 47375455302528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:32.388936 47981242110848 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:32.389416 47149196878720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:32.389966 47359779615616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:32.390528 47234034094976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.391447 47054390252416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.391565 47238872306560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:05:32.393627 47375455302528 estimator.py:1111] Calling model_fn.
W0618 12:05:32.393735 47375455302528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:05:32.395051 47359779615616 estimator.py:1111] Calling model_fn.
W0618 12:05:32.395091 47375455302528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:32.395161 47359779615616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:32.396520 47359779615616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:32.399727 47123240035200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.399729 47100994106240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.402033 46937186878336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.402063 47242507273088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.406327 46937186878336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:32.406400 47242507273088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881132.289572 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.290124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.290610 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.408557 47160132715392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.289564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.290117 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.290594 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.408554 47778446914432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.409614 47160132715392 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1dremgyf
W0618 12:05:32.409584 47778446914432 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4165vnkh
I0618 12:05:32.410571 47778446914432 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4165vnkh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7491f18e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.410581 47160132715392 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1dremgyf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae49b8b9da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.410965 47778446914432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.410971 47160132715392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881132.223005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.223933 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.224799 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.411158 47515191260032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.236288 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.237057 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.237766 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.411204 46964908090240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
I0618 12:05:32.411403 46937186878336 estimator.py:1111] Calling model_fn.
I0618 12:05:32.411481 47242507273088 estimator.py:1111] Calling model_fn.
W0618 12:05:32.411514 46937186878336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:32.411588 47242507273088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:32.412876 46937186878336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:32.412945 47242507273088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:32.412282 47515191260032 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6ur1sbk9
W0618 12:05:32.412339 46964908090240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpb3m6wwhp
I0618 12:05:32.413350 47515191260032 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6ur1sbk9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3746aefe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.413394 46964908090240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpb3m6wwhp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab727403e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.413745 47515191260032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.413793 46964908090240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.415605 47160132715392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.415621 47778446914432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.418498 46964908090240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.418509 47515191260032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:32.431773 47479906374528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.432369 47324634780544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.434657 47160132715392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.434713 47778446914432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.436075 48001384600448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.436047 47479906374528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881132.322656 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.323432 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.324193 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.436394 47060437513088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
:::MLL 1560881132.324795 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881132.325535 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881132.326241 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:32.436528 47620346246016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000022-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000013-000006.tfrecord.zz_0_0
W0618 12:05:32.436704 47324634780544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:32.437556 47234034094976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:32.437512 47060437513088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpobow7gzq
W0618 12:05:32.438187 46964908090240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:32.438298 47515191260032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:05:32.437664 47620346246016 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4fc268ccc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.438601 47060437513088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpobow7gzq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd653f8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:32.438925 47620346246016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:32.439056 47060437513088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:32.438931 47054390252416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can [2019-06-18 12:06:10] divide_golden_chunk finished: 3.321 seconds
[2019-06-18 12:06:10] generate golden chunk: 3.336 seconds
[2019-06-18 12:06:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000023-000012.index --> /lfs/lfs12/gma_akey/results/epb269/models/000023-000013.index
[2019-06-18 12:06:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000023-000012.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb
[2019-06-18 12:06:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000023-000012.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000023-000013.data-00000-of-00001
[2019-06-18 12:06:10] moving /lfs/lfs12/gma_akey/results/epb269/models/000023-000012.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000023-000013.meta
[2019-06-18 12:06:10] iteration time 22: 48.369 seconds
2019-06-18 12:06:12.001294: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881170.716852 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:06:15] minmax time: 3.252 seconds
2019-06-18 12:06:15.264010: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:06:15.269349: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:06:15.273868: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881175.285501 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 22}}
[2019-06-18 12:06:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000024-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:06:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=24 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=1023779855 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=2047559686 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=3071339517 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=4095119348 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=5118899179 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=6142679010 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=7166458841 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=8190238672 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=9214018503 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=10237798334 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=11261578165 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=12285357996 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=13309137827 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=14332917658 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=15356697489 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=16380477320 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=17404257151 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=18428036982 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=19451816813 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000022-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000023-000013 --seed=20475596644 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:06:25] eval finished: 9.792 seconds
[2019-06-18 12:06:25] Win rate 000023-000013 vs 000022-000012: 0.560
:::MLL 1560881185.137553 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:06:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=25 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=1023779856 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=2047559687 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=3071339518 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=4095119349 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=5118899180 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=6142679011 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=7166458842 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=8190238673 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=9214018504 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=10237798335 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=11261578166 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=12285357997 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=13309137828 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=14332917659 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=15356697490 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=16380477321 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=17404257152 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000024-000012 --seed=18428036983 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:06:55] selfplay finished: 30.139 seconds
[2019-06-18 12:06:55] selfplay mn: 30.157 seconds
[2019-06-18 12:06:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-25-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=25 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779856 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559687 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339518 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119349 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899180 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679011 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458842 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238673 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018504 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798335 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578166 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357997 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137828 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917659 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697490 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477321 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257152 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036983 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816814 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596645 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376476 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156307 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000024-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:06:58] divide_golden_chunk finished: 3.345 seconds
[2019-06-18 12:06:58] generate golden chunk: 3.360 seconds
[2019-06-18 12:06:59] train finished: 43.939 seconds
:::MLL 1560881180.637800 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.638543 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.639211 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.737026 47799223763840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.618313 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.619240 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.620137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.737033 47782687626112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.637458 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.638223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.638916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.738159 47569595138944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.633738 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.634658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.635378 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.738155 47009084232576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.738090 47799223763840 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx5i5ofex
W0618 12:06:20.738121 47782687626112 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxnycw383
I0618 12:06:20.739120 47799223763840 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx5i5ofex', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b796856ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.739119 47782687626112 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxnycw383', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b758eb5ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.739528 47799223763840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.739526 47782687626112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.739319 47009084232576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpa5_gyx_q
W0618 12:06:20.739352 47569595138944 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp380ijstd
I0618 12:06:20.740411 47009084232576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpa5_gyx_q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1705aae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.740440 47569595138944 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp380ijstd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43f1685e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.740875 47009084232576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.740890 47569595138944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.744349 47799223763840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.744387 47782687626112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.746090 47009084232576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.746114 47569595138944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.763608 47799223763840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.763585 47782687626112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.767582 47009084232576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.767756 47569595138944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881180.673183 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.674102 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.674915 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.793243 47455646761856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.677838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.678590 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.679247 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.793493 47581551915904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.794257 47455646761856 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz0mnn4ll
W0618 12:06:20.794489 47581551915904 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpunnimvz0
I0618 12:06:20.795251 47455646761856 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz0mnn4ll', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29698e1dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.795490 47581551915904 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpunnimvz0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b46ba163e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.795669 47455646761856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.795889 47581551915904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.800513 47455646761856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.800588 47581551915904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881180.723329 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.723762 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.724162 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.805458 47012179202944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.806548 47012179202944 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpnxysiz6y
I0618 12:06:20.807552 47012179202944 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpnxysiz6y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac228d41dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.807954 47012179202944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881180.731318 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.731771 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.732154 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.810129 47240736723840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.811100 47240736723840 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprjc5uxra
W0618 12:06:20.811954 47799223763840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:06:20.812051 47240736723840 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprjc5uxra', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af75feb0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:20.812188 47782687626112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:06:20.812442 47240736723840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.812626 47012179202944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881180.720107 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.720490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.721042 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.812677 47142589277056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.718649 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.719029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.719353 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.812901 47386955830144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.667449 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.668387 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.669227 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.814008 47900094624640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.813710 47142589277056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqqn37osw
W0618 12:06:20.813897 47386955830144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsrntdvpv
I0618 12:06:20.814716 47142589277056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqqn37osw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae085dffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.814858 47386955830144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsrntdvpv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b196b41ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.815118 47142589277056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.815249 47386955830144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.815052 47900094624640 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3e1sg0cd
I0618 12:06:20.816050 47900094624640 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3e1sg0cd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b90e4b63e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:20.816266 47799223763840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:06:20.816462 47900094624640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.816547 47782687626112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:20.816954 47240736723840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.818488 47009084232576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881180.719204 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.719946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.720654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.818617 47576875914112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.708820 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.709748 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.710634 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.818821 47622728205184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.818958 47569595138944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.819742 47142589277056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.819826 47386955830144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.819986 47581551915904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.819963 47455646761856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.819774 47576875914112 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfduw6yxe
I0618 12:06:20.819985 47622728205184 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5050629d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.820867 47576875914112 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfduw6yxe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b45a3602e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.821270 47622728205184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.821313 47576875914112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.821387 47799223763840 estimator.py:1111] Calling model_fn.
W0618 12:06:20.821502 47799223763840 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:20.821413 47900094624640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881180.676641 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.677396 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.678123 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.821335 47643167011712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
I0618 12:06:20.821668 47782687626112 estimator.py:1111] Calling model_fn.
W0618 12:06:20.821776 47782687626112 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:20.822867 47799223763840 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:20.822782 47009084232576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:20.823135 47782687626112 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:20.822343 47643167011712 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdwnw66o4
W0618 12:06:20.823270 47569595138944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:06:20.823440 47643167011712 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdwnw66o4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5512a20e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.823868 47643167011712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.826519 47622728205184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.826550 47576875914112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:06:20.827849 47009084232576 estimator.py:1111] Calling model_fn.
W0618 12:06:20.827956 47009084232576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:20.828349 47569595138944 estimator.py:1111] Calling model_fn.
W0618 12:06:20.828520 47643167011712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.828459 47569595138944 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:20.829303 47009084232576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:20.829830 47569595138944 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:20.831821 47012179202944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.836017 47240736723840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.838813 47386955830144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.839031 47142589277056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.841094 47900094624640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.848071 47643167011712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.848380 47576875914112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.848598 47622728205184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881180.761157 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.761681 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.762164 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.853641 46950560924544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.761704 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.762227 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.762723 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.853684 46962795852672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.854676 46950560924544 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpj5u0k47l
W0618 12:06:20.854704 46962795852672 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpe9is6uqn
I0618 12:06:20.855676 46962795852672 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpe9is6uqn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6a959fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.855677 46950560924544 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpj5u0k47l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab3d017de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.856069 46950560924544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.856070 46962795852672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.860735 46950560924544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.860728 46962795852672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881180.733657 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.734213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.734664 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.864837 47057095099264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.732008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.732487 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.732891 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.864986 47137290294144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.865833 47057095099264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8t5p8o5a
W0618 12:06:20.865975 47137290294144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptx54ls0c
I0618 12:06:20.866837 47057095099264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8t5p8o5a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc9e065e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.866934 47137290294144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptx54ls0c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf4a07eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.867231 47057095099264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.867328 47137290294144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.867918 47581551915904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.868394 47455646761856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.871972 47057095099264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.872019 47137290294144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.872216 47581551915904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:20.872699 47455646761856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:06:20.877301 47581551915904 estimator.py:1111] Calling model_fn.
W0618 12:06:20.877417 47581551915904 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:20.877826 47455646761856 estimator.py:1111] Calling model_fn.
W0618 12:06:20.877936 47455646761856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:20.878778 47581551915904 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881180.787038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.787462 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.787856 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.878862 47820876424064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881180.788263 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881180.788712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881180.789072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:20.879056 47378767840128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000023-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:20.879287 47455646761856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:20.879607 47012179202944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.879744 46962795852672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.880109 46950560924544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:20.879852 47820876424064 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpleytxgap
W0618 12:06:20.880035 47378767840128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3d39b4dw
I0618 12:06:20.880836 47820876424064 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpleytxgap', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e72f07e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.880994 47378767840128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3d39b4dw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b178336ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:20.881245 47820876424064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:20.881402 47378767840128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:20.882955 47240736723840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.883933 47012179202944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:20.885820 47820876424064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.885950 47378767840128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:20.885957 47386955830144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.886746 47142589277056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:20.887217 47240736723840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:20.888729 47900094624640 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPU[2019-06-18 12:06:59] moving /lfs/lfs12/gma_akey/results/epb269/models/000024-000013.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000024-000014.meta
[2019-06-18 12:06:59] moving /lfs/lfs12/gma_akey/results/epb269/models/000024-000013.index --> /lfs/lfs12/gma_akey/results/epb269/models/000024-000014.index
[2019-06-18 12:06:59] moving /lfs/lfs12/gma_akey/results/epb269/models/000024-000013.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb
[2019-06-18 12:06:59] moving /lfs/lfs12/gma_akey/results/epb269/models/000024-000013.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000024-000014.data-00000-of-00001
[2019-06-18 12:06:59] iteration time 23: 48.569 seconds
2019-06-18 12:07:00.557470: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881219.285647 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:07:03] minmax time: 3.235 seconds
2019-06-18 12:07:03.802615: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:07:03.808213: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:07:03.812931: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881223.824873 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 23}}
[2019-06-18 12:07:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:07:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=25 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=1023779856 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=2047559687 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=3071339518 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=4095119349 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=5118899180 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=6142679011 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=7166458842 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=8190238673 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=9214018504 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=10237798335 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=11261578166 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=12285357997 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=13309137828 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=14332917659 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=15356697490 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=16380477321 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=17404257152 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=18428036983 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=19451816814 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000024-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000024-000014 --seed=20475596645 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:07:14] eval finished: 10.264 seconds
[2019-06-18 12:07:14] Win rate 000024-000014 vs 000023-000013: 0.410
:::MLL 1560881234.149520 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:07:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=26 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=1023779857 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=2047559688 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=3071339519 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=4095119350 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=5118899181 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=6142679012 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=7166458843 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=8190238674 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=9214018505 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=10237798336 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=11261578167 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=12285357998 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=13309137829 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=14332917660 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=15356697491 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=16380477322 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=17404257153 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000025-000013 --seed=18428036984 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:07:44] selfplay finished: 29.944 seconds
[2019-06-18 12:07:44] selfplay mn: 29.964 seconds
[2019-06-18 12:07:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-26-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=26 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779857 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559688 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339519 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119350 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899181 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679012 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458843 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238674 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018505 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798336 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578167 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357998 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137829 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917660 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697491 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477322 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257153 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036984 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816815 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596646 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376477 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156308 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000025-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:07:47] divide_golden_chunk finished: 3.314 seconds
[2019-06-18 12:07:47] generate golden chunk: 3.331 seconds
[2019-06-18 12:07:47] train finished: 43.775 seconds
:::MLL 1560881229.102842 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.103589 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.104270 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.211947 47367856268160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.099427 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.100259 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.100942 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.212026 47157410497408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.213001 47367856268160 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8enf6zn5
W0618 12:07:09.213045 47157410497408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp14jpyba7
I0618 12:07:09.213998 47367856268160 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8enf6zn5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14f8d57e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.214047 47157410497408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp14jpyba7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae3f949ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.214398 47367856268160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.214455 47157410497408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.219444 47367856268160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.219465 47157410497408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.238649 47367856268160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.239004 47157410497408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881229.101607 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.102469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.103161 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.265589 47060775990144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.266617 47060775990144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpi3ky1zg3
I0618 12:07:09.267623 47060775990144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpi3ky1zg3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd796c4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.268032 47060775990144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881229.105100 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.105853 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.106519 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.271396 47987673805696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.273012 47060775990144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.272500 47987673805696 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8vmx4we0
I0618 12:07:09.273548 47987673805696 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8vmx4we0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba548d68e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.273942 47987673805696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.278780 47987673805696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881229.193515 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.193942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.194311 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.286148 47597393556352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.184013 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.184602 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.185131 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.286224 47724946371456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.287076 47367856268160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:09.287141 47597393556352 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmply08amnr
W0618 12:07:09.287195 47724946371456 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpg75fqv7d
W0618 12:07:09.287916 47157410497408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:07:09.288134 47597393556352 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmply08amnr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a6a528dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.288181 47724946371456 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpg75fqv7d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b681d0ffe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.288536 47597393556352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.288587 47724946371456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.291382 47367856268160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:09.292327 47060775990144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.292281 47157410497408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:09.293141 47597393556352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.293194 47724946371456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:09.296463 47367856268160 estimator.py:1111] Calling model_fn.
W0618 12:07:09.296571 47367856268160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:07:09.297421 47157410497408 estimator.py:1111] Calling model_fn.
W0618 12:07:09.297533 47157410497408 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:09.297931 47367856268160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:09.298107 47987673805696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.298907 47157410497408 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881229.141867 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.142624 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.143372 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.301150 47312506221440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.143924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.144631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.145334 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.301173 47054439900032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.302192 47312506221440 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpykxc0pze
W0618 12:07:09.302221 47054439900032 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp34i7_r_z
I0618 12:07:09.303194 47312506221440 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpykxc0pze', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0815b6ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.303218 47054439900032 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp34i7_r_z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbffc33e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.303598 47312506221440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.303616 47054439900032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.308515 47054439900032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.308527 47312506221440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881229.116291 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.117196 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.118062 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.311554 47549791241088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.312021 47597393556352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.312153 47724946371456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.312681 47549791241088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpkvhu03fo
I0618 12:07:09.313846 47549791241088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpkvhu03fo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f5500ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.314309 47549791241088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881229.175835 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.176324 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.176739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.314330 47681439474560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.134110 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.134944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.135610 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.314204 47666023678848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.137147 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.137893 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.138601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.314610 46973591389056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.315351 47681439474560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7728q1ws
W0618 12:07:09.315300 47666023678848 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxmoo16as
I0618 12:07:09.316335 47681439474560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7728q1ws', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5dfbd97e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881229.177502 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.177979 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.178385 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.316345 47804137857920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
I0618 12:07:09.316419 47666023678848 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxmoo16as', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a64ff1da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:09.315639 46973591389056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpohz_ac_z
I0618 12:07:09.316742 47681439474560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.316756 46973591389056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpohz_ac_z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab92cd0ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.316878 47666023678848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.317209 46973591389056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.317331 47804137857920 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpttt64q6w
I0618 12:07:09.318315 47804137857920 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpttt64q6w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a8d3e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.318717 47804137857920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.319331 47549791241088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.321357 47681439474560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.322242 47666023678848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.322563 46973591389056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.323277 47804137857920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.327546 47054439900032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.327594 47312506221440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881229.128455 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.129201 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.129932 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.331197 47019680174976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.332181 47019680174976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyqja3ja4
I0618 12:07:09.333186 47019680174976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyqja3ja4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3e7ebeda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.333584 47019680174976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.338253 47019680174976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.338906 47549791241088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.340347 47681439474560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.340699 47060775990144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:09.342355 47804137857920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.343077 47666023678848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.343252 46973591389056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881229.182879 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.183695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.184402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.343247 47638768726912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.186056 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.186810 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.187531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.343314 47253390300032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.345026 47060775990144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:09.344411 47638768726912 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b540c798d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:09.344428 47253390300032 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0taftl2w
I0618 12:07:09.345540 47253390300032 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0taftl2w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa52216e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.345661 47638768726912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.345717 47987673805696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:07:09.345982 47253390300032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881229.217944 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.218407 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.218832 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.349518 47662795068288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
:::MLL 1560881229.211314 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.211887 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.212387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.349554 47917720576896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.350051 47987673805696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:09.350165 47060775990144 estimator.py:1111] Calling model_fn.
W0618 12:07:09.350276 47060775990144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:09.350944 47638768726912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.351207 47253390300032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.350522 47662795068288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp5bfs_mcf
W0618 12:07:09.350556 47917720576896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxr923n2u
I0618 12:07:09.351517 47662795068288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp5bfs_mcf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b59a48e5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:09.351660 47060775990144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:07:09.351546 47917720576896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxr923n2u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94ff4cee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.351915 47662795068288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.351948 47917720576896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:09.355145 47987673805696 estimator.py:1111] Calling model_fn.
:::MLL 1560881229.204749 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.205241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.205676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.354794 47463785587584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.355253 47987673805696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881229.204706 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.205209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.205651 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.355177 47105017623424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.356613 47987673805696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:09.355825 47463785587584 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp9i9p20ff
W0618 12:07:09.356603 47917720576896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.356616 47662795068288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:09.356825 47463785587584 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp9i9p20ff', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b4eaabe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:09.356136 47105017623424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxl1nnxi6
I0618 12:07:09.357114 47105017623424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxl1nnxi6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad7c66dfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.357222 47463785587584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.357415 47019680174976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:07:09.357519 47105017623424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881229.178127 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.178659 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.179128 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.358626 47404218377088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.359494 47597393556352 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:09.359712 47724946371456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881229.183766 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881229.184271 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881229.184765 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:09.359981 47967264174976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000024-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000015-000007.tfrecord.zz_0_0
W0618 12:07:09.359628 47404218377088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdtz2pcy2
I0618 12:07:09.360621 47404218377088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdtz2pcy2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d702f3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:09.361027 47404218377088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.360963 47967264174976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgyp49_3i
I0618 12:07:09.361937 47967264174976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgyp49_3i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba088544da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:09.361920 47463785587584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.362085 47105017623424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:09.362335 47967264174976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:09.363775 47597393556352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:09.364025 47724946371456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:09.365682 47404218377088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:09.366958 47967264174976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:09.368843 47597393556352 estimator.py:1111] Calling model_fn.
W0618 12:07:09.368948 47597393556352 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:07:09.369086 47724946371456 estimator.py:1111] Calling model_fn.
W0618 12:07:09.369193 47724946371456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:09.370307 47597393556352 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:09.370549 47724946371456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:09.371896 47638768726912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.372203 47253390300032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:09.375003 47054439900032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argu[2019-06-18 12:07:47] iteration time 24: 48.336 seconds
2019-06-18 12:07:48.990120: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881267.621477 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:07:52] minmax time: 3.248 seconds
2019-06-18 12:07:52.248486: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:07:52.253895: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:07:52.258393: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881272.271962 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 24}}
[2019-06-18 12:07:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:07:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=26 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=1023779857 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=2047559688 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=3071339519 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=4095119350 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=5118899181 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=6142679012 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=7166458843 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=8190238674 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=9214018505 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=10237798336 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=11261578167 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=12285357998 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=13309137829 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=14332917660 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=15356697491 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=16380477322 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=17404257153 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=18428036984 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=19451816815 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000025-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000025-000014 --seed=20475596646 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:08:02] eval finished: 10.406 seconds
[2019-06-18 12:08:02] Win rate 000025-000014 vs 000023-000013: 0.450
:::MLL 1560881282.739765 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:08:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=27 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=1023779858 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=2047559689 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=3071339520 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=4095119351 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=5118899182 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=6142679013 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=7166458844 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=8190238675 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=9214018506 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=10237798337 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=11261578168 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=12285357999 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=13309137830 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=14332917661 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=15356697492 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=16380477323 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=17404257154 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000026-000013 --seed=18428036985 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:08:32] selfplay finished: 29.760 seconds
[2019-06-18 12:08:32] selfplay mn: 29.778 seconds
[2019-06-18 12:08:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-27-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=27 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779858 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559689 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339520 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119351 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899182 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679013 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458844 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238675 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018506 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798337 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578168 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285357999 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137830 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917661 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697492 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477323 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257154 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036985 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816816 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596647 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376478 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156309 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000026-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:08:35] divide_golden_chunk finished: 3.328 seconds
[2019-06-18 12:08:35] generate golden chunk: 3.343 seconds
[2019-06-18 12:08:36] train finished: 44.061 seconds
:::MLL 1560881277.513049 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.513965 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.514822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.628861 46956839408512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.527811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.528550 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.529216 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.628931 47467751216000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.629891 46956839408512 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp80jarclk
W0618 12:07:57.629944 47467751216000 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpbipxghvj
I0618 12:07:57.631001 46956839408512 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp80jarclk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab54651ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.631047 47467751216000 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpbipxghvj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c3b096e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.631455 46956839408512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:57.631500 47467751216000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.636306 46956839408512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.636337 47467751216000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.655646 47467751216000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.655613 46956839408512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881277.602128 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.602681 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.603198 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.692305 47877836952448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.693318 47877836952448 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmu4kp4l1
I0618 12:07:57.694295 47877836952448 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmu4kp4l1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8bb60d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.694698 47877836952448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881277.610066 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.610530 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.610914 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.696829 48007941329792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.697837 48007941329792 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprljep3qs
I0618 12:07:57.698817 48007941329792 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprljep3qs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa00e05e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.699207 48007941329792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.699364 47877836952448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.703785 48007941329792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.703815 46956839408512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:57.704181 47467751216000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:57.708121 46956839408512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:57.708508 47467751216000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:57.713181 46956839408512 estimator.py:1111] Calling model_fn.
W0618 12:07:57.713292 46956839408512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:07:57.713583 47467751216000 estimator.py:1111] Calling model_fn.
W0618 12:07:57.713695 47467751216000 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881277.553861 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.554719 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.555500 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.714358 47367220953984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.714670 46956839408512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:57.715063 47467751216000 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:57.715500 47367220953984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0mqu68id
I0618 12:07:57.716588 47367220953984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0mqu68id', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14d2f75e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.717041 47367220953984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.718468 47877836952448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.722756 47367220953984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.722796 48007941329792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881277.557313 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.558249 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.559110 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.740203 47907334308736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.575155 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.575902 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.576566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.740319 47100342952832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.741355 47907334308736 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpuofhc1u9
:::MLL 1560881277.559227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.560086 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.560825 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.742063 47202142221184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.741395 47100342952832 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2z47dj05
:::MLL 1560881277.558212 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.559055 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.559847 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.742056 47136874914688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
I0618 12:07:57.742453 47907334308736 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpuofhc1u9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92943b1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.742489 47100342952832 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2z47dj05', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6afcc2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.742904 47907334308736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:57.742937 47100342952832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.743891 47367220953984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.743139 47202142221184 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpew69m8qq
W0618 12:07:57.743111 47136874914688 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3_znukd7
I0618 12:07:57.744105 47136874914688 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3_znukd7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf3145be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.744138 47202142221184 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpew69m8qq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aee6381ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.744501 47136874914688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:57.744547 47202142221184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881277.567173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.567904 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.568584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.746991 47070881411968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.561953 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.562855 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.563715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.746995 47312876635008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.748264 47907334308736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.748342 47100342952832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.748050 47070881411968 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphly92282
W0618 12:07:57.748019 47312876635008 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmphtmm8w89
I0618 12:07:57.749006 47312876635008 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphtmm8w89', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b082bcade10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.749028 47070881411968 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmphly92282', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acfd3c0ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:57.749447 47136874914688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:57.749415 47312876635008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.749457 47202142221184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:57.749433 47070881411968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881277.554576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.555439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.556131 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.749625 46931013469056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.750644 46931013469056 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpsq4u8yv4
I0618 12:07:57.751631 46931013469056 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpsq4u8yv4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf42f95e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.752026 46931013469056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.754355 47070881411968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.754484 47312876635008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.756827 46931013469056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.765848 47877836952448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:57.768816 47202142221184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.768878 47136874914688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.769615 48007941329792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:57.770148 47877836952448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:57.770023 47907334308736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.770056 47100342952832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.773493 47070881411968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.773694 47312876635008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.773895 48007941329792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:57.775208 47877836952448 estimator.py:1111] Calling model_fn.
W0618 12:07:57.775320 47877836952448 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:57.776063 46931013469056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.776682 47877836952448 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:07:57.778930 48007941329792 estimator.py:1111] Calling model_fn.
W0618 12:07:57.779036 48007941329792 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:57.780411 48007941329792 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881277.614500 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.615062 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.615683 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.780256 47800808801152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.781275 47800808801152 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpfudpp0_a
I0618 12:07:57.782272 47800808801152 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpfudpp0_a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79c6d0de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881277.618852 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.619339 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.619747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.782342 47427468059520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
I0618 12:07:57.782679 47800808801152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.783327 47427468059520 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpl15yrl4c
I0618 12:07:57.784286 47427468059520 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpl15yrl4c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b22d9f93da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881277.635938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.636401 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.636801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.784132 47725162951552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.638096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.638573 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.638973 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.784234 47094943359872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
I0618 12:07:57.784683 47427468059520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881277.640072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.640561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.640956 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.784851 47269445723008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.640714 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.641157 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.641523 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.785021 47915869193088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.785183 47725162951552 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpc4lcztji
W0618 12:07:57.785254 47094943359872 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1v043ybj
I0618 12:07:57.786146 47725162951552 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpc4lcztji', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6829f8ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.786236 47094943359872 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1v043ybj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad56df4ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.786546 47725162951552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:57.786635 47094943359872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.785891 47269445723008 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpghcyft6m
W0618 12:07:57.786036 47915869193088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpo29i7xx1
I0618 12:07:57.786886 47269445723008 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpghcyft6m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe0f1bbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.787026 47915869193088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpo29i7xx1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9490f31e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.787280 47269445723008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:57.787427 47915869193088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.787484 47800808801152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.789323 47427468059520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881277.630110 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.630678 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.631099 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.790006 47286499771264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.629513 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.630022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.630517 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.789962 46980054582144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.791217 47725162951552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.791254 47094943359872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.791550 47367220953984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:57.790973 46980054582144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpqwifgec2
W0618 12:07:57.791021 47286499771264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7chenc3v
I0618 12:07:57.791956 46980054582144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpqwifgec2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abaae0d2da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:57.791961 47269445723008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:57.792002 47286499771264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7chenc3v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b02079bde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:57.792073 47915869193088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:57.792354 46980054582144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:57.792411 47286499771264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.795853 47367220953984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:57.797046 46980054582144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.797051 47286499771264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:57.800932 47367220953984 estimator.py:1111] Calling model_fn.
W0618 12:07:57.801046 47367220953984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:57.802416 47367220953984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:57.806637 47800808801152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881277.617869 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.618682 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.619375 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.807955 47753023488896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
:::MLL 1560881277.621160 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881277.621929 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881277.622626 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:57.807989 47150911734656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000025-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000016-000008.tfrecord.zz_0_0
W0618 12:07:57.808518 47427468059520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.809082 47150911734656 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp98f6a4ub
I0618 12:07:57.809111 47753023488896 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6ea696bcc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:57.810168 47150911734656 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp98f6a4ub', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae275ee8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:57.810233 47094943359872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:07:57.810376 47753023488896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.810380 47725162951552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:07:57.810615 47150911734656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:57.811034 47915869193088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.811026 47269445723008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.815732 47753023488896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.815886 47150911734656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:57.815954 47286499771264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.816100 46980054582144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:57.817081 47202142221184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:57.817039 47136874914688 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
   [2019-06-18 12:08:36] iteration time 25: 48.733 seconds
2019-06-18 12:08:37.740895: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881316.354037 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:08:41] minmax time: 3.274 seconds
2019-06-18 12:08:41.025384: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:08:41.030874: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:08:41.035519: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881321.049157 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 25}}
[2019-06-18 12:08:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000027-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:08:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=27 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=1023779858 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=2047559689 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=3071339520 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=4095119351 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=5118899182 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=6142679013 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=7166458844 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=8190238675 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=9214018506 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=10237798337 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=11261578168 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=12285357999 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=13309137830 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=14332917661 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=15356697492 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=16380477323 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=17404257154 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=18428036985 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=19451816816 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000023-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000026-000014 --seed=20475596647 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:08:52] eval finished: 11.276 seconds
[2019-06-18 12:08:52] Win rate 000026-000014 vs 000023-000013: 0.700
:::MLL 1560881332.386515 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:08:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=28 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=1023779859 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=2047559690 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=3071339521 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=4095119352 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=5118899183 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=6142679014 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=7166458845 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=8190238676 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=9214018507 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=10237798338 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=11261578169 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=12285358000 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=13309137831 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=14332917662 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=15356697493 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=16380477324 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=17404257155 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000027-000013 --seed=18428036986 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:09:22] selfplay finished: 30.287 seconds
[2019-06-18 12:09:22] selfplay mn: 30.305 seconds
[2019-06-18 12:09:22] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-28-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=28 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779859 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559690 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339521 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119352 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899183 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679014 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458845 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238676 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018507 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798338 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578169 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285358000 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137831 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917662 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697493 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477324 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257155 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036986 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816817 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596648 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376479 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156310 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000027-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:09:24] train finished: 43.690 seconds
:::MLL 1560881326.346611 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.347452 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.348240 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.486557 47354921239424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.347312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.348181 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.348896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.487268 47019141161856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.487606 47354921239424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0iaew5mt
I0618 12:08:46.488595 47354921239424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0iaew5mt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11f5d88e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881326.379327 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.380089 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.380772 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.488548 46966615548800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
I0618 12:08:46.488998 47354921239424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.488260 47019141161856 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxk1e3n10
:::MLL 1560881326.370643 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.371566 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.372419 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.488841 47058655638400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
I0618 12:08:46.489268 47019141161856 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxk1e3n10', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3c7cb3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.489682 47019141161856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.489696 46966615548800 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp3z7h17uo
W0618 12:08:46.489936 47058655638400 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpflec4rfw
I0618 12:08:46.490775 46966615548800 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp3z7h17uo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab78d05ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.491033 47058655638400 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpflec4rfw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2accfb0a4da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.491223 46966615548800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.491472 47058655638400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.493849 47354921239424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.494445 47019141161856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.496569 46966615548800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.496642 47058655638400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.512857 47354921239424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.514132 47019141161856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.518233 46966615548800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.518577 47058655638400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881326.416475 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.416936 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.417351 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.541039 47893068182400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.417851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.418322 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.418760 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.541089 47174102594432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.542076 47893068182400 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpht0e8f6d
W0618 12:08:46.542110 47174102594432 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpy21bnkpc
I0618 12:08:46.543054 47893068182400 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpht0e8f6d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f41e72e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.543084 47174102594432 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpy21bnkpc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7dc370e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.543460 47893068182400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.543484 47174102594432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.548158 47174102594432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.548210 47893068182400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881326.396559 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.397465 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.398171 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.550513 47759408857984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.400373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.401100 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.401753 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.550734 47665000764288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.551541 47759408857984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpl2sn0rib
W0618 12:08:46.551714 47665000764288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpbzc92ngs
I0618 12:08:46.552533 47759408857984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpl2sn0rib', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70232fde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.552682 47665000764288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpbzc92ngs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a28069e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.552933 47759408857984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.553079 47665000764288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881326.389286 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.390188 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.391047 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.553424 47145101136768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.554512 47145101136768 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptz4lp5x5
I0618 12:08:46.555643 47145101136768 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptz4lp5x5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae11b97ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.556099 47145101136768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881326.460729 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.461164 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.461528 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.556867 47789093385088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.463268 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.463645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.463967 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.556898 46956779807616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.557806 47759408857984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.557902 47665000764288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.557881 47789093385088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpe2wvgigr
W0618 12:08:46.557908 46956779807616 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzvc5hke8
I0618 12:08:46.558859 47789093385088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpe2wvgigr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b770c85bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.558879 46956779807616 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzvc5hke8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab542c47da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.559253 47789093385088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.559269 46956779807616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.560664 47354921239424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.561068 47145101136768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.562088 47019141161856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.563948 46956779807616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.563942 47789093385088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.565012 47354921239424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.566500 47019141161856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.567185 47174102594432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881326.397348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.398097 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.398795 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.566996 47866268210048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.567444 47893068182400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.568536 47058655638400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.568651 46966615548800 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.568008 47866268210048 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpww0_haeq
I0618 12:08:46.569426 47866268210048 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpww0_haeq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8904801e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.569869 47866268210048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.570108 47354921239424 estimator.py:1111] Calling model_fn.
W0618 12:08:46.570220 47354921239424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:46.571609 47354921239424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:08:46.571642 47019141161856 estimator.py:1111] Calling model_fn.
W0618 12:08:46.571766 47019141161856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:46.572805 47058655638400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.572972 46966615548800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.573147 47019141161856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:46.574521 47866268210048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.577047 47759408857984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.577259 47665000764288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:46.577856 47058655638400 estimator.py:1111] Calling model_fn.
W0618 12:08:46.577962 47058655638400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:46.578033 46966615548800 estimator.py:1111] Calling model_fn.
W0618 12:08:46.578143 46966615548800 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:46.579322 47058655638400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:46.579480 46966615548800 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:46.581020 47145101136768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.582875 46956779807616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.582914 47789093385088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.594271 47866268210048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881326.451988 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.452765 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.453419 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.600491 47473249293184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.436855 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.437766 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.438641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.600547 47011877753728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.471626 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.472142 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.472585 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.602032 47769460282240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.471531 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.472039 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.472497 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.602290 47042127188864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
I0618 12:08:46.601637 47473249293184 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d82bf5d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:46.601667 47011877753728 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprejw36l8
I0618 12:08:46.602763 47011877753728 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprejw36l8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac216dc6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.602896 47473249293184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.603211 47011877753728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.603043 47769460282240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_tozhgjt
W0618 12:08:46.603273 47042127188864 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1qhswgxe
I0618 12:08:46.604019 47769460282240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_tozhgjt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b727a4c6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.604261 47042127188864 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1qhswgxe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac921de2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.604430 47769460282240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.604664 47042127188864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881326.441444 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.441987 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.442453 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.607747 46998015660928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
:::MLL 1560881326.447652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.448139 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.448581 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.607880 47389405950848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.608352 47473249293184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.608426 47011877753728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.609081 47769460282240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.609293 47042127188864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.608761 46998015660928 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_7wjxh9q
W0618 12:08:46.608859 47389405950848 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxw5jgdky
I0618 12:08:46.609750 46998015660928 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_7wjxh9q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abedc9dae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.609829 47389405950848 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxw5jgdky', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19fd4b8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.610152 46998015660928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:46.610213 47389405950848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.614555 47174102594432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881326.429342 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.430085 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.430808 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.614416 47718406312832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.614790 46998015660928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.614863 47389405950848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.615282 47893068182400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.615523 47718406312832 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpjitp2b21
I0618 12:08:46.616531 47718406312832 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpjitp2b21', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b66973eae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.616992 47718406312832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.618848 47174102594432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881326.432073 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881326.432813 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881326.433516 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:46.619065 47208316789632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000026-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000017-000009.tfrecord.zz_0_0
W0618 12:08:46.619647 47893068182400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.620168 47208316789632 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpt8dmjs7w
I0618 12:08:46.621249 47208316789632 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpt8dmjs7w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aefd38a2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:46.621656 47208316789632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:46.622592 47718406312832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:08:46.623903 47174102594432 estimator.py:1111] Calling model_fn.
W0618 12:08:46.624010 47174102594432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:46.624760 47893068182400 estimator.py:1111] Calling model_fn.
W0618 12:08:46.624870 47893068182400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:46.624966 47759408857984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.625244 47665000764288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.625387 47174102594432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:46.626231 47893068182400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:46.626296 47208316789632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:46.628027 47769460282240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.628299 47042127188864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.629015 47145101136768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.629270 47759408857984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.629574 47665000764288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:46.630242 47011877753728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.630294 47473249293184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:46.630152 46956779807616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:46.630224 47789093385088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPU[2019-06-18 12:09:25] divide_golden_chunk finished: 3.294 seconds
[2019-06-18 12:09:26] generate golden chunk: 3.308 seconds
[2019-06-18 12:09:26] moving /lfs/lfs12/gma_akey/results/epb269/models/000027-000014.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb
[2019-06-18 12:09:26] moving /lfs/lfs12/gma_akey/results/epb269/models/000027-000014.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000027-000015.meta
[2019-06-18 12:09:26] moving /lfs/lfs12/gma_akey/results/epb269/models/000027-000014.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000027-000015.data-00000-of-00001
[2019-06-18 12:09:26] moving /lfs/lfs12/gma_akey/results/epb269/models/000027-000014.index --> /lfs/lfs12/gma_akey/results/epb269/models/000027-000015.index
[2019-06-18 12:09:26] iteration time 26: 49.690 seconds
2019-06-18 12:09:27.447735: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881366.043730 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:09:30] minmax time: 3.260 seconds
2019-06-18 12:09:30.718053: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:09:30.723574: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:09:30.728081: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881370.740085 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 26}}
[2019-06-18 12:09:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000028-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:09:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=28 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=1023779859 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=2047559690 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=3071339521 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=4095119352 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=5118899183 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=6142679014 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=7166458845 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=8190238676 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=9214018507 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=10237798338 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=11261578169 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=12285358000 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=13309137831 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=14332917662 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=15356697493 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=16380477324 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=17404257155 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=18428036986 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=19451816817 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000026-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000027-000015 --seed=20475596648 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:09:41] eval finished: 10.493 seconds
[2019-06-18 12:09:41] Win rate 000027-000015 vs 000026-000014: 0.490
:::MLL 1560881381.293025 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:09:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=29 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=1023779860 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=2047559691 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=3071339522 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=4095119353 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=5118899184 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=6142679015 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=7166458846 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=8190238677 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=9214018508 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=10237798339 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=11261578170 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=12285358001 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=13309137832 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=14332917663 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=15356697494 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=16380477325 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=17404257156 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000028-000014 --seed=18428036987 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:10:11] selfplay finished: 29.934 seconds
[2019-06-18 12:10:11] selfplay mn: 29.955 seconds
[2019-06-18 12:10:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-29-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=29 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779860 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559691 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339522 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119353 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899184 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679015 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458846 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238677 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018508 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798339 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578170 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285358001 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137832 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917663 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697494 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477325 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257156 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036987 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816818 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596649 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376480 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156311 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000028-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:10:14] divide_golden_chunk finished: 3.255 seconds
[2019-06-18 12:10:14] generate golden chunk: 3.270 seconds
[2019-06-18 12:10:14] train finished: 43.781 seconds
:::MLL 1560881376.042748 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.043637 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.044498 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.155065 47312344777600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560881376.051068 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.051787 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.052454 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.155196 47123467715456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.156122 47312344777600 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8f09w6vj
W0618 12:09:36.156208 47123467715456 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk49xzf2d
I0618 12:09:36.157114 47312344777600 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8f09w6vj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b080c173e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.157201 47123467715456 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk49xzf2d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc12240e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.157520 47312344777600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.157603 47123467715456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.162297 47123467715456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.162320 47312344777600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881376.035223 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.035954 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.036602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.169969 47282845758336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560881376.023521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.024418 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.025272 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.170136 47034875503488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.170996 47282845758336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcwg3mxz2
W0618 12:09:36.171128 47034875503488 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpd0p5evej
I0618 12:09:36.172013 47282845758336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcwg3mxz2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b012dcffdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.172118 47034875503488 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpd0p5evej', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac771a23e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.172428 47282845758336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.172559 47034875503488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881376.052776 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.053676 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.054539 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.174263 47204762698624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560881376.062910 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.063686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.064418 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.174364 47797040362368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.175302 47204762698624 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4jwrbul7
W0618 12:09:36.175374 47797040362368 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppvknq3oe
I0618 12:09:36.176302 47204762698624 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4jwrbul7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeeffb31e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.176396 47797040362368 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppvknq3oe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78e6330e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.176707 47204762698624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.176800 47797040362368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.177415 47282845758336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.177422 47034875503488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.181559 47204762698624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.181691 47312344777600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.181691 47123467715456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.181595 47797040362368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.196553 47034875503488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.196686 47282845758336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.200748 47204762698624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.200916 47797040362368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881376.064658 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.065581 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.066425 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.217251 47219137454976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.218389 47219137454976 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpdub800bv
I0618 12:09:36.219443 47219137454976 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpdub800bv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af258807e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.219920 47219137454976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881376.072254 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.072986 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.073636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.224827 47419913081728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.225160 47219137454976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881376.119568 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.120050 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.120456 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.226527 47101069906816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.225870 47419913081728 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2cq0c6jh
:::MLL 1560881376.117576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.118036 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.118449 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.226775 47975441322880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
I0618 12:09:36.226926 47419913081728 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2cq0c6jh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2117a95e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.227383 47419913081728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881376.106486 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.106928 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.107323 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.227627 47281137062784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560881376.101172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.101769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.102279 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.227576 47689048318848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.227557 47101069906816 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmposx_4msk
W0618 12:09:36.227771 47975441322880 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpck1k1f0y
I0618 12:09:36.228523 47101069906816 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmposx_4msk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad6db20ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.228761 47975441322880 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpck1k1f0y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba26fb9ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.228934 47101069906816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.229152 47975441322880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.228627 47689048318848 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpd0k7zs17
W0618 12:09:36.228654 47281137062784 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmposz776az
I0618 12:09:36.229607 47689048318848 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpd0k7zs17', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5fc15f1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.229650 47281137062784 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmposz776az', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00c7f75e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:36.229640 47123467715456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:09:36.229998 47689048318848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.230047 47281137062784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.230476 47312344777600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.232620 47419913081728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.233559 47101069906816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.233695 47975441322880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.233931 47123467715456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:36.234687 47281137062784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.234676 47689048318848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.234822 47312344777600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:09:36.239005 47123467715456 estimator.py:1111] Calling model_fn.
W0618 12:09:36.239114 47123467715456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:36.239920 47312344777600 estimator.py:1111] Calling model_fn.
W0618 12:09:36.240030 47312344777600 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:36.240478 47123467715456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:36.241389 47312344777600 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881376.115642 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.116579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.117474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.244250 47186711896960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.244634 47034875503488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.245019 47282845758336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:09:36.245509 47186711896960 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeacbc9bd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.246803 47186711896960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.246845 47219137454976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.248787 47797040362368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.248751 47204762698624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881376.135088 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.135853 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.136531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.248893 47716614935424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.249012 47034875503488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:36.249401 47282845758336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:36.249974 47716614935424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpk2eud4s5
I0618 12:09:36.251044 47716614935424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpk2eud4s5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b662c785dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.251477 47716614935424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.251931 47186711896960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.252468 47101069906816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.252645 47975441322880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881376.155450 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.155878 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.156268 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.252377 47076458910592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560881376.155681 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.156119 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.156499 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.252627 47983372190592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.253043 47204762698624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:36.253073 47797040362368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:36.253648 47281137062784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.253835 47689048318848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:36.254085 47034875503488 estimator.py:1111] Calling model_fn.
W0618 12:09:36.254195 47034875503488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:36.253372 47076458910592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1ywyuu31
W0618 12:09:36.253601 47983372190592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpy710vmwa
I0618 12:09:36.254477 47282845758336 estimator.py:1111] Calling model_fn.
W0618 12:09:36.254277 47419913081728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:36.254358 47076458910592 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1ywyuu31', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad12032ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:36.254589 47282845758336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:36.254591 47983372190592 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpy710vmwa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba448711e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.254751 47076458910592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.254991 47983372190592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.255561 47034875503488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:36.255954 47282845758336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:36.256598 47716614935424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:09:36.258119 47797040362368 estimator.py:1111] Calling model_fn.
I0618 12:09:36.258086 47204762698624 estimator.py:1111] Calling model_fn.
W0618 12:09:36.258200 47204762698624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:36.258232 47797040362368 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:36.259412 47076458910592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.259590 47797040362368 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:36.259550 47204762698624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:36.259629 47983372190592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.273473 47186711896960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881376.140410 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.140910 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.141277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.275815 47144185537408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
:::MLL 1560881376.143292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.143717 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.144088 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.275990 47293171643264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
W0618 12:09:36.276852 47144185537408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpq1a9tx9b
W0618 12:09:36.277016 47293171643264 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8vf9icsj
I0618 12:09:36.277842 47144185537408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpq1a9tx9b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae0e504fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881376.077892 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.078805 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.079615 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.277824 47258718995328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
I0618 12:09:36.278007 47293171643264 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8vf9icsj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0395488e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881376.088337 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881376.089050 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881376.089777 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:36.277915 46975878505344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000027-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000018-000009.tfrecord.zz_0_0
I0618 12:09:36.278253 47144185537408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.278337 47716614935424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:36.278396 47293171643264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.278638 47076458910592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.278727 47983372190592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:36.278849 47258718995328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmyjgxgp2
W0618 12:09:36.278923 46975878505344 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpr0g821xw
I0618 12:09:36.279843 47258718995328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmyjgxgp2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb8fbecda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.279912 46975878505344 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpr0g821xw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab9b5237e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:36.280241 47258718995328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:36.280308 46975878505344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:36.282904 47144185537408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.283039 47293171643264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.284997 47258718995328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.285037 46975878505344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:36.296211 47219137454976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.299878 47975441322880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.300003 47101069906816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.300528 47219137454976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:36.301011 47281137062784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.301326 47689048318848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:36.302047 47144185537408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_len[2019-06-18 12:10:14] moving /lfs/lfs12/gma_akey/results/epb269/models/000028-000015.index --> /lfs/lfs12/gma_akey/results/epb269/models/000028-000016.index
[2019-06-18 12:10:14] moving /lfs/lfs12/gma_akey/results/epb269/models/000028-000015.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000028-000016.data-00000-of-00001
[2019-06-18 12:10:14] moving /lfs/lfs12/gma_akey/results/epb269/models/000028-000015.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb
[2019-06-18 12:10:14] moving /lfs/lfs12/gma_akey/results/epb269/models/000028-000015.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000028-000016.meta
[2019-06-18 12:10:14] iteration time 27: 48.546 seconds
2019-06-18 12:10:16.045421: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881414.590206 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:10:19] minmax time: 3.216 seconds
2019-06-18 12:10:19.271547: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:10:19.276891: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:10:19.281421: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881419.293130 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 27}}
[2019-06-18 12:10:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000029-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:10:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=29 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=1023779860 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=2047559691 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=3071339522 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=4095119353 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=5118899184 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=6142679015 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=7166458846 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=8190238677 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=9214018508 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=10237798339 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=11261578170 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=12285358001 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=13309137832 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=14332917663 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=15356697494 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=16380477325 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=17404257156 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=18428036987 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=19451816818 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000027-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000028-000016 --seed=20475596649 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:10:29] eval finished: 10.315 seconds
[2019-06-18 12:10:29] Win rate 000028-000016 vs 000027-000015: 0.590
:::MLL 1560881429.670239 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:10:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=30 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=1023779861 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=2047559692 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=3071339523 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=4095119354 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=5118899185 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=6142679016 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=7166458847 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=8190238678 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=9214018509 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=10237798340 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=11261578171 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=12285358002 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=13309137833 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=14332917664 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=15356697495 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=16380477326 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=17404257157 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000029-000015 --seed=18428036988 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:10:59] selfplay finished: 29.624 seconds
[2019-06-18 12:10:59] selfplay mn: 29.646 seconds
[2019-06-18 12:10:59] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-30-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=30 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779861 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559692 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339523 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119354 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899185 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679016 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458847 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238678 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018509 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798340 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578171 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285358002 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137833 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917664 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697495 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477326 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257157 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036988 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816819 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596650 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376481 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156312 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000029-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:11:02] divide_golden_chunk finished: 3.310 seconds
[2019-06-18 12:11:02] generate golden chunk: 3.325 seconds
[2019-06-18 12:11:02] train finished: 43.421 seconds
:::MLL 1560881424.568053 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.568944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.569786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.721974 47488456217472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.723023 47488456217472 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpy17o2zgf
I0618 12:10:24.724351 47488456217472 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpy17o2zgf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b310d26ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.724822 47488456217472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.729667 47488456217472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881424.584168 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.585005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.585854 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.730883 47564500980608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.732016 47564500980608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp62sdg8yi
I0618 12:10:24.733102 47564500980608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp62sdg8yi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42c1c5ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.733513 47564500980608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881424.575999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.576725 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.577350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.736916 47377424626560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.738276 47564500980608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.737955 47377424626560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpxwf2iw6k
I0618 12:10:24.738990 47377424626560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpxwf2iw6k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1733270e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.739398 47377424626560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.744147 47377424626560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881424.590744 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.591472 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.592134 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.745193 47627757933440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.746184 47627757933440 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx8wp20l6
I0618 12:10:24.747178 47627757933440 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx8wp20l6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b517c2e1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.747581 47627757933440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.748992 47488456217472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.752245 47627757933440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.757501 47564500980608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.763763 47377424626560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.771539 47627757933440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881424.630691 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.631466 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.632174 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.773586 47180526109568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.622755 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.623664 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.624543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.774074 47212747080576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.774631 47180526109568 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpan1_6nc3
I0618 12:10:24.775637 47180526109568 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpan1_6nc3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae95b161e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:24.775086 47212747080576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpm0bcuqy3
I0618 12:10:24.776038 47180526109568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.776081 47212747080576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpm0bcuqy3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af0db9b1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881424.604563 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.605437 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.606109 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.775902 47346484351872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
I0618 12:10:24.776485 47212747080576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.777075 47346484351872 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpar337cev
I0618 12:10:24.778210 47346484351872 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpar337cev', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ffef7eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.778680 47346484351872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.781125 47180526109568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.781500 47212747080576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.784040 47346484351872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881424.637403 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.637936 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.638414 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.787627 46949221389184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.637932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.638455 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.638853 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.787770 47600562791296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.788660 46949221389184 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmplzda362t
W0618 12:10:24.788776 47600562791296 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0ubxw8ds
I0618 12:10:24.789656 46949221389184 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmplzda362t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab380402e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.789767 47600562791296 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0ubxw8ds', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b27393e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.790058 46949221389184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.790163 47600562791296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.794738 46949221389184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.794750 47600562791296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881424.585677 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.586593 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.587456 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.795881 46989423747968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.796812 47488456217472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:24.797020 46989423747968 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpp1ygyrwj
I0618 12:10:24.798130 46989423747968 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpp1ygyrwj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcdc7f7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.798582 46989423747968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.800241 47180526109568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881424.667619 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.668099 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.668525 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.800244 47332947538816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.665939 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.666429 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.666848 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.800359 47936452965248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.800946 47212747080576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.801125 47488456217472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:24.801278 47332947538816 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptdacbuha
W0618 12:10:24.801363 47936452965248 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4imqhn3b
I0618 12:10:24.802279 47332947538816 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptdacbuha', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cd81c8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.802341 47936452965248 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4imqhn3b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b995bd68e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.802685 47332947538816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.802744 47936452965248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881424.603580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.604463 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.605261 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.803296 47584643093376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.803916 46989423747968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.805092 47564500980608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:24.804400 47584643093376 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeeho6nj7
I0618 12:10:24.805477 47584643093376 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeeho6nj7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b477255de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.805949 47584643093376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.806196 47488456217472 estimator.py:1111] Calling model_fn.
W0618 12:10:24.806308 47488456217472 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:24.806390 47346484351872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.807314 47332947538816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.807362 47936452965248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.807668 47488456217472 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:24.809384 47564500980608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:24.811103 47584643093376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.811249 47377424626560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:24.813673 47600562791296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.813930 46949221389184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:10:24.814457 47564500980608 estimator.py:1111] Calling model_fn.
W0618 12:10:24.814566 47564500980608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881424.619540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.620214 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.620860 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.814950 47024414163840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.622498 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.623239 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.623872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.815137 46933023646592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.815586 47377424626560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:24.815937 47564500980608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:24.815986 47024414163840 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcge74sdw
W0618 12:10:24.816140 46933023646592 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp7g0wx99y
I0618 12:10:24.816992 47024414163840 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcge74sdw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac50216de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.817150 46933023646592 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp7g0wx99y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aafbaca3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.817409 47024414163840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.817556 46933023646592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.819014 47627757933440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:10:24.820654 47377424626560 estimator.py:1111] Calling model_fn.
W0618 12:10:24.820763 47377424626560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:24.822124 47377424626560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:24.822198 47024414163840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.822251 46933023646592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.823307 47627757933440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:24.825483 46989423747968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.826432 47936452965248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.826500 47332947538816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:10:24.828351 47627757933440 estimator.py:1111] Calling model_fn.
W0618 12:10:24.828462 47627757933440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:24.829813 47627757933440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:24.832101 47584643093376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881424.612621 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.613390 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.614055 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.835888 47778020991872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.711708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.712211 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.712656 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.836544 47325174170496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.708329 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.708900 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.709325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.836659 48006708818816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
I0618 12:10:24.836971 47778020991872 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b74788e6d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.838090 47778020991872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.837576 47325174170496 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmptk65xfzo
W0618 12:10:24.837658 48006708818816 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp4h6w8hdc
I0618 12:10:24.838585 47325174170496 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmptk65xfzo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b08c84e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.838631 48006708818816 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp4h6w8hdc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9b769cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.838988 47325174170496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.839029 48006708818816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.841295 47024414163840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.841386 46933023646592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:24.842917 47778020991872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.843651 48006708818816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.843627 47325174170496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881424.679481 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.679903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.680265 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.844148 47005123302272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.676178 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.676709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.677154 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.844137 47166838969216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.845218 47166838969216 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpy_dwnmad
W0618 12:10:24.845246 47005123302272 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzmywq1w_
I0618 12:10:24.846210 47166838969216 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpy_dwnmad', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae62b44ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.846229 47005123302272 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzmywq1w_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac084439e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.846618 47166838969216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.846644 47005123302272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.847621 47180526109568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:24.848501 47212747080576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:24.851353 47166838969216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.851444 47005123302272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:24.851904 47180526109568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:24.852764 47212747080576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881424.683673 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.684138 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.684544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.855991 47281218241408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
:::MLL 1560881424.684813 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.685301 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.685711 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.856151 47822893736832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.856604 47346484351872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:10:24.856933 47180526109568 estimator.py:1111] Calling model_fn.
W0618 12:10:24.857043 47180526109568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881424.661059 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.661487 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.661859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.857525 47134425092992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
W0618 12:10:24.857005 47281218241408 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpgg2dylfi
W0618 12:10:24.857130 47822893736832 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpyvikvt8i
I0618 12:10:24.857790 47212747080576 estimator.py:1111] Calling model_fn.
W0618 12:10:24.857897 47212747080576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881424.662804 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881424.663229 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881424.663592 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:24.857857 47162941457280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000028-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000019-000010.tfrecord.zz_0_0
I0618 12:10:24.858010 47281218241408 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpgg2dylfi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00ccce1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.858118 47822893736832 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpyvikvt8i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7eeb2e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:24.858418 47281218241408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:24.858518 47822893736832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:24.858393 47180526109568 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:24.858556 47134425092992 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2o06dwip
W0618 12:10:24.859242 47212747080576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer ins[2019-06-18 12:11:02] moving /lfs/lfs12/gma_akey/results/epb269/models/000029-000016.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000029-000017.data-00000-of-00001
[2019-06-18 12:11:02] moving /lfs/lfs12/gma_akey/results/epb269/models/000029-000016.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000029-000017.meta
[2019-06-18 12:11:02] moving /lfs/lfs12/gma_akey/results/epb269/models/000029-000016.index --> /lfs/lfs12/gma_akey/results/epb269/models/000029-000017.index
[2019-06-18 12:11:02] moving /lfs/lfs12/gma_akey/results/epb269/models/000029-000016.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb
[2019-06-18 12:11:02] iteration time 28: 48.194 seconds
2019-06-18 12:11:04.428420: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881462.783902 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:11:07] minmax time: 3.229 seconds
2019-06-18 12:11:07.667685: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:11:07.673141: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:11:07.677669: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881467.689944 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 28}}
[2019-06-18 12:11:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:11:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=30 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=1023779861 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=2047559692 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=3071339523 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=4095119354 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=5118899185 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=6142679016 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=7166458847 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=8190238678 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=9214018509 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=10237798340 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=11261578171 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=12285358002 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=13309137833 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=14332917664 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=15356697495 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=16380477326 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=17404257157 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=18428036988 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=19451816819 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000028-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000029-000017 --seed=20475596650 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:11:17] eval finished: 9.999 seconds
[2019-06-18 12:11:17] Win rate 000029-000017 vs 000028-000016: 0.550
:::MLL 1560881477.750982 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:11:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=31 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=1023779862 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=2047559693 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=3071339524 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=4095119355 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=5118899186 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=6142679017 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=7166458848 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=8190238679 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=9214018510 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=10237798341 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=11261578172 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=12285358003 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=13309137834 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=14332917665 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=15356697496 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=16380477327 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=17404257158 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000030-000016 --seed=18428036989 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:11:48] selfplay finished: 30.736 seconds
[2019-06-18 12:11:48] selfplay mn: 30.755 seconds
[2019-06-18 12:11:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-31-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=31 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779862 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559693 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339524 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119355 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899186 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679017 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458848 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238679 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018510 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798341 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578172 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285358003 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137834 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917665 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697496 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477327 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257158 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036989 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816820 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596651 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376482 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156313 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:11:51] train finished: 43.541 seconds
:::MLL 1560881472.933000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.933994 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.934837 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.067523 47180575515520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.068675 47180575515520 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu2igktfl
I0618 12:11:13.069793 47180575515520 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu2igktfl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae95e07fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.070254 47180575515520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.075532 47180575515520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881472.950786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.951703 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.952579 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.088730 47029922837376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.089770 47029922837376 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_dzwffo7
I0618 12:11:13.090786 47029922837376 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_dzwffo7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac64a6e8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.091190 47029922837376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881472.958233 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.958964 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.959660 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.093608 46922122568576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.094696 46922122568576 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpap5bi6g7
I0618 12:11:13.095707 46922122568576 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpap5bi6g7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad3108ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.096110 46922122568576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.096234 47029922837376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.097562 47180575515520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.100735 46922122568576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881472.953938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.954872 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.955739 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.103374 47428785963904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.104435 47428785963904 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2gc6r0q2
I0618 12:11:13.105415 47428785963904 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2gc6r0q2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b232886de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.105832 47428785963904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881472.977955 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.978716 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.979412 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.106917 47188923454336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.107919 47188923454336 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp1al84rwf
I0618 12:11:13.108907 47188923454336 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp1al84rwf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb4f9b6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.109313 47188923454336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.110576 47428785963904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.113919 47188923454336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.115381 47029922837376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.119967 46922122568576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.129847 47428785963904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.133294 47188923454336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881472.962297 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.963068 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.963783 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.141847 47416713782144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.142955 47416713782144 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpmcty9ir2
I0618 12:11:13.144049 47416713782144 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpmcty9ir2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2058f7fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.144499 47416713782144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.149619 47416713782144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.151477 47180575515520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881473.020006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.020555 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.021043 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.155368 47186155389824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560881473.024776 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.025245 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.025792 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.155540 47787988525952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.156438 47180575515520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:13.156401 47186155389824 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpddhif3oa
W0618 12:11:13.156523 47787988525952 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8a3lem1l
I0618 12:11:13.157365 47186155389824 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpddhif3oa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeaaa9e1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.157491 47787988525952 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8a3lem1l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76caaace48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.157768 47186155389824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:13.157890 47787988525952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.162381 47186155389824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:11:13.162258 47180575515520 estimator.py:1111] Calling model_fn.
W0618 12:11:13.162448 47787988525952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.162383 47180575515520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.163480 47029922837376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.163922 47180575515520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:13.167427 46922122568576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.167851 47029922837376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:13.170868 47416713782144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881473.057262 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.057739 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.058131 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.171447 47476017632128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560881473.048106 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.048654 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.049131 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.171547 47088759305088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.171766 46922122568576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:11:13.173001 47029922837376 estimator.py:1111] Calling model_fn.
W0618 12:11:13.173111 47029922837376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.172464 47476017632128 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcxyfp8ma
W0618 12:11:13.172548 47088759305088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpz50jexv2
I0618 12:11:13.173454 47476017632128 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcxyfp8ma', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2e27c0ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.173517 47088759305088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpz50jexv2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3fd5bbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.173857 47476017632128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:13.173911 47088759305088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.174482 47029922837376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:11:13.176890 46922122568576 estimator.py:1111] Calling model_fn.
W0618 12:11:13.177000 46922122568576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.177869 47428785963904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.178362 46922122568576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:13.178476 47476017632128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.178543 47088759305088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.180685 47188923454336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.181324 47186155389824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.181356 47787988525952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.182173 47428785963904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881473.023260 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.023683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.024047 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.182072 47646100489088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560881473.017333 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.017889 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.018331 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.182382 47677433619328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.183111 47646100489088 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp2j8cpnfr
I0618 12:11:13.184096 47646100489088 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp2j8cpnfr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55c17b5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:13.183379 47677433619328 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp_hqltmi_
I0618 12:11:13.184361 47677433619328 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp_hqltmi_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d0d14fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.184485 47646100489088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:13.184759 47677433619328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.184986 47188923454336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:11:13.187270 47428785963904 estimator.py:1111] Calling model_fn.
W0618 12:11:13.187375 47428785963904 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.188739 47428785963904 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:13.189155 47646100489088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.189271 47677433619328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:11:13.190082 47188923454336 estimator.py:1111] Calling model_fn.
W0618 12:11:13.190193 47188923454336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.191547 47188923454336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881472.954322 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.955212 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.956096 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.194096 47959970059136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.195132 47959970059136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpeco7pyek
I0618 12:11:13.196160 47959970059136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpeco7pyek', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ed590ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.196607 47959970059136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.197389 47476017632128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.197748 47088759305088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881472.966618 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.967490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.968307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.197432 47815761163136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560881472.967190 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.968082 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.968846 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.197532 47190700766080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.198469 47815761163136 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6wz5ccvi
W0618 12:11:13.198497 47190700766080 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmprxc7gpuh
I0618 12:11:13.199491 47815761163136 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6wz5ccvi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d420bae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.199490 47190700766080 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmprxc7gpuh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebb98adda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.199896 47815761163136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:13.199895 47190700766080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.201518 47959970059136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.204846 47815761163136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.204861 47190700766080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881472.960083 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881472.960788 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881472.961490 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.207861 47013843694464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.208209 47646100489088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.208271 47677433619328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.208862 47013843694464 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpbsdr08de
I0618 12:11:13.209850 47013843694464 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpbsdr08de', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac28c0a3da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.210244 47013843694464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.214875 47013843694464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.218250 47416713782144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.220711 47959970059136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.222537 47416713782144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:13.224209 47815761163136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.224379 47190700766080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:11:13.227602 47416713782144 estimator.py:1111] Calling model_fn.
W0618 12:11:13.227709 47416713782144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.228642 47186155389824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.228704 47787988525952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.229055 47416713782144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881473.008054 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.008645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.009146 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.229279 47590107870080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560881473.014435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.015317 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.016169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.230745 47084560188288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
:::MLL 1560881473.014328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.015243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.016084 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.230878 47930099995520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.230268 47590107870080 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp468kq5c5
I0618 12:11:13.231241 47590107870080 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp468kq5c5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b48b80fce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.231642 47590107870080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.231813 47084560188288 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp8zcubpjw
:::MLL 1560881473.025068 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.025536 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.025927 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.232574 47197859447680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
I0618 12:11:13.231990 47930099995520 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b97e12becc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.232853 47084560188288 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp8zcubpjw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad303125dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:13.232935 47186155389824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:13.232980 47787988525952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:11:13.233266 47930099995520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:13.233290 47084560188288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881473.028744 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.029281 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.029734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.233418 47634962215808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
W0618 12:11:13.234081 47013843694464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.233568 47197859447680 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpzvazql7l
:::MLL 1560881473.028496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881473.029024 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881473.029485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:13.234204 47303797748608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000029-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000020-000010.tfrecord.zz_0_0
I0618 12:11:13.234533 47197859447680 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpzvazql7l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed643bde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.234933 47197859447680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.234443 47634962215808 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp0cmiolqs
I0618 12:11:13.235423 47634962215808 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp0cmiolqs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b532996be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:13.235816 47634962215808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:13.235191 47303797748608 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpx10ubtpu
I0618 12:11:13.236159 47303797748608 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpx10ubtpu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b060ea60e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:13.236307 47590107870080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:11:13.236560 47303797748608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:13.238043 47787988525952 estimator.py:1111] Calling model_fn.
I0618 12:11:13.238015 47186155389824 estimator.py:1111] Calling model_fn.
W0618 12:11:13.238121 47186155389824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.238148 47787988525952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.238631 47930099995520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.238640 47084560188288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.239468 47186155389824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:13.239498 47787988525952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:13.239474 47197859447680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.240450 47634962215808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.241097 47303797748608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:13.244692 47476017632128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.245003 47088759305088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:13.248963 47476017632128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:13.249300 47088759305088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:11:13.254063 47476017632128 estimator.py:1111] Calling model_fn.
W0618 12:11:13.254168 47476017632128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:11:13.254404 47088759305088 estimator.py:1111] Calling model_fn.
W0618 12:11:13.254509 47088759305088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:13.255237 47590107870080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:13.255527 47476017632128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initial[2019-06-18 12:11:51] divide_golden_chunk finished: 3.335 seconds
[2019-06-18 12:11:51] generate golden chunk: 3.349 seconds
[2019-06-18 12:11:51] moving /lfs/lfs12/gma_akey/results/epb269/models/000030-000017.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb269/models/000030-000018.data-00000-of-00001
[2019-06-18 12:11:51] moving /lfs/lfs12/gma_akey/results/epb269/models/000030-000017.index --> /lfs/lfs12/gma_akey/results/epb269/models/000030-000018.index
[2019-06-18 12:11:51] moving /lfs/lfs12/gma_akey/results/epb269/models/000030-000017.meta --> /lfs/lfs12/gma_akey/results/epb269/models/000030-000018.meta
[2019-06-18 12:11:51] moving /lfs/lfs12/gma_akey/results/epb269/models/000030-000017.pb --> /lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb
[2019-06-18 12:11:51] iteration time 29: 49.115 seconds
2019-06-18 12:11:53.444107: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881511.899096 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:11:56] minmax time: 3.236 seconds
2019-06-18 12:11:56.689948: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:11:56.695525: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:11:56.700184: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881516.712020 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 29}}
[2019-06-18 12:11:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb196 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb195 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb269/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb269/models/000031-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb194 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:11:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-eval-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=31 : \
-host epb307 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=1023779862 : \
-host epb345 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=2047559693 : \
-host epb212 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=3071339524 : \
-host epb305 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=4095119355 : \
-host epb147 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=5118899186 : \
-host epb146 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=6142679017 : \
-host epb145 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=7166458848 : \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=8190238679 : \
-host epb143 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=9214018510 : \
-host epb142 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=10237798341 : \
-host epb141 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=11261578172 : \
-host epb140 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=12285358003 : \
-host epb229 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=13309137834 : \
-host epb228 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=14332917665 : \
-host epb227 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=15356697496 : \
-host epb226 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=16380477327 : \
-host epb225 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=17404257158 : \
-host epb224 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=18428036989 : \
-host epb223 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=19451816820 : \
-host epb222 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000030-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/000030-000018 --seed=20475596651 : \
-host epb221 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:12:07] eval finished: 10.634 seconds
[2019-06-18 12:12:07] Win rate 000030-000018 vs 000029-000017: 0.440
:::MLL 1560881527.408727 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:12:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-selfplay-32-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb269 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=32 : \
-host epb307 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=1023779863 : \
-host epb345 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=2047559694 : \
-host epb212 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=3071339525 : \
-host epb305 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=4095119356 : \
-host epb147 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=5118899187 : \
-host epb146 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=6142679018 : \
-host epb145 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=7166458849 : \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=8190238680 : \
-host epb143 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=9214018511 : \
-host epb142 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=10237798342 : \
-host epb141 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=11261578173 : \
-host epb140 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=12285358004 : \
-host epb229 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=13309137835 : \
-host epb228 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=14332917666 : \
-host epb227 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=15356697497 : \
-host epb226 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=16380477328 : \
-host epb225 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=17404257159 : \
-host epb224 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb269/data/holdout/000031-000017 --seed=18428036990 : \
-host epb223 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb269/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000029-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb26
[2019-06-18 12:12:38] selfplay finished: 30.651 seconds
[2019-06-18 12:12:38] selfplay mn: 30.670 seconds
[2019-06-18 12:12:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb269/mpi/out-divide_golden_chunk-32-%r.txt \
-host epb269 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=32 : \
-host epb307 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=1023779863 : \
-host epb345 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=2047559694 : \
-host epb212 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=3071339525 : \
-host epb305 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=4095119356 : \
-host epb147 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=5118899187 : \
-host epb146 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=6142679018 : \
-host epb145 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=7166458849 : \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=8190238680 : \
-host epb143 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=9214018511 : \
-host epb142 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=10237798342 : \
-host epb141 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=11261578173 : \
-host epb140 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=12285358004 : \
-host epb229 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=13309137835 : \
-host epb228 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=14332917666 : \
-host epb227 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=15356697497 : \
-host epb226 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=16380477328 : \
-host epb225 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=17404257159 : \
-host epb224 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=18428036990 : \
-host epb223 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=19451816821 : \
-host epb222 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=20475596652 : \
-host epb221 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=21499376483 : \
-host epb220 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000031-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb269 --seed=22523156314 : \
-host epb199 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb269/data/selfplay/000031-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb269/data/golde
[2019-06-18 12:12:40] train finished: 43.838 seconds
:::MLL 1560881521.969996 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881521.970796 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881521.971466 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.084460 47097791705984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881521.956634 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881521.957539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881521.958394 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.085046 47711714521984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.085553 47097791705984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp6pasmbpi
I0618 12:12:02.086560 47097791705984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp6pasmbpi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad617bb1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:02.086062 47711714521984 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf7mm5p_r
I0618 12:12:02.086968 47097791705984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.087053 47711714521984 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf7mm5p_r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6508620e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.087453 47711714521984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.091725 47097791705984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.092073 47711714521984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.110644 47097791705984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.111164 47711714521984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.158364 47711714521984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:02.158324 47097791705984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881521.966521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881521.967351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881521.968165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.159185 47592019469184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881521.967015 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881521.967875 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881521.968611 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.159362 47801459336064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.160237 47592019469184 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps757vead
W0618 12:12:02.160357 47801459336064 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpw8rduyrd
I0618 12:12:02.161319 47592019469184 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps757vead', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b492a007e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.161439 47801459336064 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpw8rduyrd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79ed973e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.161756 47592019469184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.161870 47801459336064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.162601 47097791705984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:02.162660 47711714521984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881522.052295 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.052783 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.053204 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.162625 47085771625344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881522.048422 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.048957 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.049469 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.162597 47161295639424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881522.003520 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.004484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.005387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.163908 47474497262464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.163645 47161295639424 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcaaxaxab
W0618 12:12:02.163678 47085771625344 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpvrevcgbn
I0618 12:12:02.164626 47161295639424 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcaaxaxab', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4e0dc6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.164669 47085771625344 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpvrevcgbn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad34b476da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.165015 47161295639424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.165072 47085771625344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.165072 47474497262464 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp55bjj_5t
I0618 12:12:02.166208 47474497262464 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp55bjj_5t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2dcd21ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:02.166593 47801459336064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.166596 47592019469184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:02.166662 47474497262464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.167656 47097791705984 estimator.py:1111] Calling model_fn.
I0618 12:12:02.167726 47711714521984 estimator.py:1111] Calling model_fn.
W0618 12:12:02.167784 47097791705984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.167847 47711714521984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.169138 47097791705984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:02.169197 47711714521984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:02.169623 47161295639424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.169707 47085771625344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.172075 47474497262464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.185924 47801459336064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.185881 47592019469184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.188546 47161295639424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.188799 47085771625344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881522.008903 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.009614 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.010280 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.191910 47523204723584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.193002 47523204723584 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcee4r9hi
I0618 12:12:02.194103 47523204723584 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcee4r9hi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b392452ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:02.194219 47474497262464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:12:02.194550 47523204723584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.199695 47523204723584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881522.018688 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.019623 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.020477 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.205756 46948591616896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881522.030554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.031133 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.031670 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.206596 47502797235072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.206883 46948591616896 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp37p7df48
:::MLL 1560881522.036359 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.036812 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.037203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.207762 47487769658240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
I0618 12:12:02.208010 46948591616896 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp37p7df48', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab35ab69e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:02.207587 47502797235072 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpcoaf5riz
I0618 12:12:02.208477 46948591616896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.208581 47502797235072 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpcoaf5riz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3463f13e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.208986 47502797235072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.208755 47487769658240 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpu1u4l_6e
I0618 12:12:02.209762 47487769658240 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpu1u4l_6e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30e43a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.210160 47487769658240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.213619 47502797235072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.213817 46948591616896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.214739 47487769658240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881522.031299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.031986 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.032681 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.217878 47076788298624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
I0618 12:12:02.219010 47076788298624 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb269/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad133d4bd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.220286 47076788298624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.220996 47523204723584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.225584 47076788298624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.232548 47502797235072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.233721 47487769658240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.233720 47801459336064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:02.233778 47592019469184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:02.235481 46948591616896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.235544 47161295639424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:02.236178 47085771625344 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881522.007782 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.008545 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.009235 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.237632 47742361699200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.238043 47801459336064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:02.238115 47592019469184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:02.238747 47742361699200 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpypvq89fa
I0618 12:12:02.239826 47742361699200 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpypvq89fa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c2b18de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:02.239836 47161295639424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:12:02.240259 47742361699200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881522.082245 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.082677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.083036 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.239958 47360753697664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881522.083623 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.084028 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.084387 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.240268 47445460779904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.240550 47085771625344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:02.240997 47360753697664 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpowa0chjf
W0618 12:12:02.241245 47445460779904 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpehicm5p3
I0618 12:12:02.241998 47360753697664 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpowa0chjf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13517cde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.242224 47445460779904 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpehicm5p3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b270a6c5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.242397 47360753697664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.242619 47445460779904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.243110 47801459336064 estimator.py:1111] Calling model_fn.
I0618 12:12:02.243190 47592019469184 estimator.py:1111] Calling model_fn.
W0618 12:12:02.243218 47801459336064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.243296 47592019469184 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.244578 47801459336064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:02.244667 47592019469184 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:12:02.244870 47161295639424 estimator.py:1111] Calling model_fn.
W0618 12:12:02.244978 47161295639424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.245322 47742361699200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:02.245656 47085771625344 estimator.py:1111] Calling model_fn.
W0618 12:12:02.245768 47085771625344 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.246011 47474497262464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:02.246332 47161295639424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881522.035930 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.036674 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.037431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.246076 47130871731072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881522.038524 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.039295 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.040019 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.246141 47843087618944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.247124 47085771625344 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:02.247014 47360753697664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.247171 47076788298624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.247176 47445460779904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.247168 47130871731072 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpe97eqe0y
W0618 12:12:02.247209 47843087618944 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmps34myfke
I0618 12:12:02.248190 47130871731072 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpe97eqe0y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2addcb746e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.248220 47843087618944 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmps34myfke', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b839ed45e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.248590 47130871731072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.248621 47843087618944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.250386 47474497262464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:02.253522 47130871731072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.253650 47843087618944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:02.255525 47474497262464 estimator.py:1111] Calling model_fn.
W0618 12:12:02.255638 47474497262464 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.257031 47474497262464 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881522.095951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.096387 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.096747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.259689 46913299141504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
:::MLL 1560881522.095141 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.095598 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.096012 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.259831 47832308466560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.260735 46913299141504 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmp90hgu63t
W0618 12:12:02.260846 47832308466560 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmppa5jtbw5
I0618 12:12:02.261740 46913299141504 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmp90hgu63t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab231e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.261830 47832308466560 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmppa5jtbw5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b811c578e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.262137 46913299141504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:02.262227 47832308466560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.265615 47742361699200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.265773 47360753697664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.266182 47445460779904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.266797 46913299141504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:02.266875 47832308466560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881522.005382 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881522.006139 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881522.006850 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:02.267713 47342962647936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/000021-000010.tfrecord.zz_0_0
W0618 12:12:02.268450 47523204723584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:02.268695 47342962647936 estimator.py:1760] Using temporary folder as model directory: /tmp/96730.tmpdir/tmpf_huww73
I0618 12:12:02.269690 47342962647936 estimator.py:201] Using config: {'_model_dir': '/tmp/96730.tmpdir/tmpf_huww73', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f2d0efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:02.270123 47342962647936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:02.272499 47130871731072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.272726 47523204723584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:02.273187 47843087618944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:02.274938 47342962647936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:02.277760 47523204723584 estimator.py:1111] Calling model_fn.
W0618 12:12:02.277876 47523204723584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:02.279233 47523204723584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:02.279568 47502797235072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instruc[2019-06-18 12:12:41] divide_golden_chunk finished: 3.416 seconds
[2019-06-18 12:12:41] generate golden chunk: 3.430 seconds
[2019-06-18 12:12:41] iteration time 30: 49.612 seconds
:::MLL 1560881561.510868 epoch_stop: {"value": null, "metadata": {'lineno': 737, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:12:41] Total time: 1704.078 seconds

numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000018-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000018-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000019-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000019-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000020-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000020-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000021-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000021-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000022-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000022-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000023-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000023-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000024-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000024-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000025-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000025-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000026-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000026-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000027-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000027-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000028-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000028-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000029-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000029-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb269/models/000030-000018_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb269/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb269/models/000030-000018log.txt
:::MLL 1560881564.132365 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
I0618 12:12:44.134100 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=1
I0618 12:13:11.560875 47092896502656 utils.py:86] eval finished: 27.425 seconds
I0618 12:13:11.564816 47092896502656 reference_implementation.py:563] Win rate 000001-000001 vs target: 0.070
:::MLL 1560881591.565711 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560881591.566046 eval_accuracy: {"value": 0.07, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560881591.566380 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
I0618 12:13:11.566702 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=2
I0618 12:13:40.198045 47092896502656 utils.py:86] eval finished: 28.631 seconds
I0618 12:13:40.200937 47092896502656 reference_implementation.py:563] Win rate 000002-000002 vs target: 0.060
:::MLL 1560881620.202084 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560881620.202418 eval_accuracy: {"value": 0.06, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560881620.202718 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
I0618 12:13:40.203033 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000003-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=3
I0618 12:14:06.921753 47092896502656 utils.py:86] eval finished: 26.719 seconds
I0618 12:14:06.924649 47092896502656 reference_implementation.py:563] Win rate 000003-000003 vs target: 0.090
:::MLL 1560881646.925323 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560881646.925644 eval_accuracy: {"value": 0.09, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560881646.925959 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
I0618 12:14:06.926273 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=4
I0618 12:14:32.074172 47092896502656 utils.py:86] eval finished: 25.148 seconds
I0618 12:14:32.077101 47092896502656 reference_implementation.py:563] Win rate 000004-000003 vs target: 0.080
:::MLL 1560881672.077992 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560881672.078325 eval_accuracy: {"value": 0.08, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560881672.078639 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
I0618 12:14:32.078943 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=5
I0618 12:14:56.698786 47092896502656 utils.py:86] eval finished: 24.620 seconds
I0618 12:14:56.701698 47092896502656 reference_implementation.py:563] Win rate 000005-000003 vs target: 0.150
:::MLL 1560881696.702380 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560881696.702703 eval_accuracy: {"value": 0.15, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560881696.703025 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
I0618 12:14:56.703329 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=6
I0618 12:15:22.518806 47092896502656 utils.py:86] eval finished: 25.815 seconds
I0618 12:15:22.521726 47092896502656 reference_implementation.py:563] Win rate 000006-000004 vs target: 0.160
:::MLL 1560881722.522371 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560881722.522679 eval_accuracy: {"value": 0.16, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560881722.522979 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
I0618 12:15:22.523296 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=7
I0618 12:15:48.459872 47092896502656 utils.py:86] eval finished: 25.936 seconds
I0618 12:15:48.462837 47092896502656 reference_implementation.py:563] Win rate 000007-000005 vs target: 0.180
:::MLL 1560881748.463906 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560881748.464252 eval_accuracy: {"value": 0.18, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560881748.464574 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
I0618 12:15:48.464890 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=8
I0618 12:16:14.840033 47092896502656 utils.py:86] eval finished: 26.375 seconds
I0618 12:16:14.842851 47092896502656 reference_implementation.py:563] Win rate 000008-000006 vs target: 0.180
:::MLL 1560881774.843522 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560881774.843844 eval_accuracy: {"value": 0.18, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560881774.844172 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
I0618 12:16:14.844470 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=9
I0618 12:16:39.670450 47092896502656 utils.py:86] eval finished: 24.826 seconds
I0618 12:16:39.673315 47092896502656 reference_implementation.py:563] Win rate 000009-000006 vs target: 0.120
:::MLL 1560881799.674010 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560881799.674338 eval_accuracy: {"value": 0.12, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560881799.674654 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
I0618 12:16:39.674961 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=10
I0618 12:17:04.497365 47092896502656 utils.py:86] eval finished: 24.822 seconds
I0618 12:17:04.500229 47092896502656 reference_implementation.py:563] Win rate 000010-000006 vs target: 0.250
:::MLL 1560881824.501087 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560881824.501422 eval_accuracy: {"value": 0.25, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560881824.501741 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
I0618 12:17:04.502043 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=11
I0618 12:17:29.399897 47092896502656 utils.py:86] eval finished: 24.898 seconds
I0618 12:17:29.402786 47092896502656 reference_implementation.py:563] Win rate 000011-000007 vs target: 0.260
:::MLL 1560881849.403452 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560881849.403774 eval_accuracy: {"value": 0.26, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560881849.404087 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
I0618 12:17:29.404409 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000012-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=12
I0618 12:17:54.043451 47092896502656 utils.py:86] eval finished: 24.639 seconds
I0618 12:17:54.046449 47092896502656 reference_implementation.py:563] Win rate 000012-000007 vs target: 0.210
:::MLL 1560881874.055671 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560881874.055990 eval_accuracy: {"value": 0.21, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560881874.056302 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
I0618 12:17:54.056607 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=13
I0618 12:18:20.163948 47092896502656 utils.py:86] eval finished: 26.107 seconds
I0618 12:18:20.166750 47092896502656 reference_implementation.py:563] Win rate 000013-000008 vs target: 0.220
:::MLL 1560881900.171653 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560881900.171968 eval_accuracy: {"value": 0.22, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560881900.172278 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
I0618 12:18:20.172579 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000014-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=14
I0618 12:18:44.900453 47092896502656 utils.py:86] eval finished: 24.728 seconds
I0618 12:18:44.903356 47092896502656 reference_implementation.py:563] Win rate 000014-000008 vs target: 0.340
:::MLL 1560881924.903997 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560881924.904310 eval_accuracy: {"value": 0.34, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560881924.904608 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
I0618 12:18:44.904909 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000015-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=15
I0618 12:19:08.783390 47092896502656 utils.py:86] eval finished: 23.878 seconds
I0618 12:19:08.786181 47092896502656 reference_implementation.py:563] Win rate 000015-000009 vs target: 0.490
:::MLL 1560881948.786835 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560881948.787150 eval_accuracy: {"value": 0.49, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560881948.787450 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
I0618 12:19:08.787778 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000016-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=16
I0618 12:19:35.308698 47092896502656 utils.py:86] eval finished: 26.521 seconds
I0618 12:19:35.311543 47092896502656 reference_implementation.py:563] Win rate 000016-000010 vs target: 0.460
:::MLL 1560881975.312415 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560881975.312725 eval_accuracy: {"value": 0.46, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560881975.313024 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
I0618 12:19:35.313332 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000017-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=17
I0618 12:19:58.621222 47092896502656 utils.py:86] eval finished: 23.308 seconds
I0618 12:19:58.624089 47092896502656 reference_implementation.py:563] Win rate 000017-000010 vs target: 0.480
:::MLL 1560881998.625162 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560881998.625509 eval_accuracy: {"value": 0.48, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560881998.625826 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
I0618 12:19:58.626144 47092896502656 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb269/models/000018-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb269/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb269/sgf/eval/target --seed=18
I0618 12:20:21.782770 47092896502656 utils.py:86] eval finished: 23.156 seconds
I0618 12:20:21.785759 47092896502656 reference_implementation.py:563] Win rate 000018-000011 vs target: 0.520
:::MLL 1560882021.786437 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
:::MLL 1560882021.786741 eval_accuracy: {"value": 0.52, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
:::MLL 1560882021.787058 eval_result: {"value": null, "metadata": {'lineno': 52, 'file': 'ml_perf/eval_models.py', 'iteration': 17, 'timestamp': 896.495}}
:::MLL 1560882021.787361 run_stop: {"value": null, "metadata": {'lineno': 53, 'file': 'ml_perf/eval_models.py', 'status': 'success'}}
Model 000018-000011 beat target after 896.495s
~/submission/benchmarks/minigo/clx-8260l-2s-x32
