:::MLL 1560879849.842041744 submission_org: {"value": "Intel_Corp", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.843730808 submission_platform: {"value": "32xCLX-8260L_CPUs", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.845097362 submission_division: {"value": "closed", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.846605513 submission_status: {"value": "onprem", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.848270392 submission_benchmark: {"value": "minigo", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.849784491 submission_poc_name: {"value": "Guokai Ma, Letian Kang, Christine Cheng, Mingxiao Huang", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.851400164 submission_poc_email: {"value": "guokai.ma@intel.com, letian.kang@intel.com, christine.cheng@intel.com, mingxiao.huang@intel.com", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879849.852942182 submission_entry: {"value": {"framework": "TensorFlow 1.13.1", "power": "none", "notes": "none", "interconnect": "OPA", "os": "Oracle Linux Server 7.6", "libraries": "MKLDNN (v0.18), MKL (v2019.0.3.20190220), IntelMPI (2018.1.163)", "compilers": "GCC6.3", "nodes": [{"num_nodes": 32, "cpu": "Intel(R) Xeon(R) Platinum 8260L CPU @ 2.40GHz", "num_cores": 48, "num_vcpus": "NA", "accelerator": "NA", "num_accelerators": 0, "sys_mem_size": "192G", "sys_storage_type": "SSD", "sys_storage_size": "800G", "cpu_accel_interconnect": "100Gb OPA", "network_card": "100Gb OPA", "num_network_cards": 1, "notes": "NA"}]}, "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560879864.778464223 cache_clear: {value: true, metadata: {lineno: 0, file: manual}}
~/submission/benchmarks/minigo/implementations/tensorflow ~/submission/benchmarks/minigo/clx-8260l-2s-x32
Physical cores = 48
Virtual cores = 96
NUMA cores = 24
KMP_HW_SUBSET = 2T
Output to /lfs/lfs12/gma_akey
./run_mn.sh: line 20: ulimit: max user processes: cannot modify limit: Operation not permitted
Wiping dir /lfs/lfs12/gma_akey/results/epb309
:::MLL 1560879872.416480 init_start: {"value": null, "metadata": {'lineno': 742, 'file': 'ml_perf/reference_implementation.py'}}
Making dir /lfs/lfs12/gma_akey/results/epb309/models
Making dir /lfs/lfs12/gma_akey/results/epb309/data/selfplay
Making dir /lfs/lfs12/gma_akey/results/epb309/data/holdout
Making dir /lfs/lfs12/gma_akey/results/epb309/sgf/eval
Making dir /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks
Making dir /lfs/lfs12/gma_akey/results/epb309/work_dir
Making dir /lfs/lfs12/gma_akey/results/epb309/mpi
[2019-06-18 11:44:32] Selfplay nodes = ['epb309', 'epb308', 'epb306', 'epb304', 'epb303', 'epb301', 'epb279', 'epb300', 'epb278', 'epb277', 'epb276', 'epb275', 'epb274', 'epb273', 'epb272', 'epb271', 'epb270', 'epb359', 'epb358', 'epb357', 'epb356', 'epb355', 'epb354', 'epb353', 'epb352', 'epb351']
[2019-06-18 11:44:32] Train nodes = ['epb350', 'epb139', 'epb138', 'epb136', 'epb135', 'epb170']
[2019-06-18 11:44:32] Eval nodes = ['epb309', 'epb308', 'epb306', 'epb304', 'epb303', 'epb301', 'epb279', 'epb300', 'epb278', 'epb277', 'epb276', 'epb275', 'epb274', 'epb273', 'epb272', 'epb271', 'epb270', 'epb359', 'epb358', 'epb357', 'epb356', 'epb355', 'epb354', 'epb353', 'epb352', 'epb351']
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.43s/it]
[2019-06-18 11:47:23] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py:86: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2019-06-18 11:47:23] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
2019-06-18 11:47:23.769310: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-06-18 11:47:23.781857: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[2019-06-18 11:47:23] From ./quantize_graph.py:351: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.
Instructions for updating:
`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.
2019-06-18 11:47:24.108769: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
[2019-06-18 11:47:24] From ./dual_net.py:679: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99']
Reading tf_records from 1 inputs
[2019-06-18 11:47:28] minmax time: 3.926 seconds
2019-06-18 11:47:28.045401: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:47:28.050900: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:47:28.055778: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880048.175773 init_stop: {"value": null, "metadata": {'lineno': 614, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560880048.176152 run_start: {"value": null, "metadata": {'lineno': 615, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560880048.176559 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 11:47:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:47:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=2 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=1023779833 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=2047559664 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=3071339495 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=4095119326 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=5118899157 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=6142678988 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=7166458819 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=8190238650 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=9214018481 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=10237798312 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=11261578143 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=12285357974 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=13309137805 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=14332917636 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=15356697467 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=16380477298 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=17404257129 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=18428036960 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000001-000000 --seed=19451816791 : \
-host epb3
[2019-06-18 11:48:02] selfplay finished: 34.697 seconds
[2019-06-18 11:48:02] selfplay mn: 34.718 seconds
[2019-06-18 11:48:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-2-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779833 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559664 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339495 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119326 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899157 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678988 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458819 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238650 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018481 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798312 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578143 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357974 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137805 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917636 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697467 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477298 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257129 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036960 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816791 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596622 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376453 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156284 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:48:29] divide_golden_chunk finished: 26.867 seconds
[2019-06-18 11:48:29] generate golden chunk: 26.883 seconds
[2019-06-18 11:48:33] train finished: 65.063 seconds
:::MLL 1560880072.762269 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.763132 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.763959 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.340371 47605422162816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.774901 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.775673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.776479 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.340429 47784939107200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.838866 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.839377 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.839813 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.340544 46927180866432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.843266 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.843706 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.844087 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.340613 47884182373248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:53.341458 47605422162816 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjucij68o
I0618 11:47:53.342216 47605422162816 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjucij68o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c48dd5da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.341921 47784939107200 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprh7ut_qz
I0618 11:47:53.342569 47605422162816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.342852 47784939107200 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprh7ut_qz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7614e87e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.342323 46927180866432 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp15dg30dr
W0618 11:47:53.342349 47884182373248 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4b0d91gn
I0618 11:47:53.343249 47784939107200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.343404 46927180866432 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp15dg30dr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aae5e887e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.343419 47884182373248 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4b0d91gn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d30448e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.343851 46927180866432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.343861 47884182373248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.366983 47605422162816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.367058 47784939107200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.367173 47884182373248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.367151 46927180866432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880072.793323 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.794207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.795053 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.382477 47392432984960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.802787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.803549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.804377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.382473 47506881368960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.883463 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.883890 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.884250 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.382504 47776918352768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.882702 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.883132 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.883507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.382497 46955152548736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:53.383522 47392432984960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5s021uba
I0618 11:47:53.384243 47392432984960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5s021uba', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ab1b86e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.383584 47776918352768 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7436d58d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.384590 47392432984960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.384765 47776918352768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.384612 47506881368960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpv9phj64_
I0618 11:47:53.385306 47506881368960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpv9phj64_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3557600e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.385631 47506881368960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.385006 46955152548736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptd7y8p86
I0618 11:47:53.386035 46955152548736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptd7y8p86', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4e1c67e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.386472 46955152548736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.387721 47605422162816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.388582 46927180866432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.388619 47884182373248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.391244 47784939107200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.405686 47392432984960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.405703 47506881368960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.405772 46955152548736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.405786 47776918352768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880072.875946 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.876327 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.876654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410250 47410926838656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.812730 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.813469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.814171 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410294 47530230752128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.815280 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.815990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.816701 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410331 47000563975040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.873540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.873917 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.874243 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410397 47569164260224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.856650 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.857071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.857398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410544 47131379450752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.859413 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.859790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.860121 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410582 47568265134976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.814122 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.814856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.815539 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410634 47486294987648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.817053 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.817791 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.818480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.410682 47178721194880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:53.414521 47410926838656 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbynrsswe
W0618 11:47:53.414752 47131379450752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdi1w0ghs
I0618 11:47:53.415644 47410926838656 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbynrsswe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f000a3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.414946 47530230752128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm20_xo1p
I0618 11:47:53.415844 47131379450752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdi1w0ghs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adde9b77e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.415159 47568265134976 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppohe_jkf
I0618 11:47:53.416028 47530230752128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm20_xo1p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ac71b7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.416093 47410926838656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.415332 47000563975040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpai01zr7_
W0618 11:47:53.415359 47569164260224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8_ul121d
I0618 11:47:53.416213 47568265134976 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppohe_jkf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43a2221e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.416292 47131379450752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.415563 47486294987648 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpu96z9gdq
I0618 11:47:53.416398 47569164260224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8_ul121d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43d7b9ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.415594 47178721194880 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2anq2eig
I0618 11:47:53.416424 47000563975040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpai01zr7_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf7481de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.416479 47530230752128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.416630 47486294987648 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpu96z9gdq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b308c54de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.416646 47568265134976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.416669 47178721194880 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2anq2eig', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8ef813e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.416811 47569164260224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.416864 47000563975040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.417080 47486294987648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.417114 47178721194880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880072.827892 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.828679 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.829515 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.423396 47976391340928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.897678 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.898150 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.898563 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.423425 47509079708544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.828507 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.829396 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.830126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.423432 47223491593088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.897656 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.898124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.898532 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.423475 47471751762816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 11:47:53.424813 47392432984960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.425039 47506881368960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.425498 46955152548736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.425562 47776918352768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.425641 47223491593088 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp15e8t8b_
:::MLL 1560880072.840739 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.841469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.842134 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.426558 47084245492608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.834708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.835614 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.836457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.426561 47539519394688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.904387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.904896 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.905317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.426595 47197226197888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560880072.908296 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880072.908720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880072.909078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:47:53.426645 47739526951808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz_0
I0618 11:47:53.426690 47223491593088 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp15e8t8b_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af35c075e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.426034 47976391340928 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpu3fcga5g
I0618 11:47:53.427103 47976391340928 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpu3fcga5g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2a859ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.427125 47223491593088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.426412 47509079708544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyawrbfei
W0618 11:47:53.426437 47471751762816 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpu3fqxfwn
I0618 11:47:53.427485 47509079708544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyawrbfei', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35da682e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.427508 47471751762816 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpu3fqxfwn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d297cee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.427538 47976391340928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.427926 47509079708544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.427948 47471751762816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.428067 47084245492608 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3fcz6oow
I0618 11:47:53.429172 47084245492608 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3fcz6oow', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad2f0506e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.429622 47084245492608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.431356 47539519394688 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7rzgbyzh
I0618 11:47:53.432431 47539519394688 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7rzgbyzh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3cf0c0eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:47:53.431800 47197226197888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp92wo1_hm
W0618 11:47:53.431829 47739526951808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyolmtcwf
I0618 11:47:53.432871 47539519394688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.432892 47197226197888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp92wo1_hm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed3e7d3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.432919 47739526951808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyolmtcwf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b8221eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:47:53.433331 47197226197888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:47:53.433367 47739526951808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:47:53.442775 47569164260224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.442913 47410926838656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.442931 47000563975040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.442941 47530230752128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.444301 47486294987648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.444314 47178721194880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.444310 47131379450752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.444304 47568265134976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.453431 47509079708544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.453408 47471751762816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.453433 47223491593088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.453427 47976391340928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.455876 47539519394688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.455914 47084245492608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.455998 47739526951808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.456059 47197226197888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:47:53.462354 47569164260224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.462841 47410926838656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.463862 47486294987648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.464020 47178721194880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.464096 47530230752128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.463999 47131379450752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.464154 47000563975040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.463994 47568265134976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.473052 46927180866432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:53.473183 47884182373248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:53.473211 47509079708544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.473174 47223491593088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.473242 47471751762816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.473383 47976391340928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.473582 47605422162816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:53.475467 47784939107200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:47:53.477050 47539519394688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.477140 47084245492608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.477355 47197226197888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.477422 47739526951808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:47:53.477586 46927180866432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:47:53.477770 47884182373248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:47:53.478262 47605422162816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:47:53.481005 47784939107200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:47:53.483051 46927180866432 estimator.py:1111] Calling model_fn.
W0618 11:47:53.483181 46927180866432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:47:53.483273 47884182373248 estimator.py:1111] Calling model_fn.
W0618 11:47:53.483388 47884182373248 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.conv[2019-06-18 11:48:33] iteration time 0: 65.091 seconds
2019-06-18 11:48:33.640268: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880113.267594 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 11:48:36] minmax time: 3.265 seconds
2019-06-18 11:48:36.915024: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:48:36.920602: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:48:36.925233: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880116.936784 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 0}}
[2019-06-18 11:48:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:48:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=2 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=1023779833 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=2047559664 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=3071339495 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=4095119326 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=5118899157 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=6142678988 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=7166458819 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=8190238650 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=9214018481 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=10237798312 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=11261578143 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=12285357974 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=13309137805 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=14332917636 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=15356697467 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=16380477298 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=17404257129 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=18428036960 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=19451816791 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000001-000001 --seed=20475596622 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 11:48:47] eval finished: 10.704 seconds
[2019-06-18 11:48:47] Win rate 000001-000001 vs checkpoint: 0.480
:::MLL 1560880127.734440 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 11:48:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=3 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=1023779834 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=2047559665 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=3071339496 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=4095119327 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=5118899158 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=6142678989 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=7166458820 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=8190238651 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=9214018482 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=10237798313 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=11261578144 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=12285357975 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=13309137806 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=14332917637 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=15356697468 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=16380477299 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=17404257130 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=18428036961 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000002-000000 --seed=19451816792 : \
-host epb3
[2019-06-18 11:49:17] selfplay finished: 29.507 seconds
[2019-06-18 11:49:17] selfplay mn: 29.527 seconds
[2019-06-18 11:49:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-3-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779834 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559665 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339496 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119327 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899158 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678989 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458820 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238651 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018482 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798313 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578144 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357975 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137806 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917637 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697468 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477299 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257130 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036961 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816792 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596623 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376454 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156285 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:49:20] divide_golden_chunk finished: 3.358 seconds
[2019-06-18 11:49:20] generate golden chunk: 3.372 seconds
[2019-06-18 11:49:21] train finished: 44.396 seconds
:::MLL 1560880122.138078 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.138793 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.139482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.208611 47784223347584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.140443 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.141174 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.141872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.208747 47814910186368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.209586 47784223347584 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpal2jirlk
W0618 11:48:42.209683 47814910186368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp796ehwuk
I0618 11:48:42.210637 47784223347584 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpal2jirlk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75ea3eee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.210730 47814910186368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp796ehwuk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d0f52ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.211085 47784223347584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.211165 47814910186368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.216266 47814910186368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.216261 47784223347584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880122.170533 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.171383 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.172169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.230556 47496631997312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.159209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.160120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.160964 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.230536 47888392283008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.231539 47888392283008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp988554d2
W0618 11:48:42.231564 47496631997312 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplc0klc0l
I0618 11:48:42.232586 47496631997312 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplc0klc0l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32f4771e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.232586 47888392283008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp988554d2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e2b32be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.232998 47888392283008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.233005 47496631997312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.236180 47814910186368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.236188 47784223347584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880122.171849 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.172571 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.173255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.236458 47674039829376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.166667 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.167575 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.168438 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.236553 47641510224768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.237444 47674039829376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpf9gnqo72
W0618 11:48:42.237559 47641510224768 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5bklssxb
I0618 11:48:42.238488 47674039829376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpf9gnqo72', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c42cbcda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.238584 47641510224768 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5bklssxb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b54afe17e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:42.238319 47888392283008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.238333 47496631997312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:48:42.238887 47674039829376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.238976 47641510224768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.243715 47674039829376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.243775 47641510224768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880122.177334 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.178112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.178763 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.243445 47726571541376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.173742 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.174577 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.175284 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.243453 47999271236480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.244518 47726571541376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1mnkbrnr
W0618 11:48:42.244545 47999271236480 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpv17uzgiq
I0618 11:48:42.245609 47726571541376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1mnkbrnr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b687dee1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.245641 47999271236480 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpv17uzgiq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7fc194e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.246058 47726571541376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.246101 47999271236480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880122.220057 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.220488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.220874 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.249779 46919034299264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.218747 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.219127 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.219485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.249869 47747948532608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.250974 47726571541376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.250975 47999271236480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:48:42.250761 46919034299264 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac78f5bd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:42.250831 47747948532608 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprpwqw8kk
I0618 11:48:42.251788 47747948532608 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprpwqw8kk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d78192e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.251845 46919034299264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.252181 47747948532608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.256449 46919034299264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.256733 47747948532608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.260162 47888392283008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.260409 47496631997312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.263506 47674039829376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.263788 47641510224768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880122.237720 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.238221 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.238641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.265050 47636546052992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.266455 47636546052992 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmzma0cch
I0618 11:48:42.267526 47636546052992 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmzma0cch', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5387fe2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.267980 47636546052992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880122.241611 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.242049 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.242434 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.268184 47546026488704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.240601 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.240986 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.241314 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.269666 47517366154112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.269186 47546026488704 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp36wd_lli
:::MLL 1560880122.241840 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.242243 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.242569 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.269732 47601104655232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:48:42.270246 47546026488704 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp36wd_lli', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e749b3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.270626 47546026488704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880122.241735 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.242213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.242641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.270885 47315411895168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560880122.242122 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.242608 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.242992 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.270992 47241421558656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.271193 47726571541376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.271258 47999271236480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.271002 47517366154112 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppeepiuyy
:::MLL 1560880122.195690 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.196584 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.197421 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.271623 47280161559424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.271037 47601104655232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpq62mcoki
:::MLL 1560880122.195870 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.196768 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.197582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.271683 47153671377792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:48:42.271986 47517366154112 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppeepiuyy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37c8514e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.271996 47601104655232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpq62mcoki', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b47856e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.272385 47517366154112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.272391 47601104655232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.272225 47315411895168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1y3hvbbp
W0618 11:48:42.272251 47241421558656 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbda3itae
W0618 11:48:42.272797 47636546052992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880122.197613 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.198560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.199427 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.272517 47335772062592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:48:42.273239 47315411895168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1y3hvbbp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b08c2e7ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.273240 47241421558656 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbda3itae', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af788bcee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880122.218181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.219039 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.219774 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.272562 47093351908224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.272555 47280161559424 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpqwese268
I0618 11:48:42.273646 47241421558656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.272617 47153671377792 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmps9clxw5u
I0618 11:48:42.273658 47315411895168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.273578 47280161559424 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpqwese268', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b008dd26e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.273642 47153671377792 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmps9clxw5u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae31a6b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.273992 47280161559424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.274078 47153671377792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.273593 47335772062592 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphuo65i6f
W0618 11:48:42.273616 47093351908224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptiz94pxz
I0618 11:48:42.274661 47335772062592 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphuo65i6f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d80775e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.274676 47093351908224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptiz94pxz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad50f194e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:48:42.275156 47546026488704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:48:42.275096 47335772062592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:48:42.275110 47093351908224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.276142 46919034299264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.276492 47747948532608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.277141 47517366154112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.277173 47601104655232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.278299 47241421558656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.278303 47315411895168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.278958 47153671377792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.279026 47280161559424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.280339 47335772062592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.280425 47093351908224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.284145 47814910186368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:42.284165 47784223347584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:42.288469 47814910186368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:48:42.288473 47784223347584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:48:42.292775 47636546052992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:48:42.293530 47814910186368 estimator.py:1111] Calling model_fn.
I0618 11:48:42.293534 47784223347584 estimator.py:1111] Calling model_fn.
W0618 11:48:42.293639 47814910186368 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:48:42.293639 47784223347584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:48:42.294636 47546026488704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880122.268052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.268487 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.268867 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.294434 47879314715520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.294992 47814910186368 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:48:42.295006 47784223347584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:48:42.295765 47879314715520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8k25rs7t
W0618 11:48:42.296790 47517366154112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.296798 47601104655232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:48:42.296881 47879314715520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8k25rs7t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c0e220e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.297328 47879314715520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.297820 47241421558656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.298043 47315411895168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880122.272784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.273223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.273584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.298270 47742860034944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 11:48:42.298774 47153671377792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.299022 47280161559424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.299226 47742860034944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzay4vknz
I0618 11:48:42.300191 47742860034944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzay4vknz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c48ccde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880122.272108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.272511 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.272862 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.300453 47095441265536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:48:42.300576 47742860034944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.301944 47879314715520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.302454 47335772062592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:48:42.301888 47095441265536 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmjsv1d98
W0618 11:48:42.302468 47093351908224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880122.274660 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880122.275118 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880122.275517 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:48:42.302844 47587263611776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz_0
I0618 11:48:42.303017 47095441265536 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmjsv1d98', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad58ba26e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.303451 47095441265536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.303836 47587263611776 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppkm29j8y
I0618 11:48:42.304849 47587263611776 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppkm29j8y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b480e87de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:48:42.305269 47587263611776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:48:42.305233 47742860034944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.308512 47095441265536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.309933 47587263611776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:48:42.311280 47674039829376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:42.311597 47641510224768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:42.311662 47496631997312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:42.311718 47888392283008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:48:42.315582 47674039829376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is dep[2019-06-18 11:49:21] iteration time 1: 48.087 seconds
2019-06-18 11:49:21.870546: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880161.355124 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 11:49:25] minmax time: 3.215 seconds
2019-06-18 11:49:25.096452: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:49:25.101979: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:49:25.106764: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880165.118836 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 1}}
[2019-06-18 11:49:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000003-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:49:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=3 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=1023779834 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=2047559665 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=3071339496 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=4095119327 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=5118899158 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=6142678989 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=7166458820 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=8190238651 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=9214018482 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=10237798313 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=11261578144 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=12285357975 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=13309137806 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=14332917637 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=15356697468 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=16380477299 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=17404257130 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=18428036961 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=19451816792 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000002-000001 --seed=20475596623 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 11:49:36] eval finished: 11.624 seconds
[2019-06-18 11:49:36] Win rate 000002-000001 vs checkpoint: 0.850
:::MLL 1560880176.819325 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 11:49:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=4 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=1023779835 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=2047559666 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=3071339497 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=4095119328 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=5118899159 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=6142678990 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=7166458821 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=8190238652 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=9214018483 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=10237798314 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=11261578145 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=12285357976 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=13309137807 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=14332917638 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=15356697469 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=16380477300 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=17404257131 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000003-000000 --seed=18428036962 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/
[2019-06-18 11:50:05] selfplay finished: 29.159 seconds
[2019-06-18 11:50:05] selfplay mn: 29.179 seconds
[2019-06-18 11:50:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-4-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779835 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559666 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339497 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119328 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899159 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678990 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458821 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238652 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018483 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798314 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578145 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357976 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137807 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917638 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697469 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477300 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257131 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036962 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816793 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596624 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376455 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156286 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000003-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:50:09] divide_golden_chunk finished: 3.240 seconds
[2019-06-18 11:50:09] generate golden chunk: 3.255 seconds
[2019-06-18 11:50:09] train finished: 44.292 seconds
:::MLL 1560880170.396987 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.397749 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.398462 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.465342 47898330231680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.387749 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.388679 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.389563 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.465356 47778713977728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.466371 47898330231680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp214t30i9
W0618 11:49:30.466398 47778713977728 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgltgt_5q
I0618 11:49:30.467405 47898330231680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp214t30i9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b907b8bbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.467450 47778713977728 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgltgt_5q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b74a1dc9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.467821 47898330231680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.467874 47778713977728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880170.392984 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.393712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.394347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.471702 47481040016256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.395810 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.396562 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.397261 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.471844 47980225348480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.472961 47778713977728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.472993 47898330231680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.472774 47481040016256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmps00nfswa
W0618 11:49:30.472881 47980225348480 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpweg2we5o
I0618 11:49:30.473893 47481040016256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmps00nfswa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f531c6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.473973 47980225348480 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpweg2we5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba38ce01e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.474331 47481040016256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.474394 47980225348480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.479256 47481040016256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.479250 47980225348480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880170.402182 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.402946 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.403573 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.479950 47325932753792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.397212 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.398122 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.398932 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.480200 47372015649664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.480947 47325932753792 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzofd29qb
W0618 11:49:30.481180 47372015649664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6bp8g9xe
I0618 11:49:30.481930 47325932753792 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzofd29qb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b35ff6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.482185 47372015649664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6bp8g9xe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b15f0c09e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.482330 47325932753792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.482579 47372015649664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880170.404200 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.405123 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.405988 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.483499 46913279771520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.423319 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.424045 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.424762 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.485137 47228532880256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.484599 46913279771520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzpz85iii
I0618 11:49:30.485599 46913279771520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzpz85iii', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab21f66e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.485995 46913279771520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.486150 47228532880256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpss5g3k9p
I0618 11:49:30.487271 47228532880256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpss5g3k9p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af488834e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:49:30.487234 47325932753792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.487496 47372015649664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:49:30.487717 47228532880256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880170.409500 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.410414 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.411271 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.488498 47807140684672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.416787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.417523 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.418164 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.488629 47562264298368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.489609 47807140684672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfg9m9tw5
W0618 11:49:30.489678 47562264298368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4q0zj81y
W0618 11:49:30.490829 46913279771520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:49:30.490756 47807140684672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfg9m9tw5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b4039bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.490791 47562264298368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4q0zj81y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b423c749e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.491212 47807140684672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.491230 47562264298368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.493003 47228532880256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.495821 47898330231680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.496047 47778713977728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.496393 47562264298368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.496416 47807140684672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.499174 47481040016256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.499274 47980225348480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880170.470493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.470952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.471356 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.501708 47972669539200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.459981 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.460430 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.460809 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.501832 47009323148160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.462517 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.463001 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.463416 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.501962 47989443183488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.469583 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.469995 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.470440 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.502810 47580927984512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.470654 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.471049 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.471373 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.502822 47895519388544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.502766 47972669539200 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8k6brcb1
W0618 11:49:30.502824 47009323148160 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwxlb1qhm
W0618 11:49:30.502910 47989443183488 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp594u7b_b
I0618 11:49:30.503777 47009323148160 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwxlb1qhm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac17e982e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.503834 47972669539200 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8k6brcb1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1ca839e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.503874 47989443183488 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp594u7b_b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5b24d1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.504168 47009323148160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.504274 47972669539200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.504268 47989443183488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.503838 47580927984512 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp73dg_7uj
I0618 11:49:30.504817 47580927984512 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp73dg_7uj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4694e5de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:49:30.504097 47895519388544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgatxe5lf
I0618 11:49:30.505127 47895519388544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgatxe5lf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fd401be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.505209 47580927984512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.505535 47895519388544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880170.476096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.476560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.477126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.506317 47448173044608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.507065 47325932753792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.507462 47372015649664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.507361 47448173044608 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsuf6jrni
I0618 11:49:30.508435 47448173044608 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsuf6jrni', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27ac162e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880170.460045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.460507 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.460907 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.508116 47002089640832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.464250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.464645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.464986 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.508342 47813176832896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.508753 47009323148160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:49:30.508873 47448173044608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.508853 47989443183488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.509369 47972669539200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.509910 47580927984512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.509060 47002089640832 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyswb62y6
W0618 11:49:30.509303 47813176832896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmph_groki5
I0618 11:49:30.510028 47002089640832 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyswb62y6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abfcf71ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:49:30.510198 47895519388544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:49:30.510266 47813176832896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmph_groki5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ca8020e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.510411 47002089640832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.510652 47813176832896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.510997 46913279771520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.513650 47448173044608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.515140 47002089640832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.515276 47813176832896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.516246 47228532880256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.517931 47807140684672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.517930 47562264298368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880170.455086 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.455814 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.456501 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.519127 47136081097600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.451661 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.452515 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.453176 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.519244 47050794091392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560880170.487095 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.487562 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.487904 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.519840 47084885615488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.520124 47136081097600 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpghsorexh
W0618 11:49:30.520207 47050794091392 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpq3lvbk6j
I0618 11:49:30.521108 47136081097600 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpghsorexh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf01f50e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.521173 47050794091392 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpq3lvbk6j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb26749e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.521500 47136081097600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.521567 47050794091392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.520914 47084885615488 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8w3gac3d
:::MLL 1560880170.490207 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.490697 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.491112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.521825 47874599621504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 11:49:30.521986 47084885615488 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8w3gac3d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad31677ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.522400 47084885615488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.522861 47874599621504 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8af5176cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.524031 47874599621504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:49:30.526329 47136081097600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.526376 47050794091392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.527160 47084885615488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.528689 47989443183488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.528725 47874599621504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:49:30.528675 47009323148160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.529190 47972669539200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.529510 47580927984512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.529857 47895519388544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.533517 47448173044608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.534999 47002089640832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.534947 47813176832896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.545094 47898330231680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:30.545104 47778713977728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:30.546271 47050794091392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.546447 47136081097600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.546952 47084885615488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.547170 47980225348480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:30.547266 47481040016256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:49:30.548329 47874599621504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:49:30.549444 47778713977728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:49:30.549467 47898330231680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880170.517837 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.518376 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.518805 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.550188 47060100281216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.551485 47980225348480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:49:30.551597 47481040016256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:49:30.551245 47060100281216 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoii5oyxz
I0618 11:49:30.552316 47060100281216 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoii5oyxz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd5125ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:49:30.552755 47060100281216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:49:30.554570 47778713977728 estimator.py:1111] Calling model_fn.
W0618 11:49:30.554734 47372015649664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:49:30.554611 47898330231680 estimator.py:1111] Calling model_fn.
W0618 11:49:30.554679 47778713977728 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:49:30.554716 47898330231680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:49:30.554797 47325932753792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880170.523754 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880170.524306 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880170.524707 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:49:30.555228 47918066746240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 11:49:30.556049 47778713977728 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:49:30.556075 47898330231680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:49:30.556556 47980225348480 estimator.py:1111] Calling model_fn.
W0618 11:49:30.556663 47980225348480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementa[2019-06-18 11:50:09] moving /lfs/lfs12/gma_akey/results/epb309/models/000003-000001.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb
[2019-06-18 11:50:09] moving /lfs/lfs12/gma_akey/results/epb309/models/000003-000001.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000003-000002.data-00000-of-00001
[2019-06-18 11:50:09] moving /lfs/lfs12/gma_akey/results/epb309/models/000003-000001.index --> /lfs/lfs12/gma_akey/results/epb309/models/000003-000002.index
[2019-06-18 11:50:09] moving /lfs/lfs12/gma_akey/results/epb309/models/000003-000001.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000003-000002.meta
[2019-06-18 11:50:09] iteration time 2: 48.124 seconds
2019-06-18 11:50:09.919200: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880209.479158 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 11:50:13] minmax time: 3.246 seconds
2019-06-18 11:50:13.175285: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:50:13.181015: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:50:13.185559: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880213.195874 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 2}}
[2019-06-18 11:50:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:50:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=4 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=1023779835 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=2047559666 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=3071339497 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=4095119328 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=5118899159 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=6142678990 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=7166458821 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=8190238652 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=9214018483 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=10237798314 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=11261578145 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=12285357976 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=13309137807 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=14332917638 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=15356697469 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=16380477300 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=17404257131 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=18428036962 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=19451816793 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000003-000002 --seed=20475596624 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:50:24] eval finished: 11.047 seconds
[2019-06-18 11:50:24] Win rate 000003-000002 vs 000002-000001: 0.460
:::MLL 1560880224.315701 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 11:50:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=5 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=1023779836 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=2047559667 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=3071339498 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=4095119329 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=5118899160 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=6142678991 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=7166458822 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=8190238653 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=9214018484 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=10237798315 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=11261578146 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=12285357977 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=13309137808 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=14332917639 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=15356697470 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=16380477301 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=17404257132 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000004-000001 --seed=18428036963 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/
[2019-06-18 11:50:54] selfplay finished: 29.822 seconds
[2019-06-18 11:50:54] selfplay mn: 29.839 seconds
[2019-06-18 11:50:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-5-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779836 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559667 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339498 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119329 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899160 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678991 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458822 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238653 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018484 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798315 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578146 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357977 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137808 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917639 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697470 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477301 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257132 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036963 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816794 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596625 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376456 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156287 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:50:57] train finished: 43.920 seconds
:::MLL 1560880218.408514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.409259 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.410032 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.476058 47041273992064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.410106 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.410856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.411541 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.476011 47850544694144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.477077 47850544694144 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprvnzp4nu
W0618 11:50:18.477102 47041273992064 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8l929iwa
I0618 11:50:18.478188 47041273992064 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8l929iwa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8ef036e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.478194 47850544694144 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprvnzp4nu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b855b4e4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.478574 47041273992064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.478612 47850544694144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.483287 47041273992064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.483431 47850544694144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.503278 47041273992064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.504197 47850544694144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880218.468175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.468661 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.469099 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.511328 47246597837696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.474104 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.474532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.474908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.511390 47646280311680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.512347 47646280311680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnk6ipetr
W0618 11:50:18.512308 47246597837696 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpk8rdo3aq
I0618 11:50:18.513262 47246597837696 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpk8rdo3aq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af8bd44ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.513294 47646280311680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnk6ipetr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55cc332e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.513653 47246597837696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.513680 47646280311680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.518291 47646280311680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.518294 47246597837696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880218.447865 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.448638 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.449291 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.528837 47510799774592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.450851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.451517 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.452188 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.529138 47884086948736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.529937 47510799774592 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5e4x417d
W0618 11:50:18.530222 47884086948736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpw7n7hmd6
I0618 11:50:18.531060 47510799774592 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5e4x417d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3640ee3da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.531400 47884086948736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpw7n7hmd6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d2a947da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.531520 47510799774592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.531857 47884086948736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880218.453569 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.454317 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.455018 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.533559 47859225973632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.456126 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.456872 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.457556 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.533746 47373010772864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.534526 47859225973632 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphncor8_q
W0618 11:50:18.534674 47373010772864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpldl3ccni
I0618 11:50:18.535502 47859225973632 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphncor8_q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8760c02e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.535619 47373010772864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpldl3ccni', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b162c10ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.535896 47859225973632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.536010 47373010772864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.536846 47510799774592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.537288 47884086948736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.538003 47646280311680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.538133 47246597837696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880218.483556 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.484380 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.485181 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.538984 47656679011200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.465285 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.466252 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.467109 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.538972 47990743430016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.455902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.456750 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.457449 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.538757 47367953752960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.455087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.455921 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.456743 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.538846 47599216104320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.539943 47990743430016 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpqooyyyy8
W0618 11:50:18.540004 47656679011200 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp07npw142
I0618 11:50:18.540935 47990743430016 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpqooyyyy8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5ffcd4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.540989 47656679011200 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp07npw142', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b583802be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:18.540781 47859225973632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.540805 47373010772864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.539901 47599216104320 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8ycmbunz
W0618 11:50:18.539871 47367953752960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmqew6hym
I0618 11:50:18.541345 47990743430016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.541384 47656679011200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.540996 47599216104320 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8ycmbunz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ad6f46e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.540995 47367953752960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmqew6hym', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14fea4fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880218.460732 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.461619 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.462448 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.541101 47538338427776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.474862 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.475648 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.476339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.541191 48003209655168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 11:50:18.541440 47599216104320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.541439 47367953752960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.542097 47538338427776 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5px9qt75
W0618 11:50:18.542142 48003209655168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp20v8oxqz
I0618 11:50:18.543104 47538338427776 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5px9qt75', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3caa5cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.543130 48003209655168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp20v8oxqz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8e6d8be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.543497 47538338427776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.543529 48003209655168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.546365 47656679011200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.546365 47990743430016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.546715 47367953752960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.546750 47599216104320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.548455 47538338427776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.548464 48003209655168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880218.500765 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.501242 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.501696 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.550013 47199509533568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.508167 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.508559 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.508896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.550517 47068770972544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.551516 47041273992064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:18.551825 47850544694144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:18.551022 47199509533568 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3mmicplc
I0618 11:50:18.552017 47199509533568 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3mmicplc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aedc6962e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:18.551474 47068770972544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyrnh9awx
I0618 11:50:18.552415 47199509533568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.552447 47068770972544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyrnh9awx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf55f60da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.552836 47068770972544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.555905 47041273992064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:18.556176 47850544694144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:18.556980 47199509533568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.557315 47068770972544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.558213 47510799774592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.558828 47884086948736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.560804 47859225973632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.560909 47373010772864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:18.561008 47041273992064 estimator.py:1111] Calling model_fn.
W0618 11:50:18.561116 47041273992064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:18.561276 47850544694144 estimator.py:1111] Calling model_fn.
W0618 11:50:18.561384 47850544694144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:50:18.562473 47041273992064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:18.562745 47850544694144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880218.527368 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.527805 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.528177 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.564297 47792404562816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.566066 47656679011200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.566059 47990743430016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.565346 47792404562816 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyoo3h2jt
I0618 11:50:18.566300 47792404562816 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyoo3h2jt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77d1e25e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880218.530151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.530596 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.530990 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.566185 47010216932224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 11:50:18.566693 47792404562816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.567158 47010216932224 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1b3de4d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:18.568158 48003209655168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.568173 47538338427776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:18.568298 47010216932224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.569070 47599216104320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.569316 47367953752960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.571287 47792404562816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.572901 47010216932224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880218.536152 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.536561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.536895 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.572858 47328561226624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.536711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.537106 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.537428 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.572922 47134031487872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.573856 47134031487872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4opyb07p
W0618 11:50:18.573812 47328561226624 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6vt7kpw2
I0618 11:50:18.574797 47328561226624 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6vt7kpw2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0bd2aabe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.574835 47134031487872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4opyb07p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade87ca6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.575191 47328561226624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:50:18.575236 47134031487872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.576565 47199509533568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.577140 47068770972544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.579791 47134031487872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.579841 47328561226624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.585355 47646280311680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:50:18.585718 47246597837696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880218.551157 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.551643 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.552075 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.586762 47274066310016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.587830 47274066310016 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgxb4gql_
I0618 11:50:18.588896 47274066310016 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgxb4gql_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff22844e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.589335 47274066310016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.589678 47646280311680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:50:18.590051 47246597837696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880218.556054 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.556509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.556922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.590561 47254854615936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560880218.554535 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.555040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.555464 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.590450 46943062119296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.591094 47792404562816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.591536 47254854615936 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjn9d66as
I0618 11:50:18.592497 47254854615936 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjn9d66as', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afaa9691e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:50:18.591514 46943062119296 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpakf86dr0
I0618 11:50:18.592579 46943062119296 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpakf86dr0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab211211e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.592884 47254854615936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.592613 47010216932224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:50:18.593017 46943062119296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.594006 47274066310016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:18.594738 47646280311680 estimator.py:1111] Calling model_fn.
W0618 11:50:18.594850 47646280311680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:50:18.595138 47246597837696 estimator.py:1111] Calling model_fn.
W0618 11:50:18.595245 47246597837696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880218.561574 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880218.562021 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880218.562403 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:50:18.595583 47784427983744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 11:50:18.596211 47646280311680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:18.596593 47246597837696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:50:18.596559 47784427983744 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpofspy4cx
W0618 11:50:18.597488 47254854615936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:50:18.597570 47784427983744 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpofspy4cx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75f6716dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:50:18.597994 47784427983744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:50:18.598028 46943062119296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:50:18.599442 47134031487872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:50:18.599527 47328561226624 deprecation.py:323] From ./preprocessing.py:144: parallel_in[2019-06-18 11:50:57] divide_golden_chunk finished: 3.315 seconds
[2019-06-18 11:50:57] generate golden chunk: 3.329 seconds
[2019-06-18 11:50:57] iteration time 3: 48.006 seconds
2019-06-18 11:50:57.965142: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880257.485035 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 11:51:01] minmax time: 3.234 seconds
2019-06-18 11:51:01.209733: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:51:01.215571: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:51:01.220071: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880261.231876 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 3}}
[2019-06-18 11:51:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000005-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:51:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=5 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=1023779836 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=2047559667 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=3071339498 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=4095119329 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=5118899160 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=6142678991 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=7166458822 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=8190238653 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=9214018484 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=10237798315 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=11261578146 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=12285357977 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=13309137808 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=14332917639 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=15356697470 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=16380477301 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=17404257132 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=18428036963 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=19451816794 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000004-000002 --seed=20475596625 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:51:12] eval finished: 10.927 seconds
[2019-06-18 11:51:12] Win rate 000004-000002 vs 000002-000001: 0.620
:::MLL 1560880272.233181 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 11:51:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=6 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=1023779837 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=2047559668 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=3071339499 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=4095119330 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=5118899161 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=6142678992 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=7166458823 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=8190238654 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=9214018485 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=10237798316 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=11261578147 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=12285357978 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=13309137809 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=14332917640 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=15356697471 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=16380477302 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=17404257133 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000005-000001 --seed=18428036964 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/
[2019-06-18 11:51:43] selfplay finished: 30.818 seconds
[2019-06-18 11:51:43] selfplay mn: 30.835 seconds
[2019-06-18 11:51:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-6-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779837 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559668 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339499 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119330 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899161 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678992 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458823 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238654 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018485 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798316 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578147 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357978 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137809 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917640 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697471 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477302 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257133 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036964 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816795 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596626 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376457 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156288 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000005-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:51:45] train finished: 44.109 seconds
:::MLL 1560880266.501910 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.502757 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.503604 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.571520 46938653787008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.502693 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.503579 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.504297 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.571558 47658586755968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.572566 47658586755968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3__pvmnp
W0618 11:51:06.572595 46938653787008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2b7f3qel
I0618 11:51:06.573633 47658586755968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3__pvmnp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58a9b8ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.573671 46938653787008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2b7f3qel', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab10a5f4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.574060 47658586755968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.574126 46938653787008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.578961 47658586755968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.579144 46938653787008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880266.532031 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.532756 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.533433 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.595275 46976229028736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.523270 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.524180 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.525023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.595328 47288887985024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.596415 46976229028736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6_nc9czr
W0618 11:51:06.596443 47288887985024 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpvdqdo2rs
I0618 11:51:06.597535 46976229028736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6_nc9czr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab9ca080da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.597553 47288887985024 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpvdqdo2rs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0295f51e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.597995 46976229028736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.598006 47288887985024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.599072 47658586755968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.600175 46938653787008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.603348 47288887985024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.603415 46976229028736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880266.567748 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.568255 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.568637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.609697 47225928536960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.541018 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.541729 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.542399 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.609972 47978236986240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.534087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.534993 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.535814 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.609994 47958801343360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.571205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.571659 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.572072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.610208 47625361560448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.610688 47225928536960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppgie56yq
I0618 11:51:06.611725 47225928536960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppgie56yq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3ed482e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:06.611045 47958801343360 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8xpcjc1z
W0618 11:51:06.611079 47978236986240 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2h57xy4z
W0618 11:51:06.611204 47625361560448 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5tgqlbuc
I0618 11:51:06.612033 47958801343360 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8xpcjc1z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e8fe7be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.612157 47225928536960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.612091 47978236986240 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2h57xy4z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3165c0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.612242 47625361560448 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5tgqlbuc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50ed585e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.612436 47958801343360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.612503 47978236986240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.612620 47625361560448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.616803 47225928536960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.617197 47625361560448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.617293 47958801343360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.617400 47978236986240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880266.580979 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.581468 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.581872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.622827 47301426926464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.585117 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.585492 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.585821 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.622902 47435346064256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.623857 47301426926464 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpp30ch174
W0618 11:51:06.623892 47435346064256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp697uh575
I0618 11:51:06.624847 47301426926464 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpp30ch174', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0581562e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.624868 47435346064256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp697uh575', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24af8a0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.625243 47301426926464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.625267 47435346064256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.625588 47288887985024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.625715 46976229028736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.629992 47301426926464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.630034 47435346064256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880266.553816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.554556 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.555253 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.632652 47215326118784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.556563 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.557327 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.558004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.632665 47652657939328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.552837 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.553696 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.554536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.633885 47017817887616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.561599 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.562344 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.562983 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.633877 47148144169856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.633768 47215326118784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpi8xvhzb4
W0618 11:51:06.633740 47652657939328 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpl5u46ebe
I0618 11:51:06.634836 47652657939328 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpl5u46ebe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5748560e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.634901 47215326118784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpi8xvhzb4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af175541e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.635286 47652657939328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.635362 47215326118784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.634922 47017817887616 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnz27h00k
W0618 11:51:06.634950 47148144169856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpn2tp7zws
I0618 11:51:06.636017 47017817887616 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnz27h00k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac378ebae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.636050 47148144169856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpn2tp7zws', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae1d0f8de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.636439 47017817887616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.636463 47148144169856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.636565 47225928536960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.636918 47625361560448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.637057 47958801343360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.638052 47978236986240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.640637 47652657939328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.640791 47215326118784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.641192 47017817887616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.641191 47148144169856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880266.604395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.604889 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.605317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.642789 47874319664000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.643849 47874319664000 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpa579tbca
I0618 11:51:06.644916 47874319664000 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpa579tbca', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ae4679e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.645360 47874319664000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.646815 47658586755968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.648297 46938653787008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880266.610784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.611230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.611631 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.648203 47735233897344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.649522 47301426926464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.649762 47435346064256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:51:06.649182 47735233897344 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a823f2d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:06.650198 47874319664000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:06.650274 47735233897344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.651129 47658586755968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:06.652642 46938653787008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:06.654968 47735233897344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:06.656208 47658586755968 estimator.py:1111] Calling model_fn.
W0618 11:51:06.656318 47658586755968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:06.657681 47658586755968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:51:06.657743 46938653787008 estimator.py:1111] Calling model_fn.
W0618 11:51:06.657857 46938653787008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:06.659229 46938653787008 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:06.661274 47017817887616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.661346 47148144169856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.663176 47215326118784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.663277 47652657939328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880266.617063 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.617908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.618774 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.663985 46913404162944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.595011 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.595951 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.596841 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.664135 47349966463872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.625805 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.626238 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.626618 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.664380 47515768341376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.664988 46913404162944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzbp_nup7
W0618 11:51:06.665095 47349966463872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpi2sa9_fd
:::MLL 1560880266.627718 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.628158 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.628545 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.665551 47911028249472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 11:51:06.665977 46913404162944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzbp_nup7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab29609e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.666073 47349966463872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpi2sa9_fd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10ce84be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:06.665361 47515768341376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfats_vie
I0618 11:51:06.666378 46913404162944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.666465 47349966463872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.666347 47515768341376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfats_vie', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3769149e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.666747 47515768341376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.666503 47911028249472 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpt11md08q
I0618 11:51:06.667475 47911028249472 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpt11md08q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9370680e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.667873 47911028249472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.669978 47874319664000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880266.631764 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.632151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.632473 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.669838 47812951835520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560880266.631078 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880266.631461 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880266.631804 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:06.669875 47495782044544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 11:51:06.671568 47349966463872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.671579 46913404162944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.671460 47515768341376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.670880 47495782044544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptkvhhfbi
W0618 11:51:06.670905 47812951835520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmph13n_is9
I0618 11:51:06.671855 47495782044544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptkvhhfbi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32c1cdee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.671865 47812951835520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmph13n_is9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c9a98be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:06.672252 47495782044544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:06.672259 47812951835520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:06.672533 47911028249472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.673681 47288887985024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.674194 46976229028736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.674652 47735233897344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:06.677067 47495782044544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.677109 47812951835520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:06.677991 47288887985024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:06.678538 46976229028736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:51:06.683017 47288887985024 estimator.py:1111] Calling model_fn.
W0618 11:51:06.683125 47288887985024 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:06.683634 46976229028736 estimator.py:1111] Calling model_fn.
W0618 11:51:06.683742 46976229028736 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:51:06.684125 47225928536960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.684448 47625361560448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.684471 47288887985024 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:06.684894 47958801343360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.685114 46976229028736 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:06.685839 47978236986240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:06.688435 47225928536960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:06.688760 47625361560448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:06.689212 47958801343360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:06.690167 47978236986240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensor[2019-06-18 11:51:46] divide_golden_chunk finished: 3.239 seconds
[2019-06-18 11:51:46] generate golden chunk: 3.253 seconds
[2019-06-18 11:51:46] moving /lfs/lfs12/gma_akey/results/epb309/models/000005-000002.index --> /lfs/lfs12/gma_akey/results/epb309/models/000005-000003.index
[2019-06-18 11:51:46] moving /lfs/lfs12/gma_akey/results/epb309/models/000005-000002.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000005-000003.data-00000-of-00001
[2019-06-18 11:51:46] moving /lfs/lfs12/gma_akey/results/epb309/models/000005-000002.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000005-000003.meta
[2019-06-18 11:51:46] moving /lfs/lfs12/gma_akey/results/epb309/models/000005-000002.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb
[2019-06-18 11:51:46] iteration time 4: 48.886 seconds
2019-06-18 11:51:46.900766: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880306.371144 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 11:51:50] minmax time: 3.247 seconds
2019-06-18 11:51:50.158224: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:51:50.163799: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:51:50.168357: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880310.178755 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 4}}
[2019-06-18 11:51:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000006-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:51:50] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=6 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=1023779837 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=2047559668 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=3071339499 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=4095119330 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=5118899161 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=6142678992 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=7166458823 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=8190238654 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=9214018485 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=10237798316 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=11261578147 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=12285357978 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=13309137809 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=14332917640 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=15356697471 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=16380477302 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=17404257133 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=18428036964 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=19451816795 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000005-000003 --seed=20475596626 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:52:01] eval finished: 11.383 seconds
[2019-06-18 11:52:01] Win rate 000005-000003 vs 000004-000002: 0.560
:::MLL 1560880321.635834 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 11:52:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=7 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=1023779838 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=2047559669 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=3071339500 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=4095119331 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=5118899162 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=6142678993 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=7166458824 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=8190238655 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=9214018486 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=10237798317 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=11261578148 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=12285357979 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=13309137810 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=14332917641 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=15356697472 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=16380477303 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=17404257134 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000006-000002 --seed=18428036965 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/
[2019-06-18 11:52:31] selfplay finished: 29.754 seconds
[2019-06-18 11:52:31] selfplay mn: 29.774 seconds
[2019-06-18 11:52:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-7-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779838 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559669 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339500 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119331 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899162 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678993 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458824 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238655 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018486 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798317 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578148 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357979 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137810 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917641 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697472 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477303 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257134 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036965 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816796 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596627 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376458 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156289 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000006-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:52:33] train finished: 43.663 seconds
:::MLL 1560880315.364062 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.364758 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.365493 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.428105 47431561184128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.353962 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.354822 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.355613 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.428100 47821461054336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.429092 47431561184128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmproia59ig
W0618 11:51:55.429132 47821461054336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpo86kfq2b
I0618 11:51:55.430135 47431561184128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmproia59ig', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b23cdf14e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.430193 47821461054336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpo86kfq2b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7e95c93e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.430568 47431561184128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.430624 47821461054336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.435951 47821461054336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.435964 47431561184128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.455610 47821461054336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.455771 47431561184128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880315.395343 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.396055 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.396749 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.468856 47298681103232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.397829 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.398566 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.399214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.469147 47460754912128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.469920 47298681103232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9g1v2lpw
I0618 11:51:55.471020 47298681103232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9g1v2lpw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04ddac3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:55.470229 47460754912128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoqoaztvo
I0618 11:51:55.471340 47460754912128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoqoaztvo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a9a063e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.471466 47298681103232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.471775 47460754912128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.476499 47298681103232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.476948 47460754912128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880315.406094 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.406838 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.407528 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.477685 47065185465216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.397871 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.398759 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.399620 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.477948 47227781399424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.478813 47065185465216 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpi1_i8yvc
W0618 11:51:55.479058 47227781399424 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp09jbubbx
I0618 11:51:55.479906 47065185465216 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpi1_i8yvc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace803f8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.480199 47227781399424 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp09jbubbx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af45bb89e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.480361 47065185465216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.480666 47227781399424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.485743 47065185465216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.486151 47227781399424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.497475 47298681103232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880315.452121 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.452646 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.453115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.497801 47391325959040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.498166 47460754912128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880315.458542 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.458990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.459397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.498578 47265969128320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.498865 47391325959040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1ui23a82
I0618 11:51:55.499868 47391325959040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1ui23a82', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a6fbc8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.500269 47391325959040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.499588 47265969128320 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9e9xlg3f
I0618 11:51:55.500575 47265969128320 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9e9xlg3f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd3fe2fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.501003 47265969128320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880315.459652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.460120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.460505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.501326 46915882185600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.459621 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.460092 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.460474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.501357 47085986894720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.424244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.425171 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.426008 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.501711 46989226161024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.431605 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.432348 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.433063 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.501880 48000828597120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.502380 46915882185600 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp19uujb_6
I0618 11:51:55.502405 47085986894720 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3581c2cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.503384 46915882185600 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp19uujb_6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aabbd143e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.503576 47085986894720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.502767 46989226161024 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpioh1462m
W0618 11:51:55.502868 48000828597120 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxdi1g0qu
I0618 11:51:55.503812 46915882185600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.503822 46989226161024 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpioh1462m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcd0b88dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.503918 48000828597120 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxdi1g0qu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba858ecadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:55.504024 47821461054336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:51:55.504260 46989226161024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.504347 48000828597120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.504524 47431561184128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:55.505125 47391325959040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.505792 47265969128320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880315.466079 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.466461 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.466784 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.507680 47236166468480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.467886 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.468260 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.468619 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.507841 47635374654336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.508088 47065185465216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.508346 47085986894720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.508433 46915882185600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.508450 47821461054336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:55.508977 47431561184128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:55.509093 47227781399424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.508741 47236166468480 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7gwgkdun
W0618 11:51:55.508850 47635374654336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_qom3rfc
I0618 11:51:55.509707 47236166468480 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7gwgkdun', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af64f829e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.509832 47635374654336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_qom3rfc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b53422c1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:51:55.509797 46989226161024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.509812 48000828597120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:51:55.510104 47236166468480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.510222 47635374654336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.513519 47821461054336 estimator.py:1111] Calling model_fn.
W0618 11:51:55.513625 47821461054336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:55.514028 47431561184128 estimator.py:1111] Calling model_fn.
W0618 11:51:55.514131 47431561184128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880315.465224 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.466047 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.466888 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.514352 47743434707840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.433276 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.434186 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.435084 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.514406 47787553747840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.514757 47236166468480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.514839 47635374654336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.514990 47821461054336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:55.515497 47431561184128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:55.515337 47743434707840 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjra5_zhd
W0618 11:51:55.515368 47787553747840 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5ipsntuz
I0618 11:51:55.516318 47743434707840 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjra5_zhd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c6b0d9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.516346 47787553747840 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5ipsntuz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76b0c0be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.516718 47743434707840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.516736 47787553747840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880315.466726 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.467538 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.468337 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.516865 47771594736512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.439983 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.440892 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.441731 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.516973 47811055190912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.517956 47771594736512 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpevdzfqkw
W0618 11:51:55.517999 47811055190912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpza43l3b3
I0618 11:51:55.519024 47771594736512 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpevdzfqkw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72f9859e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.519062 47811055190912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpza43l3b3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c298c4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.519424 47771594736512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.519454 47811055190912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.521724 47787553747840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.521738 47743434707840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.524741 47771594736512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.524746 47811055190912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.524852 47391325959040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.525383 47265969128320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.528516 47085986894720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.528691 46915882185600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.531326 46989226161024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.531708 48000828597120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.534661 47236166468480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.534720 47635374654336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.541585 47787553747840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.541773 47743434707840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.545324 47771594736512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.545494 47811055190912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:51:55.545536 47298681103232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:55.545855 47460754912128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:51:55.549859 47298681103232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:55.550184 47460754912128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:51:55.554936 47298681103232 estimator.py:1111] Calling model_fn.
W0618 11:51:55.555046 47298681103232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:51:55.555238 47460754912128 estimator.py:1111] Calling model_fn.
W0618 11:51:55.555347 47460754912128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880315.515095 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.515477 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.515798 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.555804 47426987430784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560880315.514444 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.514835 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.515179 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.555874 47593303016320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.556417 47298681103232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:55.556701 47460754912128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:51:55.556865 47426987430784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm25zuulh
W0618 11:51:55.556934 47593303016320 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppm96q99y
I0618 11:51:55.557919 47426987430784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm25zuulh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b22bd536e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.557981 47593303016320 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppm96q99y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b497681de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.558342 47426987430784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.558401 47593303016320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880315.519671 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.520131 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.520479 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.559672 47959260533632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.559262 47065185465216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880315.518751 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.519204 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.519574 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.559719 47678983132032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.560054 47227781399424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880315.519113 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.519696 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.520114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.560381 47009375449984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.560750 47678983132032 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcn6fls8x
W0618 11:51:55.560779 47959260533632 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplh2whe4a
I0618 11:51:55.561779 47678983132032 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcn6fls8x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5d6970ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.561790 47959260533632 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplh2whe4a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9eab466e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.562197 47678983132032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:51:55.562210 47959260533632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:51:55.561457 47009375449984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnhkjlvzx
I0618 11:51:55.562545 47009375449984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnhkjlvzx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac181b63e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:51:55.562968 47009375449984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880315.524713 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880315.525156 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880315.525540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:51:55.563259 47737284174720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 11:51:55.563310 47593303016320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.563307 47426987430784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:51:55.563863 47065185465216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:55.564699 47227781399424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:51:55.564267 47737284174720 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr3zzo_iw
I0618 11[2019-06-18 11:52:34] divide_golden_chunk finished: 3.274 seconds
[2019-06-18 11:52:34] generate golden chunk: 3.288 seconds
[2019-06-18 11:52:34] moving /lfs/lfs12/gma_akey/results/epb309/models/000006-000003.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000006-000004.data-00000-of-00001
[2019-06-18 11:52:34] moving /lfs/lfs12/gma_akey/results/epb309/models/000006-000003.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000006-000004.meta
[2019-06-18 11:52:34] moving /lfs/lfs12/gma_akey/results/epb309/models/000006-000003.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb
[2019-06-18 11:52:34] moving /lfs/lfs12/gma_akey/results/epb309/models/000006-000003.index --> /lfs/lfs12/gma_akey/results/epb309/models/000006-000004.index
[2019-06-18 11:52:34] iteration time 5: 48.370 seconds
2019-06-18 11:52:35.283799: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880354.741320 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 11:52:38] minmax time: 3.176 seconds
2019-06-18 11:52:38.469484: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:52:38.475132: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:52:38.479853: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880358.490382 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 5}}
[2019-06-18 11:52:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:52:38] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=7 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=1023779838 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=2047559669 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=3071339500 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=4095119331 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=5118899162 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=6142678993 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=7166458824 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=8190238655 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=9214018486 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=10237798317 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=11261578148 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=12285357979 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=13309137810 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=14332917641 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=15356697472 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=16380477303 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=17404257134 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=18428036965 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=19451816796 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000006-000004 --seed=20475596627 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:52:49] eval finished: 11.079 seconds
[2019-06-18 11:52:49] Win rate 000006-000004 vs 000005-000003: 0.400
:::MLL 1560880369.646052 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 11:52:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=8 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=1023779839 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=2047559670 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=3071339501 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=4095119332 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=5118899163 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=6142678994 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=7166458825 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=8190238656 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=9214018487 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=10237798318 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=11261578149 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=12285357980 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=13309137811 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=14332917642 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=15356697473 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=16380477304 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=17404257135 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000007-000003 --seed=18428036966 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/
[2019-06-18 11:53:19] selfplay finished: 30.004 seconds
[2019-06-18 11:53:19] selfplay mn: 30.021 seconds
[2019-06-18 11:53:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-8-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779839 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559670 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339501 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119332 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899163 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678994 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458825 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238656 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018487 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798318 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578149 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357980 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137811 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917642 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697473 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477304 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257135 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036966 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816797 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596628 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376459 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156290 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:53:22] train finished: 43.849 seconds
:::MLL 1560880363.756894 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.757789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.758493 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.833120 47430110139264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.760717 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.761449 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.762120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.833333 47369837093760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.834170 47430110139264 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpthczyhmt
W0618 11:52:43.834365 47369837093760 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9rh4hy3j
I0618 11:52:43.835223 47430110139264 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpthczyhmt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2377742e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.835421 47369837093760 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9rh4hy3j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b156ee67e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.835647 47430110139264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.835846 47369837093760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.840861 47430110139264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.841054 47369837093760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880363.764002 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.764746 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.765401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.842434 47747726758784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.762395 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.763112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.763916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.842472 47392433230720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.843572 47747726758784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp02ymq5vj
W0618 11:52:43.843602 47392433230720 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpn2ba37og
I0618 11:52:43.844618 47747726758784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp02ymq5vj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d6ae12e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.844634 47392433230720 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpn2ba37og', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ab1bc2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.845038 47747726758784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.845072 47392433230720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.850095 47747726758784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.850122 47392433230720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880363.785098 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.785855 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.786548 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.854361 47956526609280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.777455 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.778347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.779191 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.854715 47682411041664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.855430 47956526609280 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwkcvwcaw
I0618 11:52:43.856515 47956526609280 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwkcvwcaw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e08520da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:43.855798 47682411041664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0moe24ap
I0618 11:52:43.856900 47682411041664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0moe24ap', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5e35c26e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.856979 47956526609280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.857349 47682411041664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.860908 47430110139264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.861371 47369837093760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.862260 47956526609280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.862789 47682411041664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.870521 47747726758784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.870589 47392433230720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880363.828210 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.828771 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.829265 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.871012 47834135331712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.872097 47834135331712 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2di92cfv
I0618 11:52:43.873179 47834135331712 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2di92cfv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81893b3da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.873622 47834135331712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880363.792771 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.793681 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.794538 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.876130 47567950996352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.803061 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.803820 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.804507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.876240 47985239282560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.837568 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.838018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.838419 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.877429 47752007897984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.877209 47567950996352 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp89kzfcet
W0618 11:52:43.877256 47985239282560 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2fn0q8s3
I0618 11:52:43.878249 47567950996352 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp89kzfcet', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b438f68be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.878290 47985239282560 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2fn0q8s3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba4b7baae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.878669 47567950996352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.878708 47834135331712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:52:43.878708 47985239282560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.878437 47752007897984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfhthbuhw
I0618 11:52:43.879516 47752007897984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfhthbuhw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e6a0e2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.879966 47752007897984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.883940 47567950996352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.883965 47985239282560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.884513 47956526609280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.884608 47752007897984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880363.802478 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.803415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.804290 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.884876 47849554944896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.809709 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.810447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.811148 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.884947 47965592466304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.838792 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.839250 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.839640 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.884551 47305959654272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.840738 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.841142 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.841484 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.884735 47936781017984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.797487 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.798381 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.799277 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.884692 47650138997632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.816613 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.817368 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.818087 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.884725 47427916047232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.885206 47682411041664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.885950 47849554944896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwsvu9fzi
W0618 11:52:43.885598 47305959654272 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpx4hnc784
W0618 11:52:43.885981 47965592466304 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2synsq4i
W0618 11:52:43.885761 47936781017984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgwyxflbr
I0618 11:52:43.886573 47305959654272 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpx4hnc784', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b068f81fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:43.885756 47650138997632 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbrql3ipu
W0618 11:52:43.885785 47427916047232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcs_fmthd
I0618 11:52:43.887050 47849554944896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwsvu9fzi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b85204ffe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.887070 47965592466304 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2synsq4i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba024affe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.886723 47936781017984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgwyxflbr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b996f643e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.886770 47650138997632 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbrql3ipu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b56b2321e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.886818 47427916047232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcs_fmthd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b22f4acee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.886965 47305959654272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.887491 47849554944896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.887508 47965592466304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.887115 47936781017984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.887189 47650138997632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.887243 47427916047232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880363.844511 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.844886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.845214 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.888625 47047831724928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.846323 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.846732 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.847082 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.889304 47300431123328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.889663 47047831724928 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6bk37hog
I0618 11:52:43.890715 47047831724928 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6bk37hog', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca75e27e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.891151 47047831724928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.890372 47300431123328 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0545fb6d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.891713 47300431123328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.891733 47305959654272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.891855 47936781017984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.892275 47650138997632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.892729 47965592466304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.892748 47849554944896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.892371 47427916047232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.895838 47047831724928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.896366 47300431123328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.898886 47834135331712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.903897 47567950996352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.903909 47985239282560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.904468 47752007897984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.909053 47430110139264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:43.909482 47369837093760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:43.911582 47305959654272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.911694 47936781017984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.912666 47849554944896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.912806 47965592466304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.913373 47430110139264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:43.913813 47369837093760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:43.914704 47650138997632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.915379 47047831724928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.915712 47427916047232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.915985 47300431123328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:52:43.918157 47392433230720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:43.918212 47747726758784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:52:43.918437 47430110139264 estimator.py:1111] Calling model_fn.
W0618 11:52:43.918545 47430110139264 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:52:43.918918 47369837093760 estimator.py:1111] Calling model_fn.
W0618 11:52:43.919023 47369837093760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:52:43.919904 47430110139264 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:43.920379 47369837093760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:43.922459 47392433230720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:52:43.922549 47747726758784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880363.879651 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.880066 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.880455 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.923879 47255860224896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.880930 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.881528 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.881923 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.924314 47519856104320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.924904 47255860224896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpq06139gy
I0618 11:52:43.925867 47255860224896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpq06139gy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afae5597e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:52:43.925284 47519856104320 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpu04v784_
I0618 11:52:43.926255 47255860224896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.926244 47519856104320 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpu04v784_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b385cbade48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.926638 47519856104320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.927514 47392433230720 estimator.py:1111] Calling model_fn.
W0618 11:52:43.927623 47392433230720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:52:43.927608 47747726758784 estimator.py:1111] Calling model_fn.
W0618 11:52:43.927717 47747726758784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:52:43.928979 47392433230720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:43.929077 47747726758784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:52:43.930873 47255860224896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:52:43.931172 47519856104320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880363.888491 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.888930 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.889381 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.932225 47488298070912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.888522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.888958 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.889381 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.932301 47353017521024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.932695 47682411041664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:52:43.932759 47956526609280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880363.890595 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.890985 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.891371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.933556 47652170797952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560880363.891529 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880363.891942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880363.892261 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:52:43.933664 47110791410560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 11:52:43.933268 47488298070912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmcfd4bpb
W0618 11:52:43.933324 47353017521024 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoz_buys4
I0618 11:52:43.934307 47488298070912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmcfd4bpb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3103b97e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.934338 47353017521024 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoz_buys4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1184601e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.934707 47488298070912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.934720 47353017521024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.934627 47652170797952 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpd9e3ayk3
W0618 11:52:43.934714 47110791410560 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyjgc5g9o
I0618 11:52:43.935661 47652170797952 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpd9e3ayk3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b572b4cde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.935728 47110791410560 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyjgc5g9o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad91e92fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:52:43.936082 47652170797952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:52:43.936144 47110791410560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:52:43.936982 47682411041664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104[2019-06-18 11:53:23] divide_golden_chunk finished: 3.423 seconds
[2019-06-18 11:53:23] generate golden chunk: 3.438 seconds
[2019-06-18 11:53:23] iteration time 6: 48.366 seconds
2019-06-18 11:53:23.688351: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880403.106919 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 11:53:26] minmax time: 3.219 seconds
2019-06-18 11:53:26.917592: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:53:26.923309: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:53:26.928079: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880406.940540 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 6}}
[2019-06-18 11:53:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000008-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir 
[2019-06-18 11:53:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=8 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=1023779839 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=2047559670 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=3071339501 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=4095119332 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=5118899163 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=6142678994 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=7166458825 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=8190238656 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=9214018487 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=10237798318 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=11261578149 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=12285357980 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=13309137811 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=14332917642 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=15356697473 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=16380477304 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=17404257135 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=18428036966 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=19451816797 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000007-000004 --seed=20475596628 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:53:37] eval finished: 10.615 seconds
[2019-06-18 11:53:37] Win rate 000007-000004 vs 000005-000003: 0.620
:::MLL 1560880417.630947 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 11:53:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=9 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=1023779840 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=2047559671 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=3071339502 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=4095119333 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=5118899164 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=6142678995 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=7166458826 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=8190238657 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=9214018488 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=10237798319 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=11261578150 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=12285357981 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=13309137812 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=14332917643 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=15356697474 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=16380477305 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=17404257136 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000008-000003 --seed=18428036967 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/
[2019-06-18 11:54:06] selfplay finished: 29.212 seconds
[2019-06-18 11:54:06] selfplay mn: 29.229 seconds
[2019-06-18 11:54:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-9-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779840 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559671 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339502 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119333 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899164 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678995 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458826 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238657 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018488 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798319 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578150 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357981 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137812 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917643 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697474 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477305 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257136 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036967 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816798 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596629 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376460 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156291 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000008-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_
[2019-06-18 11:54:10] divide_golden_chunk finished: 3.311 seconds
[2019-06-18 11:54:10] generate golden chunk: 3.326 seconds
[2019-06-18 11:54:10] train finished: 43.708 seconds
:::MLL 1560880412.143312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.144103 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.144782 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.221170 47846442619776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.142271 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.143095 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.143827 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.221210 47689346622336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.222188 47846442619776 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_2j8n9vl
W0618 11:53:32.222236 47689346622336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpo4tplpqx
I0618 11:53:32.223311 47846442619776 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_2j8n9vl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8466cd9e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.223337 47689346622336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpo4tplpqx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5fd326fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.223762 47846442619776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.223789 47689346622336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.228827 47689346622336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.228840 47846442619776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880412.153598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.154360 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.155054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.230115 47026492449664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.152000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.152759 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.153563 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.230149 47506449204096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.231167 47026492449664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_lrvekmk
W0618 11:53:32.231196 47506449204096 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppghp03p1
I0618 11:53:32.232155 47026492449664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_lrvekmk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac57df6fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.232212 47506449204096 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppghp03p1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b353d9ddda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.232552 47026492449664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.232620 47506449204096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.237530 47026492449664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.237738 47506449204096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880412.174661 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.175405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.176090 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.247836 47419972551552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.169271 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.170162 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.171005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.248106 47349825168256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.248936 47689346622336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.249016 47846442619776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.248880 47419972551552 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppzs8416w
W0618 11:53:32.249120 47349825168256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp475gxom8
I0618 11:53:32.249931 47419972551552 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppzs8416w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b211b34be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.250151 47349825168256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp475gxom8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10c618bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.250368 47419972551552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.250566 47349825168256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.255526 47419972551552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.255609 47349825168256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.257882 47026492449664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.258797 47506449204096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880412.224957 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.225447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.225896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.270268 47412862116736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.195783 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.196688 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.197567 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.270797 47326396773248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.204123 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.204845 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.205536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.270852 47625138840448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.271322 47412862116736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_tckb5iz
I0618 11:53:32.272355 47412862116736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_tckb5iz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f73643e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.272773 47412862116736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.271974 47326396773248 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbon5n8iz
W0618 11:53:32.272018 47625138840448 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpg1urziu_
I0618 11:53:32.273081 47326396773248 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbon5n8iz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b51a7ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.273162 47625138840448 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpg1urziu_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50e011ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.273530 47326396773248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.273621 47625138840448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880412.229974 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.230416 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.230802 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.273657 47670338749312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.274635 47670338749312 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3vcssuhd
I0618 11:53:32.275640 47670338749312 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3vcssuhd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5b6631ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.276066 47670338749312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.276727 47419972551552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.276938 47349825168256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880412.233025 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.233404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.233726 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.276866 47403839017856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.277745 47412862116736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.277901 47403839017856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr9e0uzrv
I0618 11:53:32.278979 47403839017856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpr9e0uzrv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d5992ae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:32.278899 47326396773248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.278987 47625138840448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:53:32.279428 47403839017856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.280671 47670338749312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.284620 47403839017856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880412.235606 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.236016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.236411 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.284987 47862218597248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 11:53:32.286026 47862218597248 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88131ffcf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.287258 47862218597248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.292255 47862218597248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.296989 47689346622336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.297384 47412862116736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.297410 47846442619776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.300109 47670338749312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.301306 47689346622336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:32.301422 47326396773248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.301738 47846442619776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:32.301987 47625138840448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.305016 47403839017856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.306199 47026492449664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880412.259076 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.259454 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.259776 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.306086 47036718441344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.261245 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.261624 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.261952 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.306126 47095409517440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 11:53:32.306387 47689346622336 estimator.py:1111] Calling model_fn.
W0618 11:53:32.306497 47689346622336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560880412.261194 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.261571 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.261896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.306258 47511578010496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.258968 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.259355 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.259679 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.306352 47847354631040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 11:53:32.306817 47846442619776 estimator.py:1111] Calling model_fn.
W0618 11:53:32.306925 47846442619776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:53:32.307331 47506449204096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.307865 47689346622336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:32.307132 47095409517440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp88_7y7ie
W0618 11:53:32.307105 47036718441344 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmxa20c6j
W0618 11:53:32.307236 47511578010496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoknbutr7
I0618 11:53:32.308084 47036718441344 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmxa20c6j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac7df7b3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:32.307302 47847354631040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4s0sehc1
I0618 11:53:32.308097 47095409517440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp88_7y7ie', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad589bdee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:32.308279 47846442619776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:53:32.308194 47511578010496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoknbutr7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b366f512e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.308259 47847354631040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4s0sehc1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b849d29ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.308470 47036718441344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.308482 47095409517440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.308583 47511578010496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.308644 47847354631040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880412.245994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.246758 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.247499 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.309962 47053619540864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.234893 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.235764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.236608 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.310063 47170579108736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.310517 47026492449664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:32.311015 47053619540864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptc9o_kgk
W0618 11:53:32.311048 47170579108736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpk6g8rast
W0618 11:53:32.311696 47506449204096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:53:32.312016 47053619540864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptc9o_kgk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acbcedd7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.312048 47170579108736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpk6g8rast', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae70a32ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.312423 47053619540864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.312034 47862218597248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:53:32.312446 47170579108736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.313267 47095409517440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.313269 47036718441344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.313349 47511578010496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.313370 47847354631040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:53:32.315587 47026492449664 estimator.py:1111] Calling model_fn.
W0618 11:53:32.315694 47026492449664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:32.316816 47506449204096 estimator.py:1111] Calling model_fn.
W0618 11:53:32.316923 47506449204096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:53:32.317066 47026492449664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:32.317759 47170579108736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.317820 47053619540864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.318293 47506449204096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880412.251423 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.252294 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.253125 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.327681 47644932719488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560880412.265598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880412.266526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880412.267368 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:53:32.327697 47362616894336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 11:53:32.329318 47419972551552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.328790 47362616894336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpp2u7ef08
W0618 11:53:32.328823 47644932719488 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpg8nlcosw
I0618 11:53:32.329811 47362616894336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpp2u7ef08', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13c08aee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:53:32.329856 47644932719488 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpg8nlcosw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b557be09e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:53:32.329700 47349825168256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:53:32.330204 47362616894336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:53:32.330255 47644932719488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:53:32.332944 47095409517440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.332880 47847354631040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.333071 47036718441344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.332934 47511578010496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.333939 47419972551552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:32.334366 47349825168256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:32.335192 47362616894336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.335274 47644932719488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:53:32.337770 47170579108736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:53:32.337907 47053619540864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:53:32.339344 47419972551552 estimator.py:1111] Calling model_fn.
W0618 11:53:32.339461 47419972551552 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:53:32.339829 47349825168256 estimator.py:1111] Calling model_fn.
W0618 11:53:32.339941 47349825168256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:53:32.340910 47419972551552 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:32.341405 47349825168256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:53:32.344983 47412862116736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.347224 47670338749312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.349294 47412862116736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:53:32.350421 47326396773248 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.350518 47625138840448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:53:32.351523 47670338749312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and wi[2019-06-18 11:54:10] moving /lfs/lfs12/gma_akey/results/epb309/models/000008-000004.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000008-000005.meta
[2019-06-18 11:54:10] moving /lfs/lfs12/gma_akey/results/epb309/models/000008-000004.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000008-000005.data-00000-of-00001
[2019-06-18 11:54:10] moving /lfs/lfs12/gma_akey/results/epb309/models/000008-000004.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb
[2019-06-18 11:54:10] moving /lfs/lfs12/gma_akey/results/epb309/models/000008-000004.index --> /lfs/lfs12/gma_akey/results/epb309/models/000008-000005.index
[2019-06-18 11:54:10] iteration time 7: 47.620 seconds
2019-06-18 11:54:11.341397: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880450.726732 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 11:54:14] minmax time: 3.275 seconds
2019-06-18 11:54:14.626610: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:54:14.632147: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:54:14.636802: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880454.648010 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 7}}
[2019-06-18 11:54:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000009-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:54:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=9 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=1023779840 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=2047559671 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=3071339502 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=4095119333 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=5118899164 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=6142678995 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=7166458826 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=8190238657 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=9214018488 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=10237798319 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=11261578150 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=12285357981 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=13309137812 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=14332917643 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=15356697474 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=16380477305 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=17404257136 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=18428036967 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=19451816798 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000008-000005 --seed=20475596629 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 11:54:24] eval finished: 10.122 seconds
[2019-06-18 11:54:24] Win rate 000008-000005 vs 000007-000004: 0.750
:::MLL 1560880464.844936 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 11:54:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=10 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=1023779841 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=2047559672 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=3071339503 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=4095119334 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=5118899165 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=6142678996 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=7166458827 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=8190238658 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=9214018489 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=10237798320 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=11261578151 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=12285357982 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=13309137813 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=14332917644 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=15356697475 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=16380477306 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=17404257137 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000009-000004 --seed=18428036968 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:54:55] selfplay finished: 30.645 seconds
[2019-06-18 11:54:55] selfplay mn: 30.665 seconds
[2019-06-18 11:54:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-10-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779841 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559672 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339503 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119334 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899165 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678996 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458827 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238658 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018489 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798320 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578151 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357982 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137813 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917644 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697475 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477306 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257137 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036968 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816799 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596630 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376461 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156292 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000009-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:54:58] train finished: 43.804 seconds
:::MLL 1560880459.896049 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.896757 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.897466 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:19.973645 47336126161792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880459.898564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.899328 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.900041 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:19.973842 47640923870080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:19.974685 47336126161792 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphjz_758w
W0618 11:54:19.974852 47640923870080 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzha_nbbi
I0618 11:54:19.975747 47336126161792 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphjz_758w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d95927e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:19.975900 47640923870080 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzha_nbbi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b548cee6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:19.976172 47336126161792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:19.976325 47640923870080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:19.981267 47336126161792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:19.981364 47640923870080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880459.926129 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.926917 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.927702 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:19.981676 47108022309760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880459.902647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.903555 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.904402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:19.981705 47146175562624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:19.982683 47108022309760 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmgcm5bh2
W0618 11:54:19.982712 47146175562624 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptljqsyma
I0618 11:54:19.983693 47108022309760 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmgcm5bh2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad87985dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:19.983696 47146175562624 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptljqsyma', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae15ba25e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:19.984093 47108022309760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:19.984093 47146175562624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:19.989489 47108022309760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:19.989491 47146175562624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.001340 47336126161792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.001591 47640923870080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880459.934921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.935659 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.936350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.005551 47204465288064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880459.926481 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.927399 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.928223 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.005590 47661877973888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.006566 47204465288064 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr3xtk8tl
W0618 11:54:20.006593 47661877973888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4ln6jqea
I0618 11:54:20.007571 47204465288064 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpr3xtk8tl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeeedf8ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.007571 47661877973888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4ln6jqea', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b596de4ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.007968 47204465288064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.007967 47661877973888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880459.964738 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.965235 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.965656 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.008308 47846962770816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.009355 47846962770816 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6jstbdef
I0618 11:54:20.010415 47846962770816 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6jstbdef', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8485ce8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.010853 47846962770816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.011873 47108022309760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.012048 47146175562624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.012972 47661877973888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.013078 47204465288064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880459.930964 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.931668 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.932359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.013277 47508630913920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880459.933294 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.934020 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.934715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.013479 47706119775104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.014329 47508630913920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprnljdy13
W0618 11:54:20.014497 47706119775104 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpib4d9i5b
I0618 11:54:20.015392 47508630913920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprnljdy13', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b35bfa81e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.015535 47706119775104 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpib4d9i5b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63bae8fe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.015824 47508630913920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.015954 47706119775104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.016055 47846962770816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880459.968513 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.968963 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.969350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.017192 47920755651456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.018249 47920755651456 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwm2kfs_e
I0618 11:54:20.019335 47920755651456 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwm2kfs_e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95b4348da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.019773 47920755651456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.020987 47508630913920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.021066 47706119775104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880459.948093 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.948827 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.949491 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.023401 47056730428288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880459.936808 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.937696 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.938557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.023448 47760204145536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.024668 47920755651456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.024410 47056730428288 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpj40key5s
W0618 11:54:20.024437 47760204145536 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm1nd4mmt
I0618 11:54:20.025470 47056730428288 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpj40key5s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc8849ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.025494 47760204145536 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm1nd4mmt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b705296fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.025909 47056730428288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.025928 47760204145536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880459.982250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.982711 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.983098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.026950 47792299611008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.027996 47792299611008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnh54gdza
I0618 11:54:20.029072 47792299611008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnh54gdza', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77cba0cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.029519 47792299611008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.031177 47760204145536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.031208 47056730428288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.032750 47661877973888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880459.990019 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.990435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.990835 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.032638 47468700631936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.033493 47204465288064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.034279 47792299611008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.033606 47468700631936 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfenjlmx0
I0618 11:54:20.034587 47468700631936 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfenjlmx0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c73a05e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.034987 47468700631936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.037403 47846962770816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.039595 47468700631936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.040969 47706119775104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.041031 47508630913920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880459.969747 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.970465 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.971148 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.042523 47959606240128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880459.966921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880459.967634 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880459.968325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.042569 47481095652224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.043670 47481095652224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp81we37ug
W0618 11:54:20.043699 47959606240128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyq9sp7ie
I0618 11:54:20.044738 47481095652224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp81we37ug', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f566d5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.044764 47959606240128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyq9sp7ie', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ebfe16e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.045166 47481095652224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.045196 47959606240128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.045263 47920755651456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.049384 47336126161792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:20.049639 47640923870080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:20.050132 47481095652224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.050147 47959606240128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880460.005732 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.006186 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.006509 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.052656 47065911128960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.053452 47760204145536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.053710 47336126161792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:20.053985 47640923870080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:20.054036 47792299611008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880460.008716 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.009160 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.009540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.054231 47886755840896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.054202 47056730428288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.053786 47065911128960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpweg27t0y
I0618 11:54:20.054791 47065911128960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpweg27t0y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aceab803e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.055190 47065911128960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.055209 47886755840896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjah8z1ip
I0618 11:54:20.056188 47886755840896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjah8z1ip', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8dc9a89e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.056575 47886755840896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.058775 47336126161792 estimator.py:1111] Calling model_fn.
W0618 11:54:20.058889 47336126161792 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:20.059082 47640923870080 estimator.py:1111] Calling model_fn.
W0618 11:54:20.059190 47640923870080 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:20.059200 47468700631936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.059794 47065911128960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.060254 47336126161792 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:20.060561 47640923870080 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:20.061090 47886755840896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.065359 47146175562624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:20.065890 47108022309760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:20.070010 47481095652224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.070019 47959606240128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.070147 47146175562624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880460.022111 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.022546 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.022914 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.070527 47070534628224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.070693 47108022309760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880460.022784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.023201 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.023559 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.070706 47805741724544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560880460.024677 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.025062 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.025425 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.071158 47026336666496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.071538 47070534628224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy2cn6cbg
I0618 11:54:20.071701 47805741724544 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7aecd74d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.072518 47070534628224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy2cn6cbg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acfbf154e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.072802 47805741724544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.072916 47070534628224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.072134 47026336666496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpibz_dt6d
I0618 11:54:20.073122 47026336666496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpibz_dt6d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac574adee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880460.023960 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.024359 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.024715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.073261 47232304608128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
I0618 11:54:20.073575 47026336666496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:54:20.074371 47232304608128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmps3ogy45y
I0618 11:54:20.075510 47232304608128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmps3ogy45y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af569534e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:54:20.075579 47146175562624 estimator.py:1111] Calling model_fn.
W0618 11:54:20.075694 47146175562624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:54:20.075961 47232304608128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:54:20.076186 47108022309760 estimator.py:1111] Calling model_fn.
W0618 11:54:20.076303 47108022309760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:54:20.077152 47146175562624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:20.077453 47805741724544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.077516 47070534628224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.077769 47108022309760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:54:20.078341 47026336666496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.079256 47065911128960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.080426 47661877973888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:20.080550 47886755840896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:54:20.081027 47204465288064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:54:20.080987 47232304608128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:54:20.084729 47661877973888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:20.085346 47204465288064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:54:20.085686 47846962770816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880460.039646 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880460.040120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880460.040528 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:54:20.086102 47816503444352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 11:54:20.087140 47816503444352 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmp[2019-06-18 11:54:58] divide_golden_chunk finished: 3.335 seconds
[2019-06-18 11:54:58] generate golden chunk: 3.349 seconds
[2019-06-18 11:54:58] moving /lfs/lfs12/gma_akey/results/epb309/models/000009-000005.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb
[2019-06-18 11:54:58] moving /lfs/lfs12/gma_akey/results/epb309/models/000009-000005.index --> /lfs/lfs12/gma_akey/results/epb309/models/000009-000006.index
[2019-06-18 11:54:58] moving /lfs/lfs12/gma_akey/results/epb309/models/000009-000005.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000009-000006.meta
[2019-06-18 11:54:58] moving /lfs/lfs12/gma_akey/results/epb309/models/000009-000005.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000009-000006.data-00000-of-00001
[2019-06-18 11:54:58] iteration time 8: 48.175 seconds
2019-06-18 11:54:59.555196: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880498.901937 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 11:55:02] minmax time: 3.270 seconds
2019-06-18 11:55:02.835213: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:55:02.840682: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:55:02.845407: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880502.856385 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 8}}
[2019-06-18 11:55:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:55:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=10 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=1023779841 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=2047559672 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=3071339503 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=4095119334 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=5118899165 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=6142678996 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=7166458827 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=8190238658 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=9214018489 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=10237798320 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=11261578151 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=12285357982 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=13309137813 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=14332917644 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=15356697475 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=16380477306 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=17404257137 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=18428036968 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=19451816799 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000009-000006 --seed=20475596630 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:55:15] eval finished: 12.367 seconds
[2019-06-18 11:55:15] Win rate 000009-000006 vs 000008-000005: 0.250
:::MLL 1560880515.295517 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 11:55:15] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=11 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=1023779842 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=2047559673 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=3071339504 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=4095119335 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=5118899166 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=6142678997 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=7166458828 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=8190238659 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=9214018490 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=10237798321 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=11261578152 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=12285357983 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=13309137814 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=14332917645 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=15356697476 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=16380477307 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=17404257138 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000010-000005 --seed=18428036969 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:55:45] selfplay finished: 30.434 seconds
[2019-06-18 11:55:45] selfplay mn: 30.451 seconds
[2019-06-18 11:55:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-11-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779842 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559673 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339504 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119335 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899166 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678997 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458828 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238659 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018490 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798321 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578152 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357983 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137814 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917645 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697476 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477307 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257138 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036969 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816800 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596631 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376462 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156293 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000010-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:55:46] train finished: 44.112 seconds
:::MLL 1560880508.065706 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.066438 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.067095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.139097 47588036359040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.060106 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.060974 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.061777 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.139234 47114302378880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.140146 47588036359040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpce1oiw4s
W0618 11:55:08.140209 47114302378880 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp49nq_l9m
I0618 11:55:08.141167 47588036359040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpce1oiw4s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b483c96fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.141201 47114302378880 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp49nq_l9m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad9efd82e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.141605 47114302378880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.141604 47588036359040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.146365 47114302378880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.146392 47588036359040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.166312 47114302378880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.166563 47588036359040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880508.088442 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.089316 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.090096 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.169866 47938858423168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.094687 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.095433 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.096112 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.170002 47103810143104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.170978 47938858423168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpja_o0xgc
W0618 11:55:08.171078 47103810143104 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphmmdbpdr
I0618 11:55:08.171990 47938858423168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpja_o0xgc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99eb36ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.172065 47103810143104 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphmmdbpdr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad77e754e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.172379 47938858423168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.172459 47103810143104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.177163 47938858423168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.177222 47103810143104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880508.139204 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.139586 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.139943 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.189903 47449085543296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.138151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.138562 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.138942 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.190064 47016182752128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.190948 47449085543296 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp495559qk
W0618 11:55:08.191083 47016182752128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6bh8ti9o
I0618 11:55:08.191973 47449085543296 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp495559qk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27e279ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.192088 47016182752128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6bh8ti9o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac317756da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.192367 47449085543296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.192480 47016182752128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880508.125896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.126619 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.127371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.193519 47641894101888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.114428 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.115358 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.116210 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.193519 47918675727232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.194524 47641894101888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1v7u0jxo
W0618 11:55:08.194555 47918675727232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpo8706tg9
I0618 11:55:08.195520 47641894101888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1v7u0jxo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b54c6c2ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.195564 47918675727232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpo8706tg9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95383b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.195916 47641894101888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.195957 47918675727232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.196989 47449085543296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.197041 47016182752128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.196992 47938858423168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.197005 47103810143104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.201146 47641894101888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.201163 47918675727232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.214368 47114302378880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.214715 47588036359040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.216704 47449085543296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.216682 47016182752128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.218691 47114302378880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:08.219071 47588036359040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:08.223682 47641894101888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:08.223781 47114302378880 estimator.py:1111] Calling model_fn.
W0618 11:55:08.223706 47918675727232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.223901 47114302378880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:08.224179 47588036359040 estimator.py:1111] Calling model_fn.
W0618 11:55:08.224288 47588036359040 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:08.225257 47114302378880 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:08.225667 47588036359040 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880508.160130 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.160836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.161546 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.229933 47049505723264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.152680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.153597 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.154424 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.230072 47346118030208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.230993 47049505723264 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplzvzpxur
W0618 11:55:08.231078 47346118030208 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7rl9dc5q
I0618 11:55:08.231986 47049505723264 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplzvzpxur', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acad9a9ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.232088 47346118030208 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7rl9dc5q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fe9224e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.232393 47049505723264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.232496 47346118030208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880508.174868 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.175307 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.175673 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.232656 47857763935104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.172525 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.172992 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.173308 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.232716 47500007342976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.233713 47857763935104 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpre8cp31l
I0618 11:55:08.233772 47500007342976 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33bda6dd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.234753 47857763935104 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpre8cp31l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b87099b3e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.234938 47500007342976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.235142 47857763935104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.237397 47049505723264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.237395 47346118030208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.239789 47500007342976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.239923 47857763935104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880508.161677 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.162574 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.163413 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.240006 47802227458944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.167652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.168411 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.169122 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.240133 47778529567616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.241114 47802227458944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptc5nb999
W0618 11:55:08.241229 47778529567616 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzxpoh87p
I0618 11:55:08.242267 47802227458944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptc5nb999', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7a1b5fde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.242373 47778529567616 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzxpoh87p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7496deae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.242714 47802227458944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.242819 47778529567616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.245434 47103810143104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.245613 47938858423168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880508.198508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.199029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.199449 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.247287 46952180736896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.247969 47802227458944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.248049 47778529567616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.248356 46952180736896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7j8whlb3
I0618 11:55:08.249346 46952180736896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7j8whlb3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab430a41e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:08.249730 47103810143104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:55:08.249739 46952180736896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.249907 47938858423168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880508.205442 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.205871 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.206296 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.252324 47069197034368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.171749 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.172641 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.173513 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.252660 47404341797760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.176506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.177262 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.177965 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.252682 47443911426944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.253282 47069197034368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2hnspnkc
I0618 11:55:08.254255 47069197034368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2hnspnkc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf6f5b2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:08.254315 46952180736896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.253749 47404341797760 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpni4ajpqa
W0618 11:55:08.253780 47443911426944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5kj6s4a_
I0618 11:55:08.254647 47069197034368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.254796 47404341797760 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpni4ajpqa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d778a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.254830 47443911426944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5kj6s4a_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b26ae130e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.254788 47103810143104 estimator.py:1111] Calling model_fn.
W0618 11:55:08.254897 47103810143104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:08.254963 47938858423168 estimator.py:1111] Calling model_fn.
I0618 11:55:08.255213 47404341797760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.255069 47938858423168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:08.255259 47443911426944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.256261 47103810143104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:08.256424 47938858423168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:08.257434 47346118030208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.257510 47049505723264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.259245 47069197034368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.260274 47404341797760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.260302 47443911426944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.260649 47857763935104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.260885 47500007342976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.264279 47449085543296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.264372 47016182752128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.268578 47449085543296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:08.268709 47016182752128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:08.270264 47802227458944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.271165 47778529567616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:08.273621 47449085543296 estimator.py:1111] Calling model_fn.
W0618 11:55:08.273731 47449085543296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:08.273807 47016182752128 estimator.py:1111] Calling model_fn.
W0618 11:55:08.273916 47016182752128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:08.273853 46952180736896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880508.213343 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.213751 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.214153 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.274345 47712601850752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560880508.214256 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880508.214663 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880508.215020 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:08.274372 47126581244800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 11:55:08.275080 47449085543296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:08.275271 47016182752128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:08.275455 47126581244800 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp68ws8_e8
W0618 11:55:08.275425 47712601850752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7l9y916u
I0618 11:55:08.276444 47712601850752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7l9y916u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b653d459e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.276476 47126581244800 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp68ws8_e8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adccbb8be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:08.276838 47712601850752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:08.276867 47126581244800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:08.276760 47918675727232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.276932 47641894101888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:08.278606 47069197034368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.280265 47443911426944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.280295 47404341797760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:08.281404 47918675727232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:08.281551 47126581244800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.281578 47712601850752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:08.281590 47641894101888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:55:08.286856 47918675727232 estimator.py:1111] Calling model_fn.
W0618 11:55:08.286970 47918675727232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:08.287046 47641894101888 estimator.py:1111] Calling model_fn.
W0618 11:55:08.287160 47641894101888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:08.288424 47918675727232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:08.288608 47641894101888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init[2019-06-18 11:55:49] divide_golden_chunk finished: 3.442 seconds
[2019-06-18 11:55:49] generate golden chunk: 3.457 seconds
[2019-06-18 11:55:49] iteration time 9: 50.303 seconds
2019-06-18 11:55:49.907947: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880549.204776 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 11:55:53] minmax time: 3.223 seconds
2019-06-18 11:55:53.140512: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:55:53.146012: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:55:53.150624: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880553.163312 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 9}}
[2019-06-18 11:55:53] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000011-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:55:53] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=11 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=1023779842 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=2047559673 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=3071339504 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=4095119335 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=5118899166 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=6142678997 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=7166458828 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=8190238659 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=9214018490 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=10237798321 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=11261578152 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=12285357983 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=13309137814 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=14332917645 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=15356697476 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=16380477307 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=17404257138 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=18428036969 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=19451816800 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000010-000006 --seed=20475596631 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:56:03] eval finished: 10.261 seconds
[2019-06-18 11:56:03] Win rate 000010-000006 vs 000008-000005: 0.490
:::MLL 1560880563.501063 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 11:56:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=12 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=1023779843 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=2047559674 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=3071339505 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=4095119336 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=5118899167 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=6142678998 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=7166458829 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=8190238660 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=9214018491 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=10237798322 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=11261578153 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=12285357984 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=13309137815 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=14332917646 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=15356697477 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=16380477308 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=17404257139 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000011-000005 --seed=18428036970 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:56:33] selfplay finished: 30.268 seconds
[2019-06-18 11:56:33] selfplay mn: 30.286 seconds
[2019-06-18 11:56:33] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-12-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779843 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559674 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339505 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119336 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899167 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678998 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458829 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238660 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018491 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798322 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578153 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357984 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137815 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917646 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697477 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477308 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257139 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036970 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816801 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596632 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376463 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156294 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000011-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:56:36] train finished: 43.653 seconds
:::MLL 1560880558.365131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.366004 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.366814 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.444728 47697844745088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.370355 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.371095 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.371750 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.444826 47838422823808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.445733 47697844745088 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplg43dzs2
W0618 11:55:58.445811 47838422823808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm90xjsdv
I0618 11:55:58.446743 47697844745088 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplg43dzs2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61cdae0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.446796 47838422823808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm90xjsdv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8288c94e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.447198 47697844745088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.447246 47838422823808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.452014 47697844745088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.452069 47838422823808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.471922 47838422823808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.471969 47697844745088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880558.397046 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.397733 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.398373 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.475192 47402348274560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.393315 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.394164 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.394848 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.475301 47532015207296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.476200 47402348274560 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpindd3g64
W0618 11:55:58.476293 47532015207296 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpf2rmcl7p
I0618 11:55:58.477196 47402348274560 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpindd3g64', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1d00b7be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.477302 47532015207296 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpf2rmcl7p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b31781e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.477602 47402348274560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.477702 47532015207296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.482769 47532015207296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.482789 47402348274560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880558.403435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.404335 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.405222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.485838 47262278427520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.429201 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.429968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.430709 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.486456 47204190983040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.486846 47262278427520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpf5vydrg5
I0618 11:55:58.487935 47262278427520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpf5vydrg5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afc63e77e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:58.487421 47204190983040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbd1b6ww4
I0618 11:55:58.488341 47262278427520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.488393 47204190983040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbd1b6ww4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeedd9f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.488784 47204190983040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.493327 47262278427520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.493538 47204190983040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880558.439813 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.440269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.440678 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.494026 47735827534720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.440042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.440516 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.440912 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.494106 47629849940864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.495025 47735827534720 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprwnwcgbi
W0618 11:55:58.495085 47629849940864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpj98hue7g
I0618 11:55:58.495994 47735827534720 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprwnwcgbi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6aa5a16e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.496067 47629849940864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpj98hue7g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51f8dfada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.496385 47735827534720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.496466 47629849940864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.500996 47735827534720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.501044 47629849940864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.502303 47402348274560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.502613 47532015207296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.514991 47204190983040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.514956 47262278427520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.519727 47838422823808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:58.520205 47697844745088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:58.520347 47735827534720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.520570 47629849940864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.524029 47838422823808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.524510 47697844745088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:55:58.529072 47838422823808 estimator.py:1111] Calling model_fn.
W0618 11:55:58.529183 47838422823808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:58.529568 47697844745088 estimator.py:1111] Calling model_fn.
W0618 11:55:58.529675 47697844745088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:58.530535 47838422823808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:58.531035 47697844745088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880558.466904 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.467632 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.468321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.538422 47204024849280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.459418 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.460326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.461209 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.538524 47517100741504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.452141 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.452849 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.453509 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.538921 47658593497984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.445413 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.446352 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.447215 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.539498 47973487211392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.539439 47204024849280 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpv_u9sfzp
W0618 11:55:58.539491 47517100741504 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsxnrxv6x
I0618 11:55:58.540432 47204024849280 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpv_u9sfzp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeed3b86e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.540493 47517100741504 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsxnrxv6x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37b87f6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.540826 47204024849280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.540891 47517100741504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.540040 47658593497984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdz_rdcbl
I0618 11:55:58.541123 47658593497984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdz_rdcbl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58aa1f8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:58.540672 47973487211392 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpg1q__3el
I0618 11:55:58.541560 47658593497984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.541816 47973487211392 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpg1q__3el', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1fb404e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880558.489241 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.489742 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.490156 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.542031 47616087249792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
I0618 11:55:58.542309 47973487211392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.543066 47616087249792 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjjxyplix
I0618 11:55:58.544092 47616087249792 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjjxyplix', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ec48d9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.544539 47616087249792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.545718 47204024849280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.545855 47517100741504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.546738 47658593497984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880558.496564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.497010 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.497401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.546675 47649022874496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.547672 47973487211392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:55:58.547661 47649022874496 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b566fab5cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.548774 47649022874496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.549248 47616087249792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880558.463367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.464212 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.465043 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.549315 47303440954240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.463944 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.464818 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.465567 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.549442 47227880330112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.496880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.497302 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.497661 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.549900 47463993090944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560880558.496816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.497240 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.497598 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.550027 47414089884544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.550913 47402348274560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:58.550318 47303440954240 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplg4vmtqp
W0618 11:55:58.550409 47227880330112 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpd790951p
I0618 11:55:58.551353 47303440954240 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplg4vmtqp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05f961ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.551444 47227880330112 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpd790951p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4619e1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:58.551359 47532015207296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:55:58.551783 47303440954240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.551863 47227880330112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.550909 47463993090944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy7zsdqcr
W0618 11:55:58.550949 47414089884544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppdla4rmw
I0618 11:55:58.551901 47463993090944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy7zsdqcr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2b5b08fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.551938 47414089884544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppdla4rmw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1fbc927e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.552303 47463993090944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.552340 47414089884544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.553264 47649022874496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.555218 47402348274560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.555701 47532015207296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.556485 47303440954240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.556539 47227880330112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.556921 47414089884544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.556933 47463993090944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:55:58.560255 47402348274560 estimator.py:1111] Calling model_fn.
W0618 11:55:58.560368 47402348274560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:58.560759 47532015207296 estimator.py:1111] Calling model_fn.
W0618 11:55:58.560866 47532015207296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:58.561720 47402348274560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:58.562219 47532015207296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:58.565452 47204024849280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.566060 47517100741504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.567876 47735827534720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:58.568284 47629849940864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:55:58.568588 47658593497984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.568727 47616087249792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.568633 47204190983040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880558.499710 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.500126 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.500490 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.568974 48006707843968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.569177 47262278427520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880558.498489 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880558.498903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880558.499260 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:55:58.569389 47099504161664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 11:55:58.569549 47973487211392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.570008 48006707843968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6pvgc0_a
I0618 11:55:58.571021 48006707843968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6pvgc0_a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9b75aee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:55:58.570382 47099504161664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpim719trt
I0618 11:55:58.571349 47099504161664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpim719trt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad67dcd3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:55:58.571406 48006707843968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:55:58.571737 47099504161664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:55:58.572183 47735827534720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.572631 47629849940864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.572844 47649022874496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.573516 47204190983040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.574100 47262278427520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:55:58.576006 48006707843968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.576202 47099504161664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:55:58.576431 47303440954240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.576444 47227880330112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.576200 47414089884544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:55:58.576323 47463993090944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:55:58.577256 47735827534720 estimator.py:1111] Calling model_fn.
W0618 11:55:58.577363 47735827534720 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:58.577734 47629849940864 estimator.py:1111] Calling model_fn.
W0618 11:55:58.577847 47629849940864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:58.578714 47735827534720 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:58.579229 47629849940864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:55:58.579097 47204190983040 estimator.py:1111] Calling model_fn.
W0618 11:55:58.579234 47204190983040 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:55:58.579746 47262278427520 estimator.py:1111] Calling model_fn.
W0618 11:55:58.579864 47262278427520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:55:58.580762 47204190983040 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:55:58.581418 47262278427520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops[2019-06-18 11:56:37] divide_golden_chunk finished: 3.235 seconds
[2019-06-18 11:56:37] generate golden chunk: 3.249 seconds
[2019-06-18 11:56:37] moving /lfs/lfs12/gma_akey/results/epb309/models/000011-000006.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000011-000007.meta
[2019-06-18 11:56:37] moving /lfs/lfs12/gma_akey/results/epb309/models/000011-000006.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb
[2019-06-18 11:56:37] moving /lfs/lfs12/gma_akey/results/epb309/models/000011-000006.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000011-000007.data-00000-of-00001
[2019-06-18 11:56:37] moving /lfs/lfs12/gma_akey/results/epb309/models/000011-000006.index --> /lfs/lfs12/gma_akey/results/epb309/models/000011-000007.index
[2019-06-18 11:56:37] iteration time 10: 47.876 seconds
2019-06-18 11:56:37.843253: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880597.081351 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 11:56:41] minmax time: 3.255 seconds
2019-06-18 11:56:41.108609: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:56:41.114241: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:56:41.119024: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880601.130585 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 10}}
[2019-06-18 11:56:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000012-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:56:41] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=12 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=1023779843 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=2047559674 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=3071339505 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=4095119336 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=5118899167 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=6142678998 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=7166458829 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=8190238660 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=9214018491 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=10237798322 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=11261578153 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=12285357984 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=13309137815 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=14332917646 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=15356697477 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=16380477308 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=17404257139 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=18428036970 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=19451816801 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000011-000007 --seed=20475596632 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:56:52] eval finished: 11.058 seconds
[2019-06-18 11:56:52] Win rate 000011-000007 vs 000010-000006: 0.690
:::MLL 1560880612.257826 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 11:56:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=13 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=1023779844 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=2047559675 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=3071339506 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=4095119337 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=5118899168 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=6142678999 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=7166458830 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=8190238661 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=9214018492 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=10237798323 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=11261578154 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=12285357985 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=13309137816 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=14332917647 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=15356697478 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=16380477309 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=17404257140 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000012-000006 --seed=18428036971 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:57:21] selfplay finished: 29.680 seconds
[2019-06-18 11:57:21] selfplay mn: 29.698 seconds
[2019-06-18 11:57:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-13-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779844 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559675 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339506 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119337 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899168 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142678999 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458830 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238661 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018492 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798323 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578154 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357985 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137816 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917647 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697478 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477309 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257140 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036971 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816802 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596633 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376464 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156295 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000012-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:57:25] train finished: 43.976 seconds
:::MLL 1560880606.330038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.330798 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.331465 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.412044 47183653225344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.327209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.327964 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.328623 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.412105 47996189459328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.413072 47183653225344 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmydi3p8y
W0618 11:56:46.413131 47996189459328 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpqse8mqva
I0618 11:56:46.414126 47183653225344 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmydi3p8y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea157a1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.414162 47996189459328 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpqse8mqva', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba744690e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.414523 47183653225344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.414566 47996189459328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.419305 47996189459328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.419320 47183653225344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880606.354388 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.355280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.356140 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.436908 47266738447232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.362102 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.362828 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.363514 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.437037 46959205217152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.437979 47266738447232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpajpygdcn
W0618 11:56:46.438052 46959205217152 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsc1u1qu0
W0618 11:56:46.438730 47996189459328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.438755 47183653225344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:56:46.438989 47266738447232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpajpygdcn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd6dbdfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.439046 46959205217152 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsc1u1qu0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab5d3554e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.439389 47266738447232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.439445 46959205217152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880606.364963 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.365866 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.366724 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.442379 47020607452032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.443452 47020607452032 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnd0wac1z
W0618 11:56:46.444304 46959205217152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.444302 47266738447232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:46.444589 47020607452032 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnd0wac1z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac41f310e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.445044 47020607452032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.450692 47020607452032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.464117 46959205217152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.464115 47266738447232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880606.419884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.420736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.421522 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.471823 47529107239808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.417884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.418274 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.418636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.472453 47069097001856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.472907 47020607452032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.472928 47529107239808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5g2tgqva
I0618 11:56:46.474044 47529107239808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5g2tgqva', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a8423fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:46.473503 47069097001856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbumd1zrt
I0618 11:56:46.474518 47529107239808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.474555 47069097001856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbumd1zrt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf6964de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.474982 47069097001856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880606.418849 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.419220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.419544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.478825 47560811078528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.479826 47069097001856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.479862 47529107239808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:46.479819 47560811078528 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b41e5d63d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.480930 47560811078528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880606.407053 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.407807 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.408509 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.482094 47316066567040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.398471 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.399354 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.400226 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.482176 47510168036224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.483084 47316066567040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe9sv28gg
W0618 11:56:46.483173 47510168036224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpab4sutbq
I0618 11:56:46.484089 47316066567040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe9sv28gg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b08e9ed5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.484155 47510168036224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpab4sutbq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b361b46ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.484493 47316066567040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.484550 47510168036224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880606.429446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.429952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.430376 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.484830 47811518256000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.485482 47560811078528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.485866 47811518256000 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpntja9cqt
I0618 11:56:46.486842 47811518256000 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpntja9cqt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c45262e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880606.433087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.433526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.433910 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.486925 46963083359104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.486951 47996189459328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:56:46.487244 47811518256000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.487211 47183653225344 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:46.487914 46963083359104 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp73hg8j7m
I0618 11:56:46.488904 46963083359104 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp73hg8j7m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6ba7d0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.489304 46963083359104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.489349 47510168036224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.489411 47316066567040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880606.407814 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.408528 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.409219 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.489911 47575242044288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.399538 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.400372 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.401171 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.490084 47886997144448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.490982 47575242044288 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpze7jhyxj
W0618 11:56:46.491255 47996189459328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:46.491109 47886997144448 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpydzp9y45
W0618 11:56:46.491538 47183653225344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:56:46.492018 47575242044288 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpze7jhyxj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4541fd4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.492128 47886997144448 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpydzp9y45', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8dd80a9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:46.491894 47811518256000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:46.492411 47575242044288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.492535 47886997144448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.493869 46963083359104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:56:46.496369 47996189459328 estimator.py:1111] Calling model_fn.
W0618 11:56:46.496476 47996189459328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:56:46.496668 47183653225344 estimator.py:1111] Calling model_fn.
W0618 11:56:46.496777 47183653225344 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:46.497355 47575242044288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.497418 47886997144448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.497828 47996189459328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:46.498135 47183653225344 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:46.499190 47069097001856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880606.418453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.419207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.419902 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.501182 47587971720064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.415574 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.416326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.417036 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.501283 47409763001216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.502205 47587971720064 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmps0f_gs12
W0618 11:56:46.502235 47409763001216 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5oi1e1hq
I0618 11:56:46.503251 47587971720064 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmps0f_gs12', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4838bcbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:56:46.503060 47529107239808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:56:46.503278 47409763001216 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5oi1e1hq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ebaab7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.503680 47587971720064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.503693 47409763001216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.504902 47560811078528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.508482 47587971720064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.508446 47409763001216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.511251 47811518256000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.511535 47510168036224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.511708 47316066567040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.512434 47266738447232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:46.512530 46959205217152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:46.513437 46963083359104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.516952 47575242044288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.517083 47886997144448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.516753 47266738447232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880606.461031 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.461435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.461786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.516678 47691029123968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.516843 46959205217152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880606.460931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.461337 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.461690 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.516786 47992120951680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.517643 47691029123968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplio3n9tk
W0618 11:56:46.517753 47992120951680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy199we2l
I0618 11:56:46.518623 47691029123968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplio3n9tk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60376fee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.518746 47992120951680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy199we2l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba651e89e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.519021 47691029123968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.519143 47992120951680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.521875 47266738447232 estimator.py:1111] Calling model_fn.
I0618 11:56:46.521947 46959205217152 estimator.py:1111] Calling model_fn.
W0618 11:56:46.521985 47266738447232 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:46.522058 46959205217152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:46.523340 47266738447232 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:46.523425 46959205217152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:56:46.523675 47691029123968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.523777 47992120951680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.525109 47020607452032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:46.528133 47409763001216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.528193 47587971720064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.529504 47020607452032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:56:46.534649 47020607452032 estimator.py:1111] Calling model_fn.
W0618 11:56:46.534761 47020607452032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:56:46.536142 47020607452032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880606.485706 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.486106 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.486452 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.541674 47497312994176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.488318 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.488752 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.489119 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.542075 47395439833984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.542870 47691029123968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.543164 47992120951680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:56:46.542805 47497312994176 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpg34c6595
W0618 11:56:46.543032 47395439833984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptgwwdd6i
I0618 11:56:46.543788 47497312994176 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpg34c6595', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b331d0e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.544008 47395439833984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptgwwdd6i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b64f13e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.544186 47497312994176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:56:46.544416 47395439833984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:56:46.546534 47069097001856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:46.548799 47497312994176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.549061 47395439833984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:56:46.550836 47069097001856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:56:46.551238 47529107239808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:56:46.552069 47560811078528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880606.498382 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.498852 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.499216 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.553139 46933056304000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560880606.498055 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880606.498484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880606.498892 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:56:46.553197 47887818068864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 11:56:46.554231 46933056304000 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphtbwz612
W0618 11:56:46.554262 47887818068864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpkipqivsq
I0618 11:56:46.555211 46933056304000 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphtbwz612', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aafbcbc7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.555229 47887818068864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpkipqivsq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e08f8de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:56:46.555602 46933056304000 train.py:201] Training, steps = ?, batch = 341 -> ? examp[2019-06-18 11:57:25] divide_golden_chunk finished: 3.306 seconds
[2019-06-18 11:57:25] generate golden chunk: 3.320 seconds
[2019-06-18 11:57:25] moving /lfs/lfs12/gma_akey/results/epb309/models/000012-000007.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000012-000008.data-00000-of-00001
[2019-06-18 11:57:25] moving /lfs/lfs12/gma_akey/results/epb309/models/000012-000007.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000012-000008.meta
[2019-06-18 11:57:25] moving /lfs/lfs12/gma_akey/results/epb309/models/000012-000007.index --> /lfs/lfs12/gma_akey/results/epb309/models/000012-000008.index
[2019-06-18 11:57:25] moving /lfs/lfs12/gma_akey/results/epb309/models/000012-000007.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb
[2019-06-18 11:57:25] iteration time 11: 48.246 seconds
2019-06-18 11:57:26.138404: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880645.327083 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 11:57:29] minmax time: 3.225 seconds
2019-06-18 11:57:29.373548: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:57:29.378832: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:57:29.383336: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880649.394727 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 11}}
[2019-06-18 11:57:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:57:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=13 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=1023779844 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=2047559675 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=3071339506 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=4095119337 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=5118899168 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=6142678999 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=7166458830 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=8190238661 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=9214018492 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=10237798323 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=11261578154 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=12285357985 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=13309137816 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=14332917647 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=15356697478 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=16380477309 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=17404257140 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=18428036971 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=19451816802 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000012-000008 --seed=20475596633 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:57:42] eval finished: 13.335 seconds
[2019-06-18 11:57:42] Win rate 000012-000008 vs 000011-000007: 0.390
:::MLL 1560880662.805801 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 11:57:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=14 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=1023779845 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=2047559676 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=3071339507 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=4095119338 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=5118899169 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=6142679000 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=7166458831 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=8190238662 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=9214018493 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=10237798324 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=11261578155 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=12285357986 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=13309137817 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=14332917648 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=15356697479 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=16380477310 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=17404257141 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000013-000007 --seed=18428036972 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:58:12] selfplay finished: 29.567 seconds
[2019-06-18 11:58:12] selfplay mn: 29.585 seconds
[2019-06-18 11:58:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-14-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779845 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559676 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339507 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119338 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899169 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679000 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458831 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238662 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018493 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798324 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578155 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357986 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137817 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917648 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697479 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477310 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257141 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036972 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816803 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596634 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376465 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156296 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000013-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:58:13] train finished: 44.059 seconds
:::MLL 1560880654.675598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.676405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.677167 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.743378 46998771876736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.655679 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.656553 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.657408 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.743377 47970019459968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.744392 47970019459968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8r0r9zny
W0618 11:57:34.744426 46998771876736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpei023ig7
I0618 11:57:34.745450 47970019459968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8r0r9zny', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba12c8e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.745599 46998771876736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpei023ig7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf09b08e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.745884 47970019459968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.746064 46998771876736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:34.750678 47970019459968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.750844 46998771876736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.770698 47970019459968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.771353 46998771876736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880654.698213 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.699123 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.699959 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.778709 47373028479872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.708510 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.709248 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.709948 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.778956 47600683357056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.779708 47373028479872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpee229516
W0618 11:57:34.779912 47600683357056 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcrcf9a7h
I0618 11:57:34.780703 47373028479872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpee229516', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b162d1f2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.780915 47600683357056 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcrcf9a7h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4b2e68eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.781135 47373028479872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.781368 47600683357056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880654.703082 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.703888 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.704723 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.781698 47214465250176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.704591 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.705319 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.706007 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.781994 47611809346432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.782722 47214465250176 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpd6gxf9jw
W0618 11:57:34.782938 47611809346432 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbs2qgbul
I0618 11:57:34.783725 47214465250176 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpd6gxf9jw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af142044e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.783911 47611809346432 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbs2qgbul', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4dc5920e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.784122 47214465250176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.784300 47611809346432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:34.786159 47373028479872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.786250 47600683357056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.789122 47611809346432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.789190 47214465250176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880654.733862 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.734358 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.734803 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.791188 47560855204736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.792190 47560855204736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpv2dhxfsc
I0618 11:57:34.793166 47560855204736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpv2dhxfsc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b41e8778e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.793563 47560855204736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880654.739277 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.739726 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.740115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.793730 47466913547136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.794691 47466913547136 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9c63ndnd
I0618 11:57:34.795655 47466913547136 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9c63ndnd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c091b8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.796057 47466913547136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880654.722202 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.722948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.723632 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.797885 47768119849856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.713299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.714209 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.715086 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.797973 47872876123008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.798210 47560855204736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.798906 47768119849856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmmnbped9
W0618 11:57:34.798951 47872876123008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpz7b5j3da
I0618 11:57:34.799893 47768119849856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmmnbped9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b722a66fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.799930 47872876123008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpz7b5j3da', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a8e5cee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.800286 47768119849856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.800328 47872876123008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880654.717801 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.718697 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.719570 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.800150 46934662390656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.726292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.727039 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.727745 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.800163 47930811900800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.800591 47466913547136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.801291 47930811900800 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpb28ujpmo
W0618 11:57:34.801321 46934662390656 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpd09w3y5v
I0618 11:57:34.802386 47930811900800 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpb28ujpmo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b980b9abe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.802414 46934662390656 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpd09w3y5v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab01c776e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.802833 47930811900800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.802856 46934662390656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:34.805221 47872876123008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.805230 47768119849856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.805781 47373028479872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.806002 47600683357056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.808149 47930811900800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.808185 46934662390656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.808862 47611809346432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.809569 47214465250176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.817670 47560855204736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.818926 47970019459968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:34.819530 46998771876736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:34.820048 47466913547136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.823266 47970019459968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:34.823873 46998771876736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:34.824566 47872876123008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.824763 47768119849856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880654.748917 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.749876 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.750635 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.824521 47769512702848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.753161 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.753886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.754629 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.824559 47716437238656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.825645 47769512702848 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwce8k3r1
W0618 11:57:34.825675 47716437238656 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpv16hifr1
I0618 11:57:34.826729 47769512702848 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwce8k3r1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b727d6c4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.826789 47716437238656 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpv16hifr1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6621e0edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.827178 47769512702848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.827242 47716437238656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.828372 47970019459968 estimator.py:1111] Calling model_fn.
W0618 11:57:34.828480 47970019459968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:57:34.828992 46998771876736 estimator.py:1111] Calling model_fn.
W0618 11:57:34.829102 46998771876736 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:57:34.829837 47970019459968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:34.830235 47930811900800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.830469 46998771876736 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:34.830593 46934662390656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.832512 47716437238656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.832521 47769512702848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880654.780177 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.780670 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.781125 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.840825 47943887020928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.784184 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.784557 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.784886 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.840937 47888870241152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.783194 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.783674 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.784107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.841497 47503212184448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.785933 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.786350 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.786727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.841919 47011869873024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.783286 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.783734 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.784108 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.842273 47917809730432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.841876 47888870241152 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppjtih43m
:::MLL 1560880654.783825 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.784263 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.784679 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.842291 47145309270912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.841825 47943887020928 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp90isz_jz
I0618 11:57:34.842813 47943887020928 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp90isz_jz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b16f12e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.842839 47888870241152 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppjtih43m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e47afbda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:34.842474 47503212184448 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe4ko35_3
I0618 11:57:34.843440 47503212184448 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe4ko35_3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b347cacde10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.843209 47943887020928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:34.842881 47011869873024 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp00zb3hou
I0618 11:57:34.843231 47888870241152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.843831 47503212184448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.843838 47011869873024 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp00zb3hou', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac216641da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.844239 47011869873024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.843295 47917809730432 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95049d4d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:34.843281 47145309270912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpt7dgm71z
I0618 11:57:34.844249 47145309270912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpt7dgm71z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae127ffbe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.844395 47917809730432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.844643 47145309270912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:57:34.847976 47888870241152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.847974 47943887020928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.848515 47503212184448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.848803 47011869873024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.849055 47917809730432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.849216 47145309270912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.853497 47373028479872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:34.854089 47600683357056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:34.854737 47769512702848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.854979 47716437238656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.856888 47611809346432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:34.857774 47373028479872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:34.858415 47600683357056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:34.858164 47214465250176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880654.802372 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.802988 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.803357 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.860576 47030031709056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
:::MLL 1560880654.802332 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880654.802901 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880654.803285 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:57:34.860737 47542892503936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000003-000000.tfrecord.zz_0_0
W0618 11:57:34.861189 47611809346432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:57:34.861574 47030031709056 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxmef6ldu
W0618 11:57:34.861679 47542892503936 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpptmhgoxp
I0618 11:57:34.862559 47030031709056 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxmef6ldu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac650ebbdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:57:34.862836 47373028479872 estimator.py:1111] Calling model_fn.
I0618 11:57:34.862637 47542892503936 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpptmhgoxp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3db9ce7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:57:34.862947 47373028479872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:57:34.862501 47214465250176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:57:34.862961 47030031709056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.863025 47542892503936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:57:34.863526 47600683357056 estimator.py:1111] Calling model_fn.
W0618 11:57:34.863636 47600683357056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:57:34.864303 47373028479872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:34.865004 47600683357056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:57:34.865224 47560855204736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:57:34.866287 47611809346432 estimator.py:1111] Calling model_fn.
W0618 11:57:34.866399 47611809346432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:57:34.867128 47466913547136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:57:34.867364 47888870241152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.867406 47943887020928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:57:34.867656 47030031709056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.867692 47542892503936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:57:34.867959 47503212184448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.[2019-06-18 11:58:15] divide_golden_chunk finished: 3.313 seconds
[2019-06-18 11:58:15] generate golden chunk: 3.328 seconds
[2019-06-18 11:58:15] iteration time 12: 50.393 seconds
2019-06-18 11:58:16.572525: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880695.720577 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 11:58:19] minmax time: 3.248 seconds
2019-06-18 11:58:19.831173: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:58:19.836608: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:58:19.841207: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880699.854372 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 12}}
[2019-06-18 11:58:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000014-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:58:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=14 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=1023779845 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=2047559676 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=3071339507 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=4095119338 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=5118899169 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=6142679000 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=7166458831 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=8190238662 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=9214018493 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=10237798324 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=11261578155 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=12285357986 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=13309137817 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=14332917648 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=15356697479 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=16380477310 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=17404257141 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=18428036972 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=19451816803 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000013-000008 --seed=20475596634 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:58:30] eval finished: 10.715 seconds
[2019-06-18 11:58:30] Win rate 000013-000008 vs 000011-000007: 0.500
:::MLL 1560880710.645992 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 11:58:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=15 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=1023779846 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=2047559677 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=3071339508 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=4095119339 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=5118899170 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=6142679001 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=7166458832 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=8190238663 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=9214018494 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=10237798325 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=11261578156 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=12285357987 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=13309137818 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=14332917649 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=15356697480 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=16380477311 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=17404257142 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000014-000007 --seed=18428036973 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:58:59] selfplay finished: 28.493 seconds
[2019-06-18 11:58:59] selfplay mn: 28.513 seconds
[2019-06-18 11:58:59] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-15-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779846 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559677 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339508 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119339 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899170 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679001 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458832 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238663 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018494 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798325 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578156 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357987 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137818 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917649 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697480 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477311 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257142 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036973 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816804 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596635 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376466 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156297 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000014-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:59:02] divide_golden_chunk finished: 3.290 seconds
[2019-06-18 11:59:02] generate golden chunk: 3.306 seconds
[2019-06-18 11:59:03] train finished: 43.995 seconds
:::MLL 1560880705.126330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.127223 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.127938 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.219202 47864863114112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.130435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.131191 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.131863 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.219205 46958846776192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.220224 47864863114112 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpa12h1sg7
W0618 11:58:25.220255 46958846776192 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphzfkms92
I0618 11:58:25.221199 47864863114112 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpa12h1sg7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88b0c01e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.221221 46958846776192 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphzfkms92', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab5bdf7ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.221601 47864863114112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.221623 46958846776192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.226556 47864863114112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.226562 46958846776192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880705.141033 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.141929 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.142755 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.232626 47538566230912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.146020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.146748 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.147407 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.232725 47584332804992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.233673 47538566230912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm0mgl67p
W0618 11:58:25.233778 47584332804992 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxpndd4nu
I0618 11:58:25.234748 47538566230912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm0mgl67p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3cb7f0ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.234860 47584332804992 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxpndd4nu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b475fd74e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.235177 47538566230912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.235290 47584332804992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.240170 47538566230912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.240283 47584332804992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.246120 47864863114112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.246145 46958846776192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880705.161794 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.162712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.163543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.252436 47825003340672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.173671 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.174402 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.175087 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.252380 47564124922752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.253495 47825003340672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphsps8tz5
W0618 11:58:25.253462 47564124922752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0tqvmmzi
I0618 11:58:25.254534 47825003340672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphsps8tz5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f68ec3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.254535 47564124922752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0tqvmmzi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42ab5b7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.254936 47825003340672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.254943 47564124922752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.260003 47825003340672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.259719 47538566230912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.260023 47564124922752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.260335 47584332804992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880705.166826 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.167703 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.168557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.265558 47556795757440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.166802 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.167690 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.168554 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.265726 47259464573824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.266696 47556795757440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpup44r2oe
W0618 11:58:25.266812 47259464573824 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxge0983j
I0618 11:58:25.267772 47556795757440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpup44r2oe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b40f6814e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.267892 47259464573824 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxge0983j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afbbc2f6da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.268225 47556795757440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.268333 47259464573824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880705.187554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.188330 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.189035 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.271466 47901001606016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.177376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.178298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.179130 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.271453 47224990991232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.272495 47901001606016 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp41ann9yt
W0618 11:58:25.272528 47224990991232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxnbtj40w
I0618 11:58:25.273483 47901001606016 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp41ann9yt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b911ac5be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.273506 47224990991232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxnbtj40w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3b5665e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:25.273478 47556795757440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.273530 47259464573824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:58:25.273878 47901001606016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.273909 47224990991232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880705.214181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.214650 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.215064 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.278077 47122371789696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.212795 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.213442 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.213866 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.278170 47629233439616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.278788 47224990991232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.278802 47901001606016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.279587 47825003340672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.279978 47564124922752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.279066 47122371789696 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgtzsrv4i
W0618 11:58:25.279137 47629233439616 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpayqnjati
:::MLL 1560880705.212817 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.213219 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.213571 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.279562 47027715826560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.208335 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.208836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.209272 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.279537 46942771331968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 11:58:25.280033 47122371789696 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgtzsrv4i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbd0d19e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.280096 47629233439616 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpayqnjati', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51d4206e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.280432 47122371789696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.280478 47629233439616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.280572 46942771331968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpidefbz6p
I0618 11:58:25.280618 47027715826560 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5c6e23d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.281589 46942771331968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpidefbz6p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1ffcc1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.281796 47027715826560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.282013 46942771331968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.285107 47122371789696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.285147 47629233439616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.286756 47027715826560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.286799 46942771331968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880705.212209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.212879 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.213624 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.291827 47769341842304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.206470 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.207415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.208278 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.291915 47444498604928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.292929 47769341842304 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpiflsmm75
W0618 11:58:25.292958 47444498604928 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplv0tbnwm
I0618 11:58:25.294052 47769341842304 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpiflsmm75', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72733d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.294088 47444498604928 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplv0tbnwm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b26d1129e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:25.294376 47864863114112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:58:25.294507 47769341842304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.294444 46958846776192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 11:58:25.294532 47444498604928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.294751 47556795757440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.294820 47259464573824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.298370 47224990991232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.298456 47901001606016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.298685 47864863114112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:25.298750 46958846776192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:25.299882 47769341842304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.299885 47444498604928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880705.230623 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.231053 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.231402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.302428 46968758498176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560880705.230095 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.230539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.230926 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.302533 47259092833152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 11:58:25.303748 47864863114112 estimator.py:1111] Calling model_fn.
I0618 11:58:25.303820 46958846776192 estimator.py:1111] Calling model_fn.
W0618 11:58:25.303854 47864863114112 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:25.303928 46958846776192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:25.303465 46968758498176 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjlelbut0
W0618 11:58:25.303554 47259092833152 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpx0kni2wx
I0618 11:58:25.304440 46968758498176 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjlelbut0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab80cc0be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:25.304391 47122371789696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.304533 47629233439616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:25.304539 47259092833152 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpx0kni2wx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afba6072e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.304832 46968758498176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.304933 47259092833152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.305206 47864863114112 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:25.305287 46958846776192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:25.306323 47027715826560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.306336 46942771331968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.307664 47538566230912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:25.308133 47584332804992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:25.309534 46968758498176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.309661 47259092833152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.312046 47538566230912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:25.312473 47584332804992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880705.256320 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.256854 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.257386 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.315165 47174934569856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.316145 47174934569856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpaz9xdyvi
:::MLL 1560880705.262522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.262982 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.263380 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.316844 47519501206400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 11:58:25.317113 47174934569856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpaz9xdyvi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae80dcdfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.317513 47174934569856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:58:25.317121 47538566230912 estimator.py:1111] Calling model_fn.
W0618 11:58:25.317228 47538566230912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:25.317545 47584332804992 estimator.py:1111] Calling model_fn.
W0618 11:58:25.317655 47584332804992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:25.317824 47519501206400 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpk2osyj9x
:::MLL 1560880705.259199 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.259689 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.260135 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.318325 47739860476800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 11:58:25.318802 47519501206400 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpk2osyj9x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3847938e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:58:25.318573 47538566230912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 11:58:25.319202 47519501206400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.319015 47584332804992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:25.319334 47739860476800 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpju26qpgs
I0618 11:58:25.320309 47739860476800 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpju26qpgs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b96033e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.320713 47739860476800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880705.265159 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880705.265610 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880705.266001 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:58:25.320738 47850366215040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 11:58:25.322173 47174934569856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.321700 47850366215040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpeo2nk27j
W0618 11:58:25.322189 47769341842304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.322266 47444498604928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:58:25.322688 47850366215040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpeo2nk27j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8550aaee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:58:25.323098 47850366215040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:58:25.323793 47519501206400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.325394 47739860476800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.327658 47825003340672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:25.327708 47850366215040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:58:25.328233 47564124922752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:58:25.328742 46968758498176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.329052 47259092833152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:58:25.331999 47825003340672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:58:25.332562 47564124922752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 11:58:25.337058 47825003340672 estimator.py:1111] Calling model_fn.
W0618 11:58:25.337168 47825003340672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:58:25.337636 47564124922752 estimator.py:1111] Calling model_fn.
W0618 11:58:25.337748 47564124922752 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:58:25.338527 47825003340672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:58:25.339108 47564124922752 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for [2019-06-18 11:59:03] moving /lfs/lfs12/gma_akey/results/epb309/models/000014-000008.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb
[2019-06-18 11:59:03] moving /lfs/lfs12/gma_akey/results/epb309/models/000014-000008.index --> /lfs/lfs12/gma_akey/results/epb309/models/000014-000009.index
[2019-06-18 11:59:03] moving /lfs/lfs12/gma_akey/results/epb309/models/000014-000008.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000014-000009.meta
[2019-06-18 11:59:03] moving /lfs/lfs12/gma_akey/results/epb309/models/000014-000008.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000014-000009.data-00000-of-00001
[2019-06-18 11:59:03] iteration time 13: 48.193 seconds
2019-06-18 11:59:04.781815: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880743.913560 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 11:59:08] minmax time: 3.283 seconds
2019-06-18 11:59:08.075464: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:59:08.081068: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:59:08.085672: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880748.097471 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 13}}
[2019-06-18 11:59:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000015-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:59:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=15 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=1023779846 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=2047559677 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=3071339508 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=4095119339 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=5118899170 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=6142679001 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=7166458832 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=8190238663 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=9214018494 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=10237798325 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=11261578156 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=12285357987 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=13309137818 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=14332917649 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=15356697480 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=16380477311 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=17404257142 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=18428036973 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=19451816804 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000014-000009 --seed=20475596635 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 11:59:18] eval finished: 10.516 seconds
[2019-06-18 11:59:18] Win rate 000014-000009 vs 000013-000008: 0.510
:::MLL 1560880758.687524 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 11:59:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=16 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=1023779847 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=2047559678 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=3071339509 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=4095119340 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=5118899171 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=6142679002 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=7166458833 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=8190238664 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=9214018495 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=10237798326 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=11261578157 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=12285357988 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=13309137819 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=14332917650 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=15356697481 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=16380477312 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=17404257143 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000015-000008 --seed=18428036974 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:59:49] selfplay finished: 30.728 seconds
[2019-06-18 11:59:49] selfplay mn: 30.748 seconds
[2019-06-18 11:59:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-16-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779847 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559678 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339509 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119340 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899171 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679002 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458833 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238664 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018495 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798326 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578157 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357988 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137819 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917650 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697481 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477312 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257143 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036974 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816805 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596636 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376467 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156298 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000015-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 11:59:51] train finished: 43.545 seconds
:::MLL 1560880753.327626 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.328511 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.329302 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.398896 47520062333824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.310711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.311596 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.312379 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.398965 47938421523328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.399918 47520062333824 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpaekhhz_4
W0618 11:59:13.399946 47938421523328 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp800qzzwg
I0618 11:59:13.400899 47520062333824 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpaekhhz_4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b386905be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.400903 47938421523328 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp800qzzwg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99d12c5da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.401294 47938421523328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.401303 47520062333824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.406120 47938421523328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.406172 47520062333824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.425457 47938421523328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.425929 47520062333824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880753.354021 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.354848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.355571 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.426804 47585995400064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.335423 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.336362 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.337224 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.426908 47109770605440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.427798 47585995400064 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsk71whxi
W0618 11:59:13.427899 47109770605440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwruzrh7p
I0618 11:59:13.428794 47585995400064 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsk71whxi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47c2f06e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.428879 47109770605440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwruzrh7p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad8e1bace10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.429193 47585995400064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.429272 47109770605440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.433868 47585995400064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.433895 47109770605440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.453292 47109770605440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.453345 47585995400064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880753.401187 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.401561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.401931 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.462985 47456045675392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.396554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.396984 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.397365 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.462964 46950842573696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.463966 46950842573696 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmwy2hr9h
W0618 11:59:13.463998 47456045675392 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6fbq_1ep
I0618 11:59:13.464930 46950842573696 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmwy2hr9h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab3e0e17e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.464976 47456045675392 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6fbq_1ep', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2981550e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.465328 46950842573696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.465376 47456045675392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.470039 46950842573696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.470058 47456045675392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.473994 47938421523328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:13.474146 47520062333824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:13.478329 47938421523328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:13.478447 47520062333824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880753.393710 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.394447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.395141 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.479112 47406446314368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.391773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.392538 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.393321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.479133 47752756761472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.383687 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.384427 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.385105 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.479999 47574870549376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.381064 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.381755 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.382446 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.480050 47182589289344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.480258 47752756761472 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp922ei5ui
W0618 11:59:13.480289 47406446314368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5_j_2nz2
I0618 11:59:13.481400 47406446314368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5_j_2nz2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1df4fade48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.481404 47752756761472 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp922ei5ui', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e96b0ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:13.481087 47574870549376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpddfqpnei
I0618 11:59:13.481840 47406446314368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.481121 47182589289344 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpz2hrg_o7
I0618 11:59:13.481850 47752756761472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.482174 47574870549376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpddfqpnei', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b452bd8be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.482210 47182589289344 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpz2hrg_o7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae9d60fbe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.482630 47574870549376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.482644 47182589289344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.483409 47938421523328 estimator.py:1111] Calling model_fn.
W0618 11:59:13.483516 47938421523328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:59:13.483505 47520062333824 estimator.py:1111] Calling model_fn.
W0618 11:59:13.483611 47520062333824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:13.484865 47938421523328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:13.484953 47520062333824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:13.487148 47752756761472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.487144 47406446314368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.488001 47574870549376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.488017 47182589289344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.489331 47456045675392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.489509 46950842573696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880753.426558 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.426943 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.427263 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.493120 47407794221952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.425941 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.426373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.426715 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.493241 47077373367168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
I0618 11:59:13.494129 47407794221952 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e45524d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:13.494237 47077373367168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp54k_uzsp
I0618 11:59:13.495207 47077373367168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp54k_uzsp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad156b42e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.495246 47407794221952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.495606 47077373367168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880753.407442 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.408377 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.409117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.496824 47150547436416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.411541 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.412282 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.412998 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.497014 47547809751936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.497868 47150547436416 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9hrqoayo
W0618 11:59:13.497995 47547809751936 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6g3htzq8
I0618 11:59:13.498848 47150547436416 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9hrqoayo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae26037ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.498979 47547809751936 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6g3htzq8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3edee5be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.499245 47150547436416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.499376 47547809751936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.499935 47407794221952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.500152 47077373367168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.501318 47585995400064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:13.501369 47109770605440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:13.503978 47150547436416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.504091 47547809751936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.505628 47585995400064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:13.505646 47109770605440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880753.412594 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.413542 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.414380 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.508032 47927920890752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.420895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.421680 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.422384 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.508125 47045364593536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.509222 47752756761472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.509401 47406446314368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.509088 47927920890752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpqtkzuyta
W0618 11:59:13.509188 47045364593536 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpi_og3168
I0618 11:59:13.510200 47927920890752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpqtkzuyta', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b975f496e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.510299 47045364593536 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpi_og3168', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac9e2d4fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 11:59:13.509908 47574870549376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.509993 47182589289344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 11:59:13.510606 47927920890752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.510694 47045364593536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.510678 47585995400064 estimator.py:1111] Calling model_fn.
I0618 11:59:13.510665 47109770605440 estimator.py:1111] Calling model_fn.
W0618 11:59:13.510773 47109770605440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:13.510785 47585995400064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:13.512137 47585995400064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:13.512109 47109770605440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:13.515392 47927920890752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.515502 47045364593536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880753.443095 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.443483 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.443829 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.517919 47011870991232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.436437 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.436910 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.437345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.517953 46937846436736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.519281 47407794221952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.519371 47077373367168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.518986 47011870991232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbf3l72_b
W0618 11:59:13.518957 46937846436736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1vdlo_h3
I0618 11:59:13.519929 46937846436736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1vdlo_h3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab0da402e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.519971 47011870991232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbf3l72_b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac216753e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.520315 46937846436736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.520364 47011870991232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.523592 47150547436416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.524096 47547809751936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.524974 46937846436736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.525008 47011870991232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.535166 47927920890752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.535729 47045364593536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.536716 47456045675392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 11:59:13.537181 46950842573696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880753.475164 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.475563 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.475943 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.537518 47941060481920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.475514 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.475953 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.476281 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.537676 47927634768768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.538526 47941060481920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpptntfkr6
W0618 11:59:13.538659 47927634768768 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnc4hiuac
I0618 11:59:13.539510 47941060481920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpptntfkr6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a6e779e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.539623 47927634768768 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnc4hiuac', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b974e3b7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.539909 47941060481920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 11:59:13.540015 47927634768768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 11:59:13.541002 47456045675392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:13.541516 46950842573696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 11:59:13.544348 46937846436736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.544381 47011870991232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 11:59:13.544514 47941060481920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 11:59:13.544647 47927634768768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 11:59:13.546051 47456045675392 estimator.py:1111] Calling model_fn.
W0618 11:59:13.546159 47456045675392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 11:59:13.546630 46950842573696 estimator.py:1111] Calling model_fn.
W0618 11:59:13.546738 46950842573696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 11:59:13.547523 47456045675392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560880753.484134 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.484689 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.485190 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.548138 47842328822656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.548097 46950842573696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 11:59:13.549157 47842328822656 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppgv8ae_0
I0618 11:59:13.550156 47842328822656 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppgv8ae_0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83719a1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.550574 47842328822656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880753.488479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.488933 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.489326 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.550905 47046934414208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
:::MLL 1560880753.490996 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.491377 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880753.491768 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 11:59:13.551764 47991360955264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000005-000001.tfrecord.zz_0_0
W0618 11:59:13.551916 47046934414208 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr0o_46ic
I0618 11:59:13.552911 47046934414208 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpr0o_46ic', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca40669dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 11:59:13.553308 47046934414208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880753.495950 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880753.496397 opt_base_learning_rate: {"value[2019-06-18 11:59:52] divide_golden_chunk finished: 3.246 seconds
[2019-06-18 11:59:52] generate golden chunk: 3.260 seconds
[2019-06-18 11:59:52] moving /lfs/lfs12/gma_akey/results/epb309/models/000015-000009.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb
[2019-06-18 11:59:52] moving /lfs/lfs12/gma_akey/results/epb309/models/000015-000009.index --> /lfs/lfs12/gma_akey/results/epb309/models/000015-000010.index
[2019-06-18 11:59:52] moving /lfs/lfs12/gma_akey/results/epb309/models/000015-000009.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000015-000010.meta
[2019-06-18 11:59:52] moving /lfs/lfs12/gma_akey/results/epb309/models/000015-000009.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000015-000010.data-00000-of-00001
[2019-06-18 11:59:52] iteration time 14: 48.826 seconds
2019-06-18 11:59:53.676563: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880792.739322 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 11:59:56] minmax time: 3.266 seconds
2019-06-18 11:59:56.952994: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 11:59:56.958762: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 11:59:56.963541: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880796.975286 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 14}}
[2019-06-18 11:59:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 11:59:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=16 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=1023779847 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=2047559678 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=3071339509 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=4095119340 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=5118899171 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=6142679002 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=7166458833 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=8190238664 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=9214018495 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=10237798326 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=11261578157 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=12285357988 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=13309137819 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=14332917650 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=15356697481 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=16380477312 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=17404257143 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=18428036974 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=19451816805 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000015-000010 --seed=20475596636 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:00:08] eval finished: 11.189 seconds
[2019-06-18 12:00:08] Win rate 000015-000010 vs 000014-000009: 0.710
:::MLL 1560880808.241374 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 12:00:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=17 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=1023779848 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=2047559679 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=3071339510 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=4095119341 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=5118899172 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=6142679003 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=7166458834 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=8190238665 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=9214018496 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=10237798327 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=11261578158 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=12285357989 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=13309137820 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=14332917651 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=15356697482 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=16380477313 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=17404257144 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000016-000009 --seed=18428036975 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:00:37] selfplay finished: 29.162 seconds
[2019-06-18 12:00:37] selfplay mn: 29.180 seconds
[2019-06-18 12:00:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-17-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779848 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559679 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339510 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119341 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899172 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679003 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458834 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238665 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018496 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798327 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578158 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357989 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137820 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917651 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697482 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477313 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257144 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036975 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816806 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596637 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376468 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156299 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:00:40] train finished: 43.704 seconds
:::MLL 1560880802.258118 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.258842 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.259516 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.338086 47582092030848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.247661 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.248519 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.249370 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.338223 47027333936000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.234360 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.235267 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.236077 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.338426 47364157109120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.249971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.250704 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.251377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.338577 47522411836288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.339092 47582092030848 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6ag1u6mj
W0618 12:00:02.339210 47027333936000 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2f3rmbim
I0618 12:00:02.340087 47582092030848 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6ag1u6mj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b46da47ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.340196 47027333936000 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2f3rmbim', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5b01f0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:02.339429 47364157109120 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppkvjexuw
W0618 12:00:02.339516 47522411836288 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpd87cnaeh
I0618 12:00:02.340486 47582092030848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.340415 47364157109120 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppkvjexuw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b141c58ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.340493 47522411836288 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpd87cnaeh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38f5103e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.340584 47027333936000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.340821 47364157109120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.340889 47522411836288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.345406 47582092030848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.345405 47027333936000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.345769 47364157109120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.345818 47522411836288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.364776 47027333936000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.364820 47582092030848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.365273 47364157109120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.365501 47522411836288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880802.324634 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.325134 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.325596 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.381504 47206737236864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.324999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.325505 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.325952 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.382321 47761907684224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.382610 47206737236864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdgjs__qg
I0618 12:00:02.383731 47206737236864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdgjs__qg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef75642e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.384178 47206737236864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.383425 47761907684224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjcgaezfe
I0618 12:00:02.384504 47761907684224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjcgaezfe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70b820ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.384948 47761907684224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880802.293468 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.294350 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.295185 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.385270 47244963931008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.308045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.308741 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.309422 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.385481 47779915797376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.386297 47244963931008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpui2zpxlx
W0618 12:00:02.386472 47779915797376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphsr8hqzu
I0618 12:00:02.387416 47244963931008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpui2zpxlx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af85be13e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.387616 47779915797376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphsr8hqzu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b74e97eee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.387890 47244963931008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.388078 47779915797376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.389344 47206737236864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.390022 47761907684224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.393212 47244963931008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.393296 47779915797376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880802.331826 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.332279 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.332669 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.395660 46962123547520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.339728 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.340170 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.340587 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.396014 47330911662976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.312679 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.313442 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.314083 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.396610 47314145125248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.307847 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.308720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.309505 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.396735 47021129081728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.396623 46962123547520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpc3t_5em1
I0618 12:00:02.397601 46962123547520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpc3t_5em1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab681476e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.397026 47330911662976 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c5ec38cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.398001 46962123547520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.398138 47330911662976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.397751 47314145125248 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpkcxh7187
W0618 12:00:02.397831 47021129081728 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp72vo9k9e
I0618 12:00:02.398875 47314145125248 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpkcxh7187', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0877667e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.398925 47021129081728 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp72vo9k9e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac43e487e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.399329 47314145125248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.399369 47021129081728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.402477 46962123547520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.402669 47330911662976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.404659 47021129081728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.404684 47314145125248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.409084 47206737236864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.409651 47761907684224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.412919 47027333936000 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.412968 47582092030848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.413519 47364157109120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.413876 47522411836288 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.415310 47244963931008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.415498 47779915797376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.417279 47582092030848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:02.417242 47027333936000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:02.417802 47364157109120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:02.418225 47522411836288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880802.329543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.330435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.331320 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.419073 47126845920128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.336834 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.337604 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.338282 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.419377 47681310323584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.420195 47126845920128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0muomwmg
W0618 12:00:02.420424 47681310323584 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsnq3fov4
I0618 12:00:02.421242 47126845920128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0muomwmg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcdb7f6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.421413 47681310323584 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsnq3fov4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5df426be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.421647 47126845920128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.421819 47681310323584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.421591 46962123547520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.421811 47330911662976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:02.422333 47582092030848 estimator.py:1111] Calling model_fn.
I0618 12:00:02.422333 47027333936000 estimator.py:1111] Calling model_fn.
W0618 12:00:02.422442 47582092030848 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:02.422441 47027333936000 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:02.422855 47364157109120 estimator.py:1111] Calling model_fn.
W0618 12:00:02.422962 47364157109120 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:02.423316 47522411836288 estimator.py:1111] Calling model_fn.
W0618 12:00:02.423429 47522411836288 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:02.423787 47582092030848 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:02.423796 47027333936000 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:02.424326 47364157109120 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:02.424779 47522411836288 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:02.426654 47126845920128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.426654 47681310323584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.426767 47021129081728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.427056 47314145125248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880802.345252 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.346117 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.346963 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.434872 47153421276032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.345916 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.346812 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.347525 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.434994 46917784707968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.435971 47153421276032 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpkx4vdyxh
W0618 12:00:02.436089 46917784707968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp19y7ids9
I0618 12:00:02.437086 47153421276032 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpkx4vdyxh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae30b831e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.437215 46917784707968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp19y7ids9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac2e7a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.437489 47153421276032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.437607 46917784707968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880802.373304 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.373719 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.374088 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.440740 47234985960320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.370475 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.370906 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.371248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.440768 48001091670912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.442229 47153421276032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.442240 46917784707968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.441776 47234985960320 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1n2gcxlv
W0618 12:00:02.441809 48001091670912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9nucl8nt
I0618 12:00:02.442765 47234985960320 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1n2gcxlv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af609257da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.442788 48001091670912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9nucl8nt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8689adda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.443168 47234985960320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.443187 48001091670912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.446391 47681310323584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.446483 47126845920128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.447904 47234985960320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.447891 48001091670912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880802.383460 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.383835 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.384160 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.448114 47839693968256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
:::MLL 1560880802.384888 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880802.385269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880802.385589 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:02.448260 47355287171968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000006-000002.tfrecord.zz_0_0
W0618 12:00:02.449107 47839693968256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr0i1exel
W0618 12:00:02.449272 47355287171968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4sy23ub0
I0618 12:00:02.450089 47839693968256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpr0i1exel', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b82d48d6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.450257 47355287171968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4sy23ub0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b120ba84e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:02.450480 47839693968256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:02.450648 47355287171968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:02.455106 47839693968256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.455233 47355287171968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:02.456537 47206737236864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.457104 47761907684224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.460844 47206737236864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:02.461392 47761907684224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:02.461747 46917784707968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.461836 47153421276032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:02.466225 47206737236864 estimator.py:1111] Calling model_fn.
W0618 12:00:02.466337 47206737236864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:02.466220 47244963931008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:00:02.466425 47761907684224 estimator.py:1111] Calling model_fn.
W0618 12:00:02.466534 47761907684224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:02.467117 48001091670912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.467144 47779915797376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.467387 47234985960320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:02.467695 47206737236864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:02.467890 47761907684224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:02.469130 46962123547520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.469208 47330911662976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:02.470669 47244963931008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:02.471665 47779915797376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.da[2019-06-18 12:00:40] divide_golden_chunk finished: 3.312 seconds
[2019-06-18 12:00:40] generate golden chunk: 3.326 seconds
[2019-06-18 12:00:40] moving /lfs/lfs12/gma_akey/results/epb309/models/000016-000010.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000016-000011.meta
[2019-06-18 12:00:40] moving /lfs/lfs12/gma_akey/results/epb309/models/000016-000010.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000016-000011.data-00000-of-00001
[2019-06-18 12:00:40] moving /lfs/lfs12/gma_akey/results/epb309/models/000016-000010.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb
[2019-06-18 12:00:40] moving /lfs/lfs12/gma_akey/results/epb309/models/000016-000010.index --> /lfs/lfs12/gma_akey/results/epb309/models/000016-000011.index
[2019-06-18 12:00:40] iteration time 15: 48.052 seconds
2019-06-18 12:00:41.772378: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880840.791212 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:00:45] minmax time: 3.252 seconds
2019-06-18 12:00:45.034886: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:00:45.040428: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:00:45.045019: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880845.056870 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 15}}
[2019-06-18 12:00:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:00:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=17 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=1023779848 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=2047559679 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=3071339510 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=4095119341 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=5118899172 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=6142679003 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=7166458834 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=8190238665 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=9214018496 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=10237798327 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=11261578158 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=12285357989 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=13309137820 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=14332917651 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=15356697482 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=16380477313 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=17404257144 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=18428036975 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=19451816806 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000016-000011 --seed=20475596637 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:00:56] eval finished: 11.410 seconds
[2019-06-18 12:00:56] Win rate 000016-000011 vs 000015-000010: 0.530
:::MLL 1560880856.544325 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 12:00:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=18 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=1023779849 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=2047559680 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=3071339511 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=4095119342 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=5118899173 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=6142679004 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=7166458835 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=8190238666 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=9214018497 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=10237798328 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=11261578159 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=12285357990 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=13309137821 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=14332917652 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=15356697483 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=16380477314 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=17404257145 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000017-000010 --seed=18428036976 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:01:25] selfplay finished: 28.838 seconds
[2019-06-18 12:01:25] selfplay mn: 28.858 seconds
[2019-06-18 12:01:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-18-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779849 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559680 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339511 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119342 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899173 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679004 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458835 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238666 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018497 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798328 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578159 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357990 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137821 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917652 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697483 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477314 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257145 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036976 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816807 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596638 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376469 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156300 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:01:28] divide_golden_chunk finished: 3.336 seconds
[2019-06-18 12:01:28] generate golden chunk: 3.351 seconds
[2019-06-18 12:01:28] train finished: 43.704 seconds
:::MLL 1560880850.275781 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.276527 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.277321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.367494 47245504328576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.277401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.278130 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.278839 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.367520 48006356378496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.368565 47245504328576 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpl6xseyap
W0618 12:00:50.368682 48006356378496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpvattnwsq
I0618 12:00:50.369594 47245504328576 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpl6xseyap', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af87c170e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.369695 48006356378496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpvattnwsq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9a267fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.369990 47245504328576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.370093 48006356378496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.374712 48006356378496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.374724 47245504328576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880850.285969 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.286742 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.287533 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.381527 47459515786112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.287675 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.288393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.289072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.381670 47353849955200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.287226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.287953 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.288643 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.382010 47872690131840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.284542 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.285291 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.285971 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.381973 47649805861760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.382632 47459515786112 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy0t094am
W0618 12:00:50.382744 47353849955200 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpaf48k49d
I0618 12:00:50.383728 47459515786112 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy0t094am', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a502abe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.383842 47353849955200 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpaf48k49d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b11b5fdfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:50.382988 47649805861760 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpuojnkag7
W0618 12:00:50.383017 47872690131840 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr0k_5e4l
I0618 12:00:50.383971 47649805861760 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpuojnkag7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b569e56de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.384012 47872690131840 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpr0k_5e4l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a8346ee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.384173 47459515786112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.384304 47353849955200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.384369 47649805861760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.384417 47872690131840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.389409 47459515786112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.389281 47649805861760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.389502 47353849955200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.389364 47872690131840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.394305 47245504328576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.394356 48006356378496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.408755 47649805861760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.409030 47872690131840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.411366 47459515786112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.411780 47353849955200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880850.335795 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.336558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.337236 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.418083 47335057089408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.326669 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.327577 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.328454 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.418441 47607055238016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.419222 47335057089408 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8olqkj0a
I0618 12:00:50.420345 47335057089408 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8olqkj0a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d55d9ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:50.419574 47607055238016 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgub45f9v
I0618 12:00:50.420729 47607055238016 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgub45f9v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4caa33fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560880850.348194 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.348693 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.349238 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.420591 47424656937856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:00:50.420794 47335057089408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880850.345371 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.345842 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.346256 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.420641 47361779745664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:00:50.421175 47607055238016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.421601 47424656937856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpafvrdnce
W0618 12:00:50.421632 47361779745664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbi8mcr9e
I0618 12:00:50.422593 47424656937856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpafvrdnce', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b22326ace10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.422595 47361779745664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbi8mcr9e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b138ea51e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.422981 47424656937856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.422985 47361779745664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880850.341385 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.341806 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.342162 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.423946 47895605773184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.424996 47895605773184 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp41om6fay
W0618 12:00:50.426093 47335057089408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:00:50.426263 47895605773184 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp41om6fay', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fd927de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:50.426456 47607055238016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:00:50.426736 47895605773184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.427634 47361779745664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.427659 47424656937856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880850.338241 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.339083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.339849 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.430391 47570662159232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.338370 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.339259 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.340055 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.430359 47473141822336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.340680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.341114 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.341473 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.430425 47604386231168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.431756 47895605773184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.431412 47604386231168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe3manqmo
W0618 12:00:50.431498 47570662159232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpma_ldj_f
W0618 12:00:50.431531 47473141822336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7v05o6yx
I0618 12:00:50.432562 47570662159232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpma_ldj_f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b443101be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.432590 47473141822336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7v05o6yx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d7c578e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.432384 47604386231168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe3manqmo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c0b1e4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.432963 47570662159232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.432998 47473141822336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.432781 47604386231168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.437448 47604386231168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.437767 47570662159232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.437783 47473141822336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880850.362195 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.362863 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.363346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.439777 47457263182720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.366531 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.366956 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.367323 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.439992 47906239087488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.440785 47457263182720 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4flofhjj
W0618 12:00:50.441688 47245504328576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:00:50.441009 47906239087488 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9252f35d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.441750 47457263182720 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4flofhjj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29c9e6be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.442118 47906239087488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.442139 47457263182720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.442572 48006356378496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:50.445948 47245504328576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:50.446906 48006356378496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:50.446919 47424656937856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.446874 47906239087488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.447045 47361779745664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.446870 47457263182720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.448229 47335057089408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.449060 47607055238016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880850.365469 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.366230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.366956 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.449590 47673644061568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.358767 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.359672 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.360547 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.449638 47279495406464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:00:50.450976 47245504328576 estimator.py:1111] Calling model_fn.
W0618 12:00:50.451086 47245504328576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:50.450605 47673644061568 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpg1m67rx6
W0618 12:00:50.450648 47279495406464 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplhgnr_cw
I0618 12:00:50.451608 47673644061568 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpg1m67rx6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c2b34de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.451637 47279495406464 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplhgnr_cw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00661dbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.452013 47673644061568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.452040 47279495406464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.451970 48006356378496 estimator.py:1111] Calling model_fn.
W0618 12:00:50.452079 48006356378496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:50.452426 47245504328576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:50.452487 47895605773184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.453437 48006356378496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:50.456776 47673644061568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.456785 47279495406464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.456832 47604386231168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.457415 47473141822336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.457212 47649805861760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:50.457362 47872690131840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:50.457796 47570662159232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.460346 47459515786112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:50.460436 47353849955200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:00:50.461476 47649805861760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:50.461669 47872690131840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:50.464627 47459515786112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:50.464732 47353849955200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:00:50.466009 47457263182720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.466213 47906239087488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:00:50.466504 47649805861760 estimator.py:1111] Calling model_fn.
W0618 12:00:50.466613 47649805861760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:50.466739 47872690131840 estimator.py:1111] Calling model_fn.
W0618 12:00:50.466847 47872690131840 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:50.467975 47649805861760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:50.468208 47872690131840 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:00:50.469668 47459515786112 estimator.py:1111] Calling model_fn.
W0618 12:00:50.469775 47459515786112 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:00:50.469771 47353849955200 estimator.py:1111] Calling model_fn.
W0618 12:00:50.469885 47353849955200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:00:50.471128 47459515786112 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:50.471246 47353849955200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:00:50.476226 47673644061568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:00:50.476382 47279495406464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880850.412438 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.412816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.413156 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.477350 47350146098048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.410515 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.410889 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.411213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.477362 47159175398272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560880850.411944 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.412475 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.412909 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.478186 48005543650176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.478380 47350146098048 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoi0puy92
W0618 12:00:50.478409 47159175398272 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_z4hhjr8
I0618 12:00:50.479354 47350146098048 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoi0puy92', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10d9399e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.479382 47159175398272 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_z4hhjr8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4627c1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:00:50.479233 48005543650176 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5a73d2tx
I0618 12:00:50.479749 47350146098048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.479775 47159175398272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:00:50.480245 48005543650176 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5a73d2tx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba971f69e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.480646 48005543650176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880850.419855 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880850.420304 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880850.420685 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:00:50.482085 47014992651136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:00:50.483051 47014992651136 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8ev6jyt6
I0618 12:00:50.484015 47014992651136 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8ev6jyt6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2d085fda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:00:50.484407 47014992651136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:00:50.484347 47159175398272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.484372 47350146098048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.485238 48005543650176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:00:50.488950 47014992651136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb309/models/000017-000011.index --> /lfs/lfs12/gma_akey/results/epb309/models/000017-000012.index
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb309/models/000017-000011.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000017-000012.meta
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb309/models/000017-000011.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb
[2019-06-18 12:01:28] moving /lfs/lfs12/gma_akey/results/epb309/models/000017-000011.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000017-000012.data-00000-of-00001
[2019-06-18 12:01:28] iteration time 16: 48.037 seconds
2019-06-18 12:01:29.949782: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
Got 343197 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000009.tfrecord.zz: 13.473 seconds
Got 377287 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000004.tfrecord.zz: 13.261 seconds
Got 380188 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000005.tfrecord.zz: 14.821 seconds
Got 347264 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000006.tfrecord.zz: 14.146 seconds
Got 390428 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000000.tfrecord.zz: 15.183 seconds
Got 383972 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz: 0.312 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000002.tfrecord.zz: 14.608 seconds
Got 348718 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000007.tfrecord.zz: 13.710 seconds
Got 346341 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000008.tfrecord.zz: 11.639 seconds
Got 388737 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000003.tfrecord.zz: 15.410 seconds
Got 388250 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000000-000001.tfrecord.zz: 14.731 seconds
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/checkpoint_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/checkpointlog.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000001-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000001-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000002-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000002-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000003-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000003-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000004-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000004-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000005-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000005-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000006-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000006-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000007-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000007-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000008-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000008-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000009-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000009-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000010-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000010-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000011-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000011-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000012-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000012-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000013-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000013-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000014-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000014-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000015-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000015-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000016-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000016-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000017-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000017-000012log.txt['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880888.828806 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:01:33] minmax time: 3.242 seconds
2019-06-18 12:01:33.202341: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:01:33.207951: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:01:33.212649: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880893.224413 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 16}}
[2019-06-18 12:01:33] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:01:33] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=18 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=1023779849 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=2047559680 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=3071339511 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=4095119342 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=5118899173 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=6142679004 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=7166458835 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=8190238666 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=9214018497 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=10237798328 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=11261578159 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=12285357990 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=13309137821 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=14332917652 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=15356697483 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=16380477314 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=17404257145 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=18428036976 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=19451816807 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000017-000012 --seed=20475596638 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:01:44] eval finished: 11.569 seconds
[2019-06-18 12:01:44] Win rate 000017-000012 vs 000016-000011: 0.480
:::MLL 1560880904.868380 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:01:44] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=19 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=1023779850 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=2047559681 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=3071339512 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=4095119343 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=5118899174 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=6142679005 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=7166458836 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=8190238667 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=9214018498 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=10237798329 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=11261578160 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=12285357991 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=13309137822 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=14332917653 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=15356697484 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=16380477315 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=17404257146 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000018-000011 --seed=18428036977 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:02:13] selfplay finished: 28.927 seconds
[2019-06-18 12:02:13] selfplay mn: 28.945 seconds
[2019-06-18 12:02:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-19-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779850 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559681 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339512 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119343 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899174 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679005 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458836 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238667 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018498 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798329 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578160 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357991 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137822 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917653 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697484 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477315 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257146 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036977 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816808 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596639 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376470 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156301 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:02:16] train finished: 43.213 seconds
:::MLL 1560880898.451251 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.451989 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.452652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.539446 47881048691584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.445763 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.446662 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.447475 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.539474 47870410994560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.540606 47870410994560 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpf6wx9_0m
W0618 12:01:38.540675 47881048691584 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp30ugiym_
I0618 12:01:38.541672 47870410994560 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpf6wx9_0m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89fb6e0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.541728 47881048691584 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp30ugiym_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c757c5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.542075 47870410994560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.542133 47881048691584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.546836 47881048691584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.546837 47870410994560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.566154 47881048691584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.566193 47870410994560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880898.488105 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.488822 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.489521 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.569684 47165180449664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.472834 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.473789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.474636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.569786 47372087874432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.570735 47165180449664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8sjovgwz
W0618 12:01:38.570766 47372087874432 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3i4x17vv
I0618 12:01:38.571720 47165180449664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8sjovgwz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5c869de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.571750 47372087874432 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3i4x17vv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b15f50eae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.572117 47165180449664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.572141 47372087874432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.577051 47165180449664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.577045 47372087874432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880898.492073 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.493019 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.493876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.585710 47881863992192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.504230 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.504961 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.505647 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.585884 47466210866048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.586729 47881863992192 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpo7rbi0bm
:::MLL 1560880898.516634 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.517180 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.517675 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.587019 47230108500864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.586853 47466210866048 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp69jl_nu5
I0618 12:01:38.587733 47881863992192 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpo7rbi0bm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ca614ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.587848 47466210866048 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp69jl_nu5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2bdf398e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.588136 47881863992192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.588253 47466210866048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.588036 47230108500864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcobs9xl4
I0618 12:01:38.589079 47230108500864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcobs9xl4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4e66d5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.589478 47230108500864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880898.520880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.521310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.521677 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.591243 47398890402688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.592975 47881863992192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.593006 47466210866048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.592223 47398890402688 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpl7u24j_n
I0618 12:01:38.593197 47398890402688 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpl7u24j_n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1c329cce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.593593 47398890402688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.594197 47230108500864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.596349 47165180449664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.596380 47372087874432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.598211 47398890402688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880898.503090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.503968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.504742 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.601766 46992274596736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.502876 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.503690 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.504512 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.601833 47048617354112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.602799 46992274596736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptwgaspcl
W0618 12:01:38.603001 47048617354112 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpngar4qq1
I0618 12:01:38.604147 46992274596736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptwgaspcl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd866bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.604297 47048617354112 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpngar4qq1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acaa4b63e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.604546 46992274596736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.604747 47048617354112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.609333 46992274596736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880898.514005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.514912 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.515769 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.608998 47134710637440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.609380 47048617354112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880898.530051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.530819 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.531613 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.609174 47569835578240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.610115 47134710637440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjmvz4qel
W0618 12:01:38.610263 47569835578240 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpvliz7oti
I0618 12:01:38.611184 47134710637440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjmvz4qel', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adeb0456e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.611337 47569835578240 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpvliz7oti', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43ffbd2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.611609 47134710637440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.611774 47569835578240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.612158 47466210866048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.612135 47881863992192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.613210 47230108500864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.613988 47870410994560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.614147 47881048691584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.616852 47134710637440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.617018 47569835578240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.617444 47398890402688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.618290 47870410994560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:38.618445 47881048691584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880898.483220 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.483948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.484625 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.622401 47599126651776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.477935 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.478816 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.479623 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.622559 47502786581376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
I0618 12:01:38.623393 47870410994560 estimator.py:1111] Calling model_fn.
I0618 12:01:38.623476 47881048691584 estimator.py:1111] Calling model_fn.
W0618 12:01:38.623503 47870410994560 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:38.623585 47881048691584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:38.623545 47599126651776 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppf5qsnfe
W0618 12:01:38.623632 47502786581376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzsn37fz2
I0618 12:01:38.624673 47599126651776 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppf5qsnfe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ad19f7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.624733 47502786581376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzsn37fz2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b34634eada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:38.624857 47870410994560 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:38.624938 47881048691584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:01:38.625119 47599126651776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.625179 47502786581376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880898.559083 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.559569 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.559982 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.627647 46958910706560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.628856 46992274596736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.628978 47048617354112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.628712 46958910706560 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfc22vm7l
I0618 12:01:38.629764 46958910706560 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfc22vm7l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab5c1c74e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.630169 46958910706560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.630502 47502786581376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.630541 47599126651776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880898.564970 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.565420 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.565806 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.631550 47389297927040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
I0618 12:01:38.632556 47389297927040 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19f6db3cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.633683 47389297927040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.634878 46958910706560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.638263 47389297927040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.638797 47134710637440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.639305 47569835578240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.644762 47165180449664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.644757 47372087874432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.649096 47165180449664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:38.649104 47372087874432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880898.567340 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.567908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.568365 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.649956 47221666861952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.571908 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.572387 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.572819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.650330 47318033625984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.532889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.533305 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.533656 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.650735 47794958570368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.532188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.532646 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.533048 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.650928 47895720727424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.651284 47599126651776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.650969 47221666861952 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpltw6vh44
W0618 12:01:38.651620 47502786581376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:01:38.651949 47221666861952 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpltw6vh44', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af2ef442e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:38.651301 47318033625984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwkxivopn
I0618 12:01:38.652280 47318033625984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwkxivopn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b095f2c3dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.652345 47221666861952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.651725 47794958570368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1jh5pe6q
I0618 12:01:38.652685 47318033625984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.651914 47895720727424 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpytfhfmd3
I0618 12:01:38.652714 47794958570368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1jh5pe6q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b786a1d6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.652889 47895720727424 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpytfhfmd3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fe001dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.653119 47794958570368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.653287 47895720727424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880898.585170 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.585575 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.585900 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.653870 47316537791360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
:::MLL 1560880898.586540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.586947 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880898.587295 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:01:38.654370 47131956061056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000008-000003.tfrecord.zz_0_0
W0618 12:01:38.654218 46958910706560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:01:38.654199 47165180449664 estimator.py:1111] Calling model_fn.
I0618 12:01:38.654229 47372087874432 estimator.py:1111] Calling model_fn.
W0618 12:01:38.654305 47165180449664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:38.654341 47372087874432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:01:38.654891 47316537791360 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpf_clzrbc
I0618 12:01:38.655874 47316537791360 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpf_clzrbc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b090603ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:01:38.655343 47131956061056 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpttclk2te
W0618 12:01:38.655666 47165180449664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:01:38.655700 47372087874432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:01:38.656276 47316537791360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:01:38.656306 47131956061056 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpttclk2te', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade0c15fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:01:38.656698 47131956061056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:01:38.656967 47221666861952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.657264 47318033625984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.657450 47389297927040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:01:38.657851 47794958570368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.657947 47895720727424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.659633 47881863992192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.660067 47466210866048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.660485 47230108500864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:01:38.660973 47316537791360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.661248 47131956061056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:01:38.663925 47881863992192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:38.664380 47466210866048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:38.664768 47230108500864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:01:38.664980 47398890402688 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880898.598982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880898.599434 opt_base_learning_rate: {"value": [0.32, 0.032, 0[2019-06-18 12:02:17] divide_golden_chunk finished: 3.345 seconds
[2019-06-18 12:02:17] generate golden chunk: 3.359 seconds
[2019-06-18 12:02:17] iteration time 17: 48.346 seconds
2019-06-18 12:02:18.227658: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880937.174532 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:02:21] minmax time: 3.252 seconds
2019-06-18 12:02:21.489614: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:02:21.495362: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:02:21.499862: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880941.513514 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 17}}
[2019-06-18 12:02:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:02:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=19 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=1023779850 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=2047559681 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=3071339512 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=4095119343 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=5118899174 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=6142679005 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=7166458836 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=8190238667 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=9214018498 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=10237798329 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=11261578160 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=12285357991 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=13309137822 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=14332917653 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=15356697484 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=16380477315 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=17404257146 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=18428036977 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=19451816808 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000018-000012 --seed=20475596639 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:02:34] eval finished: 12.836 seconds
[2019-06-18 12:02:34] Win rate 000018-000012 vs 000016-000011: 0.480
:::MLL 1560880954.425143 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:02:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=20 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=1023779851 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=2047559682 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=3071339513 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=4095119344 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=5118899175 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=6142679006 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=7166458837 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=8190238668 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=9214018499 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=10237798330 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=11261578161 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=12285357992 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=13309137823 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=14332917654 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=15356697485 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=16380477316 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=17404257147 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000019-000011 --seed=18428036978 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:03:04] selfplay finished: 29.698 seconds
[2019-06-18 12:03:04] selfplay mn: 29.716 seconds
[2019-06-18 12:03:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-20-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779851 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559682 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339513 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119344 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899175 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679006 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458837 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238668 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018499 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798330 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578161 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357992 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137823 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917654 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697485 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477316 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257147 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036978 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816809 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596640 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376471 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156302 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000019-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:03:05] train finished: 44.001 seconds
:::MLL 1560880946.756443 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.757296 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.758107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.852132 47921258279808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.771122 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.771880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.772578 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.852364 47608375681920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.853171 47921258279808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppsp99qsx
W0618 12:02:26.853364 47608375681920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9wc9zzih
I0618 12:02:26.854181 47921258279808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppsp99qsx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95d22a0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.854370 47608375681920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9wc9zzih', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4cf8e87e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.854583 47921258279808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.854769 47608375681920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.859430 47921258279808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.859529 47608375681920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.878712 47921258279808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.878815 47608375681920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880946.807438 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.808318 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.809177 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.903570 47858696311680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.813775 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.814509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.815192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.903686 47531851039616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.904678 47858696311680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfaccgsvk
W0618 12:02:26.904753 47531851039616 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3wv93b8e
I0618 12:02:26.905736 47858696311680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfaccgsvk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b87412e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.905808 47531851039616 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3wv93b8e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b27af1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.906175 47858696311680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.906283 47531851039616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.911397 47858696311680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.911525 47531851039616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880946.820990 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.821738 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.822480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.919585 47101715526528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.823229 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.823990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.824653 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.919635 47335565431680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.920600 47101715526528 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpc3kyt_eo
W0618 12:02:26.920630 47335565431680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmn8ttyn6
I0618 12:02:26.921577 47101715526528 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpc3kyt_eo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad7019c0e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.921604 47335565431680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmn8ttyn6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d74265e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.921972 47101715526528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.921994 47335565431680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880946.845490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.845905 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.846225 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.924612 47333717320576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.848285 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.848660 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.848984 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.925133 47252293673856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.925634 47333717320576 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphg9sqgeu
I0618 12:02:26.926631 47333717320576 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphg9sqgeu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0d05fe7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:26.926122 47252293673856 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjurzg_3h
I0618 12:02:26.927032 47333717320576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.927089 47252293673856 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjurzg_3h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa10c43da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:02:26.926992 47101715526528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.926999 47335565431680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.927131 47608375681920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.927205 47921258279808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:02:26.927481 47252293673856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.931414 47608375681920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:26.931473 47921258279808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:26.931653 47333717320576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.932036 47252293673856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.933491 47858696311680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.934192 47531851039616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:02:26.936560 47608375681920 estimator.py:1111] Calling model_fn.
I0618 12:02:26.936606 47921258279808 estimator.py:1111] Calling model_fn.
W0618 12:02:26.936671 47608375681920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:26.936715 47921258279808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:26.938051 47608375681920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:26.938090 47921258279808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:26.946379 47335565431680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.946469 47101715526528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.950798 47333717320576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.951255 47252293673856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880946.844228 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.844973 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.845684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.956005 47893152613248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.838419 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.839321 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.840176 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.956136 47336393069440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.859774 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.860656 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.861493 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.956975 47926240834432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.864920 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.865646 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.866371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.957116 47173384983424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.957103 47893152613248 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpu65frt_y
W0618 12:02:26.957244 47336393069440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcsm9q1g5
I0618 12:02:26.958222 47893152613248 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpu65frt_y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f46ef8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.958375 47336393069440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcsm9q1g5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0da57b1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.958668 47893152613248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.958076 47926240834432 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpra79b42r
I0618 12:02:26.958818 47336393069440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.958185 47173384983424 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpkgmmi4v5
I0618 12:02:26.959201 47926240834432 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpra79b42r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b96fb25be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.959335 47173384983424 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpkgmmi4v5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7b1712e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.959634 47926240834432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.959774 47173384983424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.963818 47893152613248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.963922 47336393069440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.964338 47926240834432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.964478 47173384983424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880946.895193 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.895644 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.896047 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.967743 47330931397504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.895200 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.895649 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.896053 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.967721 47617772290944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.879223 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.879942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.880600 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.969086 47738348057472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.875838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.876661 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.877397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.969271 47127657022336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.968728 47330931397504 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptlcghwz2
W0618 12:02:26.968760 47617772290944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgnul2kvm
I0618 12:02:26.969730 47330931397504 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptlcghwz2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c5ff0ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.969745 47617772290944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgnul2kvm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f28fd5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.970131 47330931397504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.970134 47617772290944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.970123 47738348057472 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgf0y0hzr
W0618 12:02:26.970249 47127657022336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjoj4reho
I0618 12:02:26.971122 47738348057472 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgf0y0hzr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b3bdd8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.971231 47127657022336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjoj4reho', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add0bd7be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.971522 47738348057472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.971628 47127657022336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.974813 47330931397504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.974782 47617772290944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.976345 47127657022336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.976361 47738348057472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880946.906275 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.906685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.907031 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.980282 47724188885888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.907694 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.908099 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.908461 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.980431 47276511503232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.981297 47724188885888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp75ror7t7
I0618 12:02:26.981461 47276511503232 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2affb442fd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.982280 47724188885888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp75ror7t7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b67efe9be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.982585 47276511503232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.982678 47724188885888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:26.983650 47926240834432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.983824 47858696311680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.984436 47173384983424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.984233 47531851039616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.984699 47893152613248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.985121 47336393069440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.987246 47276511503232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.987216 47724188885888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:26.988139 47858696311680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:26.988527 47531851039616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:02:26.993243 47858696311680 estimator.py:1111] Calling model_fn.
W0618 12:02:26.993353 47858696311680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:26.993639 47531851039616 estimator.py:1111] Calling model_fn.
W0618 12:02:26.993751 47531851039616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:26.993880 47330931397504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.993830 47617772290944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.994271 47335565431680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.994712 47101715526528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.994693 47858696311680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:26.995095 47531851039616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:26.995525 47127657022336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:26.995500 47738348057472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880946.898407 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.898843 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.899220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.997303 47624487003008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
:::MLL 1560880946.897780 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880946.898264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880946.898637 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:02:26.997522 47458846503808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000009-000004.tfrecord.zz_0_0
W0618 12:02:26.998578 47335565431680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:26.998888 47252293673856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.999028 47333717320576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:02:26.999055 47101715526528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:26.998392 47624487003008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphuxwdn4c
W0618 12:02:26.998576 47458846503808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpog438q3e
I0618 12:02:26.999397 47624487003008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphuxwdn4c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50b937bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.999568 47458846503808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpog438q3e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a28464e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:02:26.999802 47624487003008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:02:26.999970 47458846503808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:02:27.003431 47252293673856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:02:27.003582 47333717320576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:02:27.003680 47335565431680 estimator.py:1111] Calling model_fn.
W0618 12:02:27.003785 47335565431680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:27.004209 47101715526528 estimator.py:1111] Calling model_fn.
W0618 12:02:27.004317 47101715526528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:27.004426 47624487003008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.004539 47458846503808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:02:27.005151 47335565431680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:27.005679 47101715526528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:27.006139 47724188885888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:02:27.006284 47276511503232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:02:27.008546 47252293673856 estimator.py:1111] Calling model_fn.
W0618 12:02:27.008655 47252293673856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:02:27.008739 47333717320576 estimator.py:1111] Calling model_fn.
W0618 12:02:27.008854 47333717320576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:02:27.010016 47252293673856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:02:27.010228 47333717320576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops[2019-06-18 12:03:07] divide_golden_chunk finished: 3.307 seconds
[2019-06-18 12:03:07] generate golden chunk: 3.321 seconds
[2019-06-18 12:03:07] iteration time 18: 50.289 seconds
2019-06-18 12:03:08.560897: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560880987.463923 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:03:11] minmax time: 3.217 seconds
2019-06-18 12:03:11.788155: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:03:11.793767: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:03:11.798439: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560880991.812290 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 18}}
[2019-06-18 12:03:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000020-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:03:11] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=20 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=1023779851 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=2047559682 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=3071339513 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=4095119344 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=5118899175 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=6142679006 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=7166458837 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=8190238668 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=9214018499 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=10237798330 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=11261578161 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=12285357992 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=13309137823 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=14332917654 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=15356697485 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=16380477316 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=17404257147 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=18428036978 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=19451816809 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000019-000012 --seed=20475596640 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:03:23] eval finished: 11.797 seconds
[2019-06-18 12:03:23] Win rate 000019-000012 vs 000016-000011: 0.600
:::MLL 1560881003.685578 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:03:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=21 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=1023779852 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=2047559683 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=3071339514 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=4095119345 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=5118899176 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=6142679007 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=7166458838 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=8190238669 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=9214018500 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=10237798331 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=11261578162 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=12285357993 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=13309137824 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=14332917655 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=15356697486 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=16380477317 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=17404257148 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000020-000011 --seed=18428036979 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:03:53] selfplay finished: 29.488 seconds
[2019-06-18 12:03:53] selfplay mn: 29.510 seconds
[2019-06-18 12:03:53] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-21-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779852 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559683 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339514 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119345 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899176 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679007 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458838 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238669 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018500 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798331 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578162 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357993 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137824 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917655 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697486 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477317 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257148 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036979 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816810 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596641 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376472 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156303 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000020-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:03:55] train finished: 43.551 seconds
:::MLL 1560880997.071728 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.072630 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.073442 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.172120 47587196416896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.076555 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.077245 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.077976 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.172548 47285777761152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.173206 47587196416896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzshi1ldu
I0618 12:03:17.174209 47587196416896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzshi1ldu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b480a868e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:17.173596 47285777761152 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_saon42d
I0618 12:03:17.174608 47587196416896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.174605 47285777761152 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_saon42d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b01dc92de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.175036 47285777761152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.179449 47587196416896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.179931 47285777761152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880997.082446 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.083166 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.083819 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.186103 48011088524160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.080179 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.080926 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.081599 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.186071 47126668198784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.187149 48011088524160 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpehua7i_s
W0618 12:03:17.187214 47126668198784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0xmnzs0j
I0618 12:03:17.188148 48011088524160 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpehua7i_s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baabc76be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.188213 47126668198784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0xmnzs0j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adcd0e79e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.188551 48011088524160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.188621 47126668198784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.193546 48011088524160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.193504 47126668198784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.198905 47587196416896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.199969 47285777761152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.213022 47126668198784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.213150 48011088524160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880997.108718 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.109591 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.110401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.212965 47739840701312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.109718 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.110586 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.111301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.213021 47599904555904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.214119 47739840701312 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5hi3hz4e
W0618 12:03:17.214154 47599904555904 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5dsjw_jx
I0618 12:03:17.215239 47739840701312 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5hi3hz4e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b94d57dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.215292 47599904555904 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5dsjw_jx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4afffd5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.215689 47739840701312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.215738 47599904555904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.221093 47739840701312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.221155 47599904555904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880997.098153 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.098856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.099516 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.223087 46923628757888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.085826 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.086740 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.087606 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.223271 47409274569600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.224194 46923628757888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy_h3mg4w
W0618 12:03:17.224348 47409274569600 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpagrw9r2o
:::MLL 1560880997.120582 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.121501 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.122336 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.225113 47637896614784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.126064 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.126814 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.127521 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.225228 47716546581376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
I0618 12:03:17.225296 46923628757888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy_h3mg4w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aad8acf8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.225454 47409274569600 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpagrw9r2o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e9d8e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.225755 46923628757888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.225894 47409274569600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.226132 47637896614784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpogwhss03
W0618 12:03:17.226232 47716546581376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpn7jl3nyr
I0618 12:03:17.227134 47637896614784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpogwhss03', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b53d87e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.227206 47716546581376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpn7jl3nyr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6628656dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.227532 47637896614784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.227603 47716546581376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880997.152464 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.152909 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.153285 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.227533 47747133145984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.151605 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.152138 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.152538 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.227586 47342417744768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.228592 47342417744768 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprd3vjsoj
W0618 12:03:17.228562 47747133145984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzyfg64q0
I0618 12:03:17.229547 47747133145984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzyfg64q0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d477f3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.229551 47342417744768 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprd3vjsoj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f0c945e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.229948 47342417744768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.229944 47747133145984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.231150 46923628757888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.231186 47409274569600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.232573 47716546581376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.232569 47637896614784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.234618 47342417744768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.234658 47747133145984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560880997.139557 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.140304 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.140956 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.237638 47727247881088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.129460 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.130371 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.131229 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.237888 47490578346880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.238748 47727247881088 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpp80ov3a2
I0618 12:03:17.239867 47727247881088 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpp80ov3a2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68a63e3da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:17.239202 47490578346880 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyjmdqs_e
I0618 12:03:17.240270 47727247881088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.240316 47490578346880 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyjmdqs_e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b318ba3cda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.240745 47490578346880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.243120 47739840701312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.243686 47599904555904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.245174 47727247881088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.245539 47490578346880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.247208 47587196416896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:17.248238 47285777761152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560880997.173870 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.174286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.174644 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.250894 47021513065344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.175244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.175658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.176009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.251040 46929756586880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.251570 47587196416896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:17.251913 47716546581376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.251938 47637896614784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.252578 47285777761152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:03:17.251910 47021513065344 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4552b9d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:03:17.252010 46929756586880 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgyuqkeej
W0618 12:03:17.252968 47409274569600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.253087 46923628757888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:03:17.252969 46929756586880 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgyuqkeej', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaef80ece80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.253033 47021513065344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.253376 46929756586880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.253714 47342417744768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.253799 47747133145984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:03:17.256690 47587196416896 estimator.py:1111] Calling model_fn.
W0618 12:03:17.256798 47587196416896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:17.257651 47285777761152 estimator.py:1111] Calling model_fn.
W0618 12:03:17.257760 47285777761152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:03:17.257771 47021513065344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.258032 46929756586880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.258184 47587196416896 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:17.259124 47285777761152 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:17.261059 47126668198784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:17.261237 48011088524160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:17.264508 47727247881088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.265168 47490578346880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.265384 47126668198784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:03:17.265559 48011088524160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560880997.156799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.157296 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.157736 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.265795 47420572349312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.161236 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.161637 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.161985 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.265840 47157833413504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.266828 47420572349312 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6e4zt53b
W0618 12:03:17.266857 47157833413504 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpz9yj871e
I0618 12:03:17.267799 47420572349312 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6e4zt53b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b213ef50e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.267828 47157833413504 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpz9yj871e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4127f0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.268188 47420572349312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.268221 47157833413504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560880997.193758 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.194175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.194534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.268258 47465275548544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.193818 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.194237 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.194597 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.268397 47780567950208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.269280 47465275548544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxewdncss
W0618 12:03:17.269404 47780567950208 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6e_9gm13
I0618 12:03:17.270264 47465275548544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxewdncss', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ba779be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.270382 47780567950208 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6e_9gm13', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75105dfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.270450 47126668198784 estimator.py:1111] Calling model_fn.
W0618 12:03:17.270559 47126668198784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:17.270667 47465275548544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.270595 48011088524160 estimator.py:1111] Calling model_fn.
W0618 12:03:17.270703 48011088524160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:03:17.270771 47780567950208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.271925 47126668198784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:17.272063 48011088524160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:03:17.272892 47420572349312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.272905 47157833413504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.275332 47465275548544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.275412 47780567950208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:03:17.276776 47021513065344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.277211 46929756586880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560880997.212334 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.212773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.213171 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.288102 46953111638912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.213430 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.213873 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.214301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.288378 47584445211520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.209319 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.209797 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.210260 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.289801 47289624372096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
:::MLL 1560880997.210247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560880997.210713 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560880997.211117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:03:17.289857 47949092164480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000010-000005.tfrecord.zz_0_0
W0618 12:03:17.289165 46953111638912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe5l97kcd
W0618 12:03:17.289412 47584445211520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8235anhp
I0618 12:03:17.290208 46953111638912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe5l97kcd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab46820ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.290443 47584445211520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8235anhp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47668a6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.290608 46953111638912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.290842 47584445211520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.290813 47289624372096 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpd880v_e_
W0618 12:03:17.290842 47949092164480 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp91ywcuz2
I0618 12:03:17.291787 47289624372096 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpd880v_e_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b02c1d94e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.291810 47949092164480 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp91ywcuz2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c4d315e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:03:17.292190 47289624372096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:03:17.292214 47949092164480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:03:17.292039 47420572349312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.292077 47157833413504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:03:17.292159 47739840701312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:17.292903 47599904555904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:03:17.294372 47465275548544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.pyth[2019-06-18 12:03:56] divide_golden_chunk finished: 3.312 seconds
[2019-06-18 12:03:56] generate golden chunk: 3.326 seconds
[2019-06-18 12:03:56] moving /lfs/lfs12/gma_akey/results/epb309/models/000020-000012.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000020-000013.meta
[2019-06-18 12:03:56] moving /lfs/lfs12/gma_akey/results/epb309/models/000020-000012.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000020-000013.data-00000-of-00001
[2019-06-18 12:03:56] moving /lfs/lfs12/gma_akey/results/epb309/models/000020-000012.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb
[2019-06-18 12:03:56] moving /lfs/lfs12/gma_akey/results/epb309/models/000020-000012.index --> /lfs/lfs12/gma_akey/results/epb309/models/000020-000013.index
[2019-06-18 12:03:56] iteration time 19: 49.102 seconds
2019-06-18 12:03:57.692797: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881036.566327 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:04:00] minmax time: 3.248 seconds
2019-06-18 12:04:00.950812: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:04:00.956276: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:04:00.960842: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881040.972746 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 19}}
[2019-06-18 12:04:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:04:01] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=21 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=1023779852 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=2047559683 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=3071339514 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=4095119345 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=5118899176 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=6142679007 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=7166458838 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=8190238669 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=9214018500 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=10237798331 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=11261578162 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=12285357993 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=13309137824 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=14332917655 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=15356697486 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=16380477317 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=17404257148 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=18428036979 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=19451816810 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000020-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000020-000013 --seed=20475596641 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:04:14] eval finished: 13.257 seconds
[2019-06-18 12:04:14] Win rate 000020-000013 vs 000019-000012: 0.350
:::MLL 1560881054.305397 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:04:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=22 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=1023779853 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=2047559684 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=3071339515 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=4095119346 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=5118899177 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=6142679008 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=7166458839 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=8190238670 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=9214018501 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=10237798332 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=11261578163 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=12285357994 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=13309137825 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=14332917656 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=15356697487 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=16380477318 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=17404257149 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000021-000012 --seed=18428036980 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:04:43] selfplay finished: 29.207 seconds
[2019-06-18 12:04:43] selfplay mn: 29.224 seconds
[2019-06-18 12:04:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-22-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779853 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559684 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339515 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119346 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899177 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679008 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458839 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238670 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018501 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798332 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578163 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357994 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137825 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917656 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697487 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477318 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257149 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036980 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816811 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596642 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376473 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156304 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000021-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:04:44] train finished: 43.530 seconds
:::MLL 1560881046.162302 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.163026 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.163701 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.255095 47285276656512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.152886 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.153749 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.154534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.255223 46969093182336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.256142 47285276656512 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpltmkmn5p
W0618 12:04:06.256216 46969093182336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5k1npem2
I0618 12:04:06.257139 47285276656512 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpltmkmn5p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b01beb48e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.257212 46969093182336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5k1npem2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab820b3ae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.257545 47285276656512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.257611 46969093182336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.262477 47285276656512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.262476 46969093182336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.281622 47285276656512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.281905 46969093182336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881046.188924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.189765 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.190490 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.290707 47413549466496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.188205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.189034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.189821 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.290915 47942857773952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.291767 47413549466496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm42rp0zz
W0618 12:04:06.291899 47942857773952 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpffxeq6ja
I0618 12:04:06.292772 47413549466496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm42rp0zz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f9c5c5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.292881 47942857773952 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpffxeq6ja', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ad9982e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.293179 47413549466496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.293280 47942857773952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.298144 47942857773952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.298288 47413549466496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881046.211345 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.212234 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.213076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.312190 47424733803392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.223932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.224679 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.225307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.312662 47160138158976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.313314 47424733803392 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6g_umls0
I0618 12:04:06.314426 47424733803392 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6g_umls0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2236ffce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:06.313752 47160138158976 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmps1nfa_
I0618 12:04:06.314854 47160138158976 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmps1nfa_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae49bde9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.314892 47424733803392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.315297 47160138158976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.317461 47942857773952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.317832 47413549466496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.320143 47424733803392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.320493 47160138158976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.330003 47285276656512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:06.330059 46969093182336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:06.334306 47285276656512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:06.334394 46969093182336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:04:06.339362 47285276656512 estimator.py:1111] Calling model_fn.
I0618 12:04:06.339433 46969093182336 estimator.py:1111] Calling model_fn.
W0618 12:04:06.339471 47285276656512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:06.339542 46969093182336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:06.340831 47285276656512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:06.340894 46969093182336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:06.342019 47424733803392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.342832 47160138158976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881046.259584 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.260060 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.260472 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.347910 48001552880512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.255710 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.256255 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.256741 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.347859 47407028249472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.254324 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.254806 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.255208 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.349294 47447907701632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.348855 47407028249472 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpx1tqvliq
W0618 12:04:06.348905 48001552880512 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpi0pwx8i_
:::MLL 1560881046.265588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.265970 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.266290 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.349532 47374528226176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
I0618 12:04:06.349830 47407028249472 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpx1tqvliq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e17aa6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.349889 48001552880512 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpi0pwx8i_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba884185e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.350229 47407028249472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.350291 48001552880512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.350309 47447907701632 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8zg4hse4
I0618 12:04:06.350566 47374528226176 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1686836d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.351274 47447907701632 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8zg4hse4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b279c456e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.351665 47447907701632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.351679 47374528226176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.354863 47407028249472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881046.240006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.240850 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.241668 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.354948 47656014427008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.354944 48001552880512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881046.253786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.254619 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.255333 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.355586 47525007131520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.252476 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.253314 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.254126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.355592 47721240863616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.240468 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.241334 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.242066 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.356546 47330982740864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.355996 47656014427008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcc71hn2o
W0618 12:04:06.356408 47447907701632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.356433 47374528226176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:06.356993 47656014427008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcc71hn2o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b581065fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.357390 47656014427008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.356668 47721240863616 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp19infxh6
W0618 12:04:06.356699 47525007131520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5pxvvpdb
I0618 12:04:06.357666 47721240863616 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp19infxh6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6740326dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.357695 47525007131520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5pxvvpdb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b398fc15e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881046.243834 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.244632 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.245350 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.357431 47982718956416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.243383 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.244224 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.245037 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.357596 47922241401728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
I0618 12:04:06.358067 47721240863616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.357529 47330982740864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpt1lxtlys
I0618 12:04:06.358099 47525007131520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.358502 47330982740864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpt1lxtlys', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c63001e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.358906 47330982740864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.358575 47982718956416 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplcrobls7
W0618 12:04:06.358686 47922241401728 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1e6i1dmy
I0618 12:04:06.359681 47982718956416 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplcrobls7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba421817e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.359771 47922241401728 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1e6i1dmy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b960cc33dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.360126 47982718956416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.360226 47922241401728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.362233 47656014427008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.362876 47721240863616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.362922 47525007131520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.363550 47330982740864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881046.282741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.283197 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.283604 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.364639 47347031847808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.282812 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.283264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.283665 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.364722 47007041614720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.365382 47942857773952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:06.365413 47982718956416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.365585 47922241401728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.365953 47413549466496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:06.365671 47347031847808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9tcpavnl
W0618 12:04:06.365703 47007041614720 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpb_0ggmbj
I0618 12:04:06.366664 47347031847808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9tcpavnl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b101f9a0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.366684 47007041614720 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpb_0ggmbj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac0f69ace10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.367059 47347031847808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.367087 47007041614720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.369685 47942857773952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:06.370266 47413549466496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:06.371692 47347031847808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.371695 47007041614720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.373876 47407028249472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.374308 48001552880512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:06.374724 47942857773952 estimator.py:1111] Calling model_fn.
W0618 12:04:06.374840 47942857773952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:06.375316 47413549466496 estimator.py:1111] Calling model_fn.
W0618 12:04:06.375423 47413549466496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:06.375446 47447907701632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.375542 47374528226176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.376196 47942857773952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:06.376770 47413549466496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:06.381447 47656014427008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.382243 47721240863616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.382389 47525007131520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.382692 47330982740864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.387333 47982718956416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.388467 47922241401728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.390806 47347031847808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.390861 47007041614720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:06.390999 47424733803392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:06.392182 47160138158976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:06.395326 47424733803392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:06.396522 47160138158976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:04:06.400390 47424733803392 estimator.py:1111] Calling model_fn.
W0618 12:04:06.400501 47424733803392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:06.401618 47160138158976 estimator.py:1111] Calling model_fn.
W0618 12:04:06.401728 47160138158976 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:06.401857 47424733803392 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:06.403096 47160138158976 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881046.306685 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.307175 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.307597 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.404007 47456330769280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.308219 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.308690 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.309178 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.404111 47265792127872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.405033 47456330769280 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcp3wjxw0
W0618 12:04:06.405084 47265792127872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpownxj6w5
I0618 12:04:06.406004 47456330769280 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcp3wjxw0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2992533e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.406059 47265792127872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpownxj6w5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd35564e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.406417 47456330769280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:06.406459 47265792127872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:06.411082 47265792127872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:06.411088 47456330769280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881046.336330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.336722 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.337078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.413651 47344836035456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.335889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.336318 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.336689 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.413861 47844519109504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.334680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.335119 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.335508 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.413999 47150482166656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
:::MLL 1560881046.336504 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881046.336922 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881046.337267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:06.414040 47015140725632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000011-000005.tfrecord.zz_0_0
W0618 12:04:06.414670 47344836035456 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfv1qyawu
W0618 12:04:06.414884 47844519109504 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp38e63_mi
W0618 12:04:06.414981 47150482166656 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdu0gkbon
I0618 12:04:06.415871 47844519109504 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp38e63_mi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83f4273dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:06.415658 47344836035456 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfv1qyawu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute':[2019-06-18 12:04:46] divide_golden_chunk finished: 3.348 seconds
[2019-06-18 12:04:46] generate golden chunk: 3.362 seconds
[2019-06-18 12:04:46] iteration time 20: 50.327 seconds
2019-06-18 12:04:48.036253: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881086.893557 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:04:51] minmax time: 3.271 seconds
2019-06-18 12:04:51.317204: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:04:51.322616: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:04:51.327078: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881091.340728 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 20}}
[2019-06-18 12:04:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000022-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:04:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=22 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=1023779853 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=2047559684 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=3071339515 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=4095119346 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=5118899177 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=6142679008 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=7166458839 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=8190238670 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=9214018501 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=10237798332 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=11261578163 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=12285357994 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=13309137825 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=14332917656 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=15356697487 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=16380477318 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=17404257149 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=18428036980 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=19451816811 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000021-000013 --seed=20475596642 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:05:03] eval finished: 11.882 seconds
[2019-06-18 12:05:03] Win rate 000021-000013 vs 000019-000012: 0.570
:::MLL 1560881103.299966 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:05:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=23 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=1023779854 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=2047559685 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=3071339516 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=4095119347 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=5118899178 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=6142679009 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=7166458840 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=8190238671 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=9214018502 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=10237798333 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=11261578164 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=12285357995 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=13309137826 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=14332917657 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=15356697488 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=16380477319 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=17404257150 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000022-000012 --seed=18428036981 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:05:32] selfplay finished: 28.890 seconds
[2019-06-18 12:05:32] selfplay mn: 28.909 seconds
[2019-06-18 12:05:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-23-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=23 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779854 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559685 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339516 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119347 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899178 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679009 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458840 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238671 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018502 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798333 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578164 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357995 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137826 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917657 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697488 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477319 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257150 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036981 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816812 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596643 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376474 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156305 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000022-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:05:34] train finished: 43.646 seconds
:::MLL 1560881096.675832 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.676594 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.677285 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.780844 47912859173760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.678688 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.679423 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.680073 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.781483 47668612588416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.781980 47912859173760 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0mtsbutu
I0618 12:04:56.782978 47912859173760 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0mtsbutu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93dd89ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:56.782463 47668612588416 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpes2_6e1e
I0618 12:04:56.783399 47912859173760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.783433 47668612588416 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpes2_6e1e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5aff4ebe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.783835 47668612588416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.788172 47912859173760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.788431 47668612588416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881096.686606 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.687481 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.688369 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.793753 47207203033984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.704638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.705329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.706021 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.793784 47944546861952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.794884 47207203033984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpc8ty9ady
W0618 12:04:56.794915 47944546861952 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4oc3wh0b
I0618 12:04:56.795966 47207203033984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpc8ty9ady', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef9127add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.796026 47944546861952 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4oc3wh0b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9b3e458e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.796416 47207203033984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.796468 47944546861952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.801763 47944546861952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.801764 47207203033984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.807723 47668612588416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.808220 47912859173760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.823621 47207203033984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.823762 47944546861952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881096.679935 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.680745 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.681445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.837196 47471353840512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.678613 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.679439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.680258 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.837248 47186598695808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.838228 47186598695808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbpb8nb_q
W0618 12:04:56.838258 47471353840512 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpz63dpai7
I0618 12:04:56.839280 47186598695808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbpb8nb_q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeac50a6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.839287 47471353840512 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpz63dpai7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d11c50e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.839712 47186598695808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.839750 47471353840512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.844571 47186598695808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.844570 47471353840512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881096.765078 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.765524 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.765962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.845446 47114948981632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.767064 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.767506 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.767859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.846234 47440309519232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.846476 47114948981632 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzqvghfyq
I0618 12:04:56.847466 47114948981632 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzqvghfyq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada16626e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.847864 47114948981632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.847243 47440309519232 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25d7625d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881096.728260 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.729220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.730130 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.848322 47225842758528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.743485 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.744228 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.744901 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.848466 47785095328640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
I0618 12:04:56.848331 47440309519232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.849360 47225842758528 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3y5l97_o
W0618 12:04:56.849458 47785095328640 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp40qukssg
I0618 12:04:56.850416 47225842758528 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3y5l97_o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3e82b4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.850528 47785095328640 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp40qukssg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b761e383e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.850846 47225842758528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.850961 47785095328640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.852471 47114948981632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.852860 47440309519232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.855680 47225842758528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.855685 47785095328640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.855771 47668612588416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:56.856816 47912859173760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881096.778919 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.779378 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.779752 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.858052 47666421560192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.740094 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.740851 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.741566 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.858587 47661216646016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.734127 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.735022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.735876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.858676 47783317881728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.782110 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.782544 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.782905 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.859619 47455044440960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.859054 47666421560192 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3_c9_4_8
I0618 12:04:56.860036 47666421560192 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3_c9_4_8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a7cb63dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:04:56.860057 47668612588416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:56.859630 47661216646016 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp983etw04
W0618 12:04:56.859670 47783317881728 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9nbbc583
I0618 12:04:56.860635 47661216646016 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp983etw04', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5946799e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.860440 47666421560192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.860671 47783317881728 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9nbbc583', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75b4469dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.861039 47661216646016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.861074 47783317881728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.861128 47912859173760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:56.860596 47455044440960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmyqdx584
I0618 12:04:56.861582 47455044440960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmyqdx584', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2945a76e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.861980 47455044440960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.863689 47471353840512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.863817 47186598695808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:56.865125 47668612588416 estimator.py:1111] Calling model_fn.
W0618 12:04:56.865205 47666421560192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.865230 47668612588416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:56.865963 47783317881728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.865986 47661216646016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:56.866203 47912859173760 estimator.py:1111] Calling model_fn.
W0618 12:04:56.866310 47912859173760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:56.866584 47668612588416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:56.866682 47455044440960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.867656 47912859173760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:56.871467 47114948981632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.871868 47440309519232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.874902 47785095328640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.874672 47207203033984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:56.875488 47225842758528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.875131 47944546861952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881096.731569 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.732063 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.732463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.875203 47922632868736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.733927 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.734424 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.734873 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.875351 46941048206208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.876217 47922632868736 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjxr3y6mu
W0618 12:04:56.876346 46941048206208 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpye3zpn_o
I0618 12:04:56.877196 47922632868736 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjxr3y6mu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9624187da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.877320 46941048206208 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpye3zpn_o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab199174e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.877596 47922632868736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.877711 46941048206208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.878959 47207203033984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:56.879467 47944546861952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881096.726472 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.727407 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.728266 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.881720 47772895228800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.882266 47922632868736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.882274 46941048206208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.882854 47772895228800 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzdlqbmgr
I0618 12:04:56.883960 47772895228800 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzdlqbmgr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7347097e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.884013 47207203033984 estimator.py:1111] Calling model_fn.
W0618 12:04:56.884123 47207203033984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:04:56.884430 47772895228800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.884468 47666421560192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:04:56.884538 47944546861952 estimator.py:1111] Calling model_fn.
W0618 12:04:56.884652 47944546861952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:04:56.885174 47783317881728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.885354 47661216646016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.885486 47207203033984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:56.885815 47455044440960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.886029 47944546861952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:04:56.889830 47772895228800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881096.733917 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.734658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.735358 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.897073 47327183844224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.898125 47327183844224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfc3mmf7r
I0618 12:04:56.899208 47327183844224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfc3mmf7r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b80917e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.899650 47327183844224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.901316 46941048206208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.901375 47922632868736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881096.817643 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.818132 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.818556 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.903197 47484977890176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.814919 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.815382 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.815777 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.903310 47143931863936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.904230 47484977890176 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_d7vaf40
W0618 12:04:56.904298 47143931863936 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_0upnohs
W0618 12:04:56.904868 47327183844224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:04:56.905230 47484977890176 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_d7vaf40', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b303dd39da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.905269 47143931863936 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_0upnohs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae0d5e63e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.905633 47484977890176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.905663 47143931863936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881096.805818 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.806276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.806677 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.908789 47716855714688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
:::MLL 1560881096.808191 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881096.808650 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881096.809075 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:04:56.908944 47461107327872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000012-000006.tfrecord.zz_0_0
W0618 12:04:56.910278 47143931863936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.910309 47484977890176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.909825 47716855714688 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm3shvzi6
W0618 12:04:56.910024 47461107327872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdesl4kdh
I0618 12:04:56.910882 47716855714688 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm3shvzi6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b663ad26dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.911088 47461107327872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdesl4kdh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2aaf07be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:04:56.911309 47716855714688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:04:56.911510 47461107327872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:04:56.911652 47471353840512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:56.911846 47772895228800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:04:56.911845 47186598695808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:56.916065 47716855714688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.915979 47471353840512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:56.916298 47461107327872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:04:56.916164 47186598695808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:04:56.919122 47440309519232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:04:56.919078 47114948981632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:04:56.921043 47471353840512 estimator.py:1111] Calling model_fn.
W0618 12:04:56.921149 47471353840512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is dep[2019-06-18 12:05:35] divide_golden_chunk finished: 3.328 seconds
[2019-06-18 12:05:35] generate golden chunk: 3.342 seconds
[2019-06-18 12:05:35] moving /lfs/lfs12/gma_akey/results/epb309/models/000022-000013.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000022-000014.data-00000-of-00001
[2019-06-18 12:05:35] moving /lfs/lfs12/gma_akey/results/epb309/models/000022-000013.index --> /lfs/lfs12/gma_akey/results/epb309/models/000022-000014.index
[2019-06-18 12:05:35] moving /lfs/lfs12/gma_akey/results/epb309/models/000022-000013.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000022-000014.meta
[2019-06-18 12:05:35] moving /lfs/lfs12/gma_akey/results/epb309/models/000022-000013.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb
[2019-06-18 12:05:35] iteration time 21: 48.707 seconds
2019-06-18 12:05:36.834022: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881135.601041 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:05:40] minmax time: 3.255 seconds
2019-06-18 12:05:40.098738: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:05:40.104318: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:05:40.108942: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881140.120933 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 21}}
[2019-06-18 12:05:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000023-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:05:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=23 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=1023779854 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=2047559685 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=3071339516 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=4095119347 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=5118899178 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=6142679009 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=7166458840 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=8190238671 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=9214018502 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=10237798333 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=11261578164 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=12285357995 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=13309137826 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=14332917657 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=15356697488 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=16380477319 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=17404257150 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=18428036981 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=19451816812 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000021-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000022-000014 --seed=20475596643 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:05:51] eval finished: 11.331 seconds
[2019-06-18 12:05:51] Win rate 000022-000014 vs 000021-000013: 0.520
:::MLL 1560881151.529342 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:05:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=24 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=1023779855 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=2047559686 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=3071339517 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=4095119348 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=5118899179 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=6142679010 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=7166458841 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=8190238672 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=9214018503 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=10237798334 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=11261578165 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=12285357996 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=13309137827 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=14332917658 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=15356697489 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=16380477320 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=17404257151 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000023-000013 --seed=18428036982 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:06:21] selfplay finished: 29.865 seconds
[2019-06-18 12:06:21] selfplay mn: 29.884 seconds
[2019-06-18 12:06:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-24-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=24 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779855 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559686 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339517 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119348 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899179 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679010 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458841 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238672 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018503 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798334 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578165 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357996 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137827 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917658 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697489 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477320 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257151 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036982 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816813 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596644 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376475 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156306 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000023-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:06:23] train finished: 43.650 seconds
:::MLL 1560881145.340072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.340832 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.341592 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.448257 47834948928384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.341909 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.342649 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.343321 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.448431 47986885350272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.449285 47834948928384 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpaikvel2g
W0618 12:05:45.449407 47986885350272 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpiqyaxv6m
I0618 12:05:45.450272 47834948928384 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpaikvel2g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81b9b9de80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.450379 47986885350272 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpiqyaxv6m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba519d7ae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.450679 47834948928384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.450781 47986885350272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.455564 47986885350272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.455573 47834948928384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.474813 47834948928384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.474990 47986885350272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881145.368246 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.369153 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.369989 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.476721 47536229159808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.376703 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.377453 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.378132 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.476865 47909660939136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.477867 47536229159808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmkr1skc2
W0618 12:05:45.477965 47909660939136 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpctuk1ypj
I0618 12:05:45.478969 47536229159808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmkr1skc2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3c2ca3ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.479096 47909660939136 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpctuk1ypj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b931ee89e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.479431 47536229159808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.479551 47909660939136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.484735 47536229159808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.484836 47909660939136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.506978 47536229159808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.507007 47909660939136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881145.381335 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.382267 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.383095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.508168 47056757134208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.403113 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.403873 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.404602 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.509552 47433662706560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.509292 47056757134208 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpn7iligma
I0618 12:05:45.510384 47056757134208 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpn7iligma', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc89e16e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.510829 47056757134208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.510651 47433662706560 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpimjlweka
I0618 12:05:45.511731 47433662706560 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpimjlweka', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b244b33fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.512175 47433662706560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.516097 47056757134208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881145.377173 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.377912 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.378591 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.516214 47465851061120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.369913 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.370792 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.371643 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.516403 47801417610112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.517399 47433662706560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881145.430429 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.430863 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.431249 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.517464 47363152409472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.517247 47465851061120 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp15slvjc2
W0618 12:05:45.517386 47801417610112 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpkfwprerq
I0618 12:05:45.518239 47465851061120 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp15slvjc2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2bc9c75e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.518364 47801417610112 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpkfwprerq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79eb1a8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.518642 47465851061120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.518763 47801417610112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.518541 47363152409472 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp9z7z6m3g
I0618 12:05:45.519588 47363152409472 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp9z7z6m3g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13e0764e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.520020 47363152409472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.522851 47834948928384 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.523007 47986885350272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.523637 47465851061120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.523674 47801417610112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.524788 47363152409472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881145.431553 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.431982 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.432354 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.525984 47198932034432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.527162 47834948928384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.527309 47986885350272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:05:45.526993 47198932034432 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeda42a2d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.528112 47198932034432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881145.440046 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.440833 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.441515 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.530975 47424203350912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.424307 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.425235 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.426115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.531101 47187451724672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
I0618 12:05:45.532219 47834948928384 estimator.py:1111] Calling model_fn.
W0618 12:05:45.532328 47834948928384 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:05:45.532358 47986885350272 estimator.py:1111] Calling model_fn.
W0618 12:05:45.532062 47424203350912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplm_x2ry7
W0618 12:05:45.532464 47986885350272 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:45.532100 47187451724672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzg1lwemh
W0618 12:05:45.532644 47198932034432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:05:45.533056 47424203350912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplm_x2ry7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b221761ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.533087 47187451724672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzg1lwemh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeaf7e29e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.533463 47424203350912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.533477 47187451724672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.533688 47834948928384 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:45.533819 47986885350272 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:45.537902 47056757134208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.538200 47424203350912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.538189 47187451724672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.539536 47433662706560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881145.460037 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.460468 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.460843 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.539983 47922300224384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.541070 47922300224384 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptai57yoj
I0618 12:05:45.542091 47922300224384 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptai57yoj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b961044de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.542502 47922300224384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.542873 47465851061120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881145.464539 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.464994 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.465358 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.542686 47526415922048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.543077 47801417610112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.544005 47363152409472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.543675 47526415922048 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpt9rk_hjj
I0618 12:05:45.544639 47526415922048 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpt9rk_hjj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b39e3b9be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.545041 47526415922048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.547168 47922300224384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.549601 47526415922048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.551712 47198932034432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881145.434943 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.435706 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.436394 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.556495 47928954991488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.433596 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.434397 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.435159 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.556559 47082874585984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.557379 47187451724672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.557470 47424203350912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.557723 47536229159808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.557821 47909660939136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881145.457738 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.458154 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.458503 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.557962 47578872451968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.557601 47928954991488 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpyjirdr0s
W0618 12:05:45.557629 47082874585984 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbi8yntqp
I0618 12:05:45.558698 47928954991488 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpyjirdr0s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b979cec8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881145.455365 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.455775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.456137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.558405 47191315575680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
I0618 12:05:45.558719 47082874585984 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbi8yntqp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad29e9a0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.559165 47928954991488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.559171 47082874585984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.558986 47578872451968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsap3f68e
I0618 12:05:45.559979 47578872451968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsap3f68e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b461a60de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:05:45.559372 47191315575680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp8fjwk2nv
I0618 12:05:45.560342 47191315575680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp8fjwk2nv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebde304e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.560378 47578872451968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.560728 47191315575680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881145.436902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.437432 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.437902 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.561077 47208084116352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
:::MLL 1560881145.449383 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.449902 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.450352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:05:45.561187 47870047744896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000022-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000013-000007.tfrecord.zz_0_0
W0618 12:05:45.562048 47536229159808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.562129 47909660939136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.562085 47208084116352 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbebtffm7
W0618 12:05:45.562186 47870047744896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcu26qbmq
I0618 12:05:45.563068 47208084116352 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbebtffm7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aefc5abee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.563160 47870047744896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcu26qbmq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89e5c74e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:05:45.563466 47208084116352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:05:45.563560 47870047744896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:05:45.564018 47082874585984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.564024 47928954991488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.565037 47578872451968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.565284 47191315575680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.566200 47922300224384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:05:45.567090 47536229159808 estimator.py:1111] Calling model_fn.
I0618 12:05:45.567159 47909660939136 estimator.py:1111] Calling model_fn.
W0618 12:05:45.567201 47536229159808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:45.567265 47909660939136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:05:45.568089 47208084116352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.568140 47870047744896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:05:45.568562 47536229159808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:45.568618 47909660939136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:05:45.568689 47526415922048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.583090 47928954991488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.583115 47082874585984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.583987 47578872451968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.584459 47191315575680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.586845 47056757134208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.587243 47870047744896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.587304 47208084116352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:05:45.587921 47433662706560 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.590832 47801417610112 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.590896 47465851061120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.591160 47056757134208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.591807 47363152409472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:05:45.592215 47433662706560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.595140 47801417610112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.595214 47465851061120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:05:45.596217 47056757134208 estimator.py:1111] Calling model_fn.
W0618 12:05:45.596128 47363152409472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:05:45.596327 47056757134208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881145.514191 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881145.514598 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881145.515049 opt_learning_rate_deca[2019-06-18 12:06:24] divide_golden_chunk finished: 3.317 seconds
[2019-06-18 12:06:24] generate golden chunk: 3.331 seconds
[2019-06-18 12:06:24] moving /lfs/lfs12/gma_akey/results/epb309/models/000023-000014.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb
[2019-06-18 12:06:24] moving /lfs/lfs12/gma_akey/results/epb309/models/000023-000014.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000023-000015.data-00000-of-00001
[2019-06-18 12:06:24] moving /lfs/lfs12/gma_akey/results/epb309/models/000023-000014.index --> /lfs/lfs12/gma_akey/results/epb309/models/000023-000015.index
[2019-06-18 12:06:24] moving /lfs/lfs12/gma_akey/results/epb309/models/000023-000014.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000023-000015.meta
[2019-06-18 12:06:24] iteration time 22: 49.186 seconds
2019-06-18 12:06:26.068794: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881184.787171 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:06:29] minmax time: 3.266 seconds
2019-06-18 12:06:29.345061: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:06:29.350478: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:06:29.354851: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881189.366455 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 22}}
[2019-06-18 12:06:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:06:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=24 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=1023779855 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=2047559686 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=3071339517 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=4095119348 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=5118899179 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=6142679010 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=7166458841 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=8190238672 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=9214018503 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=10237798334 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=11261578165 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=12285357996 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=13309137827 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=14332917658 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=15356697489 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=16380477320 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=17404257151 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=18428036982 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=19451816813 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000023-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000023-000015 --seed=20475596644 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:06:40] eval finished: 10.772 seconds
[2019-06-18 12:06:40] Win rate 000023-000015 vs 000022-000014: 0.300
:::MLL 1560881200.216678 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:06:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=25 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=1023779856 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=2047559687 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=3071339518 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=4095119349 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=5118899180 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=6142679011 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=7166458842 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=8190238673 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=9214018504 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=10237798335 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=11261578166 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=12285357997 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=13309137828 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=14332917659 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=15356697490 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=16380477321 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=17404257152 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000024-000014 --seed=18428036983 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:07:09] selfplay finished: 29.186 seconds
[2019-06-18 12:07:09] selfplay mn: 29.204 seconds
[2019-06-18 12:07:09] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-25-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=25 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779856 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559687 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339518 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119349 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899180 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679011 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458842 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238673 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018504 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798335 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578166 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357997 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137828 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917659 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697490 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477321 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257152 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036983 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816814 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596645 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376476 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156307 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000024-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:07:12] divide_golden_chunk finished: 3.314 seconds
[2019-06-18 12:07:12] generate golden chunk: 3.328 seconds
[2019-06-18 12:07:12] train finished: 43.471 seconds
:::MLL 1560881194.612677 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.613558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.614382 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.733363 46962626429824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.620984 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.621680 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.622324 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.734871 46942642291584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.734487 46962626429824 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7dbfjee4
I0618 12:06:34.735594 46962626429824 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7dbfjee4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab69f40de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.736003 46962626429824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881194.617887 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.618733 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.619424 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.735803 47111564788608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.616985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.617828 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.618619 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.736097 47447424516992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.735915 46942642291584 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplqhkazk4
I0618 12:06:34.736917 46942642291584 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplqhkazk4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1f81b0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.737323 46942642291584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.736921 47111564788608 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjneil8xe
W0618 12:06:34.737191 47447424516992 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp70pb2hya
I0618 12:06:34.738033 47111564788608 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjneil8xe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad94cabddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.738279 47447424516992 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp70pb2hya', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b277f787e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.738489 47111564788608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.738723 47447424516992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.740818 46962626429824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.742024 46942642291584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.743742 47111564788608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.743832 47447424516992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881194.651230 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.651928 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.652552 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.758783 48004326200192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.649653 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.650415 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.651222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.759013 48010900915072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.760070 46962626429824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.759951 48004326200192 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4rcwxtyo
W0618 12:06:34.760126 48010900915072 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0dnu82a5
I0618 12:06:34.761022 48004326200192 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4rcwxtyo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba92965ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.761226 48010900915072 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0dnu82a5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baab1481e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:34.761182 46942642291584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:06:34.761468 48004326200192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.761668 48010900915072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.765821 47111564788608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.765796 47447424516992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.766837 48004326200192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.767009 48010900915072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881194.656801 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.657645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.658522 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.776147 47167811392384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.663058 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.663769 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.664479 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.776293 47982539789184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.777175 47167811392384 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjpfom8vc
W0618 12:06:34.777281 47982539789184 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpzkv3ffkm
I0618 12:06:34.778166 47167811392384 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjpfom8vc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae6653aee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.778273 47982539789184 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpzkv3ffkm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba416d39e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.778565 47167811392384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.778672 47982539789184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.783450 47167811392384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.783488 47982539789184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881194.681518 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.682385 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.683219 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.785877 47451136746368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.691330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.692103 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.692807 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.786056 47528723297152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.682543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.683033 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.683434 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.786845 47561325118336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.684090 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.684558 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.684982 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.786878 47786114700160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.786983 47451136746368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpql11uix1
W0618 12:06:34.787117 47528723297152 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgqn_6rbn
I0618 12:06:34.788006 47451136746368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpql11uix1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b285cbcbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.788104 47528723297152 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgqn_6rbn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a6d418e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.788408 47451136746368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.788499 47528723297152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.788717 48004326200192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.787930 47561325118336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe3dbupff
W0618 12:06:34.787960 47786114700160 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpiuwj2a4n
I0618 12:06:34.788934 47561325118336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe3dbupff', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b420479bda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.788958 47786114700160 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpiuwj2a4n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b765afaada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:34.789369 48010900915072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:06:34.789328 47561325118336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.789362 47786114700160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.793099 47451136746368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.793122 47528723297152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.793924 47786114700160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.793941 47561325118336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881194.702793 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.703247 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.703652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.800716 47387309183872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.703329 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.703783 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.704187 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.800805 47140613096320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.802486 47167811392384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.801700 47387309183872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcpyxvxqy
W0618 12:06:34.801796 47140613096320 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7gi2e1or
I0618 12:06:34.802675 47387309183872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcpyxvxqy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1980516dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.802782 47140613096320 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7gi2e1or', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae01015ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.803078 47387309183872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.803186 47140613096320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.803190 47982539789184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.807643 47387309183872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.807733 47140613096320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.808076 46962626429824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.808594 46942642291584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.812364 47451136746368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.812413 47528723297152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.812401 46962626429824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:34.812919 46942642291584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:34.813152 47786114700160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.813253 47561325118336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.815423 47111564788608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.815630 47447424516992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:06:34.817517 46962626429824 estimator.py:1111] Calling model_fn.
W0618 12:06:34.817627 46962626429824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:34.818032 46942642291584 estimator.py:1111] Calling model_fn.
W0618 12:06:34.818144 46942642291584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:34.818999 46962626429824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:34.819499 46942642291584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:34.819712 47111564788608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:34.819933 47447424516992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881194.735206 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.735631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.736005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.820896 47215473271680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.735263 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.735684 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.736060 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.821322 47832480764800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
W0618 12:06:34.821914 47215473271680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy395flxf
I0618 12:06:34.822896 47215473271680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy395flxf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af17e196e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:34.822311 47832480764800 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpek1lkh6t
I0618 12:06:34.823285 47832480764800 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpek1lkh6t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81269cae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.823293 47215473271680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.823678 47832480764800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.824804 47111564788608 estimator.py:1111] Calling model_fn.
W0618 12:06:34.824913 47111564788608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:06:34.825027 47447424516992 estimator.py:1111] Calling model_fn.
W0618 12:06:34.825138 47447424516992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:34.826276 47111564788608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:34.826505 47447424516992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:34.826726 47140613096320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.826761 47387309183872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.827856 47215473271680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.828327 47832480764800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.838411 48004326200192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.838443 48010900915072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881194.748507 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.749025 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.749482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.838139 47577051272064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.747911 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.748427 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.748872 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.838414 47247701332864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.700453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.701347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.702170 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.839021 47130762044288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
:::MLL 1560881194.701417 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881194.702295 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881194.703024 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:06:34.839748 47893850362752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000023-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000014-000007.tfrecord.zz_0_0
I0618 12:06:34.839182 47577051272064 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b45add3ed68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:34.839405 47247701332864 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp90vur4qj
I0618 12:06:34.840288 47577051272064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.840386 47247701332864 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp90vur4qj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af8ff0aae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:06:34.840080 47130762044288 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwtgol3_s
I0618 12:06:34.840790 47247701332864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:06:34.841187 47130762044288 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwtgol3_s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2addc4eabe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.841624 47130762044288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.840978 47893850362752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprn0_1hnm
I0618 12:06:34.842035 47893850362752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprn0_1hnm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f70866e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:06:34.842435 47893850362752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:06:34.842718 48004326200192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:34.842758 48010900915072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:34.844971 47577051272064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.845412 47247701332864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.846372 47130762044288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.846998 47893850362752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:06:34.846839 47215473271680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:06:34.847471 47832480764800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:06:34.847790 48004326200192 estimator.py:1111] Calling model_fn.
I0618 12:06:34.847858 48010900915072 estimator.py:1111] Calling model_fn.
W0618 12:06:34.847907 48004326200192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:34.847967 48010900915072 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:34.849262 48004326200192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:34.849340 48010900915072 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:06:34.850229 47167811392384 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.851271 47982539789184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.854521 47167811392384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:06:34.855616 47982539789184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:06:34.859575 47167811392384 estimator.py:1111] Calling model_fn.
W0618 12:06:34.859685 47167811392384 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:06:34.859940 47451136746368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.860095 47528723297152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:06:34.860623 47786114700160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future ver[2019-06-18 12:07:12] iteration time 23: 48.072 seconds
2019-06-18 12:07:14.165972: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881232.859557 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:07:17] minmax time: 3.239 seconds
2019-06-18 12:07:17.415068: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:07:17.420609: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:07:17.425144: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881237.438770 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 23}}
[2019-06-18 12:07:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:07:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=25 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=1023779856 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=2047559687 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=3071339518 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=4095119349 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=5118899180 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=6142679011 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=7166458842 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=8190238673 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=9214018504 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=10237798335 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=11261578166 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=12285357997 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=13309137828 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=14332917659 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=15356697490 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=16380477321 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=17404257152 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=18428036983 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=19451816814 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000024-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000024-000015 --seed=20475596645 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:07:27] eval finished: 10.325 seconds
[2019-06-18 12:07:27] Win rate 000024-000015 vs 000022-000014: 0.380
:::MLL 1560881247.842211 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:07:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=26 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=1023779857 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=2047559688 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=3071339519 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=4095119350 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=5118899181 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=6142679012 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=7166458843 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=8190238674 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=9214018505 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=10237798336 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=11261578167 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=12285357998 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=13309137829 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=14332917660 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=15356697491 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=16380477322 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=17404257153 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000025-000014 --seed=18428036984 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:07:56] selfplay finished: 28.760 seconds
[2019-06-18 12:07:56] selfplay mn: 28.778 seconds
[2019-06-18 12:07:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-26-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=26 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779857 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559688 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339519 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119350 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899181 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679012 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458843 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238674 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018505 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798336 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578167 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357998 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137829 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917660 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697491 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477322 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257153 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036984 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816815 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596646 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376477 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156308 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000025-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:07:59] divide_golden_chunk finished: 3.366 seconds
[2019-06-18 12:08:00] generate golden chunk: 3.381 seconds
[2019-06-18 12:08:00] train finished: 43.337 seconds
:::MLL 1560881242.659298 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.660176 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.660991 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.769741 47305752687488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560881242.669383 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.670115 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.670791 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.769762 48010606674816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.770881 47305752687488 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0jhcrp2d
W0618 12:07:22.770947 48010606674816 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphr5une7p
I0618 12:07:22.771921 47305752687488 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0jhcrp2d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06832bfe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.771970 48010606674816 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphr5une7p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa9fbe4e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.772324 47305752687488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:22.772376 48010606674816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.777129 48010606674816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.777113 47305752687488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.796483 47305752687488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.796720 48010606674816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881242.737483 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.738029 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.738515 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.829232 47815595590528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560881242.718612 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.719531 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.720399 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.830218 47186625975168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560881242.725139 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.725885 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.726588 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.830603 47295455617920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.830265 47815595590528 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpredc1b3d
I0618 12:07:22.831306 47815595590528 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpredc1b3d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d382d5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.831728 47815595590528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.831330 47186625975168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpuq1c_4d1
I0618 12:07:22.832424 47186625975168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpuq1c_4d1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeac6aa8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:22.831695 47295455617920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpecohqfy0
I0618 12:07:22.832824 47295455617920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpecohqfy0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b041d6b2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.832872 47186625975168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:22.833271 47295455617920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.836742 47815595590528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.838109 47186625975168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.838415 47295455617920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881242.741547 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.742012 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.742416 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.839945 47931603239808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.840958 47931603239808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmps_h8106c
I0618 12:07:22.841973 47931603239808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmps_h8106c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b983ac59da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.842394 47931603239808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.845010 48010606674816 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.845008 47305752687488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.847005 47931603239808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.849336 48010606674816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.849341 47305752687488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:22.854384 48010606674816 estimator.py:1111] Calling model_fn.
I0618 12:07:22.854423 47305752687488 estimator.py:1111] Calling model_fn.
W0618 12:07:22.854492 48010606674816 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.854531 47305752687488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.855788 47815595590528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.855848 48010606674816 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.855907 47305752687488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.859761 47186625975168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.860174 47295455617920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881242.743448 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.744304 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.745152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.860290 47510227932032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560881242.756167 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.756933 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.757643 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.860349 46913375286144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.861426 47510227932032 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpq27k24dl
W0618 12:07:22.861457 46913375286144 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp626ezm3w
I0618 12:07:22.862429 47510227932032 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpq27k24dl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b361ed8ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.862464 46913375286144 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp626ezm3w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aab27a80e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.862829 47510227932032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:22.862872 46913375286144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.866083 47931603239808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.867728 47510227932032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.867751 46913375286144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881242.727267 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.728168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.729005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.868828 47790802903936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.869912 47790802903936 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpaq20y1zk
I0618 12:07:22.871026 47790802903936 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpaq20y1zk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77726afe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.871436 47790802903936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.876196 47790802903936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881242.732898 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.733616 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.734283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.877074 47015620187008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.878040 47015620187008 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdxu4wvcz
I0618 12:07:22.879031 47015620187008 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdxu4wvcz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2f5ed5e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.879459 47015620187008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.884164 47015620187008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.886990 47510227932032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.887093 46913375286144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881242.803029 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.803468 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.803826 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.889626 47471780729728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560881242.802132 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.802726 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.803151 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.889758 47499408257920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.890648 47471780729728 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6zuwf1j7
W0618 12:07:22.890720 47499408257920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpbez5sczs
I0618 12:07:22.891640 47471780729728 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6zuwf1j7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d2b36de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.891693 47499408257920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpbez5sczs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3399f16dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.892045 47471780729728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:07:22.892090 47499408257920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.895810 47790802903936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.896704 47499408257920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.896701 47471780729728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.902692 47815595590528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.903656 47015620187008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.906954 47815595590528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.910277 47295455617920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.910300 47186625975168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:07:22.911983 47815595590528 estimator.py:1111] Calling model_fn.
W0618 12:07:22.912092 47815595590528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.913294 47931603239808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.913450 47815595590528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.914666 47295455617920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.914724 47186625975168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.915616 47471780729728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.915785 47499408257920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.917621 47931603239808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:22.919769 47295455617920 estimator.py:1111] Calling model_fn.
W0618 12:07:22.919875 47295455617920 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:07:22.919861 47186625975168 estimator.py:1111] Calling model_fn.
W0618 12:07:22.919964 47186625975168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.921234 47295455617920 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.921324 47186625975168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:07:22.922708 47931603239808 estimator.py:1111] Calling model_fn.
W0618 12:07:22.922821 47931603239808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881242.837974 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.838434 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.838825 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.923292 47790821462912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
:::MLL 1560881242.832227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.832795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.833465 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.923303 47377954919296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.924182 47931603239808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.924391 47790821462912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe8g4twvf
W0618 12:07:22.924361 47377954919296 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpk3ocuy5c
I0618 12:07:22.925347 47377954919296 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpk3ocuy5c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1752c29e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.925373 47790821462912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe8g4twvf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7773861e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.925749 47377954919296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881242.803991 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.804582 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.805058 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.925299 47783068525440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 12:07:22.925785 47790821462912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881242.807976 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.808462 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.808874 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.926299 47513707844480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 12:07:22.926335 47783068525440 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75a569bcf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.927450 47783068525440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.927288 47513707844480 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm1bpgo8o
I0618 12:07:22.928279 47513707844480 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm1bpgo8o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b36ee43de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.928680 47513707844480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.930336 47377954919296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.930420 47790821462912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.932103 47783068525440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.933259 47513707844480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.935134 47510227932032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.935258 46913375286144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.939436 47510227932032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.939575 46913375286144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.944105 47790802903936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:07:22.944469 47510227932032 estimator.py:1111] Calling model_fn.
W0618 12:07:22.944575 47510227932032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:07:22.944675 46913375286144 estimator.py:1111] Calling model_fn.
W0618 12:07:22.944791 46913375286144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.945932 47510227932032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.946152 46913375286144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.948422 47790802903936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:07:22.949224 47377954919296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.949559 47790821462912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.950977 47783068525440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:07:22.951277 47015620187008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:07:22.952376 47513707844480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881242.750543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.751353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.752025 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.953417 47523411862400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
I0618 12:07:22.953527 47790802903936 estimator.py:1111] Calling model_fn.
:::MLL 1560881242.753939 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881242.754669 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881242.755333 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:07:22.953838 47844417643392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000024-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000015-000008.tfrecord.zz_0_0
W0618 12:07:22.953643 47790802903936 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.954500 47523411862400 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpo17t2y_u
W0618 12:07:22.955027 47790802903936 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:07:22.955561 47523411862400 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpo17t2y_u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3930ab7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:07:22.954835 47844417643392 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5qkj25j4
I0618 12:07:22.955904 47844417643392 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5qkj25j4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83ee1aee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:07:22.956002 47523411862400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.955588 47015620187008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:07:22.956326 47844417643392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:07:22.960782 47523411862400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:07:22.960888 47844417643392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:07:22.960631 47015620187008 estimator.py:1111] Calling model_fn.
W0618 12:07:22.960744 47015620187008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:07:22.962090 47015620187008 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:07:22.963193 47499408257920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy([2019-06-18 12:08:00] iteration time 24: 47.937 seconds
2019-06-18 12:08:02.155138: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881280.797156 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:08:05] minmax time: 3.240 seconds
2019-06-18 12:08:05.405256: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:08:05.410646: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:08:05.415104: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881285.428906 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 24}}
[2019-06-18 12:08:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000026-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:08:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=26 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=1023779857 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=2047559688 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=3071339519 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=4095119350 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=5118899181 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=6142679012 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=7166458843 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=8190238674 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=9214018505 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=10237798336 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=11261578167 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=12285357998 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=13309137829 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=14332917660 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=15356697491 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=16380477322 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=17404257153 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=18428036984 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=19451816815 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000022-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000025-000015 --seed=20475596646 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:08:16] eval finished: 10.833 seconds
[2019-06-18 12:08:16] Win rate 000025-000015 vs 000022-000014: 0.600
:::MLL 1560881296.340338 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:08:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=27 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=1023779858 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=2047559689 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=3071339520 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=4095119351 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=5118899182 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=6142679013 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=7166458844 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=8190238675 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=9214018506 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=10237798337 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=11261578168 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=12285357999 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=13309137830 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=14332917661 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=15356697492 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=16380477323 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=17404257154 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000026-000014 --seed=18428036985 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:08:46] selfplay finished: 30.072 seconds
[2019-06-18 12:08:46] selfplay mn: 30.090 seconds
[2019-06-18 12:08:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-27-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=27 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779858 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559689 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339520 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119351 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899182 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679013 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458844 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238675 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018506 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798337 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578168 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285357999 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137830 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917661 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697492 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477323 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257154 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036985 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816816 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596647 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376478 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156309 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000026-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:08:49] train finished: 43.933 seconds
:::MLL 1560881290.694237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.694955 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.695634 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.805831 47674789397376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.689176 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.690050 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.690885 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.805967 47520803242880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.806933 47520803242880 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnz0wbzdi
W0618 12:08:10.806893 47674789397376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpsenyk4xu
I0618 12:08:10.807884 47674789397376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpsenyk4xu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c6f795e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.807913 47520803242880 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnz0wbzdi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38952f1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.808295 47674789397376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.808312 47520803242880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.813196 47520803242880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.813257 47674789397376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.832373 47520803242880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.832875 47674789397376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881290.711753 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.712518 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.713251 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.845446 47348606608256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.713814 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.714541 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.715234 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.845805 47078708409216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.846600 47348606608256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjllrzx95
W0618 12:08:10.846865 47078708409216 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp19828ka7
I0618 12:08:10.847680 47348606608256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjllrzx95', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b107d76de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.847921 47078708409216 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp19828ka7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1a6473dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.848163 47348606608256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.848360 47078708409216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.853281 47348606608256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.853305 47078708409216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881290.753277 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.753997 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.754657 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.858992 47438878827392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.745718 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.746583 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.747435 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.858929 47823727526784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.690008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.690856 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.691671 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.859493 47394743034752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.860013 47823727526784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp84cctwq2
W0618 12:08:10.860047 47438878827392 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6pwjhbdi
I0618 12:08:10.861010 47823727526784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp84cctwq2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7f1ce0be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.861043 47438878827392 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6pwjhbdi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25821bae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.861411 47823727526784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.861449 47438878827392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.860660 47394743034752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5qwrwb15
I0618 12:08:10.861768 47394743034752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5qwrwb15', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b3b68eda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.862178 47394743034752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.866688 47438878827392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.866765 47823727526784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.866993 47394743034752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881290.781223 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.781671 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.782046 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.871659 46999242056576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.773852 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.774445 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.774962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.871693 47309082186624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
I0618 12:08:10.872717 46999242056576 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf25b6ed68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:10.872732 47309082186624 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpahfg50n3
I0618 12:08:10.873704 47309082186624 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpahfg50n3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0749a02e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.873851 46999242056576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.874099 47309082186624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.874341 47078708409216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.874374 47348606608256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881290.698381 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.699132 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.699821 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.875726 47952600077184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.757266 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.758118 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.758896 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.877148 47086536405888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.876744 47952600077184 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpc6_dm0dd
:::MLL 1560881290.762091 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.762846 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.763553 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.877691 47551552054144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
I0618 12:08:10.877861 47952600077184 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpc6_dm0dd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9d1e47de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.878316 47952600077184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.878187 47086536405888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprnhrt_dl
W0618 12:08:10.878578 46999242056576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.878709 47309082186624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:08:10.879169 47086536405888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprnhrt_dl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad378dd0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:10.878725 47551552054144 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpuwtk7pbe
I0618 12:08:10.879569 47086536405888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.879720 47551552054144 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpuwtk7pbe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3fbdf48e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.880125 47551552054144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.880557 47520803242880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:10.880993 47674789397376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:10.882948 47952600077184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.884729 47086536405888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.885027 47551552054144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.884854 47520803242880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:10.885303 47674789397376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:10.886250 47823727526784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.886324 47438878827392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.886794 47394743034752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:10.889931 47520803242880 estimator.py:1111] Calling model_fn.
W0618 12:08:10.890038 47520803242880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:10.890371 47674789397376 estimator.py:1111] Calling model_fn.
W0618 12:08:10.890478 47674789397376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:10.891404 47520803242880 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:10.891823 47674789397376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:10.897597 46999242056576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.897818 47309082186624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881290.794653 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.795101 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.795507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.899012 47746932257664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.794812 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.795280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.795679 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.899119 47765632889728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.900043 47746932257664 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_v3sqzpr
W0618 12:08:10.900106 47765632889728 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpynctxc8w
I0618 12:08:10.901029 47746932257664 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_v3sqzpr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d3b860e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.901084 47765632889728 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpynctxc8w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b71962b0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.901437 47746932257664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.901479 47765632889728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.902482 47952600077184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.904290 47086536405888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.904624 47551552054144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.906134 47746932257664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.906140 47765632889728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881290.755939 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.756427 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.756871 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.911247 47122930307968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.757949 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.758435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.758860 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.912487 46980649763712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.912287 47122930307968 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxl0fc7yy
I0618 12:08:10.913282 47122930307968 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxl0fc7yy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbf21bee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.913682 47122930307968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.913483 46980649763712 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoqwgjgw4
I0618 12:08:10.914453 46980649763712 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoqwgjgw4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abad186ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.914856 46980649763712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.918373 47122930307968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.919439 46980649763712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.922640 47078708409216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:10.923264 47348606608256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:10.925052 47765632889728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.925035 47746932257664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.926927 47078708409216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:10.927641 47348606608256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881290.841135 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.841553 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.841908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.929305 47234988303232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.842596 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.843005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.843352 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.929500 47227868304256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.930461 47234988303232 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdb_1pelu
W0618 12:08:10.930628 47227868304256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp50j2j710
I0618 12:08:10.931511 47234988303232 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdb_1pelu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af609493e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.931664 47227868304256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp50j2j710', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af460e6ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.931939 47234988303232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.932097 47227868304256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.931963 47078708409216 estimator.py:1111] Calling model_fn.
W0618 12:08:10.932077 47078708409216 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:10.932742 47348606608256 estimator.py:1111] Calling model_fn.
W0618 12:08:10.932850 47348606608256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:10.933450 47078708409216 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:10.934435 47823727526784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:10.934214 47348606608256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:10.934890 47438878827392 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:10.934626 47394743034752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881290.753287 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.754195 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.754915 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.936407 46924039938944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.757148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.757850 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.758507 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.936607 47469205128064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.936922 47234988303232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.937019 47227868304256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.937453 47122930307968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:10.937476 46924039938944 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpu1vcwy8x
W0618 12:08:10.937647 47469205128064 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpblgwo537
I0618 12:08:10.938534 46924039938944 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpu1vcwy8x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aada351be10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:10.938732 47823727526784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:10.938474 46980649763712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:08:10.938709 47469205128064 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpblgwo537', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c91b24e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.938974 46924039938944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:10.939229 47438878827392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:10.938962 47394743034752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:10.939152 47469205128064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881290.840097 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.840592 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.841009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.939401 47531105112960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560881290.841648 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881290.842147 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881290.842578 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:10.939638 48007723025280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000025-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:08:10.940486 47531105112960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjzz8452_
W0618 12:08:10.940713 48007723025280 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpf05j_rzk
I0618 12:08:10.941523 47531105112960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjzz8452_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3afb392e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.941745 48007723025280 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpf05j_rzk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba9f3dd5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:10.941952 47531105112960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.942166 48007723025280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:10.943791 47823727526784 estimator.py:1111] Calling model_fn.
W0618 12:08:10.943905 47823727526784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:10.944306 47438878827392 estimator.py:1111] Calling model_fn.
W0618 12:08:10.944415 47438878827392 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:10.944090 47394743034752 estimator.py:1111] Calling model_fn.
W0618 12:08:10.944186 46924039938944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.944199 47394743034752 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:10.944344 47469205128064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:10.945264 47823727526784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:10.944909 46999242056576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options availabl[2019-06-18 12:08:49] divide_golden_chunk finished: 3.421 seconds
[2019-06-18 12:08:49] generate golden chunk: 3.434 seconds
[2019-06-18 12:08:49] moving /lfs/lfs12/gma_akey/results/epb309/models/000026-000015.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000026-000016.data-00000-of-00001
[2019-06-18 12:08:49] moving /lfs/lfs12/gma_akey/results/epb309/models/000026-000015.index --> /lfs/lfs12/gma_akey/results/epb309/models/000026-000016.index
[2019-06-18 12:08:49] moving /lfs/lfs12/gma_akey/results/epb309/models/000026-000015.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000026-000016.meta
[2019-06-18 12:08:49] moving /lfs/lfs12/gma_akey/results/epb309/models/000026-000015.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb
[2019-06-18 12:08:49] iteration time 25: 49.110 seconds
2019-06-18 12:08:51.316158: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881329.906808 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:08:54] minmax time: 3.216 seconds
2019-06-18 12:08:54.542017: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:08:54.547493: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:08:54.552079: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881334.564220 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 25}}
[2019-06-18 12:08:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:08:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=27 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=1023779858 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=2047559689 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=3071339520 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=4095119351 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=5118899182 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=6142679013 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=7166458844 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=8190238675 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=9214018506 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=10237798337 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=11261578168 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=12285357999 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=13309137830 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=14332917661 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=15356697492 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=16380477323 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=17404257154 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=18428036985 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=19451816816 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000025-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000026-000016 --seed=20475596647 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:09:05] eval finished: 10.662 seconds
[2019-06-18 12:09:05] Win rate 000026-000016 vs 000025-000015: 0.520
:::MLL 1560881345.304884 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:09:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=28 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=1023779859 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=2047559690 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=3071339521 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=4095119352 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=5118899183 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=6142679014 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=7166458845 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=8190238676 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=9214018507 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=10237798338 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=11261578169 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=12285358000 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=13309137831 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=14332917662 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=15356697493 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=16380477324 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=17404257155 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000027-000015 --seed=18428036986 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:09:34] selfplay finished: 28.764 seconds
[2019-06-18 12:09:34] selfplay mn: 28.781 seconds
[2019-06-18 12:09:34] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-28-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=28 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779859 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559690 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339521 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119352 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899183 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679014 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458845 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238676 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018507 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798338 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578169 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285358000 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137831 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917662 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697493 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477324 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257155 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036986 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816817 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596648 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376479 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156310 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:09:37] divide_golden_chunk finished: 3.335 seconds
[2019-06-18 12:09:37] generate golden chunk: 3.349 seconds
[2019-06-18 12:09:38] train finished: 43.522 seconds
:::MLL 1560881339.775191 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.776064 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.776876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.892615 47159119504256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560881339.786211 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.786895 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.787475 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.892964 46920227951488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.893648 47159119504256 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp7bvgptf8
I0618 12:08:59.894732 47159119504256 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp7bvgptf8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae45f273e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:08:59.893947 46920227951488 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpvn2cgt47
I0618 12:08:59.895052 46920227951488 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpvn2cgt47', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aacc01b5e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.895175 47159119504256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:59.895499 46920227951488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:59.900349 47159119504256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:59.900455 46920227951488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881339.796496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.797407 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.798240 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.902463 46964459352960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.903589 46964459352960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpex6hmyog
I0618 12:08:59.904700 46964459352960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpex6hmyog', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab70c810e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.905185 46964459352960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:59.910597 46964459352960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:59.919818 46920227951488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:59.920164 47159119504256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:59.932825 46964459352960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881339.846010 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.846851 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.847645 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.935432 47307201356672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.936546 47307201356672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoxx7pi9w
I0618 12:08:59.937638 47307201356672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoxx7pi9w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b06d984fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.938081 47307201356672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:59.943294 47307201356672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881339.858141 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.858859 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.859558 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.955828 47177016288128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560881339.839980 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.840942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.841772 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.955866 47518281851776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.956870 47177016288128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpi1chkl8a
W0618 12:08:59.956911 47518281851776 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmppuziez78
I0618 12:08:59.957876 47177016288128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpi1chkl8a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae889e26e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.957896 47518281851776 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmppuziez78', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37fee5ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.958278 47177016288128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:59.958298 47518281851776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:59.963329 47518281851776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:59.963344 47177016288128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:08:59.965314 47307201356672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:59.968927 46920227951488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:59.969508 47159119504256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:59.973462 46920227951488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:08:59.974097 47159119504256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:08:59.978789 46920227951488 estimator.py:1111] Calling model_fn.
W0618 12:08:59.978902 46920227951488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:08:59.979409 47159119504256 estimator.py:1111] Calling model_fn.
W0618 12:08:59.979518 47159119504256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:59.980265 46920227951488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:59.980945 47159119504256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:59.982848 47177016288128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:08:59.982843 47518281851776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881339.886014 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.886424 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.886870 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.985519 47522658120576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.987132 46964459352960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:08:59.986602 47522658120576 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjelkrfii
I0618 12:08:59.987640 47522658120576 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjelkrfii', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3903be4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.988070 47522658120576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:59.992081 46964459352960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881339.902277 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.902781 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.903244 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.992430 47566393467776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.993082 47522658120576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881339.887799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.888555 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.889213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.993577 47356603966336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560881339.877379 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.878287 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.879150 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:08:59.993577 47645028615040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:08:59.993483 47566393467776 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxlce5ycw
I0618 12:08:59.994525 47566393467776 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxlce5ycw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b433292be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.994949 47566393467776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:08:59.994728 47645028615040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpj15v0fnu
W0618 12:08:59.994761 47356603966336 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpg4x94rot
I0618 12:08:59.995837 47645028615040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpj15v0fnu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b558197de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.995916 47356603966336 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpg4x94rot', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b125a24fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:08:59.996303 47645028615040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:59.996564 47356603966336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:08:59.997655 46964459352960 estimator.py:1111] Calling model_fn.
W0618 12:08:59.997791 46964459352960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:08:59.999381 46964459352960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:08:59.999912 47566393467776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.001567 47645028615040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881339.887178 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.887588 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.887936 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.001245 47487833707392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.001891 47356603966336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:09:00.002484 47487833707392 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30e80becf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.003977 47487833707392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881339.909638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.910021 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.910355 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.004189 47192745853824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.005157 47192745853824 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm0_pprel
I0618 12:09:00.006139 47192745853824 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm0_pprel', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec33709e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.006543 47192745853824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:00.009582 47487833707392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.011111 47192745853824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.012531 47522658120576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.017455 47307201356672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:00.018979 47566393467776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881339.913279 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.913814 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.914481 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.018992 47501406106496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560881339.918050 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.918526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.918952 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.019328 47014944678784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.020029 47501406106496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcmyku169
W0618 12:09:00.020309 47014944678784 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcjjur1fp
I0618 12:09:00.021017 47501406106496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcmyku169', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3411064e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.021279 47014944678784 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcjjur1fp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2cda9fe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881339.882013 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.882954 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.883806 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.021281 47067492316032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
I0618 12:09:00.021414 47501406106496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:00.021669 47014944678784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:00.021992 47307201356672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:00.022328 47067492316032 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpc5ihb01a
W0618 12:09:00.023209 47645028615040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:00.023332 47067492316032 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpc5ihb01a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf09bf4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.023732 47067492316032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:00.024054 47356603966336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.026095 47501406106496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.026228 47014944678784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:09:00.027291 47307201356672 estimator.py:1111] Calling model_fn.
W0618 12:09:00.027435 47307201356672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881339.891916 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.892666 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.893314 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.027904 47889875780480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.028828 47067492316032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.028890 47307201356672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:00.028883 47889875780480 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcrfpz1p7
I0618 12:09:00.029877 47889875780480 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcrfpz1p7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e839f0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.030283 47889875780480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881339.896258 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.897152 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.897946 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.030217 47672461493120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.030188 47192745853824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881339.908573 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.909311 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.910023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.031308 46999133279104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.031255 47518281851776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:00.031258 47672461493120 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2nk4jxfi
I0618 12:09:00.032245 47672461493120 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2nk4jxfi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5be4b85e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:00.031954 47177016288128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:09:00.032638 47672461493120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:00.032320 46999133279104 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4o93od9d
I0618 12:09:00.033313 46999133279104 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4o93od9d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf1f3b1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.033711 46999133279104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:00.034978 47889875780480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.035541 47518281851776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:00.035801 47487833707392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.036308 47177016288128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:00.037419 47672461493120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.038479 46999133279104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:09:00.040590 47518281851776 estimator.py:1111] Calling model_fn.
W0618 12:09:00.040699 47518281851776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:00.041419 47177016288128 estimator.py:1111] Calling model_fn.
W0618 12:09:00.041530 47177016288128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:00.042060 47518281851776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:00.042911 47177016288128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:00.045150 47501406106496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.045246 47014944678784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.048396 47067492316032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.054431 47889875780480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881339.962490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.962914 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.963294 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.055774 47227253515136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560881339.959713 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881339.960215 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881339.960596 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:00.055851 47129737528192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000026-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:09:00.056445 47672461493120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.056802 47227253515136 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpoisaq6ts
W0618 12:09:00.056870 47129737528192 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4zl1bs74
I0618 12:09:00.057781 47227253515136 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpoisaq6ts', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af43c41ae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.057855 47129737528192 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4zl1bs74', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add87d9dda0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:00.058188 47227253515136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:00.058264 47129737528192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:00.059151 46999133279104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:00.059927 47522658120576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:00.062853 47227253515136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.062943 47129737528192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:00.064244 47522658120576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:00.065919 47566393467776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:09:00.069354 47522658120576 estimator.py:1111] Calling model_fn.
W0618 12:09:00.069463 47522658120576 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:00.070200 47566393467776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:00.070846 47522658120576 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:00.072588 47645028615040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can u[2019-06-18 12:09:38] moving /lfs/lfs12/gma_akey/results/epb309/models/000027-000016.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000027-000017.data-00000-of-00001
[2019-06-18 12:09:38] moving /lfs/lfs12/gma_akey/results/epb309/models/000027-000016.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000027-000017.meta
[2019-06-18 12:09:38] moving /lfs/lfs12/gma_akey/results/epb309/models/000027-000016.index --> /lfs/lfs12/gma_akey/results/epb309/models/000027-000017.index
[2019-06-18 12:09:38] moving /lfs/lfs12/gma_akey/results/epb309/models/000027-000016.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb
[2019-06-18 12:09:38] iteration time 26: 48.242 seconds
2019-06-18 12:09:39.577996: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881378.148563 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:09:42] minmax time: 3.276 seconds
2019-06-18 12:09:42.864319: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:09:42.869751: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:09:42.874326: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881382.886291 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 26}}
[2019-06-18 12:09:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:09:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=28 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=1023779859 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=2047559690 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=3071339521 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=4095119352 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=5118899183 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=6142679014 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=7166458845 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=8190238676 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=9214018507 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=10237798338 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=11261578169 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=12285358000 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=13309137831 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=14332917662 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=15356697493 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=16380477324 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=17404257155 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=18428036986 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=19451816817 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000027-000017 --seed=20475596648 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:09:54] eval finished: 12.026 seconds
[2019-06-18 12:09:54] Win rate 000027-000017 vs 000026-000016: 0.660
:::MLL 1560881394.990841 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:09:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=29 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=1023779860 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=2047559691 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=3071339522 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=4095119353 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=5118899184 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=6142679015 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=7166458846 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=8190238677 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=9214018508 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=10237798339 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=11261578170 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=12285358001 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=13309137832 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=14332917663 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=15356697494 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=16380477325 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=17404257156 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000028-000016 --seed=18428036987 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:10:23] selfplay finished: 28.655 seconds
[2019-06-18 12:10:23] selfplay mn: 28.672 seconds
[2019-06-18 12:10:23] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-29-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=29 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779860 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559691 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339522 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119353 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899184 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679015 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458846 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238677 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018508 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798339 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578170 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285358001 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137832 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917663 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697494 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477325 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257156 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036987 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816818 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596649 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376480 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156311 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:10:26] train finished: 43.386 seconds
:::MLL 1560881388.135884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.136645 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.137326 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.259083 47477458076544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.139131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.139858 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.140524 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.259656 47980308882304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.260116 47477458076544 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_nkb_uzp
I0618 12:09:48.261109 47477458076544 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_nkb_uzp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2e7d9c4e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:48.260649 47980308882304 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2qwo66rw
I0618 12:09:48.261509 47477458076544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.261644 47980308882304 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2qwo66rw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba391dabe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.262040 47980308882304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.266464 47477458076544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.266877 47980308882304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.285899 47477458076544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.286221 47980308882304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.334416 47477458076544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:48.334611 47980308882304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881388.227536 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.228049 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.228554 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.338126 47034092118912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.228508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.228978 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.229383 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.338388 47617357632384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.338716 47477458076544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:48.338912 47980308882304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:09:48.339151 47034092118912 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac742f0bd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:48.339389 47617357632384 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpn3v5aszj
I0618 12:09:48.340266 47034092118912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.340357 47617357632384 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpn3v5aszj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f10461e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.340754 47617357632384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.343765 47477458076544 estimator.py:1111] Calling model_fn.
W0618 12:09:48.343877 47477458076544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:09:48.343959 47980308882304 estimator.py:1111] Calling model_fn.
W0618 12:09:48.344068 47980308882304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:48.344927 47034092118912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881388.190192 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.191094 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.191945 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.344984 47127648027520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.345246 47477458076544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:48.345280 47617357632384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.345431 47980308882304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:48.346042 47127648027520 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6_ppm0wt
I0618 12:09:48.347135 47127648027520 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6_ppm0wt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add0b4e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.347564 47127648027520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.352571 47127648027520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881388.246003 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.246918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.247788 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.358274 47500121088896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.255781 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.256475 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.257173 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.358545 47871693349760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.359350 47500121088896 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0udjljur
W0618 12:09:48.359580 47871693349760 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwtqe1dey
I0618 12:09:48.360353 47500121088896 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0udjljur', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b33c46e7e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.360574 47871693349760 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwtqe1dey', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a47dd3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.360759 47500121088896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.360989 47871693349760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.363893 47034092118912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.364368 47617357632384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.365526 47500121088896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.365619 47871693349760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881388.197647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.198409 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.199100 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.365248 47382029796224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.366251 47382029796224 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmx_8hz5x
I0618 12:09:48.367226 47382029796224 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmx_8hz5x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1845a45e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.367628 47382029796224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881388.194909 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.195688 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.196450 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.367442 47394378605440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.368556 47394378605440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpl1j04oj_
I0618 12:09:48.369668 47394378605440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpl1j04oj_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b25b02e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.370129 47394378605440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.372258 47127648027520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.372308 47382029796224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881388.196723 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.197580 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.198403 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.373947 47549424472960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.374994 47549424472960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpay462k46
W0618 12:09:48.375458 47394378605440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:09:48.376086 47549424472960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpay462k46', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3f3f246e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.376540 47549424472960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881388.196810 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.197561 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.198244 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.379186 47533150528384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.202564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.203344 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.204060 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.380329 47421090059136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.380298 47533150528384 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpj_e7in3j
W0618 12:09:48.381414 47549424472960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:09:48.381410 47533150528384 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpj_e7in3j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b7523be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:48.381314 47421090059136 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp22jphdq3
I0618 12:09:48.381859 47533150528384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.382308 47421090059136 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp22jphdq3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b215dd09e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.382715 47421090059136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.384634 47500121088896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.384895 47871693349760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.387272 47533150528384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.387587 47421090059136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.391754 47382029796224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.397482 47394378605440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881388.225401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.226269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.227085 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.397971 47468875084672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.234932 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.235627 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.236310 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.398190 47532254110592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.399133 47468875084672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3l2rn6p7
W0618 12:09:48.399298 47532254110592 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3gwg3jmk
I0618 12:09:48.400238 47468875084672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3l2rn6p7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2c7e064e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.400421 47532254110592 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3gwg3jmk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b3fb57e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.400676 47468875084672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.400885 47532254110592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.401013 47549424472960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.405983 47468875084672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.406171 47532254110592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881388.256883 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.257439 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.257930 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.406352 47587476882304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.267416 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.267881 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.268279 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.407075 47662042956672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.407388 47421090059136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.407373 47587476882304 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmfcdvhy3
I0618 12:09:48.408371 47587476882304 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmfcdvhy3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b481b3e1e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:48.408062 47662042956672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp89x705ns
I0618 12:09:48.408778 47587476882304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.409037 47662042956672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp89x705ns', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5977ba0e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:48.409054 47533150528384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:09:48.409436 47662042956672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.411218 47034092118912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:48.411485 47617357632384 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:48.413465 47587476882304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.414048 47662042956672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.415549 47034092118912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:48.415770 47617357632384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881388.274903 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.275378 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.275747 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.420331 47408373945216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
I0618 12:09:48.420613 47034092118912 estimator.py:1111] Calling model_fn.
W0618 12:09:48.420722 47034092118912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881388.276543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.276957 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.277325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.420718 47260011934592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
I0618 12:09:48.420831 47617357632384 estimator.py:1111] Calling model_fn.
W0618 12:09:48.420876 47127648027520 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:48.420939 47617357632384 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:48.421353 47408373945216 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpqogo_1lb
W0618 12:09:48.422076 47034092118912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:09:48.422303 47617357632384 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:09:48.422344 47408373945216 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpqogo_1lb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e67e02e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:09:48.421687 47260011934592 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1bb_i_tv
I0618 12:09:48.422656 47260011934592 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1bb_i_tv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afbdccf7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.422750 47408373945216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.423056 47260011934592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.425209 47127648027520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881388.277092 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.277673 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.278162 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.426483 47221587194752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.284570 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.285071 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.285495 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.426553 47806147376000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.426814 47468875084672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.427293 47532254110592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.427372 47408373945216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.427651 47260011934592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.427512 47221587194752 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2owtatd2
W0618 12:09:48.427567 47806147376000 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpobf00jb4
I0618 12:09:48.428486 47221587194752 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2owtatd2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af2ea848e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.428554 47806147376000 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpobf00jb4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b0504de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.428887 47221587194752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.428957 47806147376000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.430292 47127648027520 estimator.py:1111] Calling model_fn.
W0618 12:09:48.430399 47127648027520 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:09:48.431753 47127648027520 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560881388.339231 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.339710 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.340251 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.431996 47773130388352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.339180 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.339664 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.340183 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.432111 47168177333120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:09:48.432501 47500121088896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:48.432501 47587476882304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.433010 47871693349760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:09:48.433515 47221587194752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.433327 47662042956672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:09:48.433603 47806147376000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:09:48.433009 47773130388352 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5g_jb7we
W0618 12:09:48.433087 47168177333120 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprna4nvxy
I0618 12:09:48.434004 47773130388352 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5g_jb7we', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b73550dce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.434051 47168177333120 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprna4nvxy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae67b0abe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:09:48.434398 47773130388352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:09:48.434439 47168177333120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:09:48.436815 47500121088896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:09:48.437286 47871693349760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881388.290431 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.290880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.291257 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.437209 47117757694848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560881388.287747 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881388.288501 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881388.288953 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:09:48.437796 47655459447680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/resul[2019-06-18 12:10:26] divide_golden_chunk finished: 3.238 seconds
[2019-06-18 12:10:26] generate golden chunk: 3.252 seconds
[2019-06-18 12:10:26] moving /lfs/lfs12/gma_akey/results/epb309/models/000028-000017.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000028-000018.data-00000-of-00001
[2019-06-18 12:10:26] moving /lfs/lfs12/gma_akey/results/epb309/models/000028-000017.index --> /lfs/lfs12/gma_akey/results/epb309/models/000028-000018.index
[2019-06-18 12:10:26] moving /lfs/lfs12/gma_akey/results/epb309/models/000028-000017.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000028-000018.meta
[2019-06-18 12:10:26] moving /lfs/lfs12/gma_akey/results/epb309/models/000028-000017.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb
[2019-06-18 12:10:26] iteration time 27: 48.813 seconds
2019-06-18 12:10:28.438668: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881426.961631 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:10:31] minmax time: 3.255 seconds
2019-06-18 12:10:31.703812: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:10:31.709366: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:10:31.714021: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881431.726382 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 27}}
[2019-06-18 12:10:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000029-000018 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:10:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=29 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=1023779860 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=2047559691 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=3071339522 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=4095119353 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=5118899184 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=6142679015 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=7166458846 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=8190238677 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=9214018508 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=10237798339 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=11261578170 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=12285358001 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=13309137832 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=14332917663 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=15356697494 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=16380477325 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=17404257156 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=18428036987 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=19451816818 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000027-000017.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000028-000018 --seed=20475596649 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:10:42] eval finished: 10.706 seconds
[2019-06-18 12:10:42] Win rate 000028-000018 vs 000027-000017: 0.660
:::MLL 1560881442.511535 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:10:42] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=30 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=1023779861 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=2047559692 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=3071339523 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=4095119354 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=5118899185 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=6142679016 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=7166458847 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=8190238678 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=9214018509 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=10237798340 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=11261578171 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=12285358002 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=13309137833 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=14332917664 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=15356697495 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=16380477326 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=17404257157 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000029-000017 --seed=18428036988 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:11:12] selfplay finished: 30.006 seconds
[2019-06-18 12:11:12] selfplay mn: 30.024 seconds
[2019-06-18 12:11:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-30-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=30 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779861 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559692 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339523 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119354 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899185 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679016 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458847 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238678 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018509 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798340 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578171 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285358002 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137833 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917664 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697495 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477326 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257157 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036988 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816819 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596650 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376481 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156312 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000029-000017/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:11:15] train finished: 43.389 seconds
:::MLL 1560881436.949051 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881436.949764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881436.950428 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.068394 47198918349696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881436.943479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881436.944354 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881436.945191 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.068365 47881572938624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.069458 47881572938624 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpcmpn3uka
W0618 12:10:37.069488 47198918349696 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3spwp8hu
I0618 12:10:37.070515 47198918349696 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3spwp8hu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeda3595e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.070516 47881572938624 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpcmpn3uka', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8c94bbce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.070926 47198918349696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.070930 47881572938624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.075943 47198918349696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.075959 47881572938624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.095138 47198918349696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.095409 47881572938624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881436.982255 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881436.982985 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881436.983685 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.103860 47291868685184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881436.984991 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881436.985736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881436.986398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.105547 47765062198144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.105000 47291868685184 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphbeektey
I0618 12:10:37.106163 47291868685184 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphbeektey', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03479efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.106619 47291868685184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.106650 47765062198144 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4a1exp2g
I0618 12:10:37.107748 47765062198144 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4a1exp2g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b717426fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.108196 47765062198144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.111979 47291868685184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.113291 47765062198144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.133938 47291868685184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.135174 47765062198144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.143326 47198918349696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:37.143532 47881572938624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881437.035198 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.035722 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.036168 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.147556 47768081376128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.147646 47198918349696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:37.147851 47881572938624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881437.036657 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.037116 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.037536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.147819 47845446558592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
I0618 12:10:37.148617 47768081376128 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b72281bfd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:37.148819 47845446558592 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_jopjghl
I0618 12:10:37.149725 47768081376128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.149802 47845446558592 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_jopjghl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b842b6efe10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.150196 47845446558592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.152763 47198918349696 estimator.py:1111] Calling model_fn.
W0618 12:10:37.152875 47198918349696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:10:37.152930 47881572938624 estimator.py:1111] Calling model_fn.
W0618 12:10:37.153038 47881572938624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:37.154245 47198918349696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:37.154359 47768081376128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.154413 47881572938624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:37.154691 47845446558592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881436.989292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881436.990239 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881436.991098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.158185 47760067609472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.159374 47760067609472 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwkkkp2_z
I0618 12:10:37.160501 47760067609472 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwkkkp2_z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b704a739e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.160968 47760067609472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.166393 47760067609472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881436.999354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.000108 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.000822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.168710 47392957784960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881437.039197 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.039941 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.040671 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.168723 47976137532288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881437.029237 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.030129 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.031005 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.169190 47857571402624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.169765 47976137532288 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4lkri_sy
W0618 12:10:37.169810 47392957784960 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpkv5rndad
I0618 12:10:37.170775 47976137532288 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4lkri_sy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba29938fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881437.061749 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.062342 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.062812 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.170337 47694515639168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.170190 47857571402624 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3ptbswq8
I0618 12:10:37.170897 47392957784960 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpkv5rndad', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ad1003e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560881437.064077 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.064497 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.064859 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.170570 47209024570240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
I0618 12:10:37.171180 47976137532288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.171205 47857571402624 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3ptbswq8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86fe216e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.171334 47392957784960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.171622 47857571402624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.171369 47694515639168 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2dua3yek
W0618 12:10:37.171551 47209024570240 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp2ppmucqw
I0618 12:10:37.172355 47694515639168 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2dua3yek', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61073fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.172523 47209024570240 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp2ppmucqw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeffdba1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.172749 47694515639168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.172918 47209024570240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.173528 47768081376128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.173951 47845446558592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.176117 47976137532288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881437.058521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.059230 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.059917 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.176256 47684480750464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881437.054684 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.055604 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.056301 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.176446 47064613229440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.176618 47857571402624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.176532 47392957784960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.177376 47694515639168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.177443 47209024570240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.177353 47684480750464 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprmopu9f7
W0618 12:10:37.177473 47064613229440 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpm72mjlpu
I0618 12:10:37.178370 47684480750464 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprmopu9f7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5eb11fae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.178480 47064613229440 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpm72mjlpu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace5e23ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.178779 47684480750464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.178890 47064613229440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.183644 47064613229440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.183659 47684480750464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.184057 47291868685184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:37.184633 47765062198144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:37.188228 47760067609472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.188408 47291868685184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:10:37.188971 47765062198144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:37.193514 47291868685184 estimator.py:1111] Calling model_fn.
W0618 12:10:37.193624 47291868685184 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:10:37.194116 47765062198144 estimator.py:1111] Calling model_fn.
W0618 12:10:37.194224 47765062198144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:37.194995 47291868685184 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:37.195293 47976137532288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.195602 47765062198144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:37.196197 47857571402624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.196205 47694515639168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.196295 47209024570240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.198397 47392957784960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.202841 47684480750464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.203052 47064613229440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881437.010284 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.011045 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.011768 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.206856 47418402001792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.207889 47418402001792 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpngv063ej
I0618 12:10:37.208919 47418402001792 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpngv063ej', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20bd982da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.209335 47418402001792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881437.066880 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.067514 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.067904 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.213056 47017292678016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881437.066217 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.066679 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.067281 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.213394 47909366719360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.214416 47418402001792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.214082 47017292678016 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpvyzpofrx
I0618 12:10:37.215072 47017292678016 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpvyzpofrx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3599d9da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:37.214396 47909366719360 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3um3enks
I0618 12:10:37.215404 47909366719360 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3um3enks', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b930d5f3e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.215469 47017292678016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.215806 47909366719360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.220089 47017292678016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.220335 47909366719360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.220846 47768081376128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:10:37.221133 47845446558592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881437.012299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.013005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.013684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.223473 47150059783040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.224485 47150059783040 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5r0fefjg
W0618 12:10:37.225152 47768081376128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:37.225483 47150059783040 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5r0fefjg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae24326de10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:37.225470 47845446558592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:10:37.225881 47150059783040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881437.113339 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.113829 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.114252 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.228697 47349540373376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
:::MLL 1560881437.110595 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.111088 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.111498 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.228792 47837272077184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
I0618 12:10:37.230204 47768081376128 estimator.py:1111] Calling model_fn.
W0618 12:10:37.229761 47349540373376 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpvekd7f6m
W0618 12:10:37.229789 47837272077184 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpr4zgkb_z
W0618 12:10:37.230310 47768081376128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:10:37.230785 47349540373376 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpvekd7f6m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10b51f1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.230784 47837272077184 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpr4zgkb_z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8244322e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.230527 47845446558592 estimator.py:1111] Calling model_fn.
W0618 12:10:37.230636 47845446558592 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:10:37.230692 47150059783040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:10:37.231197 47349540373376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:10:37.231199 47837272077184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.231678 47768081376128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:37.231985 47845446558592 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:10:37.233819 47418402001792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.235835 47349540373376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.235835 47837272077184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:10:37.237125 47760067609472 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881437.138726 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.139204 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.139641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.238465 47357116801920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.239025 47017292678016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881437.140009 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881437.140478 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881437.140909 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:10:37.239319 47706030371712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000019-000011.tfrecord.zz_0_0
W0618 12:10:37.239395 47909366719360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:10:37.239484 47357116801920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfarzjx_u
I0618 12:10:37.240465 47357116801920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfarzjx_u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1278b62e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:10:37.240864 47357116801920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:10:37.240315 47706030371712 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmplnyhuhul
I0618 12:10:37.241319 47706030371712 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmplnyhuhul', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63b594ce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:10:37.241401 47760067609472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a l[2019-06-18 12:11:15] divide_golden_chunk finished: 3.326 seconds
[2019-06-18 12:11:15] generate golden chunk: 3.340 seconds
[2019-06-18 12:11:15] moving /lfs/lfs12/gma_akey/results/epb309/models/000029-000018.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000029-000019.data-00000-of-00001
[2019-06-18 12:11:15] moving /lfs/lfs12/gma_akey/results/epb309/models/000029-000018.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb
[2019-06-18 12:11:15] moving /lfs/lfs12/gma_akey/results/epb309/models/000029-000018.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000029-000019.meta
[2019-06-18 12:11:15] moving /lfs/lfs12/gma_akey/results/epb309/models/000029-000018.index --> /lfs/lfs12/gma_akey/results/epb309/models/000029-000019.index
[2019-06-18 12:11:15] iteration time 28: 48.957 seconds
2019-06-18 12:11:17.417262: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881475.918470 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:11:20] minmax time: 3.296 seconds
2019-06-18 12:11:20.723849: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:11:20.729517: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:11:20.734139: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881480.746635 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 28}}
[2019-06-18 12:11:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000030-000019 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:11:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=30 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=1023779861 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=2047559692 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=3071339523 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=4095119354 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=5118899185 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=6142679016 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=7166458847 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=8190238678 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=9214018509 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=10237798340 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=11261578171 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=12285358002 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=13309137833 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=14332917664 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=15356697495 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=16380477326 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=17404257157 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=18428036988 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=19451816819 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000028-000018.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000029-000019 --seed=20475596650 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:11:32] eval finished: 11.766 seconds
[2019-06-18 12:11:32] Win rate 000029-000019 vs 000028-000018: 0.490
:::MLL 1560881492.589787 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:11:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=31 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=1023779862 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=2047559693 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=3071339524 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=4095119355 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=5118899186 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=6142679017 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=7166458848 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=8190238679 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=9214018510 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=10237798341 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=11261578172 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=12285358003 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=13309137834 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=14332917665 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=15356697496 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=16380477327 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=17404257158 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000030-000018 --seed=18428036989 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:12:02] selfplay finished: 29.864 seconds
[2019-06-18 12:12:02] selfplay mn: 29.885 seconds
[2019-06-18 12:12:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-31-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=31 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779862 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559693 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339524 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119355 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899186 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679017 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458848 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238679 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018510 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798341 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578172 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285358003 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137834 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917665 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697496 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477327 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257158 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036989 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816820 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596651 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376482 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156313 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000030-000018/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:12:04] train finished: 43.733 seconds
:::MLL 1560881486.009346 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.010236 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.011046 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.135528 47222579327872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
:::MLL 1560881486.018798 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.019524 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.020169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.136599 47061039936384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.136586 47222579327872 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpfelayg7n
I0618 12:11:26.137684 47222579327872 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpfelayg7n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af325a74e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.138090 47222579327872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.137650 47061039936384 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpumb1wqfe
I0618 12:11:26.138657 47061039936384 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpumb1wqfe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd8927ce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.139073 47061039936384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.143008 47222579327872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.143817 47061039936384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881486.010513 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.011455 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.012317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.150503 47751275930496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
:::MLL 1560881486.023907 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.024618 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.025256 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.150985 47218569925504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.151628 47751275930496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpwkizn4ig
I0618 12:11:26.152731 47751275930496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpwkizn4ig', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e3e6d3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:26.152071 47218569925504 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_b9zqq6n
I0618 12:11:26.153164 47218569925504 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_b9zqq6n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af236ac9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.153183 47751275930496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:26.153610 47218569925504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.158409 47751275930496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.158918 47218569925504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.163071 47222579327872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.163652 47061039936384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881486.052719 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.053463 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.054165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.165787 47794009686912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
:::MLL 1560881486.049878 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.050592 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.051239 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.165974 47785055830912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.166813 47794009686912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpx8a1qp60
W0618 12:11:26.167022 47785055830912 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmphku1_6w_
I0618 12:11:26.167924 47794009686912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpx8a1qp60', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78318e9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.168231 47785055830912 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmphku1_6w_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b761bdd9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.168377 47794009686912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:26.168630 47785055830912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.173151 47794009686912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.173219 47785055830912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.179929 47751275930496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.180584 47218569925504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.192386 47794009686912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.192535 47785055830912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881486.010346 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.011092 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.011759 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.193057 47528605832064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.194118 47528605832064 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpdclv0klm
I0618 12:11:26.195129 47528605832064 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpdclv0klm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a66411e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.195532 47528605832064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.200904 47528605832064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881486.012814 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.013504 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.014189 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.211151 47983890154368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.211368 47061039936384 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.211622 47222579327872 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.212123 47983890154368 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpb8cz4sgv
I0618 12:11:26.213121 47983890154368 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpb8cz4sgv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba467507da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.213523 47983890154368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881486.114346 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.114774 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.115142 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.215069 47018795398016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
:::MLL 1560881486.112836 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.113273 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.113649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.215408 47949122151296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.215639 47061039936384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:26.215946 47222579327872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:11:26.216087 47018795398016 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3b32f4d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:26.216419 47949122151296 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp_cktnf4j
I0618 12:11:26.217216 47018795398016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:26.217402 47949122151296 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp_cktnf4j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c4efafe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.217801 47949122151296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.218149 47983890154368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881486.119222 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.119679 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.120098 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.218060 47225405735808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
:::MLL 1560881486.119347 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.119808 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.120207 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.218059 46961805624192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.219120 47225405735808 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpibuvhfjp
W0618 12:11:26.219150 46961805624192 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpe6q2nc2z
I0618 12:11:26.220105 47225405735808 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpibuvhfjp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3ce1eddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.220139 46961805624192 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpe6q2nc2z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab66e545dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.220497 47225405735808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:11:26.220538 46961805624192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.220589 47528605832064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:11:26.220694 47061039936384 estimator.py:1111] Calling model_fn.
W0618 12:11:26.220802 47061039936384 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:11:26.221051 47222579327872 estimator.py:1111] Calling model_fn.
W0618 12:11:26.221159 47222579327872 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:26.221848 47018795398016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.222153 47061039936384 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.222353 47949122151296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.222551 47222579327872 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.225171 47225405735808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.225166 46961805624192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.229029 47751275930496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.230063 47218569925504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.233282 47751275930496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:26.234387 47218569925504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881486.139534 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.140087 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.140580 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.236428 47047133123456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.237426 47983890154368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.237458 47047133123456 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4copc036
I0618 12:11:26.238431 47047133123456 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4copc036', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca4c3eada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.238332 47751275930496 estimator.py:1111] Calling model_fn.
I0618 12:11:26.238832 47047133123456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.238445 47751275930496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881486.143957 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.144402 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.144784 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.239382 47559526294400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
I0618 12:11:26.239524 47218569925504 estimator.py:1111] Calling model_fn.
W0618 12:11:26.239632 47218569925504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:26.239799 47751275930496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.240418 47785055830912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.240466 47794009686912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.240360 47559526294400 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpckecpcp4
I0618 12:11:26.241337 47559526294400 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpckecpcp4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b419941ee10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:26.240926 47018795398016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.240998 47218569925504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:11:26.241732 47559526294400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.241420 47949122151296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.243512 47047133123456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.244116 47225405735808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.244088 46961805624192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.244761 47785055830912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:26.244781 47794009686912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:26.246193 47559526294400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:11:26.249884 47785055830912 estimator.py:1111] Calling model_fn.
I0618 12:11:26.249892 47794009686912 estimator.py:1111] Calling model_fn.
W0618 12:11:26.249994 47785055830912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:26.250004 47794009686912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560881486.073584 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.074051 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.074457 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.249662 47510723371904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
:::MLL 1560881486.076149 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.076624 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.077051 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.250830 47331564999552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.251369 47785055830912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.251368 47794009686912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.250688 47510723371904 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpnk2jebn_
I0618 12:11:26.251683 47510723371904 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpnk2jebn_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b363c607e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.252097 47510723371904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.251830 47331564999552 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpb70rwzc1
I0618 12:11:26.252787 47331564999552 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpb70rwzc1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c85b49e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.253183 47331564999552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.256809 47510723371904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.257703 47331564999552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.262496 47047133123456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.265127 47559526294400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881486.072678 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.073513 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.074333 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.267676 47912058094464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.268085 47528605832064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.268750 47912058094464 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpqyuilcgg
I0618 12:11:26.269761 47912058094464 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpqyuilcgg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93adca4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:11:26.270173 47912058094464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.272395 47528605832064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:26.275146 47912058094464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:11:26.275968 47510723371904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.276697 47331564999552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:11:26.277508 47528605832064 estimator.py:1111] Calling model_fn.
W0618 12:11:26.277620 47528605832064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:26.278992 47528605832064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.284616 47983890154368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.288574 47018795398016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.288612 47949122151296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:11:26.288917 47983890154368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560881486.073331 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881486.074191 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881486.074904 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:11:26.289787 47829775328128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000029-000017.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000020-000011.tfrecord.zz_0_0
W0618 12:11:26.290788 47829775328128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmps5_hpd76
W0618 12:11:26.291263 46961805624192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:11:26.291784 47829775328128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmps5_hpd76', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b80855afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:11:26.291587 47225405735808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:11:26.292182 47829775328128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:11:26.292904 47018795398016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:11:26.292933 47949122151296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:11:26.294010 47983890154368 estimator.py:1111] Calling model_fn.
W0618 12:11:26.294319 47912058094464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:11:26.294119 47983890154368 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:11:26.295496 47983890154368 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:11:26.295553 46961805624192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.esti[2019-06-18 12:12:05] divide_golden_chunk finished: 3.272 seconds
[2019-06-18 12:12:05] generate golden chunk: 3.287 seconds
[2019-06-18 12:12:05] moving /lfs/lfs12/gma_akey/results/epb309/models/000030-000019.index --> /lfs/lfs12/gma_akey/results/epb309/models/000030-000020.index
[2019-06-18 12:12:05] moving /lfs/lfs12/gma_akey/results/epb309/models/000030-000019.pb --> /lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb
[2019-06-18 12:12:05] moving /lfs/lfs12/gma_akey/results/epb309/models/000030-000019.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb309/models/000030-000020.data-00000-of-00001
[2019-06-18 12:12:05] moving /lfs/lfs12/gma_akey/results/epb309/models/000030-000019.meta --> /lfs/lfs12/gma_akey/results/epb309/models/000030-000020.meta
[2019-06-18 12:12:05] iteration time 29: 49.886 seconds
2019-06-18 12:12:07.379262: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560881525.804985 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:12:10] minmax time: 3.278 seconds
2019-06-18 12:12:10.667801: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:12:10.673438: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:12:10.678075: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560881530.690249 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 29}}
[2019-06-18 12:12:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb350 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb139 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb309/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb309/models/000031-000020 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb138 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:12:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-eval-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=31 : \
-host epb308 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=1023779862 : \
-host epb306 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=2047559693 : \
-host epb304 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=3071339524 : \
-host epb303 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=4095119355 : \
-host epb301 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=5118899186 : \
-host epb279 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=6142679017 : \
-host epb300 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=7166458848 : \
-host epb278 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=8190238679 : \
-host epb277 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=9214018510 : \
-host epb276 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=10237798341 : \
-host epb275 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=11261578172 : \
-host epb274 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=12285358003 : \
-host epb273 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=13309137834 : \
-host epb272 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=14332917665 : \
-host epb271 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=15356697496 : \
-host epb270 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=16380477327 : \
-host epb359 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=17404257158 : \
-host epb358 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=18428036989 : \
-host epb357 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=19451816820 : \
-host epb356 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000030-000020.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/000030-000020 --seed=20475596651 : \
-host epb355 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:12:21] eval finished: 10.886 seconds
[2019-06-18 12:12:21] Win rate 000030-000020 vs 000029-000019: 0.410
:::MLL 1560881541.654804 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:12:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-selfplay-32-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb309 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=32 : \
-host epb308 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=1023779863 : \
-host epb306 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=2047559694 : \
-host epb304 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=3071339525 : \
-host epb303 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=4095119356 : \
-host epb301 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=5118899187 : \
-host epb279 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=6142679018 : \
-host epb300 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=7166458849 : \
-host epb278 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=8190238680 : \
-host epb277 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=9214018511 : \
-host epb276 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=10237798342 : \
-host epb275 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=11261578173 : \
-host epb274 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=12285358004 : \
-host epb273 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=13309137835 : \
-host epb272 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=14332917666 : \
-host epb271 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=15356697497 : \
-host epb270 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=16380477328 : \
-host epb359 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=17404257159 : \
-host epb358 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb309/data/holdout/000031-000019 --seed=18428036990 : \
-host epb357 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb309/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000029-000019.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019 --holdout_dir=/lfs/lfs12/gma_akey/results/epb30
[2019-06-18 12:12:52] selfplay finished: 30.689 seconds
[2019-06-18 12:12:52] selfplay mn: 30.707 seconds
[2019-06-18 12:12:52] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb309/mpi/out-divide_golden_chunk-32-%r.txt \
-host epb309 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=32 : \
-host epb308 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=1023779863 : \
-host epb306 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=2047559694 : \
-host epb304 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=3071339525 : \
-host epb303 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=4095119356 : \
-host epb301 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=5118899187 : \
-host epb279 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=6142679018 : \
-host epb300 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=7166458849 : \
-host epb278 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=8190238680 : \
-host epb277 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=9214018511 : \
-host epb276 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=10237798342 : \
-host epb275 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=11261578173 : \
-host epb274 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=12285358004 : \
-host epb273 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=13309137835 : \
-host epb272 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=14332917666 : \
-host epb271 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=15356697497 : \
-host epb270 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=16380477328 : \
-host epb359 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=17404257159 : \
-host epb358 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=18428036990 : \
-host epb357 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=19451816821 : \
-host epb356 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=20475596652 : \
-host epb355 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=21499376483 : \
-host epb354 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000031-000019.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb309 --seed=22523156314 : \
-host epb353 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb309/data/selfplay/000031-000019/* --write_path=/lfs/lfs12/gma_akey/results/epb309/data/golde
[2019-06-18 12:12:54] train finished: 43.961 seconds
:::MLL 1560881535.951253 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881535.952067 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881535.952833 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.080559 47863796691840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881535.960160 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881535.960887 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881535.961545 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.080841 46987089175424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.081568 47863796691840 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpv8npzsrd
W0618 12:12:16.081849 46987089175424 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp4kvjuy_2
I0618 12:12:16.082658 47863796691840 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpv8npzsrd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88712fce80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.082918 46987089175424 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp4kvjuy_2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc5158be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.083123 47863796691840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:16.083364 46987089175424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.087953 47863796691840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.088043 46987089175424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.107232 47863796691840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.107199 46987089175424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.155462 46987089175424 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:16.155843 47863796691840 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560881536.048645 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.049151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.049570 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.157949 47011026133888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.051067 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.051552 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.051953 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.158168 46915438101376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.158976 47011026133888 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmu62vtfa
W0618 12:12:16.159769 46987089175424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:12:16.159198 46915438101376 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb309/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaba29c1cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.159958 47011026133888 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmu62vtfa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1e419be80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:16.160173 47863796691840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:12:16.160335 46915438101376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:16.160354 47011026133888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:16.165079 46987089175424 estimator.py:1111] Calling model_fn.
W0618 12:12:16.165193 46987089175424 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:16.165204 46915438101376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.165202 47011026133888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:16.165482 47863796691840 estimator.py:1111] Calling model_fn.
W0618 12:12:16.165590 47863796691840 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:16.166556 46987089175424 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:16.166947 47863796691840 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:16.184289 46915438101376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.184319 47011026133888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881536.001826 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.002730 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.003592 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.198461 47621329818496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.199893 47621329818496 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp3b08_4px
I0618 12:12:16.201030 47621329818496 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp3b08_4px', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ffd08ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.201504 47621329818496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881536.028721 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.029472 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.030154 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.205083 47557514613632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.031789 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.032513 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.033226 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.205155 47070517420928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.206168 47557514613632 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp989ed1ox
W0618 12:12:16.206197 47070517420928 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmph520578_
:::MLL 1560881535.999075 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881535.999947 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.000764 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.206805 47798067864448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.206815 47621329818496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:16.207293 47557514613632 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp989ed1ox', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b41215a2da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.207301 47070517420928 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmph520578_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acfbe0eae10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.207750 47557514613632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:16.207755 47070517420928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.207927 47798067864448 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp5i6ar8yq
I0618 12:12:16.209051 47798067864448 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp5i6ar8yq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7923717da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.209505 47798067864448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.212714 47070517420928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.212729 47557514613632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.214830 47798067864448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881536.016328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.017089 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.017741 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.219362 47224603693952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.220446 47224603693952 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6vjx_zjz
I0618 12:12:16.221547 47224603693952 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6vjx_zjz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af39e509e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.221984 47224603693952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.226908 47224603693952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.229120 47621329818496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881536.011296 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.012018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.012707 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.230252 47201195848576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.232178 47557514613632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.231731 47011026133888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:16.232121 47070517420928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.231852 46915438101376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:16.231430 47201195848576 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp0g3detrh
I0618 12:12:16.232732 47201195848576 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp0g3detrh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aee2b193e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.233151 47201195848576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881535.999232 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.000161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.000940 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.233868 47152251614080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.234923 47152251614080 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp6u9wol8b
I0618 12:12:16.236019 47152251614080 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp6u9wol8b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae2c5cb8e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:16.236446 47798067864448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.236024 47011026133888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:12:16.236467 47152251614080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.236191 46915438101376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:16.238220 47201195848576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:12:16.241113 47011026133888 estimator.py:1111] Calling model_fn.
W0618 12:12:16.241419 47152251614080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.241223 47011026133888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:12:16.241280 46915438101376 estimator.py:1111] Calling model_fn.
W0618 12:12:16.241394 46915438101376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:12:16.242594 47011026133888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:16.242766 46915438101376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:12:16.246639 47224603693952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881536.004986 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.005872 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.006683 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.247358 47584062399360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.248365 47584062399360 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpz31r_mti
I0618 12:12:16.249365 47584062399360 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpz31r_mti', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b474fb93e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.249764 47584062399360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.254469 47584062399360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881536.104581 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.105151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.105667 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.255213 47127804236672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.107479 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.107944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.108347 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.256029 47818712961920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.256234 47127804236672 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpxd3z74us
I0618 12:12:16.257214 47127804236672 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpxd3z74us', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add149e2e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.257613 47127804236672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.257013 47818712961920 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpy7gkaa7v
I0618 12:12:16.257992 47818712961920 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpy7gkaa7v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7df1fc9e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.258398 47818712961920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881536.055655 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.056172 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.056601 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.258545 47856459232128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.059277 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.059695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.060062 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.259180 47255003022208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.259101 47201195848576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.259549 47856459232128 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmptomlyaev
I0618 12:12:16.260546 47856459232128 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmptomlyaev', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86bbd70e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:12:16.260210 47255003022208 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmw21k3yk
I0618 12:12:16.260951 47856459232128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.261026 47152251614080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:12:16.261208 47255003022208 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmw21k3yk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afab2419e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.261607 47255003022208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.262257 47127804236672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.262938 47818712961920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560881536.084028 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.084592 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.084998 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.264074 47428295988096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.080493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.081010 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.081478 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.264077 47974402679680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.265589 47856459232128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.266196 47255003022208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.265188 47428295988096 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpic4w38ig
W0618 12:12:16.265151 47974402679680 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpmjkosggp
I0618 12:12:16.266227 47974402679680 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpmjkosggp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba231d11e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.266270 47428295988096 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpic4w38ig', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b230b524dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.266633 47974402679680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:16.266664 47428295988096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560881536.020068 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.020960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.021689 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.270319 47980978623360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.023929 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.024661 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.025346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.270580 47151075275648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.271331 47428295988096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.271308 47974402679680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.271354 47980978623360 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpgu1z1s9y
W0618 12:12:16.271560 47151075275648 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmpjmkqej1d
I0618 12:12:16.272354 47980978623360 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpgu1z1s9y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3b9c62e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.272541 47151075275648 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmpjmkqej1d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae27fae0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.272756 47980978623360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:12:16.272970 47151075275648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.273579 47584062399360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560881536.072186 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.072654 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.073057 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.277026 47303538889600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
:::MLL 1560881536.071230 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560881536.071715 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560881536.072204 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:12:16.277129 47689808221056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000030-000018.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/000021-000012.tfrecord.zz_0_0
W0618 12:12:16.277687 47980978623360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.277982 47151075275648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.278056 47303538889600 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmprek92ndi
W0618 12:12:16.278123 47689808221056 estimator.py:1760] Using temporary folder as model directory: /tmp/96731.tmpdir/tmp1mzsz8ls
I0618 12:12:16.279043 47303538889600 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmprek92ndi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b05ff381e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.279099 47689808221056 estimator.py:201] Using config: {'_model_dir': '/tmp/96731.tmpdir/tmp1mzsz8ls', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5feeaa6e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:12:16.279446 47303538889600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.279296 47621329818496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:16.279674 47070517420928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:12:16.279493 47689808221056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:12:16.280177 47557514613632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:16.281166 47127804236672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.282005 47818712961920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.283973 47070517420928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:16.283710 47621329818496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:16.284094 47303538889600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.284344 47856459232128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:12:16.284126 47689808221056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:12:16.284522 47557514613632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:12:16.284908 47798067864448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:12:16.285170 47255003022208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:12:16.289042 47070517420928 estimator.py:1111] Calling model_fn.
W0618 12:12:16.289148 47070517420928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks[2019-06-18 12:12:55] divide_golden_chunk finished: 3.334 seconds
[2019-06-18 12:12:55] generate golden chunk: 3.348 seconds
[2019-06-18 12:12:55] iteration time 30: 49.907 seconds
:::MLL 1560881575.712098 epoch_stop: {"value": null, "metadata": {'lineno': 737, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:12:55] Total time: 1703.216 seconds

numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000018-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000018-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000019-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000019-000012log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000020-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000020-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000021-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000021-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000022-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000022-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000023-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000023-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000024-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000024-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000025-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000025-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000026-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000026-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000027-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000027-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000028-000018_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000028-000018log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000029-000019_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000029-000019log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb309/models/000030-000020_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb309/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb309/models/000030-000020log.txt
:::MLL 1560881578.434400 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
I0618 12:12:58.436304 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=1
I0618 12:13:22.939471 47902551466880 utils.py:86] eval finished: 24.501 seconds
I0618 12:13:22.943496 47902551466880 reference_implementation.py:563] Win rate 000001-000001 vs target: 0.030
:::MLL 1560881602.944227 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560881602.944568 eval_accuracy: {"value": 0.03, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560881602.944899 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
I0618 12:13:22.945213 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000002-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=2
I0618 12:13:47.245735 47902551466880 utils.py:86] eval finished: 24.300 seconds
I0618 12:13:47.248611 47902551466880 reference_implementation.py:563] Win rate 000002-000001 vs target: 0.120
:::MLL 1560881627.249297 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560881627.249622 eval_accuracy: {"value": 0.12, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560881627.249948 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
I0618 12:13:47.250254 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=3
I0618 12:14:12.064100 47902551466880 utils.py:86] eval finished: 24.814 seconds
I0618 12:14:12.067098 47902551466880 reference_implementation.py:563] Win rate 000003-000002 vs target: 0.110
:::MLL 1560881652.067942 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560881652.068282 eval_accuracy: {"value": 0.11, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560881652.068614 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
I0618 12:14:12.068935 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000004-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=4
I0618 12:14:39.506383 47902551466880 utils.py:86] eval finished: 27.437 seconds
I0618 12:14:39.509157 47902551466880 reference_implementation.py:563] Win rate 000004-000002 vs target: 0.050
:::MLL 1560881679.509866 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560881679.510197 eval_accuracy: {"value": 0.05, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560881679.510537 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
I0618 12:14:39.510847 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000005-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=5
I0618 12:15:04.243163 47902551466880 utils.py:86] eval finished: 24.732 seconds
I0618 12:15:04.246083 47902551466880 reference_implementation.py:563] Win rate 000005-000003 vs target: 0.100
:::MLL 1560881704.247120 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560881704.247472 eval_accuracy: {"value": 0.1, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560881704.247789 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
I0618 12:15:04.248108 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=6
I0618 12:15:29.787022 47902551466880 utils.py:86] eval finished: 25.539 seconds
I0618 12:15:29.789879 47902551466880 reference_implementation.py:563] Win rate 000006-000004 vs target: 0.060
:::MLL 1560881729.790818 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560881729.791152 eval_accuracy: {"value": 0.06, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560881729.791483 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
I0618 12:15:29.791819 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000007-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=7
I0618 12:15:54.486341 47902551466880 utils.py:86] eval finished: 24.694 seconds
I0618 12:15:54.489210 47902551466880 reference_implementation.py:563] Win rate 000007-000004 vs target: 0.190
:::MLL 1560881754.489906 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560881754.490241 eval_accuracy: {"value": 0.19, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560881754.490571 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
I0618 12:15:54.490886 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000008-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=8
I0618 12:16:20.813348 47902551466880 utils.py:86] eval finished: 26.322 seconds
I0618 12:16:20.816173 47902551466880 reference_implementation.py:563] Win rate 000008-000005 vs target: 0.260
:::MLL 1560881780.816864 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560881780.817186 eval_accuracy: {"value": 0.26, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560881780.817508 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
I0618 12:16:20.817820 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000009-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=9
I0618 12:16:45.273215 47902551466880 utils.py:86] eval finished: 24.455 seconds
I0618 12:16:45.276098 47902551466880 reference_implementation.py:563] Win rate 000009-000006 vs target: 0.170
:::MLL 1560881805.276963 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560881805.277303 eval_accuracy: {"value": 0.17, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560881805.277633 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
I0618 12:16:45.277960 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000010-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=10
I0618 12:17:09.139491 47902551466880 utils.py:86] eval finished: 23.861 seconds
I0618 12:17:09.142380 47902551466880 reference_implementation.py:563] Win rate 000010-000006 vs target: 0.320
:::MLL 1560881829.143416 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560881829.143750 eval_accuracy: {"value": 0.32, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560881829.144081 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
I0618 12:17:09.144400 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000011-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=11
I0618 12:17:32.806625 47902551466880 utils.py:86] eval finished: 23.662 seconds
I0618 12:17:32.809622 47902551466880 reference_implementation.py:563] Win rate 000011-000007 vs target: 0.310
:::MLL 1560881852.810283 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560881852.810591 eval_accuracy: {"value": 0.31, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560881852.810921 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
I0618 12:17:32.811243 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000012-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=12
I0618 12:17:56.775152 47902551466880 utils.py:86] eval finished: 23.964 seconds
I0618 12:17:56.778048 47902551466880 reference_implementation.py:563] Win rate 000012-000008 vs target: 0.180
:::MLL 1560881876.782744 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560881876.783076 eval_accuracy: {"value": 0.18, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560881876.783406 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
I0618 12:17:56.783727 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000013-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=13
I0618 12:18:19.988958 47902551466880 utils.py:86] eval finished: 23.205 seconds
I0618 12:18:19.991965 47902551466880 reference_implementation.py:563] Win rate 000013-000008 vs target: 0.310
:::MLL 1560881899.992612 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560881899.992918 eval_accuracy: {"value": 0.31, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560881899.993216 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
I0618 12:18:19.993549 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000014-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=14
I0618 12:18:44.189805 47902551466880 utils.py:86] eval finished: 24.196 seconds
I0618 12:18:44.192699 47902551466880 reference_implementation.py:563] Win rate 000014-000009 vs target: 0.250
:::MLL 1560881924.193390 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560881924.193721 eval_accuracy: {"value": 0.25, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560881924.194046 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
I0618 12:18:44.194365 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=15
I0618 12:19:07.674158 47902551466880 utils.py:86] eval finished: 23.480 seconds
I0618 12:19:07.677033 47902551466880 reference_implementation.py:563] Win rate 000015-000010 vs target: 0.360
:::MLL 1560881947.682590 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560881947.682924 eval_accuracy: {"value": 0.36, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560881947.683251 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
I0618 12:19:07.683573 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=16
I0618 12:19:29.613321 47902551466880 utils.py:86] eval finished: 21.930 seconds
I0618 12:19:29.616198 47902551466880 reference_implementation.py:563] Win rate 000016-000011 vs target: 0.390
:::MLL 1560881969.616884 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560881969.617206 eval_accuracy: {"value": 0.39, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560881969.617558 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
I0618 12:19:29.617862 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=17
I0618 12:19:52.922169 47902551466880 utils.py:86] eval finished: 23.304 seconds
I0618 12:19:52.925074 47902551466880 reference_implementation.py:563] Win rate 000017-000012 vs target: 0.470
:::MLL 1560881992.925774 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560881992.926105 eval_accuracy: {"value": 0.47, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560881992.926434 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
I0618 12:19:52.926758 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000018-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=18
I0618 12:20:14.602945 47902551466880 utils.py:86] eval finished: 21.676 seconds
I0618 12:20:14.605869 47902551466880 reference_implementation.py:563] Win rate 000018-000012 vs target: 0.450
:::MLL 1560882014.606878 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
:::MLL 1560882014.607216 eval_accuracy: {"value": 0.45, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
:::MLL 1560882014.607523 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 18}}
I0618 12:20:14.607832 47902551466880 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb309/models/000019-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb309/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb309/sgf/eval/target --seed=19
I0618 12:20:38.441270 47902551466880 utils.py:86] eval finished: 23.833 seconds
I0618 12:20:38.444148 47902551466880 reference_implementation.py:563] Win rate 000019-000012 vs target: 0.660
:::MLL 1560882038.444819 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 18}}
:::MLL 1560882038.445142 eval_accuracy: {"value": 0.66, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 18}}
:::MLL 1560882038.445508 eval_result: {"value": null, "metadata": {'lineno': 52, 'file': 'ml_perf/eval_models.py', 'iteration': 18, 'timestamp': 943.636}}
:::MLL 1560882038.445836 run_stop: {"value": null, "metadata": {'lineno': 53, 'file': 'ml_perf/eval_models.py', 'status': 'success'}}
Model 000019-000012 beat target after 943.636s
~/submission/benchmarks/minigo/clx-8260l-2s-x32
