:::MLL 1560882319.962664227 submission_org: {"value": "Intel_Corp", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.964139003 submission_platform: {"value": "32xCLX-8260L_CPUs", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.965426220 submission_division: {"value": "closed", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.966649250 submission_status: {"value": "onprem", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.967916233 submission_benchmark: {"value": "minigo", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.969168101 submission_poc_name: {"value": "Guokai Ma, Letian Kang, Christine Cheng, Mingxiao Huang", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.970422429 submission_poc_email: {"value": "guokai.ma@intel.com, letian.kang@intel.com, christine.cheng@intel.com, mingxiao.huang@intel.com", "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882319.971754482 submission_entry: {"value": {"framework": "TensorFlow 1.13.1", "power": "none", "notes": "none", "interconnect": "OPA", "os": "Oracle Linux Server 7.6", "libraries": "MKLDNN (v0.18), MKL (v2019.0.3.20190220), IntelMPI (2018.1.163)", "compilers": "GCC6.3", "nodes": [{"num_nodes": 32, "cpu": "Intel(R) Xeon(R) Platinum 8260L CPU @ 2.40GHz", "num_cores": 48, "num_vcpus": "NA", "accelerator": "NA", "num_accelerators": 0, "sys_mem_size": "192G", "sys_storage_type": "SSD", "sys_storage_size": "800G", "cpu_accel_interconnect": "100Gb OPA", "network_card": "100Gb OPA", "num_network_cards": 1, "notes": "NA"}]}, "metadata": {"lineno": 0, "file": "manual"}}
:::MLL 1560882321.112281485 cache_clear: {value: true, metadata: {lineno: 0, file: manual}}
~/submission/benchmarks/minigo/implementations/tensorflow ~/submission/benchmarks/minigo/clx-8260l-2s-x32
Physical cores = 48
Virtual cores = 96
NUMA cores = 24
KMP_HW_SUBSET = 2T
Output to /lfs/lfs12/gma_akey
./run_mn.sh: line 20: ulimit: max user processes: cannot modify limit: Operation not permitted
Wiping dir /lfs/lfs12/gma_akey/results/epb144
:::MLL 1560882329.890630 init_start: {"value": null, "metadata": {'lineno': 742, 'file': 'ml_perf/reference_implementation.py'}}
Making dir /lfs/lfs12/gma_akey/results/epb144/models
Making dir /lfs/lfs12/gma_akey/results/epb144/data/selfplay
Making dir /lfs/lfs12/gma_akey/results/epb144/data/holdout
Making dir /lfs/lfs12/gma_akey/results/epb144/sgf/eval
Making dir /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks
Making dir /lfs/lfs12/gma_akey/results/epb144/work_dir
Making dir /lfs/lfs12/gma_akey/results/epb144/mpi
[2019-06-18 12:25:29] Selfplay nodes = ['epb144', 'epb131', 'epb215', 'epb217', 'epb133', 'epb203', 'epb200', 'epb171', 'epb134', 'epb219', 'epb121', 'epb207', 'epb201', 'epb176', 'epb173', 'epb132', 'epb178', 'epb205', 'epb204', 'epb175', 'epb174', 'epb208', 'epb210', 'epb179', 'epb218', 'epb130']
[2019-06-18 12:25:29] Train nodes = ['epb213', 'epb202', 'epb206', 'epb306', 'epb301', 'epb275']
[2019-06-18 12:25:29] Eval nodes = ['epb144', 'epb131', 'epb215', 'epb217', 'epb133', 'epb203', 'epb200', 'epb171', 'epb134', 'epb219', 'epb121', 'epb207', 'epb201', 'epb176', 'epb173', 'epb132', 'epb178', 'epb205', 'epb204', 'epb175', 'epb174', 'epb208', 'epb210', 'epb179', 'epb218', 'epb130']
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.42s/it]
[2019-06-18 12:28:23] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py:86: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2019-06-18 12:28:23] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
2019-06-18 12:28:23.939884: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX512F
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-06-18 12:28:23.953204: I tensorflow/core/common_runtime/process_util.cc:113] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[2019-06-18 12:28:23] From ./quantize_graph.py:351: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.
Instructions for updating:
`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.
2019-06-18 12:28:24.276399: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
[2019-06-18 12:28:24] From ./dual_net.py:679: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99']
Reading tf_records from 1 inputs
[2019-06-18 12:28:28] minmax time: 3.800 seconds
2019-06-18 12:28:28.087042: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:28:28.092458: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:28:28.097221: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882508.179940 init_stop: {"value": null, "metadata": {'lineno': 614, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560882508.180321 run_start: {"value": null, "metadata": {'lineno': 615, 'file': 'ml_perf/reference_implementation.py'}}
:::MLL 1560882508.180734 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 12:28:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=2 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:28:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=2 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=1023779833 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=2047559664 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=3071339495 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=4095119326 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=5118899157 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=6142678988 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=7166458819 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=8190238650 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=9214018481 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=10237798312 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=11261578143 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=12285357974 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=13309137805 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=14332917636 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=15356697467 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=16380477298 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=17404257129 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=18428036960 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000001-000000 --seed=19451816791 : \
-host epb1
[2019-06-18 12:29:02] selfplay finished: 34.101 seconds
[2019-06-18 12:29:02] selfplay mn: 34.123 seconds
[2019-06-18 12:29:02] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-2-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779833 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559664 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339495 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119326 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899157 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678988 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458819 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238650 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018481 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798312 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578143 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357974 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137805 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917636 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697467 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477298 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257129 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036960 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816791 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596622 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376453 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156284 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000001-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:29:19] divide_golden_chunk finished: 17.287 seconds
[2019-06-18 12:29:19] generate golden chunk: 17.304 seconds
[2019-06-18 12:29:25] train finished: 56.877 seconds
:::MLL 1560882525.184116 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.184499 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.184823 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.702730 47810550907776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.182194 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.182577 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.182898 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.702827 47789795660672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.112037 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.112900 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.113724 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.702949 47584374842240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.112072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.112903 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.113719 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.702918 47362264597376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
I0618 12:28:45.704016 47584374842240 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b476258bcc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.704161 47810550907776 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1any38um
I0618 12:28:45.705182 47584374842240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.705273 47810550907776 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1any38um', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c0b7d8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.704712 47789795660672 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8b168g0n
I0618 12:28:45.705736 47810550907776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.705100 47362264597376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvrywhj5n
I0618 12:28:45.705851 47789795660672 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8b168g0n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b773661ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.706129 47362264597376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvrywhj5n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13ab8b3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.706264 47789795660672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.706543 47362264597376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.714134 47584374842240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.714115 47362264597376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.714245 47810550907776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.714219 47789795660672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.733990 47362264597376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.734029 47810550907776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.734017 47789795660672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.734225 47584374842240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882525.184367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.185277 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.186014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.786508 47899950269312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.183835 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.184688 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.185531 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.786663 47964767855488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.274583 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.275103 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.275558 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.786832 47484722910080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.274554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.275087 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.275544 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.786808 47359404368768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 12:28:45.788190 47899950269312 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsbn8cfmx
W0618 12:28:45.788751 47362264597376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:28:45.788980 47584374842240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:28:45.789210 47899950269312 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsbn8cfmx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b90dc1b9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.789139 47789795660672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:28:45.788721 47964767855488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprygmaj4b
I0618 12:28:45.789620 47899950269312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.789761 47964767855488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmprygmaj4b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ff3897e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.789164 47484722910080 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp02p770ob
W0618 12:28:45.789136 47359404368768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcnbcjj95
I0618 12:28:45.790126 47484722910080 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp02p770ob', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b302ea0ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.790126 47359404368768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcnbcjj95', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b13010fbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.790165 47964767855488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.790559 47484722910080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.790560 47359404368768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.791975 47810550907776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:28:45.793255 47362264597376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:28:45.793431 47789795660672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:28:45.793544 47584374842240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882525.256466 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.256843 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.257165 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.795687 47167663862656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.253580 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.254026 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.254345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.795748 47843740717952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.201848 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.202668 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.203440 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.796080 47799175615360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 12:28:45.796308 47810550907776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882525.203031 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.203852 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.204513 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.796138 47266312356736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 12:28:45.797284 47167663862656 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6cp9hqvy
W0618 12:28:45.798383 47359404368768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:28:45.798318 47167663862656 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6cp9hqvy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae65c6fce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.798389 47484722910080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.798402 47899950269312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.798415 47964767855488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.797709 47843740717952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp64c77bog
I0618 12:28:45.798519 47789795660672 estimator.py:1111] Calling model_fn.
W0618 12:28:45.798628 47789795660672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:28:45.798672 47362264597376 estimator.py:1111] Calling model_fn.
W0618 12:28:45.798783 47362264597376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:28:45.798756 47167663862656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.798762 47843740717952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp64c77bog', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83c5c1ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.798088 47799175615360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpm55btsvv
W0618 12:28:45.798113 47266312356736 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdycimj9v
I0618 12:28:45.798999 47584374842240 estimator.py:1111] Calling model_fn.
W0618 12:28:45.799115 47584374842240 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:28:45.799101 47799175615360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpm55btsvv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7965786dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.799116 47266312356736 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdycimj9v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd54585e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.799198 47843740717952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.799514 47799175615360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.799533 47266312356736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.800047 47789795660672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:28:45.800290 47362264597376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:28:45.800565 47584374842240 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:28:45.801394 47810550907776 estimator.py:1111] Calling model_fn.
W0618 12:28:45.801516 47810550907776 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:28:45.802909 47810550907776 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:28:45.807077 47266312356736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.807101 47843740717952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.807127 47799175615360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.807211 47167663862656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882525.270230 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.270641 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.271022 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.807806 47524491109248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.272057 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.272405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.272724 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.807865 47036520452992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.206988 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.207723 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.208400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.808002 46996572205952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.205115 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.205853 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.206636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.808038 47114680820608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 12:28:45.808934 47524491109248 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp228sjphs
I0618 12:28:45.809664 47524491109248 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp228sjphs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3970ff6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.809443 47036520452992 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp614g2r8m
I0618 12:28:45.809989 47524491109248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.810159 47036520452992 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp614g2r8m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac7d3ae2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.810504 47036520452992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.809910 46996572205952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpoxn641_c
W0618 12:28:45.809936 47114680820608 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7s_g7v5c
I0618 12:28:45.810897 46996572205952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpoxn641_c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abe86943e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.810927 47114680820608 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7s_g7v5c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada0666ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.811292 46996572205952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.811319 47114680820608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.817787 47036520452992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.817866 47524491109248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.818028 47114680820608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.818036 46996572205952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.818103 47359404368768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.818234 47484722910080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.818297 47899950269312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.818392 47964767855488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882525.281541 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.281888 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.282232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.818499 47979465565056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.282459 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.282803 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.283161 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.818693 47913151886208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.207328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.208203 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.208977 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.819148 47904935641984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.207168 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.208041 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.208830 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.819195 47461514208128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 12:28:45.819689 47979465565056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp30nwjwvq
I0618 12:28:45.820406 47979465565056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp30nwjwvq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba35f96ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.820721 47979465565056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.820310 47913151886208 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptb7ugd93
I0618 12:28:45.821004 47913151886208 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptb7ugd93', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93eefc2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.821319 47913151886208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.820776 47904935641984 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz8kc2l5c
W0618 12:28:45.820805 47461514208128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzatp7gei
I0618 12:28:45.821810 47904935641984 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz8kc2l5c', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9205425e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.821853 47461514208128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzatp7gei', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ac7483e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.822241 47904935641984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.822278 47461514208128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882525.206742 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.207525 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.208255 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.821754 47785263252352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.203869 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.204621 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.205343 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.821907 47385454429056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.275985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.276427 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.276824 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.822149 47378530096000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
:::MLL 1560882525.271166 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882525.271658 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882525.272061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:28:45.822133 47451683218304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_99 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz_0
W0618 12:28:45.823327 47785263252352 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3s4roo0h
I0618 12:28:45.824330 47785263252352 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3s4roo0h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76283a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.823832 47385454429056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpeku0na5j
I0618 12:28:45.824735 47785263252352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.824833 47385454429056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpeku0na5j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1911c41e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:28:45.824297 47451683218304 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl_g9vx5k
W0618 12:28:45.824320 47378530096000 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu73qnk24
I0618 12:28:45.825231 47385454429056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.825295 47378530096000 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu73qnk24', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b17750b2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.825281 47451683218304 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl_g9vx5k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b287d4f2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:28:45.825684 47378530096000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:28:45.825683 47451683218304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:28:45.826902 47799175615360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.826981 47266312356736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.826987 47843740717952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.827361 47167663862656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.828427 47979465565056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.828426 47913151886208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.828671 47904935641984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.828660 47461514208128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.833284 47378530096000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.833344 47785263252352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.833366 47385454429056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.833385 47451683218304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:28:45.836839 47036520452992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.837157 47524491109248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.837762 46996572205952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.837822 47114680820608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.847609 47913151886208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.847901 47979465565056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:28:45.848257 47461514208128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.[2019-06-18 12:29:25] iteration time 0: 56.906 seconds
2019-06-18 12:29:25.456186: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882565.087940 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 12:29:28] minmax time: 3.234 seconds
2019-06-18 12:29:28.699695: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:29:28.705009: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:29:28.709566: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882568.720402 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 0}}
[2019-06-18 12:29:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000002-000001 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=3 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:29:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-2-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=2 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=1023779833 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=2047559664 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=3071339495 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=4095119326 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=5118899157 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=6142678988 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=7166458819 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=8190238650 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=9214018481 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=10237798312 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=11261578143 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=12285357974 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=13309137805 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=14332917636 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=15356697467 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=16380477298 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=17404257129 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=18428036960 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=19451816791 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/checkpoint.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000001-000001 --seed=20475596622 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_
[2019-06-18 12:29:40] eval finished: 11.589 seconds
[2019-06-18 12:29:40] Win rate 000001-000001 vs checkpoint: 0.500
:::MLL 1560882580.372820 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 0}}
[2019-06-18 12:29:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=3 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=1023779834 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=2047559665 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=3071339496 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=4095119327 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=5118899158 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=6142678989 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=7166458820 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=8190238651 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=9214018482 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=10237798313 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=11261578144 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=12285357975 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=13309137806 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=14332917637 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=15356697468 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=16380477299 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=17404257130 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000002-000000 --seed=18428036961 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:30:10] selfplay finished: 29.709 seconds
[2019-06-18 12:30:10] selfplay mn: 29.725 seconds
[2019-06-18 12:30:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-3-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779834 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559665 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339496 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119327 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899158 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678989 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458820 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238651 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018482 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798313 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578144 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357975 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137806 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917637 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697468 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477299 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257130 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036961 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816792 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596623 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376454 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156285 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000002-000000/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:30:12] train finished: 43.943 seconds
:::MLL 1560882573.999708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.000447 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.001119 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.064807 47595869361024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882573.988108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882573.989002 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882573.989852 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.064937 47294834152320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.065891 47595869361024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfv1t0p7o
W0618 12:29:34.065962 47294834152320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfbk1uc6_
I0618 12:29:34.066992 47595869361024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfv1t0p7o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a0f791e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.067040 47294834152320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfbk1uc6_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03f8606dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.067432 47595869361024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.067468 47294834152320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882573.999224 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882573.999954 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.000675 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.070656 47378079462272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882573.994499 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882573.995382 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882573.996228 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.070682 47409883353984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.071710 47378079462272 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4kkuygim
W0618 12:29:34.071740 47409883353984 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmp8_o31t
I0618 12:29:34.072817 47378079462272 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4kkuygim', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b175a2f0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.072826 47409883353984 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmp8_o31t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ec1d7ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.073255 47409883353984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.073257 47378079462272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.072857 47294834152320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.072875 47595869361024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.078620 47378079462272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882574.053496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.054061 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.054548 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.078005 47063261832064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.078624 47409883353984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882573.995229 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882573.996082 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882573.996869 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.078936 47992713896832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882573.995442 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882573.996233 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882573.997016 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.078987 47950018020224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.079404 47063261832064 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyhjqrypa
:::MLL 1560882574.017750 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.018521 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.019285 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.080609 46964279595904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.080022 47992713896832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpipbmz75_
:::MLL 1560882574.005316 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.006247 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.007087 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.080654 47369731879808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.080047 47950018020224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp11xk2wcs
I0618 12:29:34.080523 47063261832064 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyhjqrypa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace0d973e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.081092 47992713896832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpipbmz75_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba675403e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.081122 47950018020224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp11xk2wcs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9c8460ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.080989 47063261832064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.081526 47992713896832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.081550 47950018020224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.081710 47369731879808 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwzrz52mi
I0618 12:29:34.081755 46964279595904 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab701ca2d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.082792 47369731879808 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwzrz52mi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1568a10e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.082981 46964279595904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.083231 47369731879808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.086289 47063261832064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.086792 47992713896832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.086823 47950018020224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.088283 46964279595904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.088407 47369731879808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.093742 47294834152320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.093788 47595869361024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882574.031540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.032269 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.032948 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.095991 47769434473344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882574.025838 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.026700 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.027569 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.096124 46984714605440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.097052 47769434473344 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppzy08pn2
W0618 12:29:34.097127 46984714605440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjoziutcx
I0618 12:29:34.098131 47769434473344 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppzy08pn2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7278c29e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.098198 46984714605440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjoziutcx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abbc3cfadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.098572 47769434473344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.098640 46984714605440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882574.072073 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.072490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.072922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.098411 47199381001088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882574.070448 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.070837 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.071174 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.098916 47178046436224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882574.067711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.068128 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.068467 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.098945 47695482962816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.099762 47199381001088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptx6ws9du
W0618 12:29:34.099918 47178046436224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpycrq5k5s
W0618 12:29:34.099946 47695482962816 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1pb_obkm
I0618 12:29:34.100754 47199381001088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptx6ws9du', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aedbeecee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.100894 47178046436224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpycrq5k5s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae8c7494e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.100898 47695482962816 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1pb_obkm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6140e80e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:29:34.100795 47409883353984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.100894 47378079462272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:29:34.101284 47178046436224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.101280 47695482962816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.101283 47199381001088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882574.075383 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.075800 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.076236 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.101395 47274652930944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882574.047359 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.048140 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.048922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.102641 47384557110144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882574.033822 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.034714 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.035537 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.102740 47382585521024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.102355 47274652930944 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk8dlid_w
I0618 12:29:34.103312 47274652930944 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpk8dlid_w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aff457b4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.103703 47274652930944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.104007 47769434473344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.104018 46984714605440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.103702 47384557110144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpokj0lgdc
W0618 12:29:34.103801 47382585521024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj44arcrt
I0618 12:29:34.104793 47384557110144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpokj0lgdc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b18dc480e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.104896 47382585521024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj44arcrt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1866c40e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.105235 47384557110144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.105340 47382585521024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.105892 47199381001088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.106058 47695482962816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.106069 47178046436224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.107254 47950018020224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.107259 47992713896832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.108252 47274652930944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.108867 47063261832064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.110785 47382585521024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.110811 47384557110144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.110731 46964279595904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.110778 47369731879808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882574.086299 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.086783 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.087135 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.114769 46926631781248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
:::MLL 1560882574.086070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.086483 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.086898 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.114828 48008889611136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.115711 46926631781248 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfk684huv
W0618 12:29:34.115774 48008889611136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuw8c57ok
I0618 12:29:34.116678 46926631781248 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfk684huv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aae3dce1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.116736 48008889611136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuw8c57ok', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa39660e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.117059 46926631781248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.117115 48008889611136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.121804 48008889611136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.121796 46926631781248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.125532 47199381001088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882574.101429 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.101893 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.102269 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.125582 47856494998400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.125884 47178046436224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.125874 47695482962816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.126105 47769434473344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.126151 46984714605440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.126921 47856494998400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsesbn3m7
I0618 12:29:34.127957 47856494998400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsesbn3m7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86bdf8ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:29:34.127898 47274652930944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:29:34.128367 47856494998400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882574.107342 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.107846 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.108239 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.130429 47757732402048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.131378 47757732402048 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6w8wsr0r
W0618 12:29:34.132211 47382585521024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:29:34.132334 47757732402048 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6w8wsr0r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6fbf431e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:29:34.132302 47384557110144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:29:34.132723 47757732402048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882574.112504 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.112935 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.113330 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.132032 47564216451968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.133019 47856494998400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.132959 47564216451968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqzn6haq1
I0618 12:29:34.133917 47564216451968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqzn6haq1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42b0d01e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.134316 47564216451968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:29:34.137398 47757732402048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.138822 47564216451968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882574.116941 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.117382 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.117776 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.140747 47131964900224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.141343 48008889611136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.141349 46926631781248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.141933 47294834152320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:29:34.142222 47595869361024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:29:34.142164 47131964900224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfkozj1px
I0618 12:29:34.143176 47131964900224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfkozj1px', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade0c9cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.143589 47131964900224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882574.123495 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882574.123909 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882574.124279 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:29:34.146561 47895566459776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz_0
W0618 12:29:34.146207 47294834152320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:29:34.146528 47595869361024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:29:34.147462 47895566459776 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjbe4hcw0
W0618 12:29:34.148287 47131964900224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:29:34.148407 47895566459776 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjbe4hcw0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8fd6cfee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:29:34.148789 47895566459776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:29:34.151264 47294834152320 estimator.py:1111] Calling model_fn.
W0618 12:29:34.151372 47294834152320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:29:34.151577 47595869361024 estimator.py:1111] Calling model_fn.
W0618 12:29:34.151690 47595869361024 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:29:34.152293 47378079462272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:29:34.152387 47409883353984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:29:34.152738 47294834152320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:29:34.153339 47895566459776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:29:34.153268 47856494998400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:29:34.153049 47595869361024 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:29:34.154795 47992713896832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:29:34.155051 47950018020224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:29:34.156902 47378079462272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is dep[2019-06-18 12:30:13] divide_golden_chunk finished: 3.294 seconds
[2019-06-18 12:30:13] generate golden chunk: 3.308 seconds
[2019-06-18 12:30:13] moving /lfs/lfs12/gma_akey/results/epb144/models/000002-000001.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000002-000002.meta
[2019-06-18 12:30:13] moving /lfs/lfs12/gma_akey/results/epb144/models/000002-000001.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000002-000002.data-00000-of-00001
[2019-06-18 12:30:13] moving /lfs/lfs12/gma_akey/results/epb144/models/000002-000001.index --> /lfs/lfs12/gma_akey/results/epb144/models/000002-000002.index
[2019-06-18 12:30:13] moving /lfs/lfs12/gma_akey/results/epb144/models/000002-000001.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb
[2019-06-18 12:30:13] iteration time 1: 48.358 seconds
2019-06-18 12:30:13.844414: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882613.445404 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 12:30:17] minmax time: 3.206 seconds
2019-06-18 12:30:17.060438: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:30:17.065746: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:30:17.070364: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882617.079724 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 1}}
[2019-06-18 12:30:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=4 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:30:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-3-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=3 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=1023779834 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=2047559665 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=3071339496 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=4095119327 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=5118899158 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=6142678989 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=7166458820 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=8190238651 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=9214018482 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=10237798313 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=11261578144 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=12285357975 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=13309137806 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=14332917637 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=15356697468 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=16380477299 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=17404257130 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=18428036961 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=19451816792 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000002-000002 --seed=20475596623 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:30:27] eval finished: 10.536 seconds
[2019-06-18 12:30:27] Win rate 000002-000002 vs 000001-000001: 0.470
:::MLL 1560882627.678699 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 1}}
[2019-06-18 12:30:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=4 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=1023779835 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=2047559666 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=3071339497 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=4095119328 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=5118899159 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=6142678990 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=7166458821 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=8190238652 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=9214018483 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=10237798314 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=11261578145 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=12285357976 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=13309137807 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=14332917638 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=15356697469 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=16380477300 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=17404257131 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000003-000001 --seed=18428036962 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:30:57] selfplay finished: 29.341 seconds
[2019-06-18 12:30:57] selfplay mn: 29.357 seconds
[2019-06-18 12:30:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-4-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779835 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559666 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339497 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119328 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899159 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678990 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458821 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238652 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018483 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798314 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578145 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357976 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137807 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917638 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697469 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477300 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257131 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036962 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816793 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596624 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376455 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156286 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000003-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:31:00] divide_golden_chunk finished: 3.226 seconds
[2019-06-18 12:31:00] generate golden chunk: 3.240 seconds
[2019-06-18 12:31:01] train finished: 44.427 seconds
:::MLL 1560882622.289778 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.290497 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.291183 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.354731 47410399556480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.283408 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.284299 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.285120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.354849 47452876911488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 12:30:22.355854 47410399556480 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ee09c8d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.356137 47452876911488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpm2i97u8q
I0618 12:30:22.357074 47410399556480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.357220 47452876911488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpm2i97u8q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28c4758e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.357661 47452876911488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.362561 47410399556480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.362993 47452876911488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882622.310177 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.310927 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.311584 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.374609 47567833912192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.303101 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.303980 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.304815 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.374671 46988554396544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.375688 47567833912192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1cyfv0vh
W0618 12:30:22.375715 46988554396544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuauoug8v
I0618 12:30:22.376784 47567833912192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1cyfv0vh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43886e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.376796 46988554396544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuauoug8v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abca8ae3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.377224 47567833912192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.377225 46988554396544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.382553 47567833912192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.382600 46988554396544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882622.332407 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.333217 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.333989 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.384475 47234490303360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.314219 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.315142 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.315981 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.384661 47234346591104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.385214 47410399556480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.385528 47452876911488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.385555 47234490303360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvr8tm1_6
W0618 12:30:22.385723 47234346591104 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8omclnhc
I0618 12:30:22.386667 47234490303360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvr8tm1_6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5eb9a5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.386805 47234346591104 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8omclnhc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5e3097dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.387112 47234490303360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.387243 47234346591104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.392687 47234490303360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.392684 47234346591104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882622.365570 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.365948 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.366267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.399686 47369667036032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.367400 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.367815 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.368175 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.399964 47624714396544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.400730 47369667036032 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9umdfhxp
W0618 12:30:22.400961 47624714396544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk43zz7zy
I0618 12:30:22.401800 47369667036032 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9umdfhxp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1564c39dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.402015 47624714396544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpk43zz7zy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b50c6c57dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.402241 47369667036032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.402450 47624714396544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882622.371064 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.371520 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.371922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.402455 47495562908544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.403497 47495562908544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsooe4kto
I0618 12:30:22.404558 47495562908544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsooe4kto', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32b4be2dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.405001 47495562908544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.404999 47567833912192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.405138 46988554396544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882622.336704 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.337433 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.338107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.405347 47639246816128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.332690 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.333560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.334311 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.405370 47671541490560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.406356 47671541490560 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgefejou5
W0618 12:30:22.406386 47639246816128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprkas7rbx
W0618 12:30:22.407296 47369667036032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:30:22.407360 47671541490560 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgefejou5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5bade23e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.407422 47624714396544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:30:22.407391 47639246816128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmprkas7rbx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5428f89e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.407754 47671541490560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.407785 47639246816128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.410192 47495562908544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882622.380211 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.380663 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.381060 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.410543 47809480704896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.411574 47809480704896 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_jsus7uk
I0618 12:30:22.412639 47809480704896 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_jsus7uk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bcbb38dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.412836 47671541490560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.412837 47639246816128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:30:22.413072 47809480704896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.415278 47234346591104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.415819 47234490303360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882622.340573 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.341498 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.342361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.415609 47680781689728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.347787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.348507 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.349158 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.415662 48003543208832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.416719 47680781689728 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4brhjj53
W0618 12:30:22.416752 48003543208832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp122h1jqt
I0618 12:30:22.417829 47680781689728 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4brhjj53', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5dd4a47e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.417859 48003543208832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp122h1jqt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8faba5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.417884 47809480704896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:30:22.418276 47680781689728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.418312 48003543208832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882622.356576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.357276 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.357986 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.418854 47283655725952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.344269 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.345187 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.346032 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.418866 47251913331584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.419949 47283655725952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpctureee1
W0618 12:30:22.419981 47251913331584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc5uewpcd
I0618 12:30:22.421035 47283655725952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpctureee1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b015e171e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.421072 47251913331584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc5uewpcd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af9fa189e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.421473 47283655725952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.421500 47251913331584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.423650 47680781689728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.423673 48003543208832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.426671 47283655725952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.426693 47251913331584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.428339 47369667036032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.428508 47624714396544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882622.397737 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.398173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.398543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.430199 47165292893056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.430952 47495562908544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.431272 47165292893056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5dyb_b07
I0618 12:30:22.432342 47165292893056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5dyb_b07', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5cf1dae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.432763 47165292893056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882622.401046 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.401513 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.401915 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.432882 47293500011392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.434379 47671541490560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.433875 47293500011392 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyis1q9eo
W0618 12:30:22.434731 47639246816128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:30:22.434945 47293500011392 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyis1q9eo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03a8db0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.435379 47293500011392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.437378 47410399556480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:30:22.437399 47452876911488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:30:22.437636 47809480704896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.437859 47165292893056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.440308 47293500011392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.441789 47410399556480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:30:22.441803 47452876911488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:30:22.445211 47680781689728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.445218 48003543208832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:30:22.446979 47410399556480 estimator.py:1111] Calling model_fn.
I0618 12:30:22.446990 47452876911488 estimator.py:1111] Calling model_fn.
W0618 12:30:22.447106 47410399556480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:30:22.447112 47452876911488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:30:22.447409 47283655725952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.447601 47251913331584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.448580 47410399556480 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:30:22.448547 47452876911488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560882622.417518 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.417908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.418233 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.451166 47324558287744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.420188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.420624 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.421009 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.452357 47614865347456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.452194 47324558287744 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplhr1ezp5
I0618 12:30:22.453214 47324558287744 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplhr1ezp5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ae412be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.453621 47324558287744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.453341 47614865347456 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkipc2k9i
:::MLL 1560882622.420199 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.420588 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.420909 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.453558 47754716656512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
I0618 12:30:22.454407 47614865347456 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkipc2k9i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e7bb8edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:30:22.454839 47614865347456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882622.421485 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.421871 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.422264 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.454238 46940812305280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.454582 47754716656512 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp030ffljt
I0618 12:30:22.455677 47754716656512 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp030ffljt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6f0b827e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.455284 46940812305280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyf4c5d2w
I0618 12:30:22.456116 47754716656512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.456590 47567833912192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:30:22.456335 46940812305280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyf4c5d2w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab18b07be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.456869 46988554396544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:30:22.456751 46940812305280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.458664 47324558287744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.459275 47165292893056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882622.425429 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.425825 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.426148 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.459333 47421081777024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
:::MLL 1560882622.426778 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882622.427158 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882622.427516 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:30:22.459423 47801600893824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz_0
W0618 12:30:22.459778 47614865347456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.460361 47421081777024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphgq9fomu
W0618 12:30:22.460464 47801600893824 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9i4gc55_
I0618 12:30:22.461436 47421081777024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphgq9fomu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b215d524e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.461225 47567833912192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:30:22.461517 47801600893824 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9i4gc55_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b79f6073e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:30:22.460950 47754716656512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.461559 47293500011392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:30:22.461546 46988554396544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:30:22.461872 47421081777024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:30:22.461939 47801600893824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:30:22.461441 46940812305280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:30:22.466807 47567833912192 estimator.py:1111] Calling model_fn.
W0618 12:30:22.466988 47421081777024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.467051 47801600893824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:30:22.466921 47567833912192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:30:22.467153 46988554396544 estimator.py:1111] Calling model_fn.
W0618 12:30:22.467267 46988554396544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:30:22.468383 47567833912192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:30:22.468719 46988554396544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:30:22.469220 47234346591104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.[2019-06-18 12:31:01] iteration time 2: 48.082 seconds
2019-06-18 12:31:01.956814: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882661.527226 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 12:31:05] minmax time: 3.218 seconds
2019-06-18 12:31:05.184046: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:31:05.189443: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:31:05.193993: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882665.205147 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 2}}
[2019-06-18 12:31:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000004-000002 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=5 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:31:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-4-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=4 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=1023779835 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=2047559666 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=3071339497 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=4095119328 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=5118899159 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=6142678990 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=7166458821 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=8190238652 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=9214018483 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=10237798314 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=11261578145 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=12285357976 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=13309137807 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=14332917638 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=15356697469 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=16380477300 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=17404257131 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=18428036962 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=19451816793 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000003-000002 --seed=20475596624 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:31:16] eval finished: 11.747 seconds
[2019-06-18 12:31:17] Win rate 000003-000002 vs 000001-000001: 0.730
:::MLL 1560882677.011967 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 2}}
[2019-06-18 12:31:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=5 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=1023779836 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=2047559667 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=3071339498 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=4095119329 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=5118899160 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=6142678991 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=7166458822 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=8190238653 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=9214018484 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=10237798315 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=11261578146 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=12285357977 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=13309137808 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=14332917639 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=15356697470 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=16380477301 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=17404257132 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000004-000001 --seed=18428036963 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:31:47] selfplay finished: 30.581 seconds
[2019-06-18 12:31:47] selfplay mn: 30.597 seconds
[2019-06-18 12:31:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-5-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779836 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559667 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339498 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119329 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899160 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678991 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458822 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238653 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018484 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798315 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578146 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357977 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137808 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917639 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697470 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477301 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257132 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036963 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816794 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596625 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376456 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156287 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000004-000001/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:31:49] train finished: 43.923 seconds
:::MLL 1560882670.390739 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.391628 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.392476 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.463714 47278472835968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560882670.395302 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.396013 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.396695 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.463796 47732255343488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 12:31:10.464828 47278472835968 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00292a8d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:31:10.464862 47732255343488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmpmfh_5r
I0618 12:31:10.465933 47732255343488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmpmfh_5r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b69d0b61dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.466052 47278472835968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.466378 47732255343488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.471281 47278472835968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.471475 47732255343488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882670.424799 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.425509 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.426232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.492580 47599441990528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560882670.419957 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.420838 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.421654 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.492724 47235328410496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.494410 47732255343488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.493653 47599441990528 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5h6fwm8h
:::MLL 1560882670.429942 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.430696 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.431463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.494375 47709478335360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.493753 47235328410496 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6y_f6zd3
I0618 12:31:10.494729 47599441990528 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5h6fwm8h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ae46b2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560882670.420108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.420990 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.421841 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.494688 47350288159616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.494876 47278472835968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:31:10.494828 47235328410496 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6y_f6zd3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af61d8ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.495178 47599441990528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.495265 47235328410496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.495432 47709478335360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmkf8wve9
W0618 12:31:10.495669 47350288159616 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8xapuy0q
I0618 12:31:10.496505 47709478335360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmkf8wve9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6483188e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.496698 47350288159616 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8xapuy0q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10e1b15dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.496950 47709478335360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.497125 47350288159616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.500470 47599441990528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.500503 47235328410496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.502367 47709478335360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.502386 47350288159616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882670.466569 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.466983 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.467307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.503932 47522011075456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.505018 47522011075456 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpom3ja30d
I0618 12:31:10.506124 47522011075456 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpom3ja30d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38dd2d1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.506578 47522011075456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882670.468765 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.469187 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.469519 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.507120 47675960136576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.508123 47675960136576 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_8ypo0sy
I0618 12:31:10.509132 47675960136576 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_8ypo0sy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5cb5415e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.509567 47675960136576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.511538 47522011075456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.514147 47675960136576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882670.443320 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.444113 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.444818 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.514077 48011180118912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560882670.445494 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.446178 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.446871 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.514228 47817944900480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.515107 48011180118912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4d6azsaq
W0618 12:31:10.515260 47817944900480 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp17gd50tz
I0618 12:31:10.516150 48011180118912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4d6azsaq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baac1ec6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.516299 47817944900480 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp17gd50tz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7dc434fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.516581 48011180118912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.516722 47817944900480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882670.481899 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.482294 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.482628 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.518210 47908015838080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560882670.483722 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.484093 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.484417 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.518410 47514358453120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.519238 47908015838080 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7owec_md
W0618 12:31:10.519398 47514358453120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpasug8ix2
I0618 12:31:10.520264 47908015838080 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7owec_md', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92bcda6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.520415 47514358453120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpasug8ix2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37150b6dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.520678 47908015838080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.520835 47514358453120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.521488 48011180118912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.521590 47817944900480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.522971 47599441990528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.523076 47235328410496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.523496 47709478335360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.524118 47350288159616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.525387 47908015838080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.525642 47514358453120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.531225 47522011075456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882670.461929 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.462670 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.463496 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.531298 47628270568320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560882670.463649 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.464404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.465102 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.531328 47568956605312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.532349 47628270568320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmgjdyx5_
I0618 12:31:10.533410 47628270568320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmgjdyx5_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b519abc5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:31:10.532628 47568956605312 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp30njzxsg
I0618 12:31:10.533734 47568956605312 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp30njzxsg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b43cb591e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.533830 47628270568320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.533780 47675960136576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:31:10.534169 47568956605312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882670.464145 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.465045 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.465883 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.537447 47931128066944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.539101 47628270568320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.539484 47568956605312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.538547 47931128066944 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpspoy0avx
I0618 12:31:10.539652 47931128066944 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpspoy0avx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b981e730e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.540093 47931128066944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882670.506119 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.506977 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.507752 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.543201 47439413408640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.544049 48011180118912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.544419 47817944900480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.545048 47732255343488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.545337 47278472835968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.545241 47908015838080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.544256 47439413408640 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpa2ra_5z7
W0618 12:31:10.545501 47514358453120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:31:10.545336 47439413408640 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpa2ra_5z7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b25a1f8be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:31:10.545579 47931128066944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:31:10.545758 47439413408640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882670.511916 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.512331 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.512675 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.547562 47604195722112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
:::MLL 1560882670.512483 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.512871 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.513193 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.547580 46994608178048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.548535 47604195722112 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9s_asv09
W0618 12:31:10.548566 46994608178048 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpw5mnawau
I0618 12:31:10.549502 47604195722112 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9s_asv09', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4bffc35e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.549531 46994608178048 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpw5mnawau', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abe11839e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:31:10.549541 47732255343488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:31:10.549829 47278472835968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:31:10.549888 47604195722112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.549917 46994608178048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.550815 47439413408640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.554554 47604195722112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.554562 46994608178048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:31:10.554754 47732255343488 estimator.py:1111] Calling model_fn.
W0618 12:31:10.554883 47732255343488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560882670.519909 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.520309 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.520649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.554877 47453671207808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
I0618 12:31:10.555063 47278472835968 estimator.py:1111] Calling model_fn.
:::MLL 1560882670.520881 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882670.521258 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882670.521611 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:31:10.554969 47326254584704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz_0
W0618 12:31:10.555179 47278472835968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:31:10.556342 47732255343488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:31:10.555831 47453671207808 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5f7mclvo
W0618 12:31:10.555922 47326254584704 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplbqq0r21
W0618 12:31:10.556648 47278472835968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:31:10.556803 47453671207808 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5f7mclvo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28f3cd7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.556898 47326254584704 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplbqq0r21', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b492e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:31:10.557187 47453671207808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:31:10.557285 47326254584704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:31:10.559099 47628270568320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.559582 47568956605312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.562016 47453671207808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.562040 47326254584704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:31:10.565805 47931128066944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.570764 47599441990528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.571033 47235328410496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.570931 47439413408640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.574107 47604195722112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.574299 46994608178048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.575099 47599441990528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:31:10.575377 47235328410496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:31:10.575648 47350288159616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.575603 47709478335360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.578747 47522011075456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.579958 47350288159616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:31:10.579982 47709478335360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:31:10.580175 47599441990528 estimator.py:1111] Calling model_fn.
W0618 12:31:10.580283 47599441990528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:31:10.580460 47235328410496 estimator.py:1111] Calling model_fn.
W0618 12:31:10.580568 47235328410496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:31:10.580704 47675960136576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:31:10.581468 47453671207808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.581639 47599441990528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:31:10.581816 47326254584704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:31:10.581935 47235328410496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:31:10.583052 47522011075456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:31:10.585006 47675960136576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:31:10.585009 47350288159616 estimator.py:1111] Calling model_fn.
I0618 12:31:10.585084 47709478335360 estimator.py:1111] Calling model_fn.
W0618 12:31:10.585117 47350288159616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:31:10.585194 47709478335360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:31:10.586485 47350288159616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:31:10.586568 47709478335360 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:31:10.588114 47522011075456 estimator.py:1111] Calling model_fn.
W0618 12:31:10.588222 47522011075456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560882670.554937 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.[2019-06-18 12:31:50] divide_golden_chunk finished: 3.351 seconds
[2019-06-18 12:31:50] generate golden chunk: 3.365 seconds
[2019-06-18 12:31:50] moving /lfs/lfs12/gma_akey/results/epb144/models/000004-000002.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb
[2019-06-18 12:31:50] moving /lfs/lfs12/gma_akey/results/epb144/models/000004-000002.index --> /lfs/lfs12/gma_akey/results/epb144/models/000004-000003.index
[2019-06-18 12:31:50] moving /lfs/lfs12/gma_akey/results/epb144/models/000004-000002.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000004-000003.meta
[2019-06-18 12:31:51] moving /lfs/lfs12/gma_akey/results/epb144/models/000004-000002.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000004-000003.data-00000-of-00001
[2019-06-18 12:31:51] iteration time 3: 49.487 seconds
2019-06-18 12:31:51.497969: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882711.014802 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 12:31:54] minmax time: 3.217 seconds
2019-06-18 12:31:54.725390: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:31:54.730786: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:31:54.735024: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882714.744737 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 3}}
[2019-06-18 12:31:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000005-000003 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=6 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:31:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-5-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=5 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=1023779836 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=2047559667 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=3071339498 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=4095119329 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=5118899160 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=6142678991 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=7166458822 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=8190238653 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=9214018484 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=10237798315 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=11261578146 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=12285357977 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=13309137808 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=14332917639 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=15356697470 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=16380477301 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=17404257132 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=18428036963 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=19451816794 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000004-000003 --seed=20475596625 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:32:06] eval finished: 11.491 seconds
[2019-06-18 12:32:06] Win rate 000004-000003 vs 000003-000002: 0.620
:::MLL 1560882726.297798 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 3}}
[2019-06-18 12:32:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=6 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=1023779837 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=2047559668 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=3071339499 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=4095119330 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=5118899161 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=6142678992 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=7166458823 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=8190238654 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=9214018485 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=10237798316 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=11261578147 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=12285357978 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=13309137809 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=14332917640 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=15356697471 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=16380477302 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=17404257133 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000005-000002 --seed=18428036964 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:32:36] selfplay finished: 30.154 seconds
[2019-06-18 12:32:36] selfplay mn: 30.174 seconds
[2019-06-18 12:32:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-6-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779837 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559668 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339499 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119330 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899161 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678992 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458823 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238654 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018485 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798316 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578147 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357978 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137809 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917640 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697471 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477302 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257133 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036964 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816795 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596626 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376457 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156288 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000005-000002/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:32:38] train finished: 43.968 seconds
:::MLL 1560882719.957303 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.958181 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.958966 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.030008 47700101686144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882719.964244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.965004 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.965655 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.030159 47699817489280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.031137 47700101686144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppu_ahxmi
W0618 12:32:00.031251 47699817489280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzgcmh2zj
I0618 12:32:00.032291 47700101686144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppu_ahxmi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6254343e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.032348 47699817489280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzgcmh2zj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b624343be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.032770 47700101686144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.032799 47699817489280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.038288 47699817489280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.038473 47700101686144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882719.969786 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.970559 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.971267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.046048 47197584868224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882719.971849 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.972560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.973230 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.046064 47190493737856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.047170 47197584868224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9ijvvonk
I0618 12:32:00.047208 47190493737856 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aebad340cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.048296 47197584868224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9ijvvonk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed53de1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.048441 47190493737856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.048753 47197584868224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.053735 47190493737856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.053887 47197584868224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882719.979662 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.980577 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.981411 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.054068 47510110737280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882719.987192 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.987926 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.988636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.054250 47901530293120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.055093 47510110737280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyha2ar4u
W0618 12:32:00.055222 47901530293120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp68xamy3n
I0618 12:32:00.056144 47510110737280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyha2ar4u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3617dc6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.056273 47901530293120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp68xamy3n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b913a48ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.056565 47510110737280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.056668 47901530293120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.061282 47699817489280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.061396 47901530293120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.061404 47510110737280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.062005 47700101686144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882720.026078 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.026454 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.026893 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.064860 47345436353408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882720.028656 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.029075 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.029454 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.065682 47316869526400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.065866 47345436353408 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5no2_ybr
I0618 12:32:00.066833 47345436353408 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5no2_ybr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fc080ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.067263 47345436353408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.066633 47316869526400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxx33toek
I0618 12:32:00.067667 47316869526400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxx33toek', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0919c98e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.068091 47316869526400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882720.000461 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.001205 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.001900 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.067898 47449437860736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882719.992664 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.993547 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.994377 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.067974 46947539870592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882719.992341 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.993167 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.993924 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.069056 47968270001024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882719.993354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882719.994171 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882719.994796 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.069139 47593810449280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.068946 47449437860736 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpobeij7l5
W0618 12:32:00.068993 46947539870592 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpx9ffhq9s
I0618 12:32:00.069984 47449437860736 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpobeij7l5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27f779be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.070042 46947539870592 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpx9ffhq9s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab31c063dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.070403 47449437860736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.070463 46947539870592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.070071 47968270001024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpon0yhfrr
W0618 12:32:00.070109 47593810449280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8iodoppx
I0618 12:32:00.071126 47968270001024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpon0yhfrr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba0c447fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.071149 47593810449280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8iodoppx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4994c0add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.071556 47968270001024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.071577 47593810449280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.072094 47345436353408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.072723 47316869526400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.075715 46947539870592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.075782 47449437860736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.076065 47190493737856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.076290 47197584868224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.076797 47968270001024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.076806 47593810449280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882720.014008 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.014752 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.015437 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.078022 47176152433536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882720.008004 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.008907 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.009732 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.078064 47388258034560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.079032 47176152433536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzbn5a6vb
W0618 12:32:00.079064 47388258034560 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1vwqgzc0
I0618 12:32:00.080026 47176152433536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzbn5a6vb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae856651dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.080054 47388258034560 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1vwqgzc0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19b8dfbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.080433 47176152433536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.080452 47388258034560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.081339 47901530293120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.081520 47510110737280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.085756 47388258034560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.085779 47176152433536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882720.047504 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.048016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.048442 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.085793 47074204865408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.086891 47074204865408 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpa_66_4ij
I0618 12:32:00.087998 47074204865408 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpa_66_4ij', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad099d8add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.088420 47074204865408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882720.051914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.052374 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.052794 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.088918 47420992344960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.089881 47420992344960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdxwmw2mn
I0618 12:32:00.090853 47420992344960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdxwmw2mn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2157fdae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.091247 47420992344960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882720.052791 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.053179 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.053498 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.090678 47294101865344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.091591 47345436353408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.092193 47316869526400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.091749 47294101865344 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphk8vie00
W0618 12:32:00.093135 47074204865408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:32:00.092747 47294101865344 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphk8vie00', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03ccba9dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560882720.055352 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.055826 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.056258 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.092634 47063432278912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
I0618 12:32:00.093146 47294101865344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.093592 47063432278912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuu0iair7
I0618 12:32:00.094543 47063432278912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuu0iair7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace17c00e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.094993 47063432278912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.095787 47420992344960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.097871 47593810449280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.097927 47968270001024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.098190 46947539870592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.097872 47294101865344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.098612 47449437860736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.099636 47063432278912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.105338 47388258034560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.105470 47176152433536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882720.071226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.071616 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.071946 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.108721 47082257523584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882720.072522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.072951 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.073389 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.109218 47146626532224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.109826 47700101686144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:00.110138 47699817489280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:00.109720 47082257523584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp71v7duq4
I0618 12:32:00.110704 47082257523584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp71v7duq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad279d27e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:32:00.110230 47146626532224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7bs9wxt5
I0618 12:32:00.111087 47082257523584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.111207 47146626532224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7bs9wxt5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae176839e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.111603 47146626532224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.112604 47074204865408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.114142 47700101686144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:00.114516 47699817489280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:00.115345 47420992344960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.115686 47082257523584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.116151 47146626532224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.117736 47294101865344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:32:00.119200 47700101686144 estimator.py:1111] Calling model_fn.
W0618 12:32:00.119308 47700101686144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:00.119108 47063432278912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:32:00.119623 47699817489280 estimator.py:1111] Calling model_fn.
W0618 12:32:00.119732 47699817489280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:00.120671 47700101686144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:00.121105 47699817489280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560882720.084718 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.085200 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.085577 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.123859 47515666805632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
:::MLL 1560882720.084703 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882720.085179 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882720.085557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:00.123941 47757744030592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz_0
W0618 12:32:00.124857 47515666805632 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpip0de7bo
W0618 12:32:00.124895 47757744030592 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc6ae17pn
W0618 12:32:00.125797 47190493737856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:32:00.125845 47515666805632 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpip0de7bo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3763073dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:00.125844 47757744030592 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc6ae17pn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6fbff47e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:32:00.125804 47197584868224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:32:00.126236 47757744030592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:00.126250 47515666805632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:00.129226 47901530293120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:00.129430 47510110737280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:00.130119 47190493737856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:00.130121 47197584868224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:00.130999 47515666805632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.131006 47757744030592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:00.133530 47901530293120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:00.133731 47510110737280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:32:00.135161 47197584868224 estimator.py:1111] Calling model_fn.
W0618 12:32:00.135211 47082257523584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:32:00.135205 47190493737856 estimator.py:1111] Calling model_fn.
W0618 12:32:00.135267 47197584868224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:00.135313 47190493737856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:00.135595 47146626532224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:00.136634 47197584868224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:00.136692 47190493737856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:00.139064 47345436353408 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function mai[2019-06-18 12:32:39] divide_golden_chunk finished: 3.308 seconds
[2019-06-18 12:32:39] generate golden chunk: 3.323 seconds
[2019-06-18 12:32:39] moving /lfs/lfs12/gma_akey/results/epb144/models/000005-000003.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000005-000004.meta
[2019-06-18 12:32:39] moving /lfs/lfs12/gma_akey/results/epb144/models/000005-000003.index --> /lfs/lfs12/gma_akey/results/epb144/models/000005-000004.index
[2019-06-18 12:32:39] moving /lfs/lfs12/gma_akey/results/epb144/models/000005-000003.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000005-000004.data-00000-of-00001
[2019-06-18 12:32:39] moving /lfs/lfs12/gma_akey/results/epb144/models/000005-000003.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb
[2019-06-18 12:32:39] iteration time 4: 48.821 seconds
2019-06-18 12:32:40.444109: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882759.835712 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 12:32:43] minmax time: 3.228 seconds
2019-06-18 12:32:43.682840: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:32:43.688424: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:32:43.693082: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882763.702850 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 4}}
[2019-06-18 12:32:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=7 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:32:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-6-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=6 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=1023779837 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=2047559668 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=3071339499 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=4095119330 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=5118899161 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=6142678992 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=7166458823 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=8190238654 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=9214018485 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=10237798316 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=11261578147 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=12285357978 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=13309137809 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=14332917640 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=15356697471 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=16380477302 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=17404257133 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=18428036964 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=19451816795 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000005-000004 --seed=20475596626 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:32:54] eval finished: 10.381 seconds
[2019-06-18 12:32:54] Win rate 000005-000004 vs 000004-000003: 0.390
:::MLL 1560882774.146601 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 4}}
[2019-06-18 12:32:54] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=7 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=1023779838 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=2047559669 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=3071339500 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=4095119331 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=5118899162 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=6142678993 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=7166458824 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=8190238655 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=9214018486 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=10237798317 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=11261578148 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=12285357979 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=13309137810 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=14332917641 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=15356697472 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=16380477303 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=17404257134 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000006-000003 --seed=18428036965 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:33:24] selfplay finished: 30.365 seconds
[2019-06-18 12:33:24] selfplay mn: 30.382 seconds
[2019-06-18 12:33:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-7-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779838 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559669 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339500 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119331 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899162 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678993 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458824 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238655 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018486 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798317 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578148 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357979 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137810 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917641 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697472 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477303 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257134 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036965 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816796 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596627 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376458 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156289 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000006-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:33:27] train finished: 43.484 seconds
:::MLL 1560882768.881487 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.882213 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.882983 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:48.947175 47272975840128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.870975 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.871848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.872676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:48.947295 47400872272768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
I0618 12:32:48.948218 47272975840128 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afee1850d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:32:48.948264 47400872272768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp2bmapd86
I0618 12:32:48.949255 47400872272768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp2bmapd86', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ca8bdbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:48.949312 47272975840128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:48.949663 47400872272768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:48.954415 47272975840128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:48.954566 47400872272768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882768.896811 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.897540 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.898227 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:48.966877 47901949739904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.893564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.894406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.895077 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:48.966889 47835347592064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:48.967964 47835347592064 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcshwp0_h
W0618 12:32:48.968027 47901949739904 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfcgfmokc
I0618 12:32:48.969010 47835347592064 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcshwp0_h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b81d17cee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:48.969076 47901949739904 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfcgfmokc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b915348fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:48.969423 47835347592064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:48.969501 47901949739904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:48.974206 47400872272768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:48.974304 47272975840128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:48.974606 47901949739904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:48.974609 47835347592064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882768.931570 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.932328 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.932928 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:48.995198 46962894775168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.922788 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.923678 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.924543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:48.995246 47564014060416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:48.996694 47835347592064 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:48.996270 46962894775168 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1hgi8wx1
W0618 12:32:48.996936 47901949739904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:48.996297 47564014060416 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpblhz5ypt
I0618 12:32:48.997347 46962894775168 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1hgi8wx1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6af3f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:48.997353 47564014060416 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpblhz5ypt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42a4bfddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:48.997782 46962894775168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:48.997781 47564014060416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:49.003227 46962894775168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.003260 47564014060416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882768.975384 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.975775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.976101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.016738 47249001329536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.976832 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.977206 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.977561 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.017028 47314900370304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.976181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.976660 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.977038 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.017147 46947715089280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.975692 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.976210 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.976633 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.017169 47706178458496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:49.017718 47249001329536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprsgkxb4r
I0618 12:32:49.018690 47249001329536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmprsgkxb4r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af94c86fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:32:49.017975 47314900370304 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp53dqs4xx
I0618 12:32:49.019004 47314900370304 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp53dqs4xx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b08a46a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.019077 47249001329536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:49.018244 46947715089280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6njuwivz
W0618 12:32:49.018273 47706178458496 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqoh0zff3
I0618 12:32:49.019219 46947715089280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6njuwivz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab32677be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.019242 47706178458496 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqoh0zff3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63be685dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.019403 47314900370304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.019617 46947715089280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.019637 47706178458496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:49.022982 46962894775168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.023176 47564014060416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882768.949006 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.949845 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.950685 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.023019 47774933975936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.959431 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.960294 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.961061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.023030 47910840238976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882768.970506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.971319 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.972075 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.023575 47715295982464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:49.023832 47249001329536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882768.941843 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.942764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.943594 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.023614 47619949945728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:49.024098 47314900370304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.024363 46947715089280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.024363 47706178458496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.024098 47910840238976 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8ieifjqe
W0618 12:32:49.024068 47774933975936 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphjibqh0g
W0618 12:32:49.024580 47715295982464 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk71pdmb9
W0618 12:32:49.024612 47619949945728 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwfj5_9ez
I0618 12:32:49.025045 47774933975936 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphjibqh0g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b73c08e4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.025084 47910840238976 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8ieifjqe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9365334e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.025628 47715295982464 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpk71pdmb9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65dddabe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.025652 47619949945728 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwfj5_9ez', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4faac99dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.025435 47774933975936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.025475 47910840238976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.026062 47715295982464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.026081 47619949945728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:49.026802 47400872272768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:49.027517 47272975840128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:49.030472 47910840238976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.030465 47774933975936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.031105 47400872272768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:49.031245 47619949945728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.031250 47715295982464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882768.964736 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.965471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.966135 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.031614 47708298687360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:49.031882 47272975840128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882768.957401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882768.958293 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882768.959162 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.031724 47938087125888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:49.032722 47708298687360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptd0y2xqw
W0618 12:32:49.032799 47938087125888 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcatvw0l7
I0618 12:32:49.033720 47708298687360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptd0y2xqw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b643cc87e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.033803 47938087125888 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcatvw0l7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b99bd3dde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.034118 47708298687360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.034200 47938087125888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.036173 47400872272768 estimator.py:1111] Calling model_fn.
W0618 12:32:49.036279 47400872272768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:32:49.036980 47272975840128 estimator.py:1111] Calling model_fn.
W0618 12:32:49.037090 47272975840128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:49.037663 47400872272768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:49.038458 47272975840128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:49.039269 47938087125888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.039286 47708298687360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.043412 47249001329536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.043637 47314900370304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.044082 46947715089280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.044145 47706178458496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.046640 47835347592064 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:49.046678 47901949739904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:49.050314 47910840238976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.050351 47774933975936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.050950 47901949739904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:49.050937 47835347592064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:49.052304 47619949945728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.052696 47715295982464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:32:49.055984 47901949739904 estimator.py:1111] Calling model_fn.
I0618 12:32:49.055981 47835347592064 estimator.py:1111] Calling model_fn.
W0618 12:32:49.056088 47901949739904 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:49.056089 47835347592064 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:49.057435 47901949739904 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:49.057443 47835347592064 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:49.061454 47708298687360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:32:49.061635 47938087125888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882769.020133 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.020516 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.020878 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.061586 47540974101376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882769.021048 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.021475 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.021823 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.061688 47654765921152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882769.020152 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.020652 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.021029 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.061180 47811952845696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
W0618 12:32:49.062583 47540974101376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc2qxvlax
W0618 12:32:49.062662 47654765921152 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbcbw_siz
W0618 12:32:49.062204 47811952845696 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp2sctjrbz
I0618 12:32:49.063567 47540974101376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc2qxvlax', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3d4775ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.063628 47654765921152 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbcbw_siz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b57c5fb5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.063212 47811952845696 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp2sctjrbz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c5f0d7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.063949 47540974101376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.064020 47654765921152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882769.023372 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.023832 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.024220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.063407 47869946291072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
I0618 12:32:49.063611 47811952845696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:49.064361 47869946291072 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0v7l1bov
I0618 12:32:49.065334 47869946291072 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0v7l1bov', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b89dfbb2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.065731 47869946291072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:32:49.068580 47540974101376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.068715 47654765921152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.068303 47811952845696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.070381 47869946291072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:32:49.071603 47564014060416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:49.071668 46962894775168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:32:49.075936 47564014060416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:32:49.076028 46962894775168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882769.040285 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.040767 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.041138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.080644 47198197056384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882769.040774 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.041201 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.041536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.080728 47921105232768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
:::MLL 1560882769.040061 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882769.040450 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882769.040769 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:32:49.080740 47233401267072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz_0
I0618 12:32:49.081050 47564014060416 estimator.py:1111] Calling model_fn.
I0618 12:32:49.081115 46962894775168 estimator.py:1111] Calling model_fn.
W0618 12:32:49.081166 47564014060416 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:49.081226 46962894775168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:32:49.081614 47198197056384 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp47ao9u__
W0618 12:32:49.081669 47921105232768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpo_uyz29m
W0618 12:32:49.082536 47564014060416 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:32:49.082588 46962894775168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:32:49.082583 47198197056384 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp47ao9u__', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aed785b5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.082642 47921105232768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpo_uyz29m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b95c90abdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:32:49.081801 47233401267072 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpohgfppgf
I0618 12:32:49.082847 47233401267072 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpohgfppgf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5aab0fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:32:49.082977 47198197056384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:32:49.083032 47921105232768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882769.042752 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 156088276[2019-06-18 12:33:27] divide_golden_chunk finished: 3.323 seconds
[2019-06-18 12:33:27] generate golden chunk: 3.338 seconds
[2019-06-18 12:33:27] iteration time 5: 48.032 seconds
2019-06-18 12:33:28.429903: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882807.868261 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 12:33:31] minmax time: 3.220 seconds
2019-06-18 12:33:31.660266: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:33:31.665579: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:33:31.670168: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882811.681578 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 5}}
[2019-06-18 12:33:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000007-000004 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=8 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:33:31] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-7-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=7 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=1023779838 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=2047559669 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=3071339500 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=4095119331 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=5118899162 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=6142678993 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=7166458824 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=8190238655 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=9214018486 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=10237798317 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=11261578148 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=12285357979 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=13309137810 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=14332917641 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=15356697472 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=16380477303 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=17404257134 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=18428036965 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=19451816796 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000006-000004 --seed=20475596627 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:33:43] eval finished: 11.585 seconds
[2019-06-18 12:33:43] Win rate 000006-000004 vs 000004-000003: 0.630
:::MLL 1560882823.330122 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 5}}
[2019-06-18 12:33:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=8 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=1023779839 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=2047559670 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=3071339501 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=4095119332 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=5118899163 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=6142678994 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=7166458825 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=8190238656 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=9214018487 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=10237798318 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=11261578149 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=12285357980 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=13309137811 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=14332917642 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=15356697473 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=16380477304 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=17404257135 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000007-000003 --seed=18428036966 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:34:12] selfplay finished: 29.659 seconds
[2019-06-18 12:34:13] selfplay mn: 29.678 seconds
[2019-06-18 12:34:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-8-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779839 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559670 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339501 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119332 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899163 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678994 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458825 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238656 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018487 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798318 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578149 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357980 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137811 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917642 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697473 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477304 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257135 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036966 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816797 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596628 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376459 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156290 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000007-000003/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:34:15] train finished: 43.404 seconds
:::MLL 1560882816.916461 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.917347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.918188 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:36.994039 47684621607808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882816.923069 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.923764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.924418 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:36.994155 47031393547136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
I0618 12:33:36.995100 47684621607808 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5eb984fd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:33:36.995119 47031393547136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmps49ywui7
I0618 12:33:36.996100 47031393547136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmps49ywui7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac6a217be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:36.996237 47684621607808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:36.996504 47031393547136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.001308 47684621607808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.001423 47031393547136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882816.923908 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.924815 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.925699 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.001694 47733255455616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882816.929630 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.930363 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.931023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.001748 47378508067712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.002674 47733255455616 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpva_mq1l9
W0618 12:33:37.002706 47378508067712 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgmv8kbd7
I0618 12:33:37.003708 47733255455616 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpva_mq1l9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6a0c529dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.003750 47378508067712 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgmv8kbd7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1773bb0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.004122 47733255455616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.004173 47378508067712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.009294 47733255455616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.009323 47378508067712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.023007 47684621607808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.023305 47031393547136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.029112 47733255455616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.029420 47378508067712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882816.957325 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.958114 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.958795 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.038649 47193727529856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882816.960417 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.961153 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.961849 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.038898 47750842499968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.039772 47193727529856 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzvhkhx5z
W0618 12:33:37.040005 47750842499968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxa0xmuux
I0618 12:33:37.040860 47193727529856 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzvhkhx5z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec6df3be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.041142 47750842499968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxa0xmuux', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6e24979e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.041297 47193727529856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.041587 47750842499968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.046653 47193727529856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.046926 47750842499968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882817.002861 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.003234 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.003559 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.050253 47205136954240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882817.001982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.002367 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.002777 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.050303 47176372683648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.051359 47205136954240 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5hzd1j4f
W0618 12:33:37.051388 47176372683648 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpo6jb8ovd
I0618 12:33:37.052366 47205136954240 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5hzd1j4f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef1601bdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.052382 47176372683648 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpo6jb8ovd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae86385de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.052755 47205136954240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.052768 47176372683648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882816.982260 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.983046 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.983732 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.056093 47634064593792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882816.980434 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.981240 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.982075 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.056136 47010576982912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.057488 47205136954240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.057490 47176372683648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.057116 47634064593792 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu9no_d0t
W0618 12:33:37.057146 47010576982912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphxx12t8u
I0618 12:33:37.058097 47634064593792 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu9no_d0t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52f4162e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.058111 47010576982912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphxx12t8u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac1c9543e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.058486 47634064593792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.058497 47010576982912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882817.020652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.021094 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.021468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.063925 47065524962176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.063476 47634064593792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.063481 47010576982912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882817.020605 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.021052 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.021428 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.063966 47520516350848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882817.007693 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.008190 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.008612 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.064843 47146049762176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882817.009721 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.010129 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.010487 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.065295 47694319575936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.064961 47065524962176 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcwnkijec
W0618 12:33:37.064990 47520516350848 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpv94rqs3v
I0618 12:33:37.065952 47520516350848 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpv94rqs3v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3884157e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.065950 47065524962176 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcwnkijec', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace947bce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560882816.982155 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.983034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.983926 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.065673 47868142367616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882816.995086 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.995844 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.996546 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.065708 47252776973184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
I0618 12:33:37.066351 47065524962176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.066408 47520516350848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.065919 47146049762176 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplw950zik
I0618 12:33:37.066902 47146049762176 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplw950zik', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae15422ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:33:37.066269 47694319575936 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp22q50krc
I0618 12:33:37.067219 47694319575936 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp22q50krc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60fb903e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.067293 47146049762176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.066705 47868142367616 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpptd6aeqz
W0618 12:33:37.066736 47252776973184 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsfxkahw6
I0618 12:33:37.067613 47694319575936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.067686 47868142367616 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpptd6aeqz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8974356e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.067707 47252776973184 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsfxkahw6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa2d92be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.068089 47868142367616 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.068108 47252776973184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.068808 47193727529856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.069127 47750842499968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.070994 47065524962176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.071031 47520516350848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.071996 47146049762176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.072239 47694319575936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882816.996537 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.997260 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.997958 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.072897 46927073592192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882816.992907 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882816.993819 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882816.994508 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.073066 47785935668096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.073480 47252776973184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.073493 47868142367616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.074056 46927073592192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpin2e87du
W0618 12:33:37.074116 47785935668096 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpe8lmclwa
I0618 12:33:37.075193 46927073592192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpin2e87du', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aae58238e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.075215 47785935668096 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpe8lmclwa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76504ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.075666 46927073592192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.075669 47785935668096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.076153 47031393547136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.076298 47684621607808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.077111 47205136954240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.077110 47176372683648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.077799 47733255455616 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.078724 47378508067712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.080659 47031393547136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.080845 47684621607808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.081029 47785935668096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.081078 46927073592192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.082123 47733255455616 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.083071 47378508067712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.083625 47634064593792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.083594 47010576982912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:33:37.086037 47031393547136 estimator.py:1111] Calling model_fn.
W0618 12:33:37.086163 47031393547136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:33:37.086219 47684621607808 estimator.py:1111] Calling model_fn.
W0618 12:33:37.086338 47684621607808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:33:37.087218 47733255455616 estimator.py:1111] Calling model_fn.
W0618 12:33:37.087326 47733255455616 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:33:37.087633 47031393547136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:33:37.087821 47684621607808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:33:37.088199 47378508067712 estimator.py:1111] Calling model_fn.
W0618 12:33:37.088309 47378508067712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:33:37.088702 47733255455616 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:33:37.089667 47378508067712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:33:37.090469 47520516350848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882817.047704 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.048200 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.048638 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.089975 47890358080384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.090735 47065524962176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.091444 47146049762176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.091754 47694319575936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.091074 47890358080384 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphvjltsu5
I0618 12:33:37.092153 47890358080384 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphvjltsu5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8ea05e6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.092589 47890358080384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882817.053855 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.054308 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.054719 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.095722 47898727273344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.096318 47252776973184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.096519 47868142367616 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.096806 47898727273344 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9i27n30r
W0618 12:33:37.097470 47890358080384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:33:37.097768 47898727273344 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9i27n30r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9093362e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.098163 47898727273344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.102936 47898727273344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.103863 47785935668096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.104061 46927073592192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882817.065526 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.065983 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.066371 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.109494 47979626132352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
:::MLL 1560882817.068481 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.068904 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.069293 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.109726 47707420636032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.110493 47979626132352 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp17nurn8g
I0618 12:33:37.111466 47979626132352 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp17nurn8g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba36928ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:33:37.110760 47707420636032 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3rcze3qy
I0618 12:33:37.111850 47707420636032 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3rcze3qy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6408728e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.111869 47979626132352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:33:37.112287 47707420636032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882817.069330 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.069736 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.070150 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.112121 47055669134208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.113154 47055669134208 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpov_nk360
I0618 12:33:37.114116 47055669134208 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpov_nk360', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc4907ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:33:37.114514 47055669134208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882817.075488 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882817.075971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882817.076419 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:33:37.115463 47391347721088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz_0
W0618 12:33:37.116617 47979626132352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.117189 47707420636032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.116561 47391347721088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5qv9kl4m
I0618 12:33:37.117546 47391347721088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5qv9kl4m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a71089e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:33:37.117207 47890358080384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:33:37.117931 47391347721088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:33:37.118093 47193727529856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.118222 47750842499968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.119063 47055669134208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.122524 47391347721088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:33:37.122375 47193727529856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.122503 47750842499968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.124579 47205136954240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:33:37.124211 47898727273344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:33:37.125026 47176372683648 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:33:37.127405 47193727529856 estimator.py:1111] Calling model_fn.
W0618 12:33:37.127509 47193727529856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:33:37.127555 47750842499968 estimator.py:1111] Calling model_fn.
W0618 12:33:37.127668 47750842499968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:33:37.128843 47205136954240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:33:37.128856 47193727529856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:33:37.129030 47750842499968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:33:37.129347 47176372683648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterato[2019-06-18 12:34:16] divide_golden_chunk finished: 3.322 seconds
[2019-06-18 12:34:16] generate golden chunk: 3.336 seconds
[2019-06-18 12:34:16] moving /lfs/lfs12/gma_akey/results/epb144/models/000007-000004.index --> /lfs/lfs12/gma_akey/results/epb144/models/000007-000005.index
[2019-06-18 12:34:16] moving /lfs/lfs12/gma_akey/results/epb144/models/000007-000004.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000007-000005.meta
[2019-06-18 12:34:16] moving /lfs/lfs12/gma_akey/results/epb144/models/000007-000004.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb
[2019-06-18 12:34:16] moving /lfs/lfs12/gma_akey/results/epb144/models/000007-000004.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000007-000005.data-00000-of-00001
[2019-06-18 12:34:16] iteration time 6: 48.518 seconds
2019-06-18 12:34:16.983117: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882856.386069 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 12:34:20] minmax time: 3.221 seconds
2019-06-18 12:34:20.214469: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:34:20.219911: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:34:20.224538: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882860.234333 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 6}}
[2019-06-18 12:34:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000008-000005 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=9 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir 
[2019-06-18 12:34:20] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-8-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=8 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=1023779839 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=2047559670 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=3071339501 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=4095119332 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=5118899163 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=6142678994 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=7166458825 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=8190238656 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=9214018487 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=10237798318 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=11261578149 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=12285357980 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=13309137811 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=14332917642 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=15356697473 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=16380477304 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=17404257135 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=18428036966 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=19451816797 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000007-000005 --seed=20475596628 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:34:30] eval finished: 10.604 seconds
[2019-06-18 12:34:30] Win rate 000007-000005 vs 000006-000004: 0.570
:::MLL 1560882870.901288 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 6}}
[2019-06-18 12:34:30] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=9 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=1023779840 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=2047559671 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=3071339502 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=4095119333 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=5118899164 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=6142678995 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=7166458826 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=8190238657 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=9214018488 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=10237798319 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=11261578150 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=12285357981 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=13309137812 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=14332917643 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=15356697474 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=16380477305 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=17404257136 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000008-000004 --seed=18428036967 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/
[2019-06-18 12:34:58] selfplay finished: 27.958 seconds
[2019-06-18 12:34:58] selfplay mn: 27.977 seconds
[2019-06-18 12:34:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-9-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779840 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559671 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339502 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119333 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899164 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678995 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458826 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238657 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018488 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798319 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578150 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357981 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137812 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917643 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697474 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477305 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257136 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036967 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816798 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596629 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376460 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156291 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000008-000004/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_
[2019-06-18 12:35:02] divide_golden_chunk finished: 3.305 seconds
[2019-06-18 12:35:02] generate golden chunk: 3.320 seconds
[2019-06-18 12:35:03] train finished: 43.704 seconds
:::MLL 1560882865.407650 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.408393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.409096 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.474862 47805111075712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.398906 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.399768 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.400589 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.474859 47339365942144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.475866 47805111075712 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpryzjqvv4
W0618 12:34:25.475840 47339365942144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpoov_pb3_
I0618 12:34:25.476817 47339365942144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpoov_pb3_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e56ad7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.476830 47805111075712 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpryzjqvv4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ac7405e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.477216 47805111075712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.477211 47339365942144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.482381 47339365942144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.482441 47805111075712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882865.409451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.410347 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.411170 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.489575 47672474936192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.415696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.416418 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.417094 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.489635 47817259230080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.490652 47672474936192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp27nmjufg
I0618 12:34:25.490740 47817259230080 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d9b566d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.491710 47672474936192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp27nmjufg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5be5856dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.491987 47817259230080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.492158 47672474936192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.497330 47817259230080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.497385 47672474936192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.505217 47339365942144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.505464 47805111075712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.519878 47817259230080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.520084 47672474936192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882865.477941 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.478323 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.478708 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.524211 48003057312640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.478734 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.479133 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.479487 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.524353 47019948209024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.525236 48003057312640 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppwe423mv
W0618 12:34:25.525362 47019948209024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpda0fmeb3
I0618 12:34:25.526230 48003057312640 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppwe423mv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8ddc43e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.526323 47019948209024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpda0fmeb3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac3f7e59dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.526633 48003057312640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.526718 47019948209024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882865.453534 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.454278 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.454954 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.527107 46929740186496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.449521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.450435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.451106 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.527216 47435716682624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.528130 46929740186496 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnola2pua
W0618 12:34:25.528188 47435716682624 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwrndw58_
I0618 12:34:25.529166 46929740186496 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnola2pua', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaef7148dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.529192 47435716682624 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwrndw58_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24c5a12e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.529585 46929740186496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.529608 47435716682624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.531263 47019948209024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.531277 48003057312640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882865.451592 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.452404 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.453045 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.534078 47490462004096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.455019 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.455735 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.456401 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.534308 47336668205952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.534669 46929740186496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.534648 47435716682624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882865.489016 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.489396 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.489736 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.534999 47487535285120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.490790 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.491157 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.491486 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.535433 46989661565824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.535087 47490462004096 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpoxf3nmgt
W0618 12:34:25.535261 47336668205952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyg9y9fd4
I0618 12:34:25.536142 47490462004096 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpoxf3nmgt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3184b48e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.536298 47336668205952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyg9y9fd4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0db5e16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.536577 47490462004096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.536710 47336668205952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.536023 47487535285120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc3iko0wa
I0618 12:34:25.537009 47487535285120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc3iko0wa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30d6424e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:34:25.536368 46989661565824 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpewur3bku
I0618 12:34:25.537342 46989661565824 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpewur3bku', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abceaac3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.537403 47487535285120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.537744 46989661565824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.541565 47490462004096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.541672 47336668205952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.542088 47487535285120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.542405 46989661565824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.550675 47019948209024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.550731 48003057312640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.555069 47805111075712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:34:25.555459 47339365942144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:34:25.556562 46929740186496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.556560 47435716682624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.559387 47805111075712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:34:25.559857 47339365942144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:34:25.561359 47490462004096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.561567 47487535285120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.561933 46989661565824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.562103 47336668205952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:34:25.564429 47805111075712 estimator.py:1111] Calling model_fn.
W0618 12:34:25.564537 47805111075712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:34:25.564952 47339365942144 estimator.py:1111] Calling model_fn.
W0618 12:34:25.565059 47339365942144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:34:25.565896 47805111075712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:34:25.566425 47339365942144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560882865.492289 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.493085 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.493786 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.567186 47171198296960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.490394 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.491116 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.491899 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.567244 47862148375424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.568209 47171198296960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9totkwgb
W0618 12:34:25.568241 47862148375424 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpptf3yk4n
W0618 12:34:25.569578 47817259230080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:34:25.569268 47171198296960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9totkwgb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae72f1aee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.569300 47862148375424 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpptf3yk4n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b880ef07e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:34:25.570131 47672474936192 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:34:25.569711 47171198296960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.569746 47862148375424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.573894 47817259230080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:34:25.574473 47672474936192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:34:25.574513 47171198296960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.574537 47862148375424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882865.495605 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.496526 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.497336 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.575325 46979899827072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.495547 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.496465 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.497279 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.575469 47234070131584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.576447 46979899827072 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6b6_r6qx
W0618 12:34:25.576536 47234070131584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp__s7uiix
I0618 12:34:25.577541 46979899827072 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6b6_r6qx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abaa4d3fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.577658 47234070131584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp__s7uiix', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af5d28f0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.577980 46979899827072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.578121 47234070131584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.578967 47817259230080 estimator.py:1111] Calling model_fn.
W0618 12:34:25.579077 47817259230080 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:34:25.579571 47672474936192 estimator.py:1111] Calling model_fn.
W0618 12:34:25.579678 47672474936192 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:34:25.580429 47817259230080 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:34:25.581046 47672474936192 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560882865.537435 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.537874 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.538268 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.582670 47451474269056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.583268 46979899827072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.583364 47234070131584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882865.536757 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.537184 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.537515 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.583579 47351445296000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.583680 47451474269056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7sc03uhr
I0618 12:34:25.584692 47451474269056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7sc03uhr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2870daee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560882865.541089 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.541546 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.541926 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.584639 47661812986752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.539585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.540044 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.540432 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.584706 47120536642432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 12:34:25.585083 47451474269056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.584677 47351445296000 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpur66gvak
I0618 12:34:25.585748 47351445296000 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpur66gvak', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1126a9ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.586140 47351445296000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.585614 47661812986752 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpw2ezpndf
W0618 12:34:25.585703 47120536642432 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwblqjeha
I0618 12:34:25.586584 47661812986752 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpw2ezpndf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b596a050dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.586672 47120536642432 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwblqjeha', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adb636f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.586977 47661812986752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:34:25.587077 47120536642432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:34:25.589781 47451474269056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.590814 47351445296000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.591603 47661812986752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.591687 47120536642432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:34:25.594534 47171198296960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.594747 47862148375424 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.598016 47019948209024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:34:25.598159 48003057312640 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:34:25.602288 47019948209024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:34:25.602441 48003057312640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882865.558870 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.559364 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.559800 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.604279 47815529579392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.605767 46979899827072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.605872 47234070131584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:34:25.605295 47815529579392 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpha0oh172
I0618 12:34:25.606307 47815529579392 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpha0oh172', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d343e1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:34:25.606729 47815529579392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882865.559227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.559713 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.560138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.607130 48000280179584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
I0618 12:34:25.607317 47019948209024 estimator.py:1111] Calling model_fn.
W0618 12:34:25.607403 46929740186496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:34:25.607426 47019948209024 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:34:25.607629 47435716682624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:34:25.607491 48003057312640 estimator.py:1111] Calling model_fn.
W0618 12:34:25.607601 48003057312640 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560882865.563519 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.563892 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.564222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.607712 47900717499264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
:::MLL 1560882865.564656 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882865.565112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882865.565513 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:34:25.607768 46947488519040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz_0
W0618 12:34:25.608098 48000280179584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk74mhlcg
W0618 12:34:25.608828 47487535285120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well a[2019-06-18 12:35:03] moving /lfs/lfs12/gma_akey/results/epb144/models/000008-000005.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000008-000006.meta
[2019-06-18 12:35:03] moving /lfs/lfs12/gma_akey/results/epb144/models/000008-000005.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb
[2019-06-18 12:35:03] moving /lfs/lfs12/gma_akey/results/epb144/models/000008-000005.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000008-000006.data-00000-of-00001
[2019-06-18 12:35:03] moving /lfs/lfs12/gma_akey/results/epb144/models/000008-000005.index --> /lfs/lfs12/gma_akey/results/epb144/models/000008-000006.index
[2019-06-18 12:35:04] iteration time 7: 47.620 seconds
2019-06-18 12:35:04.633032: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882904.005794 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 12:35:07] minmax time: 3.211 seconds
2019-06-18 12:35:07.854080: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:35:07.859520: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:35:07.864203: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882907.874407 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 7}}
[2019-06-18 12:35:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000009-000006 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=10 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:35:07] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-9-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=9 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=1023779840 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=2047559671 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=3071339502 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=4095119333 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=5118899164 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=6142678995 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=7166458826 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=8190238657 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=9214018488 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=10237798319 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=11261578150 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=12285357981 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=13309137812 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=14332917643 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=15356697474 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=16380477305 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=17404257136 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=18428036967 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=19451816798 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000008-000006 --seed=20475596629 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/result
[2019-06-18 12:35:18] eval finished: 10.643 seconds
[2019-06-18 12:35:18] Win rate 000008-000006 vs 000007-000005: 0.650
:::MLL 1560882918.577862 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 7}}
[2019-06-18 12:35:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=10 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=1023779841 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=2047559672 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=3071339503 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=4095119334 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=5118899165 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=6142678996 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=7166458827 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=8190238658 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=9214018489 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=10237798320 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=11261578151 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=12285357982 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=13309137813 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=14332917644 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=15356697475 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=16380477306 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=17404257137 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000009-000005 --seed=18428036968 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:35:49] selfplay finished: 31.286 seconds
[2019-06-18 12:35:49] selfplay mn: 31.303 seconds
[2019-06-18 12:35:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-10-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779841 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559672 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339503 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119334 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899165 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678996 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458827 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238658 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018489 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798320 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578151 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357982 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137813 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917644 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697475 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477306 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257137 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036968 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816799 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596630 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376461 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156292 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000009-000005/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:35:51] train finished: 43.503 seconds
:::MLL 1560882913.095012 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.095728 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.096382 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.173348 47971417097088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.092729 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.093467 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.094169 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.173416 47523509068672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.174357 47971417097088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf39jkpgm
I0618 12:35:13.174434 47523509068672 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b393676bd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.175414 47971417097088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf39jkpgm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba17fdcce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.175730 47523509068672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.175870 47971417097088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.181079 47971417097088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.181159 47523509068672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882913.104233 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.105145 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.106020 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.190382 47787773539200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.191478 47787773539200 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyrh6uhac
I0618 12:35:13.192591 47787773539200 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyrh6uhac', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76bdda8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.193041 47787773539200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882913.110894 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.111786 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.112527 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.194082 47174487565184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.112031 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.112799 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.113482 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.195428 46916446208896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.195215 47174487565184 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqs9hksvt
I0618 12:35:13.196347 47174487565184 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqs9hksvt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7f3291e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.196804 47174487565184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.196448 46916446208896 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbvj13mxa
I0618 12:35:13.197511 46916446208896 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbvj13mxa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aabdeb28e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.197954 46916446208896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882913.148699 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.149456 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.150233 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.197762 47179967935360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.198408 47787773539200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.198706 47179967935360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpy7mapyk6
I0618 12:35:13.199683 47179967935360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpy7mapyk6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae939d0fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.200069 47179967935360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882913.119618 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.120373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.120976 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.200925 47068494812032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.118257 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.118987 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.119813 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.200966 47979146281856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.202131 47174487565184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.201985 47068494812032 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgp3uf6s1
W0618 12:35:13.202013 47979146281856 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpai57a72m
I0618 12:35:13.203067 47068494812032 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgp3uf6s1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf45802e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.203116 47979146281856 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpai57a72m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba34c8ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:35:13.203078 46916446208896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.203392 47971417097088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:35:13.203506 47068494812032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.203551 47979146281856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.203744 47523509068672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.204808 47179967935360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.208583 47979146281856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.208585 47068494812032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.218311 47787773539200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882913.174244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.174669 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.175025 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.221417 47325055800192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.171926 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.172308 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.172639 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.221426 47055466443648 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.222429 47325055800192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgvau4pxl
W0618 12:35:13.222462 47055466443648 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpd0cx4isi
I0618 12:35:13.223413 47325055800192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgvau4pxl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0b01ba1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.223430 47055466443648 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpd0cx4isi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc3cf2fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.223815 47325055800192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.223819 47055466443648 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.224547 47174487565184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.225082 46916446208896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.224906 47179967935360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882913.177354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.177776 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.178110 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.226754 47497335223168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.180005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.180391 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.180727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.226775 47704619393920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.228286 47979146281856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.228346 47068494812032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.228449 47325055800192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.228494 47055466443648 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.227774 47497335223168 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpezqa5f9o
W0618 12:35:13.227805 47704619393920 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpv238riho
I0618 12:35:13.228817 47497335223168 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpezqa5f9o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b331e618e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.228842 47704619393920 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpv238riho', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b63617afe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.229203 47497335223168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.229231 47704619393920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882913.152181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.153090 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.153882 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.232879 47535663965056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.158476 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.159185 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.159842 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.232995 47123954500480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.233857 47704619393920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.233873 47497335223168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.233951 47535663965056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpm55ylhbk
W0618 12:35:13.234044 47123954500480 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpa8mafwoe
I0618 12:35:13.235021 47535663965056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpm55ylhbk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3c0af3be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.235128 47123954500480 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpa8mafwoe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adc2f27de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.235458 47535663965056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.235560 47123954500480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.240672 47535663965056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.240712 47123954500480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882913.168320 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.169034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.169694 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.242053 47193609134976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.153476 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.154367 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.155180 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.242181 47395758240640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.243082 47193609134976 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjroiwpnc
W0618 12:35:13.243136 47395758240640 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyusio6c8
I0618 12:35:13.244082 47193609134976 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjroiwpnc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aec66e52e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.244128 47395758240640 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyusio6c8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b77ebce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.244506 47193609134976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.244526 47395758240640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.247768 47325055800192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.247881 47055466443648 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882913.200623 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.201034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.201389 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.247306 47470956417920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
:::MLL 1560882913.202226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.202686 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.203047 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.248404 47976327291776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.248310 47470956417920 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvlvr8c01
W0618 12:35:13.249675 47395758240640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.249687 47193609134976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:35:13.249280 47470956417920 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvlvr8c01', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2cfa14ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.249671 47470956417920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.249366 47976327291776 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp30b8totc
I0618 12:35:13.250338 47976327291776 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp30b8totc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2a4887e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.250733 47976327291776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.253206 47523509068672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.253324 47971417097088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.253203 47704619393920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.253371 47497335223168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.254367 47470956417920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.255316 47976327291776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882913.210884 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.211325 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.211689 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.257246 46963936949120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.257529 47523509068672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:35:13.257646 47971417097088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882913.213373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882913.213839 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882913.214228 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:35:13.258481 47884467680128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz_0
W0618 12:35:13.258241 46963936949120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0euu30wu
I0618 12:35:13.259308 46963936949120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0euu30wu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab6ed5dce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.259714 46963936949120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:35:13.259513 47884467680128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp74uy089l
I0618 12:35:13.260484 47884467680128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp74uy089l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d4145fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:35:13.260874 47884467680128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:35:13.262573 47523509068672 estimator.py:1111] Calling model_fn.
W0618 12:35:13.262680 47523509068672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:35:13.262698 47971417097088 estimator.py:1111] Calling model_fn.
W0618 12:35:13.262809 47971417097088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:35:13.262820 47535663965056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.262871 47123954500480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.264037 47523509068672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:35:13.264171 47971417097088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:35:13.264344 46963936949120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.265455 47884467680128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:35:13.266366 47787773539200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.270656 47787773539200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:35:13.272350 47395758240640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.272442 47193609134976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.272155 47179967935360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.273927 47470956417920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.274757 47976327291776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.275279 47174487565184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.275926 46916446208896 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:35:13.275690 47787773539200 estimator.py:1111] Calling model_fn.
W0618 12:35:13.275800 47787773539200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:35:13.276451 47068494812032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.276458 47979146281856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:35:13.276444 47179967935360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:35:13.277154 47787773539200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:35:13.279938 47174487565184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:35:13.280761 47979146281856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:35:13.280685 46916446208896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:35:13.280769 47068494812032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:35:13.281499 47179967935360 estimator.py:1111] Calling model_fn.
W0618 12:35:13.281608 47179967935360 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:35:13.282960 47179967935360 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:35:13.283708 46963936949120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:35:13.285080 47884467680128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:35:13.285149 47174487565184 estimator.py:1111] Calling model_fn.
W0618 12:35:13.285257 47174487565184 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:35:13.285842 47068494812032 estimator.py:1111] Calling model_fn.
I0618 12:35:13.285796 47979146281856 estimator.py:1111] Calling model_fn.
W0618 12:35:13.285907 47979146281856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:35:13.285950 47068494812032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:35:13.285840 46916446208896 estimator.py:1111] Calling model_fn.
W0618 12:35:13.285944 46916446208896 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:35:13.286614 47174487565184 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:35:13.287321 47068494812032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site[2019-06-18 12:35:53] divide_golden_chunk finished: 3.318 seconds
[2019-06-18 12:35:53] generate golden chunk: 3.331 seconds
[2019-06-18 12:35:53] moving /lfs/lfs12/gma_akey/results/epb144/models/000009-000006.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb
[2019-06-18 12:35:53] moving /lfs/lfs12/gma_akey/results/epb144/models/000009-000006.index --> /lfs/lfs12/gma_akey/results/epb144/models/000009-000007.index
[2019-06-18 12:35:53] moving /lfs/lfs12/gma_akey/results/epb144/models/000009-000006.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000009-000007.data-00000-of-00001
[2019-06-18 12:35:53] moving /lfs/lfs12/gma_akey/results/epb144/models/000009-000006.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000009-000007.meta
[2019-06-18 12:35:53] iteration time 8: 49.246 seconds
2019-06-18 12:35:53.925248: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560882953.251969 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 12:35:57] minmax time: 3.223 seconds
2019-06-18 12:35:57.157991: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:35:57.163346: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:35:57.167883: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560882957.178126 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 8}}
[2019-06-18 12:35:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000010-000007 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=11 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:35:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-10-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=10 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=1023779841 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=2047559672 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=3071339503 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=4095119334 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=5118899165 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=6142678996 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=7166458827 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=8190238658 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=9214018489 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=10237798320 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=11261578151 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=12285357982 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=13309137813 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=14332917644 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=15356697475 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=16380477306 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=17404257137 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=18428036968 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=19451816799 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000009-000007 --seed=20475596630 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:36:08] eval finished: 11.270 seconds
[2019-06-18 12:36:08] Win rate 000009-000007 vs 000008-000006: 0.540
:::MLL 1560882968.511362 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 8}}
[2019-06-18 12:36:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=11 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=1023779842 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=2047559673 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=3071339504 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=4095119335 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=5118899166 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=6142678997 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=7166458828 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=8190238659 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=9214018490 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=10237798321 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=11261578152 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=12285357983 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=13309137814 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=14332917645 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=15356697476 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=16380477307 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=17404257138 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000010-000006 --seed=18428036969 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:36:39] selfplay finished: 31.028 seconds
[2019-06-18 12:36:39] selfplay mn: 31.047 seconds
[2019-06-18 12:36:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-11-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779842 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559673 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339504 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119335 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899166 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678997 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458828 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238659 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018490 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798321 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578152 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357983 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137814 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917645 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697476 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477307 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257138 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036969 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816800 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596631 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376462 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156293 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000010-000006/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:36:40] train finished: 43.524 seconds
:::MLL 1560882962.352444 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.353353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.354197 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.440282 47424645723008 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.363147 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.363886 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.364530 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.440275 47289302004608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.441358 47424645723008 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp512v5q14
W0618 12:36:02.441385 47289302004608 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpg7tw_gv0
I0618 12:36:02.442454 47424645723008 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp512v5q14', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2231bfcdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.442466 47289302004608 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpg7tw_gv0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b02aea27e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.442908 47424645723008 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.442909 47289302004608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882962.356296 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.357130 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.357843 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.443379 47907245933440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.355665 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.356512 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.357325 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.443520 47595635901312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 12:36:02.444550 47907245933440 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b928ef69d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:36:02.444597 47595635901312 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwti1ihdj
I0618 12:36:02.445754 47595635901312 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwti1ihdj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a018ebe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.445841 47907245933440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.446204 47595635901312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.448345 47289302004608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.448411 47424645723008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882962.368172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.369107 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.369998 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.450150 47021708854144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.392647 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.393462 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.394232 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.450358 47377277162368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.451206 47907245933440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.451321 47595635901312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.451185 47021708854144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmcwywg3i
W0618 12:36:02.451333 47377277162368 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4_fc4fs4
I0618 12:36:02.452240 47021708854144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmcwywg3i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac460d71e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.452364 47377277162368 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4_fc4fs4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b172a5cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.452662 47021708854144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.452783 47377277162368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.457705 47021708854144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.457726 47377277162368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.470579 47289302004608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.470961 47424645723008 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.473741 47595635901312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.473788 47907245933440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.477339 47021708854144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.477458 47377277162368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882962.432345 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.432807 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.433213 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.487607 47648659010432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.437361 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.437873 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.438220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.487804 47984276042624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.488685 47648659010432 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpossx651v
W0618 12:36:02.488900 47984276042624 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpog4htrur
I0618 12:36:02.489752 47648659010432 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpossx651v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5659fb4dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.490017 47984276042624 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpog4htrur', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba47e50ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.490178 47648659010432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.490466 47984276042624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882962.435645 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.436019 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.436335 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.493567 47204657046400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.437305 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.437776 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.438115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.493677 47083215635328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.494960 47648659010432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.494537 47204657046400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpr57lky17
W0618 12:36:02.495300 47984276042624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.494666 47083215635328 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp2c9bhj5x
I0618 12:36:02.495651 47083215635328 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp2c9bhj5x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad2b2ee0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.495510 47204657046400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpr57lky17', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeef966fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.496044 47083215635328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.495947 47204657046400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560882962.418291 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.419066 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.419816 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.496111 47726918357888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.421106 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.421849 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.422533 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.496108 47104212710272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.497290 47726918357888 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzhbzau4y
W0618 12:36:02.497320 47104212710272 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdqj08rmm
I0618 12:36:02.498363 47726918357888 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzhbzau4y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b68929a2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.498379 47104212710272 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdqj08rmm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad79673de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.498793 47726918357888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.498799 47104212710272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.500597 47083215635328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.500649 47204657046400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.503870 47726918357888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.503889 47104212710272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.514930 47984276042624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.515023 47648659010432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882962.437695 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.438602 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.439471 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.515765 47415716995968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.437640 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.438541 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.439409 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.515916 47711638983552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.430244 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.431146 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.432034 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.516228 47222569014144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.437045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.437795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.438488 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.516567 47929024824192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.516760 47415716995968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj7yrarwr
W0618 12:36:02.516906 47711638983552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl1rhjtnj
I0618 12:36:02.517767 47415716995968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj7yrarwr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b201d8e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.517927 47711638983552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl1rhjtnj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6503e16dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.518187 47415716995968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.517336 47222569014144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpeb1a536v
I0618 12:36:02.518347 47711638983552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.518471 47222569014144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpeb1a536v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af32509de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:36:02.517665 47929024824192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpog_uaiju
I0618 12:36:02.518816 47929024824192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpog_uaiju', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b97a1161e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.518927 47222569014144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.519271 47929024824192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.519898 47083215635328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.520251 47204657046400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.522663 47424645723008 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:02.522786 47289302004608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:02.523013 47415716995968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.523148 47711638983552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.523796 47907245933440 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:02.524122 47595635901312 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:02.524241 47222569014144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.523970 47104212710272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.524138 47726918357888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.524727 47929024824192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882962.473365 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.473764 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.474130 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.524707 47518576796544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.473530 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.473945 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.474283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.524859 47762720916352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.525725 47518576796544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7c6ajupk
W0618 12:36:02.525811 47762720916352 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkpcxtxz3
I0618 12:36:02.526730 47518576796544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7c6ajupk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38107a3dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.526789 47762720916352 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkpcxtxz3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70e899de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.527155 47518576796544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:02.527214 47762720916352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.527268 47424645723008 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:02.527430 47289302004608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:02.528089 47907245933440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:02.528462 47595635901312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560882962.482460 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.482971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.483418 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.528929 47487991276416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.530698 47377277162368 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:02.531213 47021708854144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:02.529986 47487991276416 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyoz2z6n2
I0618 12:36:02.531072 47487991276416 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyoz2z6n2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30f1702e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.531504 47487991276416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.531902 47518576796544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.531885 47762720916352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:36:02.532704 47424645723008 estimator.py:1111] Calling model_fn.
W0618 12:36:02.532825 47424645723008 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:36:02.532881 47289302004608 estimator.py:1111] Calling model_fn.
W0618 12:36:02.532999 47289302004608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:36:02.533154 47907245933440 estimator.py:1111] Calling model_fn.
W0618 12:36:02.533264 47907245933440 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:36:02.533546 47595635901312 estimator.py:1111] Calling model_fn.
W0618 12:36:02.533656 47595635901312 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:36:02.534292 47424645723008 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:02.534449 47289302004608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:02.534635 47907245933440 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:02.535012 47595635901312 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:02.535000 47377277162368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:02.535545 47021708854144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:02.536623 47487991276416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560882962.492519 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.492999 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.493398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.538474 47771747513216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
I0618 12:36:02.540058 47377277162368 estimator.py:1111] Calling model_fn.
W0618 12:36:02.540165 47377277162368 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:36:02.540635 47021708854144 estimator.py:1111] Calling model_fn.
W0618 12:36:02.540745 47021708854144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:36:02.539526 47771747513216 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6nfsi0e7
I0618 12:36:02.540618 47771747513216 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6nfsi0e7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7302a0be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.541073 47771747513216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:02.541521 47377277162368 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:02.542110 47021708854144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:02.542856 47415716995968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.543043 47711638983552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.546127 47771747513216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:02.546689 47222569014144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.547735 47929024824192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.551313 47518576796544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.551314 47762720916352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560882962.509284 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.509779 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.510206 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.558169 47260586066816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.509029 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.509444 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.509832 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.558180 47664324625280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
:::MLL 1560882962.509407 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560882962.509848 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560882962.510170 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:02.558300 47666945823616 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz_0
W0618 12:36:02.558503 47487991276416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:02.559265 47260586066816 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbdwn9iny
W0618 12:36:02.559225 47664324625280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4rwaxxnm
W0618 12:36:02.559328 47666945823616 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9cmwysoi
I0618 12:36:02.560287 47664324625280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4rwaxxnm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b59ffb99dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:02.560315 47260586066816 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbdwn9iny', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afbff081[2019-06-18 12:36:42] divide_golden_chunk finished: 3.321 seconds
[2019-06-18 12:36:42] generate golden chunk: 3.335 seconds
[2019-06-18 12:36:42] moving /lfs/lfs12/gma_akey/results/epb144/models/000010-000007.index --> /lfs/lfs12/gma_akey/results/epb144/models/000010-000008.index
[2019-06-18 12:36:42] moving /lfs/lfs12/gma_akey/results/epb144/models/000010-000007.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000010-000008.data-00000-of-00001
[2019-06-18 12:36:42] moving /lfs/lfs12/gma_akey/results/epb144/models/000010-000007.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb
[2019-06-18 12:36:42] moving /lfs/lfs12/gma_akey/results/epb144/models/000010-000007.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000010-000008.meta
[2019-06-18 12:36:42] iteration time 9: 49.682 seconds
2019-06-18 12:36:43.647958: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883002.933707 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 12:36:46] minmax time: 3.225 seconds
2019-06-18 12:36:46.883111: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:36:46.888463: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:36:46.893017: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883006.903279 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 9}}
[2019-06-18 12:36:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000011-000008 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=12 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:36:46] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-11-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=11 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=1023779842 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=2047559673 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=3071339504 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=4095119335 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=5118899166 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=6142678997 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=7166458828 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=8190238659 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=9214018490 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=10237798321 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=11261578152 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=12285357983 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=13309137814 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=14332917645 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=15356697476 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=16380477307 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=17404257138 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=18428036969 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=19451816800 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000010-000008 --seed=20475596631 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:36:58] eval finished: 11.278 seconds
[2019-06-18 12:36:58] Win rate 000010-000008 vs 000009-000007: 0.670
:::MLL 1560883018.244575 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 9}}
[2019-06-18 12:36:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=12 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=1023779843 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=2047559674 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=3071339505 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=4095119336 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=5118899167 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=6142678998 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=7166458829 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=8190238660 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=9214018491 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=10237798322 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=11261578153 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=12285357984 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=13309137815 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=14332917646 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=15356697477 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=16380477308 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=17404257139 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000011-000007 --seed=18428036970 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:37:28] selfplay finished: 30.747 seconds
[2019-06-18 12:37:29] selfplay mn: 30.766 seconds
[2019-06-18 12:37:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-12-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779843 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559674 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339505 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119336 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899167 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678998 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458829 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238660 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018491 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798322 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578153 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357984 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137815 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917646 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697477 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477308 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257139 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036970 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816801 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596632 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376463 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156294 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000011-000007/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:37:30] train finished: 43.335 seconds
:::MLL 1560883012.082665 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.083369 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.084044 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.163029 47023616062336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.080739 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.081510 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.082293 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.163104 47425109492608 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.164097 47023616062336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpboty5c8e
I0618 12:36:52.164218 47425109492608 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b224d645d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.165243 47023616062336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpboty5c8e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac4d284be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.165501 47425109492608 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.165695 47023616062336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.170760 47425109492608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.170861 47023616062336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.193163 47023616062336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.193233 47425109492608 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883012.159000 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.159423 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.159771 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.211311 47099524727680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.212310 47099524727680 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_m7tnkha
I0618 12:36:52.213280 47099524727680 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_m7tnkha', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad67f06fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.213669 47099524727680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883012.159578 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.159968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.160288 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.216743 47112572932992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.218337 47099524727680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.217750 47112572932992 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpp86sxmq6
I0618 12:36:52.218786 47112572932992 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpp86sxmq6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad988c2edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.219172 47112572932992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883012.136722 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.137611 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.138470 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.219357 47563193164672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.149463 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.150253 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.151034 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.219433 47607601775488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.220340 47563193164672 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmaocwkya
W0618 12:36:52.220432 47607601775488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpb82of97r
I0618 12:36:52.221336 47563193164672 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmaocwkya', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4273d1fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.221424 47607601775488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpb82of97r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4ccac79e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.221732 47563193164672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.221825 47607601775488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.223581 47112572932992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.226747 47563193164672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.226845 47607601775488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.237970 47099524727680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883012.149928 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.150813 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.151684 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.240535 47079450723200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.170508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.171311 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.172111 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.240489 47934634406784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.152508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.153287 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.153998 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.240780 47804996862848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.155042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.155776 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.156450 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.240826 47331333960576 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.241464 47934634406784 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7cjgwkfy
W0618 12:36:52.241556 47079450723200 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf_j717xn
I0618 12:36:52.242622 47934634406784 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7cjgwkfy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b98ef717e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.242675 47079450723200 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf_j717xn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1d2861dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:36:52.241768 47804996862848 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp05ex932k
I0618 12:36:52.243035 47934634406784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.241802 47331333960576 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpibguldoq
I0618 12:36:52.243087 47079450723200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.243045 47112572932992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:36:52.242816 47804996862848 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp05ex932k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ac0719dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.242827 47331333960576 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpibguldoq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c77ef4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.243265 47331333960576 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.243270 47804996862848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.245207 47425109492608 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.245289 47023616062336 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.248079 47079450723200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.248073 47934634406784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.248251 47563193164672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.248054 47331333960576 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.248077 47804996862848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.248770 47607601775488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.249834 47425109492608 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:52.249932 47023616062336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883012.180454 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.181228 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.181931 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.250068 47267232801664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.168709 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.169643 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.170479 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.250194 47339104854912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.251112 47267232801664 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7otjy_wn
W0618 12:36:52.251231 47339104854912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdodv9hlm
I0618 12:36:52.252176 47267232801664 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7otjy_wn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afd8b352e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.252288 47339104854912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdodv9hlm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0e471dae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.252602 47267232801664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.252706 47339104854912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.255305 47425109492608 estimator.py:1111] Calling model_fn.
I0618 12:36:52.255395 47023616062336 estimator.py:1111] Calling model_fn.
W0618 12:36:52.255421 47425109492608 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:36:52.255520 47023616062336 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:36:52.256891 47425109492608 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:52.256973 47023616062336 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:52.257642 47339104854912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.257614 47267232801664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.267773 47331333960576 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.267957 47804996862848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.270453 47079450723200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.270554 47934634406784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883012.191985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.192898 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.193770 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.271812 47632479499136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.208780 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.209609 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.210357 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.271949 47175332451200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.272922 47632479499136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9sq_tgbb
W0618 12:36:52.273009 47175332451200 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmph1e9ymeh
I0618 12:36:52.274008 47632479499136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9sq_tgbb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52959b8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.274088 47175332451200 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmph1e9ymeh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae825852e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.274448 47632479499136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.274527 47175332451200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.277185 47267232801664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.277460 47339104854912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.279814 47175332451200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.279824 47632479499136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883012.228365 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.228862 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.229234 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.281582 47033830462336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.229522 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.229971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.230359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.282006 47942773793664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.227949 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.228410 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.228851 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.281628 47349590016896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.283039 47942773793664 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpca07viay
W0618 12:36:52.282694 47033830462336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsqlrh7bu
I0618 12:36:52.284041 47942773793664 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpca07viay', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ad496be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:36:52.282752 47349590016896 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpugqc21np
I0618 12:36:52.283791 47033830462336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsqlrh7bu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac733582dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.283973 47349590016896 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpugqc21np', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10b8149e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.284433 47942773793664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.284209 47033830462336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.284394 47349590016896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883012.233952 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.234393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.234770 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.284800 47082054058880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.285656 47099524727680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.285732 47082054058880 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj3a74dpb
I0618 12:36:52.286695 47082054058880 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj3a74dpb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad26db1ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.287117 47082054058880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.288763 47033830462336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.289310 47942773793664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.288906 47349590016896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.289994 47099524727680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:52.290115 47112572932992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.291736 47082054058880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.294423 47112572932992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:36:52.295097 47099524727680 estimator.py:1111] Calling model_fn.
W0618 12:36:52.295206 47099524727680 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:36:52.296579 47099524727680 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883012.244632 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.245112 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.245648 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.297184 47182345241472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
:::MLL 1560883012.244691 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.245168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.245734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.297198 47425169548160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.298218 47182345241472 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8ow5hndp
W0618 12:36:52.298243 47425169548160 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpq7cwr3ed
I0618 12:36:52.299192 47182345241472 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8ow5hndp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae9c783de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.299215 47425169548160 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpq7cwr3ed', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2250f89e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.299457 47112572932992 estimator.py:1111] Calling model_fn.
W0618 12:36:52.299566 47112572932992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:36:52.299597 47182345241472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:36:52.299609 47425169548160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:36:52.300302 47563193164672 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.300920 47112572932992 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:52.301343 47607601775488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.301607 47175332451200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.301779 47632479499136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.304189 47182345241472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.304202 47425169548160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:36:52.304693 47563193164672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:52.305781 47607601775488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:36:52.308253 47033830462336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.308342 47349590016896 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.308847 47942773793664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:36:52.309718 47563193164672 estimator.py:1111] Calling model_fn.
W0618 12:36:52.309829 47563193164672 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:36:52.310848 47607601775488 estimator.py:1111] Calling model_fn.
W0618 12:36:52.310961 47607601775488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:36:52.311186 47563193164672 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:36:52.311345 47082054058880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:36:52.312319 47607601775488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883012.261909 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.262342 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.262744 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.314921 47271298401152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.315134 47331333960576 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.315402 47804996862848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:36:52.315989 47271298401152 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxrvrxrnj
I0618 12:36:52.316982 47271298401152 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxrvrxrnj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe7d895e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:36:52.317374 47271298401152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883012.266783 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883012.267241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883012.267636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:36:52.317539 47683901596544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000001-000000.tfrecord.zz_0_0
W0618 12:36:52.318516 47683901596544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprtphe76a
I0618 12:36:52.319487 47683901596544 estimator[2019-06-18 12:37:32] divide_golden_chunk finished: 3.234 seconds
[2019-06-18 12:37:32] generate golden chunk: 3.248 seconds
[2019-06-18 12:37:32] moving /lfs/lfs12/gma_akey/results/epb144/models/000011-000008.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000011-000009.meta
[2019-06-18 12:37:32] moving /lfs/lfs12/gma_akey/results/epb144/models/000011-000008.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000011-000009.data-00000-of-00001
[2019-06-18 12:37:32] moving /lfs/lfs12/gma_akey/results/epb144/models/000011-000008.index --> /lfs/lfs12/gma_akey/results/epb144/models/000011-000009.index
[2019-06-18 12:37:32] moving /lfs/lfs12/gma_akey/results/epb144/models/000011-000008.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb
[2019-06-18 12:37:32] iteration time 10: 49.366 seconds
2019-06-18 12:37:33.054353: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883052.300280 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 12:37:36] minmax time: 3.206 seconds
2019-06-18 12:37:36.270651: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:37:36.276110: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:37:36.280682: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883056.292421 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 10}}
[2019-06-18 12:37:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000012-000009 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=13 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:37:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-12-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=12 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=1023779843 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=2047559674 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=3071339505 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=4095119336 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=5118899167 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=6142678998 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=7166458829 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=8190238660 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=9214018491 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=10237798322 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=11261578153 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=12285357984 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=13309137815 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=14332917646 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=15356697477 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=16380477308 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=17404257139 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=18428036970 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=19451816801 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000011-000009 --seed=20475596632 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:37:47] eval finished: 11.387 seconds
[2019-06-18 12:37:47] Win rate 000011-000009 vs 000010-000008: 0.590
:::MLL 1560883067.742990 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 10}}
[2019-06-18 12:37:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=13 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=1023779844 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=2047559675 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=3071339506 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=4095119337 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=5118899168 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=6142678999 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=7166458830 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=8190238661 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=9214018492 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=10237798323 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=11261578154 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=12285357985 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=13309137816 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=14332917647 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=15356697478 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=16380477309 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=17404257140 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000012-000008 --seed=18428036971 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:38:16] selfplay finished: 29.184 seconds
[2019-06-18 12:38:16] selfplay mn: 29.201 seconds
[2019-06-18 12:38:16] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-13-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779844 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559675 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339506 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119337 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899168 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142678999 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458830 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238661 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018492 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798323 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578154 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357985 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137816 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917647 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697478 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477309 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257140 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036971 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816802 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596633 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376464 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156295 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000012-000008/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:38:20] train finished: 43.792 seconds
:::MLL 1560883061.468362 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.469168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.469899 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.535435 47761716392832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.452104 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.452963 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.453758 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.535488 47213784400768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.536457 47213784400768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpb4hcxn5o
I0618 12:37:41.536496 47761716392832 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b70acb9fd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.537478 47213784400768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpb4hcxn5o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af1196f5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.537601 47761716392832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.537877 47213784400768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.542621 47761716392832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.542744 47213784400768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.562966 47761716392832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.563067 47213784400768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883061.499784 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.500684 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.501502 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.582943 47554730435456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.506797 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.507532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.508203 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.583045 47184382559104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.583938 47554730435456 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_tsk2555
W0618 12:37:41.584019 47184382559104 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpe3m553pw
I0618 12:37:41.584971 47554730435456 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_tsk2555', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b407b66fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.585028 47184382559104 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpe3m553pw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea40f2de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.585386 47554730435456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.585443 47184382559104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.590344 47554730435456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.590353 47184382559104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883061.551533 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.551911 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.552235 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.607505 47606041297792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.553871 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.554253 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.554611 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.608387 47975406732160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.608500 47606041297792 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_4yjccka
I0618 12:37:41.609490 47606041297792 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_4yjccka', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c6dc49e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.609889 47606041297792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.609365 47975406732160 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgtecn6kj
I0618 12:37:41.610330 47975406732160 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgtecn6kj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba26da9ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.610722 47975406732160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.611958 47554730435456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.611992 47184382559104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.614521 47606041297792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.615247 47975406732160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.615762 47761716392832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:37:41.615759 47213784400768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:37:41.620079 47761716392832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:37:41.620053 47213784400768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883061.539767 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.540670 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.541523 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.624817 47818383709056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.547451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.548173 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.548812 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.624893 47153980142464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 12:37:41.625177 47761716392832 estimator.py:1111] Calling model_fn.
I0618 12:37:41.625135 47213784400768 estimator.py:1111] Calling model_fn.
W0618 12:37:41.625245 47213784400768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:37:41.625284 47761716392832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:37:41.625816 47818383709056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj536dbuo
W0618 12:37:41.626590 47213784400768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:37:41.625869 47153980142464 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkohh6vh3
W0618 12:37:41.626642 47761716392832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:37:41.626827 47818383709056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj536dbuo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7dde5cae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.626864 47153980142464 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkohh6vh3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae32cd2ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.627236 47818383709056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.627268 47153980142464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.632368 47818383709056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.632396 47153980142464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.633979 47606041297792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.634456 47975406732160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883061.563751 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.564605 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.565386 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.645067 47842341905280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.563401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.564280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.565072 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.645136 47183073112960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.646092 47842341905280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpve04zuoh
W0618 12:37:41.646122 47183073112960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz9khh92x
I0618 12:37:41.647101 47842341905280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpve04zuoh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b837261be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.647125 47183073112960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz9khh92x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae9f2e64e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.647574 47183073112960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.647610 47842341905280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883061.583706 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.584152 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.584536 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.647778 46939656258432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.587549 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.587968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.588360 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.648162 47064041395072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.648791 46939656258432 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_8u4oedd
W0618 12:37:41.649106 47064041395072 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpe_991jf2
I0618 12:37:41.649842 46939656258432 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_8u4oedd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1461fde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.650145 47064041395072 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpe_991jf2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace3c0e6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.650269 46939656258432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.650565 47064041395072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.652419 47183073112960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.652426 47842341905280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.653685 47818383709056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.654132 47153980142464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883061.565773 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.566685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.567529 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.654839 47221930009472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.575174 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.575914 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.576605 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.654877 47206186910592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.654938 46939656258432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.655152 47064041395072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.655877 47221930009472 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpt48hs46v
W0618 12:37:41.655907 47206186910592 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzfcyjmxk
I0618 12:37:41.656917 47221930009472 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpt48hs46v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af2fef37dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.656934 47206186910592 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzfcyjmxk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef5496de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.657351 47221930009472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.657356 47206186910592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.662657 47206186910592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.662733 47221930009472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.665026 47554730435456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:37:41.665361 47184382559104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:37:41.669659 47554730435456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:37:41.670009 47184382559104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:37:41.672092 47183073112960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.672223 47842341905280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.674248 46939656258432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.674445 47064041395072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:37:41.675108 47554730435456 estimator.py:1111] Calling model_fn.
W0618 12:37:41.675223 47554730435456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:37:41.675507 47184382559104 estimator.py:1111] Calling model_fn.
W0618 12:37:41.675627 47184382559104 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:37:41.676670 47554730435456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:37:41.677092 47184382559104 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:37:41.681705 47606041297792 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:37:41.681856 47975406732160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883061.579819 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.580682 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.581448 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.681963 47346088604544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.580401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.581264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.582002 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.681986 47470781457280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.683056 47346088604544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpa5k5misj
W0618 12:37:41.683088 47470781457280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1de98a0z
I0618 12:37:41.684150 47346088604544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpa5k5misj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0fe7614dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.684166 47470781457280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1de98a0z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2cefa72e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.684548 47346088604544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.684979 47206186910592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:37:41.684559 47470781457280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.685069 47221930009472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.686051 47606041297792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:37:41.686167 47975406732160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:37:41.689350 47470781457280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.689371 47346088604544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:37:41.691168 47606041297792 estimator.py:1111] Calling model_fn.
I0618 12:37:41.691232 47975406732160 estimator.py:1111] Calling model_fn.
W0618 12:37:41.691277 47606041297792 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:37:41.691339 47975406732160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560883061.635021 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.635423 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.635765 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.691910 47146298336128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.634904 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.635320 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.635663 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.692151 47171816813440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.692657 47606041297792 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:37:41.692698 47975406732160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:37:41.692933 47146298336128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpse1mm913
W0618 12:37:41.693169 47171816813440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpw4g0iod7
:::MLL 1560883061.639539 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.640034 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.640484 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.693678 46998433211264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
I0618 12:37:41.693914 47146298336128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpse1mm913', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae162f3ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.694139 47171816813440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpw4g0iod7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae753f8ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.694311 47146298336128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:37:41.694527 47171816813440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.694732 46998433211264 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplgvm7dcw
I0618 12:37:41.695763 46998433211264 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplgvm7dcw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abef580fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:37:41.696192 46998433211264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.699005 47146298336128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883061.647246 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.647733 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.648215 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.698999 47051854726016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.699184 47171816813440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.699950 47051854726016 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp60rfavgb
I0618 12:37:41.700929 47051854726016 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp60rfavgb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb65ac9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:37:41.700958 46998433211264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:37:41.701320 47051854726016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.705884 47051854726016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:37:41.705781 47818383709056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:37:41.706312 47153980142464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883061.653813 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.654184 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.654506 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.707950 47084900475776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
:::MLL 1560883061.655830 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883061.656207 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883061.656540 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:37:41.709224 47874592207744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000002-000000.tfrecord.zz_0_0
W0618 12:37:41.708911 47346088604544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.709030 47470781457280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:37:41.708957 47084900475776 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1pmb4t66
I0618 12:37:41.709942 47084900475776 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1pmb4t66', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3175abe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:37:41.710098 47818383709056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:37:41.710335 47084900475776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:37:41.710651 47153980142464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.[2019-06-18 12:38:20] divide_golden_chunk finished: 3.305 seconds
[2019-06-18 12:38:20] generate golden chunk: 3.319 seconds
[2019-06-18 12:38:20] moving /lfs/lfs12/gma_akey/results/epb144/models/000012-000009.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb
[2019-06-18 12:38:20] moving /lfs/lfs12/gma_akey/results/epb144/models/000012-000009.index --> /lfs/lfs12/gma_akey/results/epb144/models/000012-000010.index
[2019-06-18 12:38:20] moving /lfs/lfs12/gma_akey/results/epb144/models/000012-000009.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000012-000010.data-00000-of-00001
[2019-06-18 12:38:20] moving /lfs/lfs12/gma_akey/results/epb144/models/000012-000009.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000012-000010.meta
[2019-06-18 12:38:20] iteration time 11: 48.012 seconds
2019-06-18 12:38:21.108982: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883100.312050 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 12:38:24] minmax time: 3.287 seconds
2019-06-18 12:38:24.405363: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:38:24.410763: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:38:24.415273: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883104.425680 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 11}}
[2019-06-18 12:38:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=14 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:38:24] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-13-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=13 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=1023779844 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=2047559675 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=3071339506 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=4095119337 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=5118899168 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=6142678999 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=7166458830 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=8190238661 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=9214018492 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=10237798323 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=11261578154 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=12285357985 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=13309137816 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=14332917647 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=15356697478 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=16380477309 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=17404257140 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=18428036971 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=19451816802 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000012-000010 --seed=20475596633 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:38:35] eval finished: 10.700 seconds
[2019-06-18 12:38:35] Win rate 000012-000010 vs 000011-000009: 0.430
:::MLL 1560883115.187542 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 11}}
[2019-06-18 12:38:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=14 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=1023779845 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=2047559676 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=3071339507 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=4095119338 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=5118899169 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=6142679000 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=7166458831 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=8190238662 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=9214018493 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=10237798324 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=11261578155 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=12285357986 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=13309137817 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=14332917648 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=15356697479 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=16380477310 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=17404257141 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000013-000009 --seed=18428036972 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:39:04] selfplay finished: 28.820 seconds
[2019-06-18 12:39:04] selfplay mn: 28.840 seconds
[2019-06-18 12:39:04] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-14-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779845 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559676 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339507 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119338 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899169 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679000 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458831 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238662 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018493 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798324 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578155 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357986 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137817 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917648 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697479 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477310 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257141 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036972 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816803 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596634 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376465 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156296 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000013-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:39:07] divide_golden_chunk finished: 3.314 seconds
[2019-06-18 12:39:07] generate golden chunk: 3.329 seconds
[2019-06-18 12:39:08] train finished: 43.752 seconds
:::MLL 1560883109.634034 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.634932 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.635727 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.723764 47272086733696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.633816 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.634677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.635488 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.723815 46992283202432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.724894 47272086733696 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpujzy50tw
I0618 12:38:29.724953 46992283202432 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd86ef4cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.725971 47272086733696 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpujzy50tw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afeac865e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.726202 46992283202432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.726411 47272086733696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883109.653181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.653950 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.654680 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.728531 47725485732736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.638909 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.639815 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.640674 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.728775 47780566430592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.729714 47725485732736 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpaw495wcg
W0618 12:38:29.729917 47780566430592 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpygt_orvp
I0618 12:38:29.730823 47725485732736 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpaw495wcg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b683d360e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.731017 47780566430592 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpygt_orvp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b751046ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.731282 47725485732736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.731476 47780566430592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.731637 46992283202432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.731664 47272086733696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.736745 47725485732736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.736809 47780566430592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883109.668393 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.669117 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.669808 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.749222 47216992551808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.664632 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.665517 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.666184 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.749302 47792799277952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.750295 47216992551808 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu9y0_q_n
W0618 12:38:29.750373 47792799277952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpufhdsgna
I0618 12:38:29.751302 47216992551808 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu9y0_q_n', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af1d8a7de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.751364 47792799277952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpufhdsgna', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77e9693e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.751705 47216992551808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.751778 47792799277952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.753958 46992283202432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.754006 47272086733696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.756480 47792799277952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.756480 47216992551808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.759297 47725485732736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.759665 47780566430592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.776264 47792799277952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.776624 47216992551808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883109.696583 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.697285 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.697984 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.777307 47005664916352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.684391 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.685303 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.686127 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.777275 47110853227392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.710639 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.711068 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.711458 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.778170 47531625022336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.714576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.714959 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.715286 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.778161 47017045803904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.683511 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.684411 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.685239 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.778449 47855578805120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.701501 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.702164 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.702835 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.778574 47030635664256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.778355 47005664916352 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1wk483na
W0618 12:38:29.778384 47110853227392 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj6vzkgxc
I0618 12:38:29.779421 47005664916352 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1wk483na', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac0a48c0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.779451 47110853227392 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj6vzkgxc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad922422e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.779847 47005664916352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.779881 47110853227392 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.779186 47531625022336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxgsckqpz
W0618 12:38:29.779215 47017045803904 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3soi2r4e
I0618 12:38:29.780200 47531625022336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxgsckqpz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b1a365e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.780244 47017045803904 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3soi2r4e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac34ae69e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:38:29.779539 47855578805120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf47zlf9b
W0618 12:38:29.779613 47030635664256 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcjg2f3h2
I0618 12:38:29.780625 47531625022336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.780673 47017045803904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.780602 47855578805120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf47zlf9b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86875cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.780691 47030635664256 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcjg2f3h2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac674eb5dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.781069 47855578805120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.781169 47030635664256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883109.725210 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.725666 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.726083 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.780833 47557996200832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.781826 47557996200832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwx_j3955
I0618 12:38:29.782856 47557996200832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwx_j3955', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b413e0e9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.783270 47557996200832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.785103 47110853227392 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883109.730735 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.731193 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.731586 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.784842 47482827469696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.785144 47005664916352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.785331 47531625022336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.785329 47017045803904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.786384 47855578805120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.786471 47030635664256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.785830 47482827469696 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpd7av7ue0
I0618 12:38:29.786884 47482827469696 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpd7av7ue0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2fbda6be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.787273 47482827469696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.788073 47557996200832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883109.730616 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.731049 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.731433 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.791262 46952546829184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.791817 47482827469696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883109.725722 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.726286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.726794 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.791307 47457271104384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.712721 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.713418 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.714077 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.791965 47479670625152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.708943 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.709857 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.710523 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.792073 47033028502400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.792276 46952546829184 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpblmcome_
W0618 12:38:29.792305 47457271104384 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqu4fs6pk
I0618 12:38:29.793308 46952546829184 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpblmcome_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab446764e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.793342 47457271104384 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqu4fs6pk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29ca5f9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:38:29.793099 47479670625152 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpg0rjybe4
W0618 12:38:29.793204 47033028502400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpocsen5as
I0618 12:38:29.793737 46952546829184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.794247 47479670625152 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpg0rjybe4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f017d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.793769 47457271104384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.794315 47033028502400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpocsen5as', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac7038b3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.794709 47479670625152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:38:29.794767 47033028502400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.798576 47457271104384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.798607 46952546829184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.800163 47033028502400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.800230 47479670625152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:38:29.803734 46992283202432 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:38:29.804029 47272086733696 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:38:29.804762 47017045803904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.804794 47531625022336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.804872 47005664916352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.805046 47110853227392 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.807352 47557996200832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.808018 46992283202432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:38:29.808363 47272086733696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:38:29.808389 47725485732736 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:38:29.808440 47780566430592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:38:29.808841 47855578805120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.809001 47030635664256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.811172 47482827469696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.812685 47725485732736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:38:29.812735 47780566430592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:38:29.813045 46992283202432 estimator.py:1111] Calling model_fn.
W0618 12:38:29.813153 46992283202432 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:38:29.813479 47272086733696 estimator.py:1111] Calling model_fn.
W0618 12:38:29.813590 47272086733696 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:38:29.814492 46992283202432 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:38:29.814944 47272086733696 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:38:29.817767 47725485732736 estimator.py:1111] Calling model_fn.
I0618 12:38:29.817798 47780566430592 estimator.py:1111] Calling model_fn.
W0618 12:38:29.817872 47725485732736 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:38:29.817903 47780566430592 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:38:29.818142 47457271104384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.818191 46952546829184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.819218 47725485732736 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:38:29.819272 47780566430592 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:38:29.822763 47033028502400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.822990 47479670625152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:38:29.823835 47792799277952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:38:29.824182 47216992551808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:38:29.828130 47792799277952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:38:29.828478 47216992551808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:38:29.833348 47792799277952 estimator.py:1111] Calling model_fn.
W0618 12:38:29.833469 47792799277952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:38:29.833788 47216992551808 estimator.py:1111] Calling model_fn.
W0618 12:38:29.833911 47216992551808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:38:29.834896 47792799277952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:38:29.835300 47216992551808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883109.777661 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.778055 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.778379 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.837346 47553820439424 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.838359 47553820439424 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdwjt4atu
I0618 12:38:29.839351 47553820439424 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdwjt4atu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4045298e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.839751 47553820439424 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883109.779018 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.779418 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.779740 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.839750 47189044544384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.840838 47189044544384 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp677lrdew
I0618 12:38:29.841968 47189044544384 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp677lrdew', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aeb56d31e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.842421 47189044544384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:38:29.844490 47553820439424 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883109.789709 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.790090 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.790415 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.846189 47971503723392 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.789038 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.789434 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.789773 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.846173 47252019262336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
:::MLL 1560883109.789807 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.790206 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.790576 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.847141 47883003474816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.847569 47189044544384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883109.790681 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883109.791060 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883109.791397 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:38:29.847628 48006300074880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000003-000001.tfrecord.zz_0_0
W0618 12:38:29.847243 47971503723392 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpota3nd1y
W0618 12:38:29.847214 47252019262336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpp00y8seg
I0618 12:38:29.848188 47252019262336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpp00y8seg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa00690e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:38:29.848201 47971503723392 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpota3nd1y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_clu[2019-06-18 12:39:08] iteration time 12: 47.886 seconds
2019-06-18 12:39:09.039539: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883148.198475 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 12:39:12] minmax time: 3.236 seconds
2019-06-18 12:39:12.285126: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:39:12.290560: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:39:12.295220: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883152.307370 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 12}}
[2019-06-18 12:39:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=15 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:39:12] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-14-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=14 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=1023779845 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=2047559676 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=3071339507 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=4095119338 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=5118899169 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=6142679000 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=7166458831 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=8190238662 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=9214018493 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=10237798324 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=11261578155 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=12285357986 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=13309137817 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=14332917648 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=15356697479 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=16380477310 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=17404257141 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=18428036972 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=19451816803 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000013-000010 --seed=20475596634 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:39:22] eval finished: 10.021 seconds
[2019-06-18 12:39:22] Win rate 000013-000010 vs 000011-000009: 0.450
:::MLL 1560883162.393612 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 12}}
[2019-06-18 12:39:22] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=15 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=1023779846 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=2047559677 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=3071339508 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=4095119339 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=5118899170 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=6142679001 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=7166458832 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=8190238663 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=9214018494 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=10237798325 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=11261578156 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=12285357987 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=13309137818 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=14332917649 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=15356697480 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=16380477311 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=17404257142 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000014-000009 --seed=18428036973 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:39:51] selfplay finished: 28.885 seconds
[2019-06-18 12:39:51] selfplay mn: 28.905 seconds
[2019-06-18 12:39:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-15-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779846 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559677 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339508 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119339 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899170 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679001 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458832 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238663 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018494 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798325 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578156 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357987 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137818 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917649 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697480 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477311 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257142 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036973 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816804 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596635 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376466 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156297 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000014-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:39:54] divide_golden_chunk finished: 3.302 seconds
[2019-06-18 12:39:54] generate golden chunk: 3.317 seconds
[2019-06-18 12:39:55] train finished: 43.632 seconds
:::MLL 1560883157.511027 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.511753 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.512460 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.589632 47373161669504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.500022 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.500914 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.501758 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.589808 47416833557376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.590629 47373161669504 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwobtelh9
I0618 12:39:17.590842 47416833557376 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20601b9d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.591593 47373161669504 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwobtelh9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16350f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.591976 47416833557376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.591978 47373161669504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.597357 47373161669504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.597373 47416833557376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883157.511652 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.512490 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.513309 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.603403 47985165808512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.521536 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.522272 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.522893 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.603752 47286321038208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.604524 47985165808512 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpn2ka3a8q
W0618 12:39:17.604819 47286321038208 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvkn30biq
I0618 12:39:17.605633 47985165808512 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpn2ka3a8q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba4b3597e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.605896 47286321038208 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvkn30biq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b01fcf48e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.606081 47985165808512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.606333 47286321038208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.611413 47985165808512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.611574 47286321038208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883157.520852 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.521773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.522622 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.612615 47411586528128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.525287 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.526018 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.526672 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.612723 47583877276544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.613781 47411586528128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp50o3nezi
W0618 12:39:17.613810 47583877276544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpottzaztk
I0618 12:39:17.614896 47411586528128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp50o3nezi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1f275c4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.614975 47583877276544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpottzaztk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4744b06dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.615346 47411586528128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.615413 47583877276544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.619759 47373161669504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.620127 47416833557376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.620762 47583877276544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.620795 47411586528128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.633464 47985165808512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.633805 47286321038208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.643049 47583877276544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.643422 47411586528128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883157.545761 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.546685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.547564 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.644858 46939318154112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.562598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.563329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.564006 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.644991 47645185307520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.645894 46939318154112 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpiim5albz
W0618 12:39:17.645988 47645185307520 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplfrn4l62
:::MLL 1560883157.553087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.554016 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.554709 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.646595 47407859880832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.552469 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.553279 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.554118 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.646657 47394602349440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
I0618 12:39:17.646882 46939318154112 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpiim5albz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab131f8ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.646976 47645185307520 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplfrn4l62', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b558aeebe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.647288 46939318154112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.647371 47645185307520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.647733 47407859880832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj2xaf6xe
W0618 12:39:17.647760 47394602349440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpa2uq7v17
I0618 12:39:17.648816 47407859880832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj2xaf6xe', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e493c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.648844 47394602349440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpa2uq7v17', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b33064dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.649255 47407859880832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.649287 47394602349440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883157.589032 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.589416 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.589745 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.650313 47779637343104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.590540 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.590980 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.591330 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.650431 47195168326528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.590496 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.591038 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.591400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.650878 47495795594112 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.590361 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.590782 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.591239 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.651437 47782346883968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.651378 47779637343104 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3jv0ga0w
W0618 12:39:17.651463 47195168326528 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuml6g8xt
W0618 12:39:17.652214 47645185307520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.652222 46939318154112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:39:17.652375 47779637343104 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3jv0ga0w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b74d8e5fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.652489 47195168326528 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuml6g8xt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aecc3d47e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.652780 47779637343104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.651947 47495795594112 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcuexvxt6
I0618 12:39:17.652887 47195168326528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.652927 47495795594112 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcuexvxt6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32c29cadd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:39:17.652461 47782346883968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyl8cjzxm
I0618 12:39:17.653326 47495795594112 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.653409 47782346883968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyl8cjzxm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b757a665dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.653804 47782346883968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.654636 47407859880832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.654633 47394602349440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.657418 47779637343104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.657492 47195168326528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.657985 47495795594112 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.658322 47782346883968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883157.606278 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.606695 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.607050 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.667436 47452788679552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.606701 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.607119 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.607441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.667411 47080309781376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.576184 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.577066 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.577861 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.667257 47906456490880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.576303 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.577168 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.577940 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.667278 47332213732224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.668509 47452788679552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfierc_yg
W0618 12:39:17.668483 47080309781376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptgb_20q_
I0618 12:39:17.669454 47080309781376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptgb_20q_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad205ba3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.669476 47452788679552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfierc_yg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b28bf333e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:39:17.668319 47332213732224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpg7_90ovc
W0618 12:39:17.668347 47906456490880 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpx2jmhpmy
I0618 12:39:17.669307 47332213732224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpg7_90ovc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cac5f7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.669335 47906456490880 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpx2jmhpmy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b925fe8ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.669846 47080309781376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.669861 47452788679552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.669711 47332213732224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:39:17.669729 47906456490880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.670866 47373161669504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:39:17.671412 47416833557376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:39:17.671803 47645185307520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.671998 46939318154112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.674501 47080309781376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.674504 47452788679552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.674642 47332213732224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.674718 47906456490880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.675387 47373161669504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:39:17.675960 47416833557376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:39:17.676635 47779637343104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.676743 47195168326528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.676771 47394602349440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.676848 47407859880832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.677358 47495795594112 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.677484 47782346883968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:39:17.680640 47373161669504 estimator.py:1111] Calling model_fn.
W0618 12:39:17.680748 47373161669504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:39:17.681175 47416833557376 estimator.py:1111] Calling model_fn.
W0618 12:39:17.681290 47416833557376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:39:17.682190 47373161669504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:39:17.682411 47985165808512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:39:17.682780 47416833557376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:39:17.682667 47286321038208 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:39:17.686742 47985165808512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:39:17.686994 47286321038208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:39:17.691809 47985165808512 estimator.py:1111] Calling model_fn.
W0618 12:39:17.691918 47985165808512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:39:17.692077 47286321038208 estimator.py:1111] Calling model_fn.
W0618 12:39:17.692185 47286321038208 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:39:17.692243 47583877276544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:39:17.692682 47411586528128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:39:17.693293 47985165808512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883157.635110 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.635566 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.635941 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.693414 47185499149184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.693561 47286321038208 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:39:17.693783 47452788679552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.693774 47080309781376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.693846 47332213732224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.694031 47906456490880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:39:17.694476 47185499149184 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzpci_1q5
I0618 12:39:17.695446 47185499149184 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzpci_1q5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea83809e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.695849 47185499149184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883157.639247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.639690 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.640079 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.696254 47738245370752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.696530 47583877276544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:39:17.697019 47411586528128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:39:17.697206 47738245370752 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpi7jcqrxa
I0618 12:39:17.698173 47738245370752 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpi7jcqrxa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6b35be9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.698561 47738245370752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:39:17.700528 47185499149184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:39:17.701570 47583877276544 estimator.py:1111] Calling model_fn.
W0618 12:39:17.701675 47583877276544 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:39:17.702091 47411586528128 estimator.py:1111] Calling model_fn.
W0618 12:39:17.702199 47411586528128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:39:17.703033 47583877276544 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:39:17.703073 47738245370752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:39:17.703581 47411586528128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883157.644493 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.645006 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.645447 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.705301 47787571311488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.706291 47787571311488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpor48px_q
I0618 12:39:17.707266 47787571311488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpor48px_q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76b1ccce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.707665 47787571311488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883157.650374 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.650819 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.651227 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.707947 47248402764672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
W0618 12:39:17.708923 47248402764672 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptspgb_l_
I0618 12:39:17.709880 47248402764672 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptspgb_l_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af928d99e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:39:17.710285 47248402764672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883157.643943 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.644427 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883157.644842 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:39:17.709604 47579781989248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000004-000001.tfrecord.zz_0_0
:::MLL 1560883157.640224 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883157.640767 opt_base_learning_rate: {"value[2019-06-18 12:39:55] iteration time 13: 47.762 seconds
2019-06-18 12:39:56.841324: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883195.960369 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 12:40:00] minmax time: 3.238 seconds
2019-06-18 12:40:00.090049: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:40:00.102458: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:40:00.106909: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883200.119190 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 13}}
[2019-06-18 12:40:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=16 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:40:00] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-15-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=15 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=1023779846 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=2047559677 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=3071339508 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=4095119339 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=5118899170 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=6142679001 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=7166458832 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=8190238663 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=9214018494 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=10237798325 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=11261578156 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=12285357987 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=13309137818 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=14332917649 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=15356697480 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=16380477311 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=17404257142 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=18428036973 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=19451816804 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000014-000010 --seed=20475596635 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:40:10] eval finished: 10.442 seconds
[2019-06-18 12:40:10] Win rate 000014-000010 vs 000011-000009: 0.450
:::MLL 1560883210.622737 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 13}}
[2019-06-18 12:40:10] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=16 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=1023779847 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=2047559678 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=3071339509 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=4095119340 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=5118899171 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=6142679002 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=7166458833 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=8190238664 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=9214018495 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=10237798326 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=11261578157 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=12285357988 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=13309137819 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=14332917650 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=15356697481 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=16380477312 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=17404257143 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000015-000009 --seed=18428036974 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:40:39] selfplay finished: 28.876 seconds
[2019-06-18 12:40:39] selfplay mn: 28.894 seconds
[2019-06-18 12:40:39] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-16-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779847 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559678 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339509 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119340 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899171 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679002 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458833 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238664 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018495 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798326 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578157 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357988 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137819 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917650 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697481 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477312 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257143 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036974 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816805 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596636 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376467 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156298 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000015-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:40:42] divide_golden_chunk finished: 3.234 seconds
[2019-06-18 12:40:42] generate golden chunk: 3.249 seconds
[2019-06-18 12:40:43] train finished: 43.307 seconds
:::MLL 1560883205.334828 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.335687 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.336503 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.425819 47301091152768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.340387 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.341080 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.341767 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.425889 47473082307456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.426860 47301091152768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc5vns2pl
I0618 12:40:05.426972 47473082307456 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2d78cb6d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.427927 47301091152768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc5vns2pl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b056d529e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.428175 47473082307456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.428348 47301091152768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.433647 47473082307456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.433676 47301091152768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883205.349573 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.350323 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.351002 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.435231 47717083046784 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.339564 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.340472 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.341329 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.435432 47715418899328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.436362 47717083046784 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwu6_1_xy
W0618 12:40:05.436552 47715418899328 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgwkkrg25
I0618 12:40:05.437446 47717083046784 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwu6_1_xy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b66485f3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.437634 47715418899328 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgwkkrg25', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b65e52e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.437889 47717083046784 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.438081 47715418899328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.443185 47717083046784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.443269 47715418899328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.455942 47301091152768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.456284 47473082307456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883205.369388 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.370250 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.371052 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.462378 47144137786240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.377048 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.377782 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.378474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.462549 47700092859264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.369249 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.370145 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.370980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.463124 47330275308416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.390108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.390977 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.391767 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.463129 47149192635264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.463370 47144137786240 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdbzh2s7z
W0618 12:40:05.463516 47700092859264 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvve3nuvp
I0618 12:40:05.464340 47144137786240 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdbzh2s7z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae0e22c5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.464473 47700092859264 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvve3nuvp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6253ad8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.464730 47144137786240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.464874 47700092859264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.464227 47330275308416 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpadu01zat
W0618 12:40:05.464195 47149192635264 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxedaiirf
I0618 12:40:05.465168 47149192635264 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxedaiirf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae20f772e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.465205 47330275308416 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpadu01zat', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0c38d58e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:40:05.465234 47717083046784 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:40:05.465591 47149192635264 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.465643 47330275308416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.465519 47715418899328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.469492 47700092859264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.469490 47144137786240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.470976 47330275308416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.471038 47149192635264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883205.386507 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.387310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.388093 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.474145 47506729272192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.362070 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.362953 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.363797 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.474302 47136741790592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.475226 47506729272192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_10r0ys7
W0618 12:40:05.475365 47136741790592 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpag8s9d1s
I0618 12:40:05.476209 47506729272192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_10r0ys7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b354e4f5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.476348 47136741790592 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpag8s9d1s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf29565e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.476612 47506729272192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.476747 47136741790592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883205.417935 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.418314 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.418641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.480608 47389663474560 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.420060 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.420428 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.420757 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.481209 47817824564096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.481332 47506729272192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.481352 47136741790592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.481680 47389663474560 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphto1xnfh
:::MLL 1560883205.419587 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.419979 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.420339 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.482425 47271814222720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.419851 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.420266 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.420606 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.482467 47358335140736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 12:40:05.482694 47389663474560 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphto1xnfh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a0ca50dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:40:05.482233 47817824564096 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmph9qseaxb
I0618 12:40:05.483090 47389663474560 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.483206 47817824564096 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmph9qseaxb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7dbd08ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.483602 47817824564096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.483439 47271814222720 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7bst8gv_
W0618 12:40:05.483472 47358335140736 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuximjvu7
:::MLL 1560883205.393354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.394258 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.395110 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.483995 47817054294912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.410156 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.410985 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.411757 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.484010 47797354500992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
I0618 12:40:05.484421 47271814222720 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7bst8gv_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afe9c482e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.484435 47358335140736 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuximjvu7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b12c1549e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.484821 47271814222720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.484835 47358335140736 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.485139 47797354500992 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnkzt7tph
W0618 12:40:05.485175 47817054294912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp08em9lyo
I0618 12:40:05.486291 47797354500992 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnkzt7tph', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b78f8ec5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.486315 47817054294912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp08em9lyo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d8f1f6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.486737 47797354500992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.486755 47817054294912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.487702 47389663474560 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.488215 47817824564096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.488759 47700092859264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.488828 47144137786240 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.489533 47271814222720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.489532 47358335140736 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.492105 47817054294912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.492126 47797354500992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.493310 47330275308416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.494191 47149192635264 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.500723 47506729272192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.500741 47136741790592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.506871 47389663474560 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.507500 47817824564096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.507850 47301091152768 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:05.508212 47473082307456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:05.508791 47271814222720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.508901 47358335140736 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.512492 47301091152768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:05.512866 47473082307456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:05.513644 47717083046784 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883205.428188 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.428743 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.429246 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.513312 47777842029440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.428869 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.429391 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.429817 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.513763 47269045597056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.514271 47715418899328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:05.514347 47817054294912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.514438 47797354500992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.514322 47777842029440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3p2ti06u
I0618 12:40:05.515306 47777842029440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3p2ti06u', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b746de3be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:40:05.514720 47269045597056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8d4xtbm_
I0618 12:40:05.515671 47269045597056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8d4xtbm_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afdf7424e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.515702 47777842029440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.516062 47269045597056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.517911 47301091152768 estimator.py:1111] Calling model_fn.
W0618 12:40:05.518024 47301091152768 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:40:05.517915 47717083046784 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:40:05.518327 47473082307456 estimator.py:1111] Calling model_fn.
W0618 12:40:05.518440 47473082307456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560883205.458708 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.459161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.459534 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.518238 47666403099520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.518613 47715418899328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:05.519462 47301091152768 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:05.519919 47473082307456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:05.519336 47666403099520 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3_qjznwl
I0618 12:40:05.520370 47666403099520 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3_qjznwl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5a7b9c9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.520798 47666403099520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.520326 47777842029440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.520637 47269045597056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:40:05.522946 47717083046784 estimator.py:1111] Calling model_fn.
W0618 12:40:05.523054 47717083046784 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:40:05.523731 47715418899328 estimator.py:1111] Calling model_fn.
W0618 12:40:05.523842 47715418899328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:40:05.524400 47717083046784 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883205.463609 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.463985 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.464307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.524897 47957023765376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.467081 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.467613 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.468021 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.525047 46999085626240 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.525211 47715418899328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:05.525657 47666403099520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883205.465111 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.465513 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.465915 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.525905 46990712169344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.525893 47957023765376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvw45ruak
W0618 12:40:05.526025 46999085626240 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc8z0s0kr
I0618 12:40:05.526874 47957023765376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvw45ruak', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9e25f3edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.527004 46999085626240 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc8z0s0kr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf1c63fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.527261 47957023765376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:05.527398 46999085626240 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.526863 46990712169344 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpy_eh54sm
I0618 12:40:05.527846 46990712169344 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpy_eh54sm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd294b3dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:05.528237 46990712169344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:05.531911 46999085626240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.531910 47957023765376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.532813 46990712169344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:05.536589 47700092859264 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:05.536629 47144137786240 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:05.539785 47777842029440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.539858 47269045597056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:05.540884 47700092859264 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:05.540918 47144137786240 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883205.481119 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.481504 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.481822 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.543397 47885535396736 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
:::MLL 1560883205.480354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883205.480747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883205.481131 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:05.543451 46944612803456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000005-000002.tfrecord.zz_0_0
W0618 12:40:05.543655 47330275308416 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2[2019-06-18 12:40:43] iteration time 14: 47.486 seconds
2019-06-18 12:40:44.370017: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883243.446948 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 12:40:47] minmax time: 3.228 seconds
2019-06-18 12:40:47.608315: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:40:47.613793: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:40:47.618289: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883247.630149 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 14}}
[2019-06-18 12:40:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000016-000010 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=17 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:40:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-16-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=16 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=1023779847 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=2047559678 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=3071339509 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=4095119340 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=5118899171 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=6142679002 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=7166458833 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=8190238664 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=9214018495 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=10237798326 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=11261578157 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=12285357988 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=13309137819 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=14332917650 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=15356697481 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=16380477312 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=17404257143 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=18428036974 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=19451816805 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000015-000010 --seed=20475596636 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:40:58] eval finished: 10.334 seconds
[2019-06-18 12:40:58] Win rate 000015-000010 vs 000011-000009: 0.730
:::MLL 1560883258.027952 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 14}}
[2019-06-18 12:40:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=17 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=1023779848 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=2047559679 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=3071339510 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=4095119341 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=5118899172 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=6142679003 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=7166458834 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=8190238665 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=9214018496 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=10237798327 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=11261578158 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=12285357989 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=13309137820 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=14332917651 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=15356697482 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=16380477313 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=17404257144 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000016-000009 --seed=18428036975 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:41:28] selfplay finished: 30.267 seconds
[2019-06-18 12:41:28] selfplay mn: 30.284 seconds
[2019-06-18 12:41:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-17-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779848 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559679 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339510 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119341 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899172 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679003 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458834 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238665 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018496 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798327 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578158 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357989 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137820 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917651 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697482 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477313 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257144 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036975 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816806 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596637 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376468 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156299 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000016-000009/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:41:31] train finished: 43.406 seconds
:::MLL 1560883252.849195 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.849895 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.850543 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.937053 47088706147200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.844384 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.845299 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.846141 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.937085 47479464993664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:52.938201 47479464993664 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp38nklmkm
I0618 12:40:52.938195 47088706147200 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3fa30ad30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.939288 47479464993664 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp38nklmkm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2ef53b7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.939481 47088706147200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:52.939740 47479464993664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:52.944768 47088706147200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:52.944862 47479464993664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883252.865965 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.866871 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.867734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.958421 47357182362496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:52.959556 47357182362496 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdqmuf36a
I0618 12:40:52.960671 47357182362496 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdqmuf36a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b127c9e9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.961118 47357182362496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883252.886287 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.887124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.887862 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.961845 47644995040128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:52.962919 47644995040128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpme5qwcso
I0618 12:40:52.964039 47644995040128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpme5qwcso', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b557f978e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.964486 47644995040128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:52.966384 47357182362496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:52.967097 47479464993664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:52.967268 47088706147200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:52.969639 47644995040128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883252.892934 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.893777 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.894468 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.984949 47374785753984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.892042 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.892836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.893596 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.984913 47871785104256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:52.986088 47374785753984 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwdr18126
W0618 12:40:52.986054 47871785104256 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdxqlpwbv
I0618 12:40:52.987158 47871785104256 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdxqlpwbv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8a4d554e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.987183 47374785753984 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwdr18126', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1695dd0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883252.924272 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.924655 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.924978 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.987154 47694248522624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
I0618 12:40:52.987613 47871785104256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:52.987629 47374785753984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:52.988641 47357182362496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:52.988223 47694248522624 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpheo4rrz6
I0618 12:40:52.989335 47694248522624 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpheo4rrz6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b60f7540e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.989792 47694248522624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:52.992131 47644995040128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:52.992936 47871785104256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:52.992970 47374785753984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883252.905250 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.906038 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.906722 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.993658 47273200391040 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.902296 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.903040 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.903700 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.993703 47565371716480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:52.994787 47694248522624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:52.994836 47273200391040 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk1ca2bxb
W0618 12:40:52.994864 47565371716480 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0nyd0yb9
I0618 12:40:52.995923 47565371716480 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0nyd0yb9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42f5abee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.995920 47273200391040 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpk1ca2bxb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afeeee76e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.996322 47565371716480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:52.996325 47273200391040 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883252.918870 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.919308 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.919693 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:52.996770 47160305955712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:52.997749 47160305955712 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphk0n0vpc
I0618 12:40:52.998728 47160305955712 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphk0n0vpc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae4a5df0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:52.999120 47160305955712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:53.001084 47273200391040 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.001128 47565371716480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.003638 47160305955712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883252.945757 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.946205 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.946590 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.007957 47486941250432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:53.008957 47486941250432 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpeapqied9
I0618 12:40:53.009992 47486941250432 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpeapqied9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b30b2da1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.010403 47486941250432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:53.013988 47694248522624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883252.953192 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.953618 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.954029 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.013763 47416581936000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:53.014934 47871785104256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.015048 47486941250432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.015198 47374785753984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.014751 47416581936000 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl87yh9tx
I0618 12:40:53.015718 47416581936000 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl87yh9tx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20511c1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.016112 47416581936000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883252.923336 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.924260 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.925107 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.016520 46989340410752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.931126 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.931822 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.932494 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.016563 48002665194368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.906109 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.907022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.907892 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.017338 47238240285568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:53.017619 47479464993664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883252.940449 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.941291 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.942163 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.017372 47350591886208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:53.018211 47088706147200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.017547 46989340410752 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfpi5kby5
W0618 12:40:53.017576 48002665194368 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_g98d4tm
I0618 12:40:53.018559 46989340410752 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfpi5kby5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcd787de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.018570 48002665194368 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_g98d4tm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8c664ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.018960 48002665194368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:53.018960 46989340410752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:53.018525 47350591886208 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc6q3ecn0
W0618 12:40:53.018556 47238240285568 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpb3z4iaxl
I0618 12:40:53.019660 47350591886208 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc6q3ecn0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10f3cbddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.019663 47238240285568 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpb3z4iaxl', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af6cb1e8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.020109 47238240285568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:53.020118 47350591886208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:53.020638 47416581936000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.020473 47565371716480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.020543 47273200391040 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.022009 47479464993664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.022589 47088706147200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.022854 47160305955712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.023887 48002665194368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.023891 46989340410752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.025408 47350591886208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.025402 47238240285568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:40:53.027065 47479464993664 estimator.py:1111] Calling model_fn.
W0618 12:40:53.027191 47479464993664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:40:53.027745 47088706147200 estimator.py:1111] Calling model_fn.
W0618 12:40:53.027864 47088706147200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:40:53.028647 47479464993664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:53.029344 47088706147200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:53.034262 47486941250432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.038245 47357182362496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.039833 47416581936000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883252.966939 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.967406 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.967814 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.039635 47531629396864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.965020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.965497 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.965922 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.039696 47791622394752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:53.041359 47644995040128 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.040661 47531629396864 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdcd91u8v
W0618 12:40:53.040696 47791622394752 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqdhcqptw
I0618 12:40:53.041643 47531629396864 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdcd91u8v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3b1a791e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.041666 47791622394752 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqdhcqptw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b77a3436e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.042041 47531629396864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:53.042057 47791622394752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:53.042564 47357182362496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.043202 48002665194368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.043191 46989340410752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883252.979424 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.979799 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.980176 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.044901 47328319943552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
:::MLL 1560883252.978108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883252.978488 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883252.978802 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:40:53.044933 47161828295552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000006-000003.tfrecord.zz_0_0
W0618 12:40:53.045700 47644995040128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.046023 47328319943552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfn9mubf4
W0618 12:40:53.045994 47161828295552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpamrwcmcr
I0618 12:40:53.046980 47161828295552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpamrwcmcr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5009c1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:40:53.047018 47328319943552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfn9mubf4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0bc448fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:40:53.046684 47791622394752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.046694 47531629396864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:40:53.047370 47161828295552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:40:53.047424 47328319943552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:40:53.047507 47238240285568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:40:53.047630 47357182362496 estimator.py:1111] Calling model_fn.
W0618 12:40:53.047738 47357182362496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:40:53.047963 47350591886208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.049094 47357182362496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:40:53.050803 47644995040128 estimator.py:1111] Calling model_fn.
W0618 12:40:53.050914 47644995040128 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:40:53.051991 47161828295552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.052025 47328319943552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:40:53.052289 47644995040128 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:53.061257 47694248522624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.065558 47694248522624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.065968 47791622394752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.066198 47531629396864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.067352 47871785104256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.067507 47374785753984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.068394 47565371716480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.068741 47273200391040 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:40:53.069955 47160305955712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:40:53.070578 47694248522624 estimator.py:1111] Calling model_fn.
W0618 12:40:53.070685 47694248522624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:40:53.071131 47328319943552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.071414 47161828295552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:40:53.072036 47694248522624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:40:53.071994 47871785104256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.072163 47374785753984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:40:53.072660 47565371716480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/p[2019-06-18 12:41:31] divide_golden_chunk finished: 3.409 seconds
[2019-06-18 12:41:31] generate golden chunk: 3.423 seconds
[2019-06-18 12:41:31] moving /lfs/lfs12/gma_akey/results/epb144/models/000016-000010.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000016-000011.meta
[2019-06-18 12:41:31] moving /lfs/lfs12/gma_akey/results/epb144/models/000016-000010.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000016-000011.data-00000-of-00001
[2019-06-18 12:41:31] moving /lfs/lfs12/gma_akey/results/epb144/models/000016-000010.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb
[2019-06-18 12:41:31] moving /lfs/lfs12/gma_akey/results/epb144/models/000016-000010.index --> /lfs/lfs12/gma_akey/results/epb144/models/000016-000011.index
[2019-06-18 12:41:31] iteration time 15: 48.337 seconds
2019-06-18 12:41:32.761874: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883291.783611 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:41:35] minmax time: 3.208 seconds
2019-06-18 12:41:35.979886: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:41:35.985225: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:41:35.989599: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883296.000310 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 15}}
[2019-06-18 12:41:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000017-000011 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=18 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:41:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-17-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=17 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=1023779848 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=2047559679 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=3071339510 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=4095119341 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=5118899172 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=6142679003 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=7166458834 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=8190238665 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=9214018496 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=10237798327 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=11261578158 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=12285357989 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=13309137820 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=14332917651 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=15356697482 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=16380477313 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=17404257144 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=18428036975 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=19451816806 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000016-000011 --seed=20475596637 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:41:48] eval finished: 12.213 seconds
[2019-06-18 12:41:48] Win rate 000016-000011 vs 000015-000010: 0.540
:::MLL 1560883308.274217 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 15}}
[2019-06-18 12:41:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=18 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=1023779849 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=2047559680 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=3071339511 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=4095119342 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=5118899173 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=6142679004 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=7166458835 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=8190238666 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=9214018497 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=10237798328 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=11261578159 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=12285357990 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=13309137821 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=14332917652 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=15356697483 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=16380477314 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=17404257145 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000017-000010 --seed=18428036976 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:42:18] selfplay finished: 30.098 seconds
[2019-06-18 12:42:18] selfplay mn: 30.115 seconds
[2019-06-18 12:42:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-18-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779849 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559680 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339511 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119342 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899173 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679004 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458835 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238666 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018497 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798328 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578159 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357990 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137821 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917652 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697483 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477314 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257145 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036976 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816807 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596638 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376469 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156300 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000017-000010/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:42:19] train finished: 43.368 seconds
:::MLL 1560883301.212068 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.212893 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.213704 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.285815 47584758981504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.192439 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.193330 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.194163 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.285950 47077290718080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.286928 47584758981504 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsrhlxdui
W0618 12:41:41.287015 47077290718080 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbr7wy8_o
I0618 12:41:41.287999 47584758981504 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsrhlxdui', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47793e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.288061 47077290718080 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbr7wy8_o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad151c6ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.288430 47584758981504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.288496 47077290718080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.293755 47077290718080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.293798 47584758981504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.315981 47077290718080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.316357 47584758981504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883301.231235 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.231942 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.232594 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.319922 47332609078144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.224940 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.225832 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.226676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.320155 47490891510656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:41:41.321089 47332609078144 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0cc3f00d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:41:41.321251 47490891510656 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyp019yg0
I0618 12:41:41.322362 47332609078144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.322348 47490891510656 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyp019yg0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b319e4e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.322800 47490891510656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.327685 47332609078144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.327936 47490891510656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883301.245663 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.246380 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.247054 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.329261 47496345817984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.237587 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.238451 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.239329 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.329434 47496621941632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.330291 47496345817984 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjc68srqh
W0618 12:41:41.330417 47496621941632 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwtmmj49l
I0618 12:41:41.331322 47496345817984 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjc68srqh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32e3686e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.331417 47496621941632 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwtmmj49l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32f3ddbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.331718 47496345817984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.331814 47496621941632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.336829 47496345817984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.336856 47496621941632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883301.259608 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.260293 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.260952 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.347380 47137806762880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.256916 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.257634 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.258348 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.347662 47059445568384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.278896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.279329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.279668 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.348083 47583944889216 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.282045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.282455 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.282812 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.348333 47630972449664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.348373 47137806762880 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1x9z1csm
W0618 12:41:41.348659 47059445568384 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppsc87ga4
I0618 12:41:41.349366 47137806762880 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1x9z1csm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf68d09e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.349637 47059445568384 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppsc87ga4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acd2a1fae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.349769 47137806762880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.349789 47332609078144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.349951 47490891510656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:41:41.350030 47059445568384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.349138 47583944889216 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqg1as4xg
W0618 12:41:41.349347 47630972449664 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp71s44x2k
I0618 12:41:41.350125 47583944889216 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqg1as4xg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4748b82e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.350325 47630972449664 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp71s44x2k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b523bc7ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.350514 47583944889216 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.350726 47630972449664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.354887 47137806762880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.355062 47059445568384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.355084 47583944889216 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.355279 47630972449664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.356169 47496621941632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.356251 47496345817984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883301.275634 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.276373 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.277045 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.359495 47947386839936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.264924 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.265809 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.266634 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.359636 47020477653888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.360494 47947386839936 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp88pcsbou
:::MLL 1560883301.267386 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.268274 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.269123 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.361599 47523297719168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.360649 47020477653888 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpb8wzjpmc
:::MLL 1560883301.273787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.274532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.275246 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.361686 47231513674624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:41:41.361636 47947386839936 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp88pcsbou', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9be78c3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.361776 47020477653888 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpb8wzjpmc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac417747e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.362080 47947386839936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.362205 47020477653888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.362698 47523297719168 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf34x3_z6
W0618 12:41:41.362754 47231513674624 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp83ko5uze
I0618 12:41:41.363872 47231513674624 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp83ko5uze', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af53a2e9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.363870 47523297719168 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf34x3_z6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3929ddce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.364328 47523297719168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.364327 47231513674624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.366871 47077290718080 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.367024 47584758981504 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.366730 47947386839936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.366821 47020477653888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.369464 47231513674624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.369504 47523297719168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.371295 47077290718080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:41:41.371403 47584758981504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:41:41.374192 47583944889216 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.374469 47630972449664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:41:41.376325 47077290718080 estimator.py:1111] Calling model_fn.
W0618 12:41:41.376440 47077290718080 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:41:41.376451 47584758981504 estimator.py:1111] Calling model_fn.
W0618 12:41:41.376561 47584758981504 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:41:41.377034 47137806762880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.377173 47059445568384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.377864 47077290718080 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:41:41.378045 47584758981504 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883301.315077 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.315464 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.315784 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.380640 47238910071680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
:::MLL 1560883301.314313 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.314712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.315078 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.380830 47626638058368 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.381651 47238910071680 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp74w693pr
W0618 12:41:41.381782 47626638058368 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkcl8b2p9
I0618 12:41:41.382639 47238910071680 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp74w693pr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af6f30a9dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.382744 47626638058368 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkcl8b2p9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b51396e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.383038 47238910071680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.383121 47626638058368 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.386085 47947386839936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.386244 47020477653888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.387625 47238910071680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.387674 47626638058368 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.391721 47231513674624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.391853 47523297719168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.400321 47490891510656 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.400567 47332609078144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.403971 47496621941632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.404306 47496345817984 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.404627 47490891510656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:41:41.404912 47332609078144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:41:41.406813 47238910071680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:41:41.407026 47626638058368 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883301.337087 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.337643 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.338137 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.407608 47211393004416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.408284 47496621941632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:41:41.408612 47496345817984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883301.341166 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.341633 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.342007 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.408284 47003133297536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:41:41.409709 47490891510656 estimator.py:1111] Calling model_fn.
W0618 12:41:41.408630 47211393004416 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpw6y__q4m
W0618 12:41:41.409819 47490891510656 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:41:41.410010 47332609078144 estimator.py:1111] Calling model_fn.
W0618 12:41:41.410117 47332609078144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:41:41.409597 47211393004416 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpw6y__q4m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af08ae58e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:41:41.409270 47003133297536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpurz4g4lm
I0618 12:41:41.409993 47211393004416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.410237 47003133297536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpurz4g4lm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac00da68e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.410627 47003133297536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.411179 47490891510656 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:41:41.411481 47332609078144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883301.345370 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.345880 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.346320 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.412744 46997825545088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:41:41.413324 47496621941632 estimator.py:1111] Calling model_fn.
W0618 12:41:41.413433 47496621941632 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560883301.347863 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.348296 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.348622 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.413228 47393894065024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:41:41.413797 47496345817984 estimator.py:1111] Calling model_fn.
W0618 12:41:41.413907 47496345817984 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560883301.350730 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.351130 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.351492 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.414032 47544232018816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
W0618 12:41:41.413754 46997825545088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxh0me0lg
I0618 12:41:41.414751 46997825545088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxh0me0lg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abed148add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:41:41.414785 47496621941632 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:41:41.414206 47393894065024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplmps0_fi
W0618 12:41:41.414565 47211393004416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:41:41.415147 46997825545088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:41:41.415188 47393894065024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplmps0_fi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b08cebe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:41:41.415269 47496345817984 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883301.350398 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883301.350837 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883301.351222 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:41:41.415345 47604581557120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000007-000003.tfrecord.zz_0_0
I0618 12:41:41.415580 47393894065024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.415144 47003133297536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.415008 47544232018816 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzpaj1_7g
I0618 12:41:41.415997 47544232018816 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzpaj1_7g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e09a5de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.416394 47544232018816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.416323 47604581557120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpv_fgmpnk
I0618 12:41:41.417283 47604581557120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpv_fgmpnk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c16c2ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:41:41.417684 47604581557120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:41:41.419775 46997825545088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.420187 47393894065024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.420903 47544232018816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:41:41.421747 47583944889216 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:41:41.421802 47630972449664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy ar[2019-06-18 12:42:21] divide_golden_chunk finished: 3.309 seconds
[2019-06-18 12:42:21] generate golden chunk: 3.323 seconds
[2019-06-18 12:42:21] moving /lfs/lfs12/gma_akey/results/epb144/models/000017-000011.index --> /lfs/lfs12/gma_akey/results/epb144/models/000017-000012.index
[2019-06-18 12:42:21] moving /lfs/lfs12/gma_akey/results/epb144/models/000017-000011.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000017-000012.meta
[2019-06-18 12:42:21] moving /lfs/lfs12/gma_akey/results/epb144/models/000017-000011.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb
[2019-06-18 12:42:21] moving /lfs/lfs12/gma_akey/results/epb144/models/000017-000011.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000017-000012.data-00000-of-00001
[2019-06-18 12:42:21] iteration time 16: 49.968 seconds
2019-06-18 12:42:22.756811: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
Got 343492 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000009.tfrecord.zz: 13.432 seconds
Got 377150 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000004.tfrecord.zz: 13.500 seconds
Got 379927 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz: 0.312 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000005.tfrecord.zz: 14.915 seconds
Got 347710 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000006.tfrecord.zz: 13.968 seconds
Got 391566 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000000.tfrecord.zz: 14.777 seconds
Got 383972 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000002.tfrecord.zz: 13.625 seconds
Got 348718 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000007.tfrecord.zz: 14.445 seconds
Got 346042 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000008.tfrecord.zz: 14.105 seconds
Got 389066 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz: 0.311 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000003.tfrecord.zz: 15.095 seconds
Got 387822 examples
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz: 0.316 seconds
Writing examples to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000000-000001.tfrecord.zz: 15.300 seconds
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/checkpoint_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/checkpointlog.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000001-000001_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000001-000001log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000002-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000002-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000003-000002_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000003-000002log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000004-000003_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000004-000003log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000005-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000005-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000006-000004_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000006-000004log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000007-000005_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000007-000005log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000008-000006_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000008-000006log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000009-000007_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000009-000007log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000010-000008_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000010-000008log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000011-000009_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000011-000009log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000012-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000012-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000013-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000013-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000014-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000014-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000015-000010_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000015-000010log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000016-000011_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000016-000011log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000017-000012_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000017-000012log.txt['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883341.751339 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:42:25] minmax time: 3.200 seconds
2019-06-18 12:42:25.967637: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:42:25.973075: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:42:25.977599: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883345.988733 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 16}}
[2019-06-18 12:42:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000018-000012 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=19 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:42:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-18-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=18 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=1023779849 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=2047559680 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=3071339511 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=4095119342 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=5118899173 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=6142679004 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=7166458835 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=8190238666 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=9214018497 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=10237798328 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=11261578159 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=12285357990 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=13309137821 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=14332917652 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=15356697483 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=16380477314 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=17404257145 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=18428036976 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=19451816807 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000017-000012 --seed=20475596638 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:42:36] eval finished: 10.951 seconds
[2019-06-18 12:42:37] Win rate 000017-000012 vs 000016-000011: 0.490
:::MLL 1560883357.001760 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 16}}
[2019-06-18 12:42:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=19 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=1023779850 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=2047559681 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=3071339512 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=4095119343 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=5118899174 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=6142679005 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=7166458836 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=8190238667 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=9214018498 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=10237798329 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=11261578160 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=12285357991 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=13309137822 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=14332917653 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=15356697484 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=16380477315 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=17404257146 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000018-000011 --seed=18428036977 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:43:06] selfplay finished: 29.430 seconds
[2019-06-18 12:43:06] selfplay mn: 29.447 seconds
[2019-06-18 12:43:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-19-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779850 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559681 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339512 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119343 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899174 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679005 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458836 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238667 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018498 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798329 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578160 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357991 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137822 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917653 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697484 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477315 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257146 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036977 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816808 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596639 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376470 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156301 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000018-000011/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:43:09] train finished: 43.273 seconds
:::MLL 1560883351.190599 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.191510 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.192147 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.287681 47002752693120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.194543 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.195251 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.195908 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.287825 46938840621952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:42:31.288868 47002752693120 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abff6f70d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:42:31.288978 46938840621952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmwqsp2s5
I0618 12:42:31.290097 47002752693120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.290101 46938840621952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmwqsp2s5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab115820e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.290562 46938840621952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.295573 47002752693120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.295968 46938840621952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883351.233696 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.234431 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.235160 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.314284 47857885238144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.218993 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.219855 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.220689 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.314432 47148918915968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.315342 47857885238144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp92qdz1es
W0618 12:42:31.315410 47148918915968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuq4df349
I0618 12:42:31.316349 47857885238144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp92qdz1es', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8710d61e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.316407 47148918915968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuq4df349', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae1ff268e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.316747 47857885238144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.316803 47148918915968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.317691 47002752693120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.318287 46938840621952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.321837 47857885238144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.321910 47148918915968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.342753 47857885238144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.342998 47148918915968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883351.279159 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.279622 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.280016 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.349761 47134992917376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.263427 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.264201 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.264876 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.350900 47148146926464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.244410 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.245341 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.246215 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.350947 47918200501120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.350877 47134992917376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptdn2vz92
I0618 12:42:31.351867 47134992917376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptdn2vz92', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adec118be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883351.257994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.258683 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.259375 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.351780 47919224234880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:42:31.352262 47134992917376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883351.255354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.256096 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.256833 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.352116 47604861375360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.352042 47148146926464 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp29ekls_m
W0618 12:42:31.352065 47918200501120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxzpkeivv
I0618 12:42:31.353163 47148146926464 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp29ekls_m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae1d122ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.353183 47918200501120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxzpkeivv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b951be80e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:42:31.352792 47919224234880 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp19moe93y
I0618 12:42:31.353812 47919224234880 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp19moe93y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9558ecfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.353618 47148146926464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.353628 47918200501120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.353226 47604861375360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpv47e4b7k
I0618 12:42:31.354216 47919224234880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.354224 47604861375360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpv47e4b7k', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c27706dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.354623 47604861375360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.356944 47134992917376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.358972 47919224234880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.359006 47148146926464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.359021 47918200501120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.359294 47604861375360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883351.298027 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.298496 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.298954 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.359691 47659885577088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.360684 47659885577088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp61gp_haj
I0618 12:42:31.361674 47659885577088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp61gp_haj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58f7230e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.362068 47659885577088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883351.277114 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.277786 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.278442 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.362529 47997538358144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.261914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.262811 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.263652 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.362617 47032640902016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.363700 47032640902016 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9myqbucg
W0618 12:42:31.363671 47997538358144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc15a2ybc
I0618 12:42:31.364813 47032640902016 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9myqbucg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac6ec70ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.364835 47997538358144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc15a2ybc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba794cf9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.365264 47032640902016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.365305 47997538358144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.366811 47659885577088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.370584 47032640902016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.370628 47997538358144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.370877 46938840621952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.370938 47002752693120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.375294 46938840621952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.375355 47002752693120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.376199 47134992917376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.378183 47919224234880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.378668 47604861375360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:42:31.380572 46938840621952 estimator.py:1111] Calling model_fn.
I0618 12:42:31.380625 47002752693120 estimator.py:1111] Calling model_fn.
W0618 12:42:31.380701 46938840621952 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:42:31.380764 47002752693120 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:42:31.380918 47918200501120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.381510 47148146926464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883351.265317 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.266036 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.266711 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.381258 46949653848960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.260373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.261301 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.262114 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.381291 47963810259840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.382154 46938840621952 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:42:31.382234 47002752693120 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:42:31.382279 46949653848960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgce61ftw
W0618 12:42:31.382307 47963810259840 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmdp6p_hi
I0618 12:42:31.383325 46949653848960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgce61ftw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab39a06fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.383353 47963810259840 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmdp6p_hi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9fba75be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.383748 46949653848960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.383777 47963810259840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.386409 47659885577088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.388487 46949653848960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.388494 47963810259840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.392715 47032640902016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.393217 47997538358144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883351.325327 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.325699 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.326023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.396071 47807196054400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.396370 47857885238144 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.396517 47148918915968 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883351.327131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.327517 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.327827 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.396705 48009506136960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.397084 47807196054400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5yu0jj27
I0618 12:42:31.398073 47807196054400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5yu0jj27', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b43867e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:42:31.397696 48009506136960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6306qhdj
I0618 12:42:31.398477 47807196054400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.398678 48009506136960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6306qhdj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa5e257e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.399077 48009506136960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883351.327921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.328429 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.328799 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.399871 47299252192128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.327548 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.328005 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.328453 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.399841 47573659485056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.401015 47857885238144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.401191 47148918915968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.400876 47299252192128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxyz36c9q
W0618 12:42:31.400848 47573659485056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_mwhh_n7
I0618 12:42:31.401827 47573659485056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_mwhh_n7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b44e3a95e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.401846 47299252192128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxyz36c9q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04ffb64e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.402216 47573659485056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.402241 47299252192128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.403116 47807196054400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.403690 48009506136960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:42:31.406455 47857885238144 estimator.py:1111] Calling model_fn.
W0618 12:42:31.406572 47857885238144 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:42:31.406658 47148918915968 estimator.py:1111] Calling model_fn.
W0618 12:42:31.406773 47148918915968 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:42:31.406880 47299252192128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.406906 47573659485056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.408012 47857885238144 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:42:31.408238 47148918915968 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:42:31.407773 46949653848960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.407825 47963810259840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.422258 47807196054400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.422765 48009506136960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.424333 47134992917376 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883351.332588 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.333052 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.333455 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.424132 47116095796096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.329858 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.330323 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.330733 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.424124 47632964318080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.356778 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.357151 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.357476 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.424807 47225568174976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
:::MLL 1560883351.358630 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.358999 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.359317 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.425300 47810403734400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
W0618 12:42:31.426016 47919224234880 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.425879 47299252192128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.425947 47573659485056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:42:31.425137 47116095796096 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9hiktuv6
W0618 12:42:31.426440 47604861375360 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.425166 47632964318080 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplf_1pfx8
W0618 12:42:31.425791 47225568174976 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl4vue6i1
:::MLL 1560883351.358103 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.358517 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.358840 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.426395 47279458816896 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:42:31.426125 47116095796096 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9hiktuv6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada5abd7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.426157 47632964318080 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplf_1pfx8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b52b2812e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883351.356846 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883351.357278 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883351.357615 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:42:31.426578 47718095893376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000008-000004.tfrecord.zz_0_0
I0618 12:42:31.426761 47225568174976 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl4vue6i1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af3d7cd7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:42:31.426278 47810403734400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu9nbh0fa
I0618 12:42:31.426518 47116095796096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.426558 47632964318080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.427159 47225568174976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:42:31.427257 47810403734400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu9nbh0fa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c02b7de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.427658 47810403734400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.427374 47279458816896 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpulvgmdra
W0618 12:42:31.427564 47718095893376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpoyym3nwj
I0618 12:42:31.428358 47279458816896 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpulvgmdra', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0063ef6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.428530 47718095893376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpoyym3nwj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6684bdfdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:42:31.428755 47279458816896 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.428695 47134992917376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:42:31.428923 47718095893376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:42:31.430304 47919224234880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.430330 47918200501120 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.430738 47604861375360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.430828 47148146926464 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:42:31.431256 47116095796096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.431818 47225568174976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.431269 47632964318080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.432198 47810403734400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.433447 47279458816896 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:42:31.433457 47718095893376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:42:31.433839 47134992917376 estimator.py:1111] Calling model_fn.
W0618 12:42:31.433948 47134992917376 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:42:31.434747 47918200501120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:42:31.435392 47919224234880 estimator.py:1111] Calling model_fn.
W0618 12:42:31.435320 47134992917376 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:42:31.435254 47148146926464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:42:31.435501 47919224234880 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorfl[2019-06-18 12:43:09] divide_golden_chunk finished: 3.248 seconds
[2019-06-18 12:43:09] generate golden chunk: 3.262 seconds
[2019-06-18 12:43:09] moving /lfs/lfs12/gma_akey/results/epb144/models/000018-000012.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000018-000013.meta
[2019-06-18 12:43:09] moving /lfs/lfs12/gma_akey/results/epb144/models/000018-000012.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000018-000013.data-00000-of-00001
[2019-06-18 12:43:09] moving /lfs/lfs12/gma_akey/results/epb144/models/000018-000012.index --> /lfs/lfs12/gma_akey/results/epb144/models/000018-000013.index
[2019-06-18 12:43:09] moving /lfs/lfs12/gma_akey/results/epb144/models/000018-000012.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb
[2019-06-18 12:43:09] iteration time 17: 48.007 seconds
2019-06-18 12:43:10.767773: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883389.758437 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:43:13] minmax time: 3.201 seconds
2019-06-18 12:43:13.979129: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:43:13.984488: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:43:13.989055: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883393.999964 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 17}}
[2019-06-18 12:43:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=20 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:43:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-19-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=19 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=1023779850 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=2047559681 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=3071339512 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=4095119343 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=5118899174 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=6142679005 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=7166458836 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=8190238667 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=9214018498 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=10237798329 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=11261578160 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=12285357991 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=13309137822 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=14332917653 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=15356697484 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=16380477315 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=17404257146 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=18428036977 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=19451816808 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000018-000013 --seed=20475596639 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:43:26] eval finished: 11.983 seconds
[2019-06-18 12:43:26] Win rate 000018-000013 vs 000017-000012: 0.460
:::MLL 1560883406.045578 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 17}}
[2019-06-18 12:43:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=20 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=1023779851 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=2047559682 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=3071339513 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=4095119344 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=5118899175 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=6142679006 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=7166458837 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=8190238668 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=9214018499 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=10237798330 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=11261578161 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=12285357992 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=13309137823 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=14332917654 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=15356697485 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=16380477316 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=17404257147 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000019-000012 --seed=18428036978 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:43:55] selfplay finished: 29.344 seconds
[2019-06-18 12:43:55] selfplay mn: 29.362 seconds
[2019-06-18 12:43:55] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-20-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779851 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559682 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339513 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119344 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899175 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679006 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458837 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238668 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018499 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798330 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578161 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357992 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137823 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917654 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697485 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477316 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257147 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036978 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816809 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596640 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376471 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156302 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000019-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:43:57] train finished: 43.527 seconds
:::MLL 1560883399.244381 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.245204 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.245871 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.343368 47351560819584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.243590 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.244440 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.245217 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.343502 47517030118272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
I0618 12:43:19.344559 47351560819584 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b112d8cad30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.344595 47517030118272 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_kr5jx5l
I0618 12:43:19.345675 47517030118272 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_kr5jx5l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b37b449be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.345846 47351560819584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.346125 47517030118272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.351236 47351560819584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.351306 47517030118272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.373383 47517030118272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.374023 47351560819584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883399.272648 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.273554 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.274458 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.393708 47131664044928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.394820 47131664044928 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuhj_bp3x
I0618 12:43:19.395946 47131664044928 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuhj_bp3x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2addfaae0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.396398 47131664044928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.296181 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.296919 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.297614 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.399442 47417726120832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.400504 47417726120832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3l574ejg
I0618 12:43:19.401607 47417726120832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3l574ejg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b20954efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.401719 47131664044928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:43:19.402066 47417726120832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.290576 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.291287 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.291934 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.405311 47328699868032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.285951 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.286807 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.287596 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.405809 47776726467456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.406326 47328699868032 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpox9lr5vd
I0618 12:43:19.407344 47328699868032 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpox9lr5vd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0bdaee3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.407219 47417726120832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.406812 47776726467456 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp9st1k8hm
I0618 12:43:19.407751 47328699868032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.407828 47776726467456 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp9st1k8hm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b742b659e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.408237 47776726467456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.336072 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.336453 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.336771 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.408778 47137709572992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.335259 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.335746 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.336115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.409186 46973697999744 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.409861 47137709572992 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpenne4s74
I0618 12:43:19.410938 47137709572992 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpenne4s74', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adf63059e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.410193 46973697999744 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpirprg97m
I0618 12:43:19.411264 46973697999744 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpirprg97m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab9332b8dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.411356 47137709572992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.411686 46973697999744 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.412876 47328699868032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.413152 47776726467456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.416308 47137709572992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.416528 46973697999744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883399.274848 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.275604 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.276307 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.421127 47959407555456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.422289 47959407555456 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfhq1j4cc
I0618 12:43:19.423407 47959407555456 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfhq1j4cc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9eb409ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.423572 47131664044928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:43:19.423885 47959407555456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.424945 47517030118272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:43:19.425225 47351560819584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883399.276487 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.277361 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.278182 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.428200 47832417649536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.429271 47517030118272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:43:19.429211 47417726120832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883399.283672 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.284335 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.285049 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.428753 46938756481920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.429290 47959407555456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.429538 47351560819584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:43:19.429237 47832417649536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpreaw4yq8
I0618 12:43:19.430241 47832417649536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpreaw4yq8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8122d99e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.429738 46938756481920 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu46qq4bh
I0618 12:43:19.430641 47832417649536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.430717 46938756481920 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu46qq4bh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab1107e5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.431112 46938756481920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.432441 47328699868032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.433242 47776726467456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:43:19.434405 47517030118272 estimator.py:1111] Calling model_fn.
W0618 12:43:19.434520 47517030118272 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:43:19.434615 47351560819584 estimator.py:1111] Calling model_fn.
W0618 12:43:19.434723 47351560819584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:43:19.435876 47517030118272 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:43:19.436088 47351560819584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:43:19.435543 47832417649536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.435957 46938756481920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.436565 47137709572992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.437074 46973697999744 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.451877 47959407555456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.454889 47832417649536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.455328 46938756481920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883399.287705 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.288581 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.289464 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.455821 47229479465856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.297185 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.297939 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.298642 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.456023 47303727309696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.277009 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.277731 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.278395 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.455870 47443432919936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.456922 47229479465856 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3cq0324d
W0618 12:43:19.457108 47303727309696 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptfozru33
W0618 12:43:19.456942 47443432919936 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0scmx1qk
I0618 12:43:19.458032 47229479465856 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3cq0324d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4c0ef0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.458203 47303727309696 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptfozru33', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b060a733e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.458018 47443432919936 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0scmx1qk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b26918d9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883399.383992 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.384380 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.384710 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.458026 47117046072192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
I0618 12:43:19.458485 47229479465856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.385209 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.385587 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.385916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.458273 47511844942720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
I0618 12:43:19.458458 47443432919936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.458660 47303727309696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.387001 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.387500 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.387928 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.459030 47205229769600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.459046 47117046072192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf1a10anq
W0618 12:43:19.459268 47511844942720 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmgu8fk_d
I0618 12:43:19.460031 47117046072192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf1a10anq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ada93619e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.460249 47511844942720 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmgu8fk_d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b367f3a2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.460427 47117046072192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.460645 47511844942720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.460053 47205229769600 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdfvw_ohk
I0618 12:43:19.461043 47205229769600 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdfvw_ohk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aef1b8a0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.461457 47205229769600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.390975 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.391425 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.391812 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.461661 47492073653120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.462642 47492073653120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7v46oy9q
I0618 12:43:19.463627 47492073653120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7v46oy9q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b31e4c45e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.463547 47443432919936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.463754 47229479465856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.463889 47303727309696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:43:19.464022 47492073653120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883399.349247 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.349732 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.350152 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.464401 47396495078272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.351161 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.351671 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.352122 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.464561 47230229001088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.465269 47117046072192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.465389 47511844942720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.466132 47205229769600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.465409 47396495078272 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0ocm3a8x
W0618 12:43:19.465540 47230229001088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpepe1o4cy
I0618 12:43:19.466381 47396495078272 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0ocm3a8x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ba3d70dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.466530 47230229001088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpepe1o4cy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af4ed9c0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.466783 47396495078272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.466929 47230229001088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.468543 47492073653120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.471360 47396495078272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.471516 47230229001088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.475901 47131664044928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883399.334787 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.335329 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.335771 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.475781 47989894513536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.340339 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.340756 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.341120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.476033 47554600997760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
W0618 12:43:19.476791 47989894513536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz_b4a95d
W0618 12:43:19.476999 47554600997760 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpp_k4hfcr
I0618 12:43:19.477785 47989894513536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz_b4a95d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5cd33de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.477981 47554600997760 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpp_k4hfcr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4073afde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.478183 47989894513536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:43:19.478370 47554600997760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.480552 47131664044928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:43:19.480731 47328699868032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:43:19.481190 47776726467456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:43:19.481133 47417726120832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:43:19.482775 47989894513536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.482881 47554600997760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:43:19.485068 47328699868032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:43:19.485065 47117046072192 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.485129 46973697999744 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:43:19.485181 47137709572992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:43:19.485074 47443432919936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.485434 47205229769600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.485532 47776726467456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:43:19.485797 47229479465856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.485779 47511844942720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.485888 47303727309696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.485780 47417726120832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:43:19.486061 47131664044928 estimator.py:1111] Calling model_fn.
W0618 12:43:19.486176 47131664044928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:43:19.487632 47131664044928 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:43:19.487698 47492073653120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.489547 46973697999744 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:43:19.489623 47137709572992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883399.374968 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.375443 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.375820 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.489450 47288045314944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
:::MLL 1560883399.370670 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883399.371156 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883399.371593 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:43:19.489832 47717591692160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000009-000005.tfrecord.zz_0_0
I0618 12:43:19.490212 47328699868032 estimator.py:1111] Calling model_fn.
W0618 12:43:19.490325 47328699868032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:43:19.490651 47776726467456 estimator.py:1111] Calling model_fn.
W0618 12:43:19.490761 47776726467456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:43:19.490339 47396495078272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.490671 47230229001088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:43:19.490460 47288045314944 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptvk02y69
I0618 12:43:19.491456 47288045314944 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptvk02y69', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0263bafe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:43:19.490781 47717591692160 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfssmbcey
I0618 12:43:19.491283 47417726120832 estimator.py:1111] Calling model_fn.
W0618 12:43:19.491400 47417726120832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:43:19.491703 47328699868032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:43:19.491767 47717591692160 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfssmbcey', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6666b08e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:43:19.491860 47288045314944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.492113 47776726467456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:43:19.492155 47717591692160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:43:19.492863 47417726120832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:43:19.495033 46973697999744 estimator.py:1111] Calling model_fn.
W0618 12:43:19.495147 46973697999744 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:43:19.495123 47137709572992 estimator.py:1111] Calling model_fn.
W0618 12:43:19.495239 47137709572992 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:43:19.49[2019-06-18 12:43:58] divide_golden_chunk finished: 3.224 seconds
[2019-06-18 12:43:58] generate golden chunk: 3.238 seconds
[2019-06-18 12:43:58] iteration time 18: 48.889 seconds
2019-06-18 12:43:59.737971: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883438.647572 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:44:02] minmax time: 3.228 seconds
2019-06-18 12:44:02.976118: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:44:02.981578: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:44:02.986146: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883442.998532 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 18}}
[2019-06-18 12:44:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000020-000013 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=21 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:44:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-20-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=20 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=1023779851 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=2047559682 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=3071339513 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=4095119344 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=5118899175 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=6142679006 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=7166458837 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=8190238668 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=9214018499 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=10237798330 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=11261578161 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=12285357992 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=13309137823 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=14332917654 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=15356697485 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=16380477316 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=17404257147 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=18428036978 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=19451816809 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000019-000013 --seed=20475596640 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:44:13] eval finished: 10.717 seconds
[2019-06-18 12:44:13] Win rate 000019-000013 vs 000017-000012: 0.570
:::MLL 1560883453.777462 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 18}}
[2019-06-18 12:44:13] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=21 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=1023779852 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=2047559683 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=3071339514 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=4095119345 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=5118899176 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=6142679007 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=7166458838 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=8190238669 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=9214018500 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=10237798331 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=11261578162 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=12285357993 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=13309137824 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=14332917655 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=15356697486 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=16380477317 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=17404257148 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000020-000012 --seed=18428036979 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:44:43] selfplay finished: 30.158 seconds
[2019-06-18 12:44:43] selfplay mn: 30.176 seconds
[2019-06-18 12:44:43] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-21-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779852 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559683 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339514 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119345 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899176 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679007 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458838 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238669 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018500 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798331 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578162 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357993 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137824 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917655 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697486 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477317 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257148 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036979 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816810 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596641 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376472 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156303 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000020-000012/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:44:45] train finished: 42.951 seconds
:::MLL 1560883448.237490 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.238357 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.239201 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.348237 47604818518912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.256902 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.257582 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.258245 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.348390 47821899539328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.242235 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.243104 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.243962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.348112 47306079703936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.257175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.257862 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.258533 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.348216 47885967102848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.349365 47604818518912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphmd3b5do
I0618 12:44:08.349545 47821899539328 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7eafebecc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.350468 47604818518912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphmd3b5do', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4c24e27dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.349219 47306079703936 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyxkq52dr
W0618 12:44:08.349312 47885967102848 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_na2wnu0
I0618 12:44:08.350826 47821899539328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.350312 47306079703936 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyxkq52dr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0696a9edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.350912 47604818518912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.350376 47885967102848 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_na2wnu0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d9aa55dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.350716 47306079703936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.350780 47885967102848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.356137 47821899539328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.356139 47604818518912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.355806 47306079703936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.355826 47885967102848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883448.251131 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.251873 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.252599 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.373721 47388344877952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.253212 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.253916 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.254580 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.373902 47043924861824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.375072 47306079703936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.374827 47388344877952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvfr33xnx
W0618 12:44:08.375154 47885967102848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.375000 47043924861824 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzgwdxjai
I0618 12:44:08.375938 47388344877952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvfr33xnx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b19be0cddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.376081 47043924861824 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzgwdxjai', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac98d047e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883448.283577 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.284272 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.284943 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.375882 47410018894720 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
I0618 12:44:08.376399 47388344877952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883448.277584 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.278477 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.279297 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.376302 47585870095232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
I0618 12:44:08.376537 47043924861824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.376886 47410018894720 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7stkylpp
I0618 12:44:08.377883 47410018894720 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7stkylpp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ec9ec1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.377295 47585870095232 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnd46t04o
W0618 12:44:08.378027 47821899539328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.378206 47604818518912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:44:08.378285 47410018894720 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.378283 47585870095232 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnd46t04o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b47bb787e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883448.264638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.265523 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.266359 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.378341 47286944863104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
I0618 12:44:08.378693 47585870095232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883448.271243 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.271971 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.272636 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.378417 47674285765504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.273011 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.273757 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.274420 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.378565 46955651134336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.250752 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.251670 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.252463 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.378710 46995710985088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.379512 47286944863104 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgexpz45e
W0618 12:44:08.379711 47674285765504 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf4qzsass
W0618 12:44:08.379710 46955651134336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk8d7yqba
I0618 12:44:08.380639 47286944863104 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgexpz45e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0222236e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.379788 46995710985088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfyolxoed
I0618 12:44:08.380803 47674285765504 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf4qzsass', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c51748e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.380841 46955651134336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpk8d7yqba', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4ff7e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.380892 46995710985088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfyolxoed', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abe533f1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.381103 47286944863104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.381257 47674285765504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.381291 46955651134336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.381336 46995710985088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.381748 47388344877952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.381772 47043924861824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.383047 47410018894720 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.383382 47585870095232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.386502 47286944863104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.386550 47674285765504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.386663 46995710985088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.386707 46955651134336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.402244 47410018894720 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883448.326312 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.326843 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.327253 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.402149 47900037276544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.402942 47585870095232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883448.325938 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.326444 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.326916 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.402302 47930905092992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.403696 47043924861824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.403754 47388344877952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.403143 47900037276544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppw3m5sic
W0618 12:44:08.403285 47930905092992 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpy_vm26vc
I0618 12:44:08.404119 47900037276544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppw3m5sic', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b90e14b3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.404256 47930905092992 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpy_vm26vc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b981128be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.404520 47900037276544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.404652 47930905092992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.408555 46995710985088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.408722 47286944863104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.408715 47674285765504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.408965 46955651134336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.409207 47900037276544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.409246 47930905092992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883448.344641 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.345020 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.345348 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.418609 47380139205504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.343506 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.343890 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.344224 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.419025 47410491306880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.326116 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.326576 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.326980 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.419269 47436126978944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.326658 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.327105 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.327480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.419522 47564261741440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.419621 47380139205504 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpysrnbavx
I0618 12:44:08.420592 47380139205504 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpysrnbavx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b17d4f42e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.420011 47410491306880 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf97ku98i
I0618 12:44:08.420994 47380139205504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.421010 47410491306880 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf97ku98i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1ee6147e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.420233 47436126978944 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp44a20qh6
I0618 12:44:08.421202 47436126978944 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp44a20qh6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b24de15de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.420494 47564261741440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcigil9f_
I0618 12:44:08.421410 47410491306880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.421483 47564261741440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcigil9f_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b42b3832e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.421594 47436126978944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.421882 47564261741440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.422735 47306079703936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:08.423113 47885967102848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883448.322762 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.323169 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.323526 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.423379 47495981884288 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.324771 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.325186 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.325545 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.423679 47860097803136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.424399 47495981884288 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7k9_g2n9
W0618 12:44:08.424653 47860097803136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfz5j1fpk
I0618 12:44:08.425379 47495981884288 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7k9_g2n9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32cdb73dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.425663 47380139205504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:44:08.425642 47860097803136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfz5j1fpk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8794b73e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.425790 47495981884288 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.426041 47410491306880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:44:08.426080 47860097803136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.426173 47436126978944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.426439 47564261741440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.427046 47306079703936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:08.427402 47885967102848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:08.428288 47900037276544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.428413 47930905092992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.429489 47821899539328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:08.429533 47604818518912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:08.430526 47495981884288 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.430722 47860097803136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883448.355489 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.355930 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.356334 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.431855 47804745802624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
:::MLL 1560883448.356293 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.356712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.357070 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.431899 47773586961280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
I0618 12:44:08.432084 47306079703936 estimator.py:1111] Calling model_fn.
W0618 12:44:08.432204 47306079703936 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:44:08.432478 47885967102848 estimator.py:1111] Calling model_fn.
W0618 12:44:08.432591 47885967102848 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:08.432902 47804745802624 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl21v3beb
W0618 12:44:08.432929 47773586961280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpp0i8w472
W0618 12:44:08.433811 47821899539328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:08.433806 47604818518912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:44:08.433871 47804745802624 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl21v3beb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ab17abe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:08.433910 47773586961280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpp0i8w472', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7370445e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:08.433540 47306079703936 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:44:08.434269 47804745802624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:08.434314 47773586961280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:08.433961 47885967102848 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:44:08.438862 47821899539328 estimator.py:1111] Calling model_fn.
I0618 12:44:08.438833 47604818518912 estimator.py:1111] Calling model_fn.
W0618 12:44:08.438942 47604818518912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:08.438973 47821899539328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:08.438932 47804745802624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.438963 47773586961280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:08.440324 47821899539328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:08.440285 47604818518912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:08.444930 47380139205504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.445205 47436126978944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.445464 47410491306880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.445554 47564261741440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.449796 47495981884288 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.449985 47860097803136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:08.450411 47410018894720 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883448.375138 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.375520 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.375845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.451124 47242288366464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.451359 47585870095232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883448.376911 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883448.377286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883448.377655 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:08.451433 47595522737024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000010-000006.tfrecord.zz_0_0
W0618 12:44:08.452144 47388344877952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager [2019-06-18 12:44:47] divide_golden_chunk finished: 3.329 seconds
[2019-06-18 12:44:47] generate golden chunk: 3.343 seconds
[2019-06-18 12:44:47] moving /lfs/lfs12/gma_akey/results/epb144/models/000020-000013.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000020-000014.meta
[2019-06-18 12:44:47] moving /lfs/lfs12/gma_akey/results/epb144/models/000020-000013.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000020-000014.data-00000-of-00001
[2019-06-18 12:44:47] moving /lfs/lfs12/gma_akey/results/epb144/models/000020-000013.index --> /lfs/lfs12/gma_akey/results/epb144/models/000020-000014.index
[2019-06-18 12:44:47] moving /lfs/lfs12/gma_akey/results/epb144/models/000020-000013.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb
[2019-06-18 12:44:47] iteration time 19: 48.690 seconds
2019-06-18 12:44:48.572158: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883487.337741 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:44:51] minmax time: 3.271 seconds
2019-06-18 12:44:51.853577: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:44:51.859017: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:44:51.863513: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883491.874436 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 19}}
[2019-06-18 12:44:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000021-000014 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=22 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:44:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-21-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=21 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=1023779852 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=2047559683 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=3071339514 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=4095119345 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=5118899176 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=6142679007 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=7166458838 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=8190238669 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=9214018500 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=10237798331 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=11261578162 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=12285357993 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=13309137824 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=14332917655 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=15356697486 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=16380477317 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=17404257148 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=18428036979 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=19451816810 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000019-000013.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000020-000014 --seed=20475596641 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:45:03] eval finished: 11.320 seconds
[2019-06-18 12:45:03] Win rate 000020-000014 vs 000019-000013: 0.510
:::MLL 1560883503.254272 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 19}}
[2019-06-18 12:45:03] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=22 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=1023779853 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=2047559684 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=3071339515 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=4095119346 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=5118899177 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=6142679008 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=7166458839 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=8190238670 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=9214018501 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=10237798332 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=11261578163 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=12285357994 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=13309137825 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=14332917656 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=15356697487 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=16380477318 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=17404257149 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000021-000013 --seed=18428036980 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:45:32] selfplay finished: 29.466 seconds
[2019-06-18 12:45:32] selfplay mn: 29.486 seconds
[2019-06-18 12:45:32] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-22-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779853 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559684 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339515 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119346 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899177 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679008 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458839 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238670 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018501 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798332 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578163 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357994 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137825 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917656 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697487 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477318 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257149 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036980 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816811 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596642 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376473 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156304 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000021-000013/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:45:34] train finished: 43.060 seconds
:::MLL 1560883497.106989 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.107882 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.108710 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.211277 47847860310912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.119638 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.120379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.121066 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.211357 47815497143168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
I0618 12:44:57.212505 47815497143168 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7d324f1d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:57.212523 47847860310912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp00a6f53f
I0618 12:44:57.213625 47847860310912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp00a6f53f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b84bb4dde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.213760 47815497143168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.214076 47847860310912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.219048 47815497143168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.219267 47847860310912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883497.130118 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.130790 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.131461 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.233165 46930846180224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.128327 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.129080 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.129867 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.233245 47655943029632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.234199 46930846180224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz1mxubdd
:::MLL 1560883497.114846 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.115725 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.116499 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.234549 47932756988800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.234270 47655943029632 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpoi_sezn1
:::MLL 1560883497.118967 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.119709 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.120398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.234792 47482795623296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
I0618 12:44:57.235207 46930846180224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz1mxubdd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aaf3900ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.235286 47655943029632 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpoi_sezn1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b580c249e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.235617 46930846180224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.235696 47655943029632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.235684 47932756988800 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4vzxxk35
W0618 12:44:57.235862 47482795623296 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpov6l0ht9
I0618 12:44:57.236795 47932756988800 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4vzxxk35', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b987f8a5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.236959 47482795623296 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpov6l0ht9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2fbbc0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.237239 47932756988800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.237398 47482795623296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.240743 46930846180224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.240833 47655943029632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.241002 47815497143168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.241320 47847860310912 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.242635 47932756988800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.242662 47482795623296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883497.143348 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.144100 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.144779 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.249298 48003062231936 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.139376 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.140265 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.140958 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.249515 47142014915456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.250457 48003062231936 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqrhfawld
W0618 12:44:57.250623 47142014915456 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmps_jk73l0
I0618 12:44:57.251596 48003062231936 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqrhfawld', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8de0f4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.251717 47142014915456 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmps_jk73l0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae063a3de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.252060 48003062231936 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.252162 47142014915456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.257433 48003062231936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.257431 47142014915456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883497.150450 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.151333 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.152192 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.259543 46975370380160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.165213 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.165952 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.166676 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.259925 47822561993600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.260612 46930846180224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.260911 47655943029632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.260611 46975370380160 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnnnaiy4s
I0618 12:44:57.261627 46975370380160 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnnnaiy4s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab996da1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:57.260965 47822561993600 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpiro_fxvj
I0618 12:44:57.262036 47822561993600 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpiro_fxvj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7ed7683e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.262063 46975370380160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.262485 47822561993600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.264548 47482795623296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.264565 47932756988800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.267279 46975370380160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.267756 47822561993600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883497.194620 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.195055 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.195441 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.270983 47245098902400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.271988 47245098902400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_mzw_yb4
I0618 12:44:57.272956 47245098902400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_mzw_yb4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af863ecbe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.273356 47245098902400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883497.199363 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.199789 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.200151 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.274264 47843361129344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.275246 47843361129344 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8giok5d2
I0618 12:44:57.276229 47843361129344 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8giok5d2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83af21ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.276636 47843361129344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.278009 47245098902400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.279244 47142014915456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.279374 48003062231936 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.281154 47843361129344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883497.188770 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.189183 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.189539 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.283204 47812508177280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.185353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.185923 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.186337 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.283507 47040137331584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.284223 47812508177280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl184vvih
W0618 12:44:57.284489 47040137331584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmrg0377d
I0618 12:44:57.285217 47812508177280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl184vvih', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7c80272e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.285456 47040137331584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmrg0377d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac8ab434e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.285618 47812508177280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.285851 47040137331584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.289310 46975370380160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.290410 47822561993600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.290265 47812508177280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.290387 47040137331584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.290958 47815497143168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.291054 47847860310912 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.295247 47815497143168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:57.295353 47847860310912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883497.217623 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.218083 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.218485 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.295516 47382373843840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.217888 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.218352 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.218736 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.295760 47294162715520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.296999 47245098902400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.296535 47382373843840 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz9rq1web
W0618 12:44:57.296757 47294162715520 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_srlay9h
I0618 12:44:57.297517 47382373843840 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz9rq1web', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b185a261e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.297744 47294162715520 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_srlay9h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03d05b1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.297914 47382373843840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.298141 47294162715520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.300165 47843361129344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:44:57.300281 47815497143168 estimator.py:1111] Calling model_fn.
W0618 12:44:57.300392 47815497143168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:44:57.300411 47847860310912 estimator.py:1111] Calling model_fn.
W0618 12:44:57.300525 47847860310912 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:57.301762 47815497143168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.301890 47847860310912 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.302645 47382373843840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.302766 47294162715520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.308928 47655943029632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.309453 46930846180224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.309620 47040137331584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.309674 47812508177280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883497.233097 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.233493 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.233814 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.311586 47457418068864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.232584 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.232998 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.233346 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.311636 47103794615168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.313259 47655943029632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:57.312615 47457418068864 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpokhbmtij
W0618 12:44:57.312646 47103794615168 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzf42ig0y
I0618 12:44:57.313596 47457418068864 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpokhbmtij', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b29d321fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:57.313490 47482795623296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:44:57.313615 47103794615168 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzf42ig0y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad77d886e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:57.313809 46930846180224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:57.313666 47932756988800 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:44:57.313996 47457418068864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.314008 47103794615168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883497.163625 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.164410 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.165233 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.313870 47236877411200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
:::MLL 1560883497.164253 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.165126 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.165833 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.314474 47077450908544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.314892 47236877411200 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp47upqipm
I0618 12:44:57.315888 47236877411200 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp47upqipm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af679e2be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:57.315469 47077450908544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxhj2u6bv
I0618 12:44:57.316281 47236877411200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.316507 47077450908544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxhj2u6bv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad15b535e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.316930 47077450908544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.317803 47482795623296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:57.317998 47932756988800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:44:57.318301 47655943029632 estimator.py:1111] Calling model_fn.
W0618 12:44:57.318408 47655943029632 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:57.318649 47103794615168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.318656 47457418068864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:44:57.318918 46930846180224 estimator.py:1111] Calling model_fn.
W0618 12:44:57.319029 46930846180224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:57.319754 47655943029632 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.320390 46930846180224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.321136 47236877411200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.321960 47382373843840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.322021 47294162715520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.321595 47077450908544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:44:57.322880 47482795623296 estimator.py:1111] Calling model_fn.
W0618 12:44:57.322988 47482795623296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:44:57.323101 47932756988800 estimator.py:1111] Calling model_fn.
W0618 12:44:57.323214 47932756988800 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:57.324362 47482795623296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.324579 47932756988800 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.328819 47142014915456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883497.253911 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.254339 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.254723 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.328991 47644613821312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.329417 48003062231936 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883497.253937 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883497.254356 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883497.254736 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:44:57.329418 47391010059136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000011-000007.tfrecord.zz_0_0
W0618 12:44:57.330065 47644613821312 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfkbc_6yy
I0618 12:44:57.331088 47644613821312 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfkbc_6yy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5568de9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:44:57.330473 47391010059136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuvk0j3qq
I0618 12:44:57.331465 47391010059136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuvk0j3qq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a5ce84e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:44:57.331492 47644613821312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:44:57.331860 47391010059136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:44:57.333131 47142014915456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:57.333745 48003062231936 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:44:57.336116 47644613821312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.336433 47391010059136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:44:57.337646 47457418068864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.337710 47103794615168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:44:57.338174 47142014915456 estimator.py:1111] Calling model_fn.
W0618 12:44:57.338284 47142014915456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:44:57.338857 48003062231936 estimator.py:1111] Calling model_fn.
W0618 12:44:57.338975 48003062231936 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:44:57.339654 47142014915456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.340361 48003062231936 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:44:57.340646 47236877411200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.341018 47077450908544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:44:57.342181 46975370380160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.343095 47822561993600 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.344546 47245098902400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:44:57.346848 46975370380160 deprecation.py:323] [2019-06-18 12:45:36] divide_golden_chunk finished: 3.316 seconds
[2019-06-18 12:45:36] generate golden chunk: 3.330 seconds
[2019-06-18 12:45:36] moving /lfs/lfs12/gma_akey/results/epb144/models/000021-000014.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000021-000015.meta
[2019-06-18 12:45:36] moving /lfs/lfs12/gma_akey/results/epb144/models/000021-000014.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb
[2019-06-18 12:45:36] moving /lfs/lfs12/gma_akey/results/epb144/models/000021-000014.index --> /lfs/lfs12/gma_akey/results/epb144/models/000021-000015.index
[2019-06-18 12:45:36] moving /lfs/lfs12/gma_akey/results/epb144/models/000021-000014.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000021-000015.data-00000-of-00001
[2019-06-18 12:45:36] iteration time 20: 48.781 seconds
2019-06-18 12:45:37.257829: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883536.118531 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:45:40] minmax time: 3.264 seconds
2019-06-18 12:45:40.532065: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:45:40.537501: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:45:40.542095: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883540.553044 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 20}}
[2019-06-18 12:45:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000022-000015 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=23 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:45:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-22-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=22 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=1023779853 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=2047559684 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=3071339515 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=4095119346 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=5118899177 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=6142679008 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=7166458839 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=8190238670 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=9214018501 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=10237798332 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=11261578163 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=12285357994 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=13309137825 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=14332917656 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=15356697487 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=16380477318 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=17404257149 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=18428036980 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=19451816811 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000020-000014.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000021-000015 --seed=20475596642 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:45:51] eval finished: 10.956 seconds
[2019-06-18 12:45:51] Win rate 000021-000015 vs 000020-000014: 0.530
:::MLL 1560883551.572730 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 20}}
[2019-06-18 12:45:51] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=23 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=1023779854 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=2047559685 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=3071339516 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=4095119347 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=5118899178 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=6142679009 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=7166458840 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=8190238671 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=9214018502 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=10237798333 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=11261578164 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=12285357995 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=13309137826 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=14332917657 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=15356697488 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=16380477319 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=17404257150 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000022-000014 --seed=18428036981 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:46:21] selfplay finished: 29.545 seconds
[2019-06-18 12:46:21] selfplay mn: 29.563 seconds
[2019-06-18 12:46:21] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-23-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=23 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779854 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559685 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339516 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119347 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899178 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679009 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458840 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238671 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018502 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798333 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578164 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357995 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137826 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917657 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697488 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477319 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257150 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036981 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816812 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596643 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376474 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156305 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000022-000014/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:46:23] train finished: 42.979 seconds
:::MLL 1560883545.760586 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.761448 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.762311 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.866554 47355190997888 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.765704 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.766414 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.767076 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.866654 47132841444224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.867666 47355190997888 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7w65tiqg
I0618 12:45:45.867799 47132841444224 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ade40dbdd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.868780 47355190997888 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7w65tiqg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1205ecce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.869071 47132841444224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.869225 47355190997888 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.874428 47132841444224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.874463 47355190997888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883545.771831 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.772570 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.773280 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.876191 47843514000256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.774453 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.775167 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.775831 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.876268 47226957144960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.877276 47843514000256 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0i_u25z_
W0618 12:45:45.877303 47226957144960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpiawhksq_
I0618 12:45:45.878273 47843514000256 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0i_u25z_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83b83e7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.878294 47226957144960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpiawhksq_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af42a976e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.878670 47843514000256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.878700 47226957144960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.883516 47843514000256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.883554 47226957144960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.896548 47132841444224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.896704 47355190997888 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.902935 47843514000256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.903111 47226957144960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883545.792680 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.793591 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.794414 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.909606 47856098714496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.805275 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.805997 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.806615 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.909623 47520569574272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.803354 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.804051 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.804756 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.910376 47183860147072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.793016 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.793914 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.794787 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.910775 46966269051776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.910785 47520569574272 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3f4mn4oq
W0618 12:45:45.910754 47856098714496 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpohe023xf
I0618 12:45:45.911894 47520569574272 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3f4mn4oq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3887418e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.911892 47856098714496 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpohe023xf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86a659fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.912333 47520569574272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.912337 47856098714496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.911515 47183860147072 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpawq6aptf
I0618 12:45:45.912658 47183860147072 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpawq6aptf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea21cf7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:45:45.911872 46966269051776 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmg0igim0
I0618 12:45:45.912975 46966269051776 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmg0igim0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab7785ede48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.913123 47183860147072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.913437 46966269051776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.917685 47856098714496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.917693 47520569574272 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.918513 47183860147072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.918591 46966269051776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883545.847717 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.848145 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.848523 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.926523 47012503700352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.774730 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.775586 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.776372 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.926606 47931547317120 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.927533 47012503700352 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdrpomikk
:::MLL 1560883545.850920 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.851312 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.851650 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.928385 46998771168128 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
I0618 12:45:45.928541 47012503700352 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdrpomikk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac23c2b6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:45:45.927702 47931547317120 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyah6g4oz
I0618 12:45:45.928939 47012503700352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.928805 47931547317120 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyah6g4oz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9837704e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.929253 47931547317120 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.929361 46998771168128 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpau84yn4_
I0618 12:45:45.930353 46998771168128 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpau84yn4_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abf09a5be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.930762 46998771168128 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.933573 47012503700352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.934687 47931547317120 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883545.775175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.776022 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.776734 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.934839 47524274742144 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.935291 46998771168128 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.935936 47524274742144 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvn2cdswn
I0618 12:45:45.937045 47524274742144 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvn2cdswn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b396419fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883545.857527 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.857972 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.858373 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.937342 47295860568960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
I0618 12:45:45.937497 47524274742144 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.938326 47295860568960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnhm_8lga
I0618 12:45:45.939316 47295860568960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnhm_8lga', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b04358e4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.939717 47295860568960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.939744 47856098714496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.939942 47520569574272 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883545.862323 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.862773 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.863167 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.939875 47055546946432 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.940273 46966269051776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.940976 47183860147072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.940896 47055546946432 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkawb5s2g
I0618 12:45:45.941869 47055546946432 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkawb5s2g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc41bf5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.942270 47055546946432 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.942727 47524274742144 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.944357 47295860568960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.946097 47132841444224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:45:45.946565 47355190997888 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:45:45.946837 47055546946432 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.950364 47132841444224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:45:45.950857 47355190997888 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:45:45.951171 47843514000256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:45:45.951469 47226957144960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:45:45.952658 47012503700352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883545.788633 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.789422 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.790099 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.952251 47350052578176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.792096 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.792754 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.793424 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.952308 47343137997696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.954477 46998771168128 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.953351 47343137997696 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpk3ih36ks
W0618 12:45:45.953320 47350052578176 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplbwt2z2v
I0618 12:45:45.954339 47343137997696 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpk3ih36ks', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0f37828e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.954333 47350052578176 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplbwt2z2v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b10d3a6be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.954736 47343137997696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.954737 47350052578176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.955403 47132841444224 estimator.py:1111] Calling model_fn.
W0618 12:45:45.955527 47132841444224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:45:45.955481 47843514000256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:45:45.955822 47226957144960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:45:45.955883 47355190997888 estimator.py:1111] Calling model_fn.
W0618 12:45:45.955991 47355190997888 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:45:45.956879 47132841444224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:45:45.956785 47931547317120 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.957338 47355190997888 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:45:45.959735 47343137997696 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.959911 47350052578176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:45:45.960553 47843514000256 estimator.py:1111] Calling model_fn.
W0618 12:45:45.960663 47843514000256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:45:45.960923 47226957144960 estimator.py:1111] Calling model_fn.
W0618 12:45:45.961033 47226957144960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:45:45.962037 47843514000256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:45:45.962402 47226957144960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:45:45.963448 47295860568960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883545.881782 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.882284 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.882725 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.964222 47098585236352 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.964837 47524274742144 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883545.888316 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.888702 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.889030 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.965244 47784008029056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.965261 47098585236352 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyp9i93ko
W0618 12:45:45.965978 47055546946432 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:45:45.966250 47098585236352 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyp9i93ko', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad647077e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.966650 47098585236352 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.966258 47784008029056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppmn0_8b8
I0618 12:45:45.967266 47784008029056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppmn0_8b8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b75dd696e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.967673 47784008029056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.971284 47098585236352 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.972237 47784008029056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883545.845233 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.845735 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.846159 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.972311 47145613558656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.848516 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.848929 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.849292 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.972410 47673737704320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.973379 47145613558656 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppwpru97m
W0618 12:45:45.973449 47673737704320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxown0ux4
I0618 12:45:45.974435 47145613558656 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppwpru97m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae13a22de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.974488 47673737704320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxown0ux4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c30c9ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.974867 47145613558656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:45:45.974913 47673737704320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883545.895659 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.896077 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.896402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.977107 47165272597376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.898382 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.898762 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.899095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.978161 47118806053760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.978129 47165272597376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpd2clrecg
I0618 12:45:45.979115 47165272597376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpd2clrecg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5cde7fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:45:45.978728 47343137997696 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:45:45.979518 47165272597376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.979602 47145613558656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.979359 47350052578176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.979621 47673737704320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.979129 47118806053760 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpv6zwzptr
I0618 12:45:45.980116 47118806053760 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpv6zwzptr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adafc48cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:45:45.980516 47118806053760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:45:45.984110 47165272597376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.985066 47118806053760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:45:45.990406 47098585236352 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883545.860033 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.860530 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.860972 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.990263 47946072716160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
:::MLL 1560883545.860895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883545.861393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883545.861816 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:45:45.990696 47156506043264 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000012-000008.tfrecord.zz_0_0
W0618 12:45:45.991550 47784008029056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:45:45.991642 47520569574272 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:45:45.991684 47856098714496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:45:45.991284 47946072716160 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmmg6s6he
W0618 12:45:45.992594 46966269051776 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:45:45.992279 47946072716160 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmmg6s6he', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': [2019-06-18 12:46:24] divide_golden_chunk finished: 3.244 seconds
[2019-06-18 12:46:24] generate golden chunk: 3.258 seconds
[2019-06-18 12:46:24] moving /lfs/lfs12/gma_akey/results/epb144/models/000022-000015.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000022-000016.meta
[2019-06-18 12:46:24] moving /lfs/lfs12/gma_akey/results/epb144/models/000022-000015.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000022-000016.data-00000-of-00001
[2019-06-18 12:46:24] moving /lfs/lfs12/gma_akey/results/epb144/models/000022-000015.index --> /lfs/lfs12/gma_akey/results/epb144/models/000022-000016.index
[2019-06-18 12:46:24] moving /lfs/lfs12/gma_akey/results/epb144/models/000022-000015.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb
[2019-06-18 12:46:24] iteration time 21: 48.323 seconds
2019-06-18 12:46:25.673411: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883584.441243 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:46:28] minmax time: 3.225 seconds
2019-06-18 12:46:28.908623: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:46:28.914202: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:46:28.918770: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883588.930121 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 21}}
[2019-06-18 12:46:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=24 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:46:28] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-23-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=23 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=1023779854 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=2047559685 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=3071339516 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=4095119347 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=5118899178 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=6142679009 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=7166458840 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=8190238671 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=9214018502 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=10237798333 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=11261578164 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=12285357995 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=13309137826 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=14332917657 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=15356697488 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=16380477319 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=17404257150 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=18428036981 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=19451816812 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000022-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000022-000016 --seed=20475596643 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:46:40] eval finished: 11.760 seconds
[2019-06-18 12:46:40] Win rate 000022-000016 vs 000021-000015: 0.420
:::MLL 1560883600.752137 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 21}}
[2019-06-18 12:46:40] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=24 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=1023779855 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=2047559686 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=3071339517 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=4095119348 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=5118899179 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=6142679010 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=7166458841 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=8190238672 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=9214018503 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=10237798334 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=11261578165 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=12285357996 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=13309137827 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=14332917658 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=15356697489 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=16380477320 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=17404257151 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000023-000015 --seed=18428036982 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:47:09] selfplay finished: 29.086 seconds
[2019-06-18 12:47:09] selfplay mn: 29.103 seconds
[2019-06-18 12:47:09] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-24-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=24 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779855 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559686 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339517 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119348 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899179 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679010 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458841 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238672 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018503 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798334 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578165 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357996 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137827 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917658 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697489 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477320 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257151 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036982 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816813 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596644 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376475 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156306 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000023-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:47:12] train finished: 43.309 seconds
:::MLL 1560883594.173796 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.174685 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.175537 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.282121 47222692115328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.178467 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.179165 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.179845 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.282376 47111626920832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.283273 47222692115328 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxzz_bd1s
W0618 12:46:34.283505 47111626920832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6tluc7w2
I0618 12:46:34.284391 47222692115328 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxzz_bd1s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af32c603e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.284645 47111626920832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6tluc7w2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad9505fde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.284852 47222692115328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.285121 47111626920832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.290167 47222692115328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.290515 47111626920832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883594.198686 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.199435 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.200126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.296583 46991416435584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.193412 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.194351 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.195229 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.296630 47280441635712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.297639 46991416435584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjy99yiox
W0618 12:46:34.297672 47280441635712 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzbjm7bf0
I0618 12:46:34.298637 46991416435584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjy99yiox', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd53457e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.298662 47280441635712 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzbjm7bf0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b009e840e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.299035 46991416435584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.299048 47280441635712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.303997 46991416435584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.304006 47280441635712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.312112 47222692115328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.313678 47111626920832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.323272 47280441635712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.323317 46991416435584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883594.194364 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.195235 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.196018 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.328154 47332180865920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.198881 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.199600 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.200290 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.328954 47181496578944 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.221871 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.222650 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.223361 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.329018 47376179344256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.219061 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.219774 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.220480 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.329068 47015412786048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.329322 47332180865920 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbzkbeo4p
I0618 12:46:34.330418 47332180865920 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbzkbeo4p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0caa6a0dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.330891 47332180865920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.330081 47181496578944 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae994ee4d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:46:34.330230 47376179344256 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptt0w8gfu
W0618 12:46:34.330265 47015412786048 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyhqkp0oj
I0618 12:46:34.331375 47181496578944 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.331340 47376179344256 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptt0w8gfu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b16e8ed8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.331366 47015412786048 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyhqkp0oj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac2e990be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.331789 47376179344256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.331828 47015412786048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.336240 47332180865920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.336485 47181496578944 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.337150 47015412786048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.337206 47376179344256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883594.246883 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.247405 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.247946 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.337554 46991732495232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.338655 46991732495232 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplaur63oh
I0618 12:46:34.339669 46991732495232 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplaur63oh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd661c2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883594.259545 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.259931 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.260313 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.339536 47757581218688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
I0618 12:46:34.340066 46991732495232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.340521 47757581218688 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpns8oem5j
I0618 12:46:34.341491 47757581218688 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpns8oem5j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6fb6403e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.341888 47757581218688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.344713 46991732495232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883594.243635 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.244393 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.245091 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.345911 47063185134464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.240175 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.241015 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.241696 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.346026 47946696045440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.346396 47757581218688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.347040 47063185134464 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl55kft2p
W0618 12:46:34.347135 47946696045440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxdu4or88
I0618 12:46:34.348155 47063185134464 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl55kft2p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ace0904ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.348226 47946696045440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxdu4or88', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9bbe5f8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.348607 47063185134464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.348688 47946696045440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.354005 47063185134464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.354102 47946696045440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.358501 47332180865920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.358620 47181496578944 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.359277 47015412786048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.359312 47376179344256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.363831 46991732495232 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.363923 47222692115328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:46:34.365377 47111626920832 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:46:34.365507 47757581218688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.368557 47222692115328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:46:34.370032 47111626920832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883594.214592 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.215339 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.216031 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.369627 47069008089984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.212487 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.213218 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.213981 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.369933 47954954466176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.371783 46991416435584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:46:34.370671 47069008089984 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyr_o9dbb
W0618 12:46:34.371857 47280441635712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:46:34.370930 47954954466176 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpewtmpvno
I0618 12:46:34.371666 47069008089984 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyr_o9dbb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acf64181e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.371913 47954954466176 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpewtmpvno', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9daa9d0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.372066 47069008089984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.372311 47954954466176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.374019 47222692115328 estimator.py:1111] Calling model_fn.
W0618 12:46:34.374131 47222692115328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:46:34.375500 47111626920832 estimator.py:1111] Calling model_fn.
W0618 12:46:34.375603 47222692115328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:46:34.375622 47111626920832 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:46:34.375940 47063185134464 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.376105 46991416435584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:46:34.376161 47280441635712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:46:34.376574 47946696045440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.376726 47069008089984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.377081 47111626920832 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:46:34.376975 47954954466176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883594.279533 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.279958 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.280329 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.378749 46987948704640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.281383 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.281805 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.282177 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.378884 47990093935488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.296351 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.296819 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.297220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.378912 47699211432832 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.296307 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.296774 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.297175 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.379100 47765598368640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.379789 46987948704640 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkge9h2nr
W0618 12:46:34.379868 47990093935488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcr3d47fa
W0618 12:46:34.379936 47699211432832 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppk_b3_pi
I0618 12:46:34.380778 46987948704640 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkge9h2nr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abc84941e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:46:34.380103 47765598368640 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpilw8zfu7
I0618 12:46:34.380841 47990093935488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcr3d47fa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba5d916ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.380904 47699211432832 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppk_b3_pi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b621f23fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.381072 47765598368640 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpilw8zfu7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b71941c4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.381173 46987948704640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.381239 47990093935488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.381303 47699211432832 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.381363 46991416435584 estimator.py:1111] Calling model_fn.
I0618 12:46:34.381380 47280441635712 estimator.py:1111] Calling model_fn.
I0618 12:46:34.381474 47765598368640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.381475 46991416435584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:46:34.381493 47280441635712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:46:34.382845 46991416435584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:46:34.382842 47280441635712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:46:34.385799 46987948704640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.385823 47990093935488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.385962 47699211432832 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.386010 47765598368640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883594.303355 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.303800 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.304398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.388575 47366802625408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.303221 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.303665 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.304238 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.388708 46993268462464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.389617 47366802625408 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpmlueglyj
W0618 12:46:34.389693 46993268462464 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp37x0iwj0
I0618 12:46:34.390602 47366802625408 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpmlueglyj', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14ba081dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.390671 46993268462464 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp37x0iwj0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abdc1a92e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.391001 47366802625408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:46:34.391071 46993268462464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.395613 47366802625408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.395673 46993268462464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:46:34.395723 47069008089984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.396103 47954954466176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.404861 46987948704640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.404979 47990093935488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.405062 47765598368640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:46:34.405118 47699211432832 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883594.324401 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.324780 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.325101 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.405443 47196105421696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.326532 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.326910 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.327233 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.406344 47003560551296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.406472 47196105421696 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpomg9ucfd
I0618 12:46:34.407455 47196105421696 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpomg9ucfd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aecfbaf8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:46:34.407430 47332180865920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:46:34.407831 47181496578944 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:46:34.407851 47196105421696 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.407334 47003560551296 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu_3pibr8
I0618 12:46:34.408330 47003560551296 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu_3pibr8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac0271dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:46:34.408737 47003560551296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:46:34.409521 47015412786048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:46:34.409737 47376179344256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883594.274598 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.275062 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.275464 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.409877 47391059723136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
:::MLL 1560883594.273389 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883594.273879 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883594.274302 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:46:34.409999 46976592077696 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000022-000014.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000013-000009.tfrecord.zz_0_0
W0618 12:46:34.411214 46991732495232 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being d[2019-06-18 12:47:13] divide_golden_chunk finished: 3.279 seconds
[2019-06-18 12:47:13] generate golden chunk: 3.293 seconds
[2019-06-18 12:47:13] iteration time 22: 48.708 seconds
2019-06-18 12:47:14.425795: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883633.149673 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:47:17] minmax time: 3.260 seconds
2019-06-18 12:47:17.695571: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:47:17.701120: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:47:17.705795: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883637.718825 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 22}}
[2019-06-18 12:47:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=25 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:47:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-24-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=24 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=1023779855 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=2047559686 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=3071339517 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=4095119348 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=5118899179 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=6142679010 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=7166458841 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=8190238672 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=9214018503 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=10237798334 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=11261578165 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=12285357996 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=13309137827 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=14332917658 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=15356697489 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=16380477320 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=17404257151 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=18428036982 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=19451816813 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000023-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000023-000016 --seed=20475596644 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:47:29] eval finished: 11.820 seconds
[2019-06-18 12:47:29] Win rate 000023-000016 vs 000021-000015: 0.330
:::MLL 1560883649.601478 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 22}}
[2019-06-18 12:47:29] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=25 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=1023779856 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=2047559687 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=3071339518 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=4095119349 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=5118899180 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=6142679011 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=7166458842 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=8190238673 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=9214018504 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=10237798335 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=11261578166 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=12285357997 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=13309137828 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=14332917659 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=15356697490 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=16380477321 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=17404257152 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000024-000015 --seed=18428036983 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:47:58] selfplay finished: 29.157 seconds
[2019-06-18 12:47:58] selfplay mn: 29.178 seconds
[2019-06-18 12:47:58] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-25-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=25 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779856 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559687 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339518 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119349 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899180 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679011 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458842 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238673 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018504 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798335 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578166 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357997 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137828 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917659 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697490 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477321 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257152 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036983 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816814 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596645 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376476 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156307 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000024-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:48:01] train finished: 43.386 seconds
:::MLL 1560883642.891923 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.892638 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.893288 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.004307 47974256501632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.895178 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.895908 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.896551 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.004611 47748084335488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
I0618 12:47:23.005486 47974256501632 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba2291abd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:47:23.005690 47748084335488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsjmclo2m
I0618 12:47:23.006758 47974256501632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.006778 47748084335488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsjmclo2m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d80314e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.007211 47748084335488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.012158 47974256501632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.012432 47748084335488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883642.907099 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.907989 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.908794 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.015688 46940352852864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.911585 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.912293 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.912960 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.015721 47545553822592 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.016851 47545553822592 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmph7_a0_9b
W0618 12:47:23.016883 46940352852864 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpv1evewsg
I0618 12:47:23.017979 47545553822592 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmph7_a0_9b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e586efe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.018004 46940352852864 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpv1evewsg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab16fa50e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.018445 46940352852864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.018439 47545553822592 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.023756 46940352852864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.023791 47545553822592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.034301 47974256501632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.034540 47748084335488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883642.932536 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.933378 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.934136 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.043607 47384223527808 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.932034 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.932832 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.933631 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.043959 47005912851328 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.044733 47384223527808 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp3t5cxsb2
I0618 12:47:23.045862 47384223527808 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp3t5cxsb2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b18c8660e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:47:23.045048 47005912851328 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6miip0_z
W0618 12:47:23.045876 46940352852864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.045963 47545553822592 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:47:23.046170 47005912851328 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6miip0_z', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac0b3533e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.046316 47384223527808 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.046626 47005912851328 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.051536 47384223527808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.051817 47005912851328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883642.968845 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.969336 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.969776 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.058223 47346441671552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.059231 47346441671552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvuicb539
:::MLL 1560883642.951353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.952220 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.953048 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.059836 47420960117632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.958240 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.958989 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.959696 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.060027 46991911031680 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
I0618 12:47:23.060227 47346441671552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvuicb539', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0ffc6cae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.060633 47346441671552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.060836 47420960117632 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgfsxhm4h
W0618 12:47:23.061030 46991911031680 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpp_tel7vt
I0618 12:47:23.061836 47420960117632 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgfsxhm4h', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b215611ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.062026 46991911031680 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpp_tel7vt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd70c05e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.062243 47420960117632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.062440 46991911031680 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.065388 47346441671552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883642.972711 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.973126 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.973494 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.065712 47829747028864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.067188 47420960117632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.067244 46991911031680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.066693 47829747028864 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxsr9yldw
I0618 12:47:23.067671 47829747028864 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxsr9yldw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8083ab2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.068070 47829747028864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.072566 47829747028864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.073219 47384223527808 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.074066 47005912851328 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.084631 47346441671552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.085267 47974256501632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.085349 47748084335488 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.086616 47420960117632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.087399 46991911031680 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883642.984963 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.985457 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.986014 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.087750 47972668949376 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.994748 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.995163 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.995484 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.087973 47809340265344 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.089566 47974256501632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.089685 47748084335488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.088785 47972668949376 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpoz58kfti
W0618 12:47:23.088972 47809340265344 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8um5yqsq
I0618 12:47:23.089748 47972668949376 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpoz58kfti', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba1ca7a8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.089937 47809340265344 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8um5yqsq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bc354ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.090132 47972668949376 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.090329 47809340265344 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.091749 47829747028864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:47:23.094671 47974256501632 estimator.py:1111] Calling model_fn.
W0618 12:47:23.094791 47974256501632 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:47:23.094817 47748084335488 estimator.py:1111] Calling model_fn.
W0618 12:47:23.094934 47748084335488 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:47:23.094763 47972668949376 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.094925 47809340265344 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.096210 47974256501632 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:47:23.096346 47748084335488 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:47:23.097386 46940352852864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.097566 47545553822592 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883642.983370 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.984244 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.985118 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.097588 47284438176640 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.987914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.988643 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.989259 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.097935 47408641213312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.098699 47284438176640 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbmdx6zva
I0618 12:47:23.099855 47284438176640 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbmdx6zva', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b018cba6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:47:23.099000 47408641213312 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6ymtelxg
I0618 12:47:23.100289 47408641213312 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6ymtelxg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e77ce5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.100329 47284438176640 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.100759 47408641213312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.101825 46940352852864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.102001 47545553822592 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883643.021026 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883643.021471 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883643.021797 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.105071 47528553063296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.105581 47284438176640 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883643.020682 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883643.021092 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883643.021474 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.105676 47521348928384 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.105955 47408641213312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.106091 47528553063296 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1fu7ztr6
I0618 12:47:23.107078 47528553063296 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1fu7ztr6', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3a631bfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.107020 46940352852864 estimator.py:1111] Calling model_fn.
W0618 12:47:23.107130 46940352852864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:47:23.107136 47545553822592 estimator.py:1111] Calling model_fn.
W0618 12:47:23.107248 47545553822592 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:47:23.106657 47521348928384 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgrxfoqp4
I0618 12:47:23.107479 47528553063296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.107626 47521348928384 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgrxfoqp4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b38b5b59e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.108024 47521348928384 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883642.980320 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.981070 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.981778 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.107769 47055603929984 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883642.975373 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883642.976233 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883642.977095 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.107959 46943988622208 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.108491 46940352852864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:47:23.108600 47545553822592 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:47:23.108799 47055603929984 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpc7j1bcx7
W0618 12:47:23.108960 46943988622208 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp64pknmyx
I0618 12:47:23.109803 47055603929984 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpc7j1bcx7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acc4524ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.109933 46943988622208 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp64pknmyx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab2485a7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.110205 47055603929984 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.110327 46943988622208 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.112096 47528553063296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.112566 47521348928384 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.113735 47972668949376 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.114057 47809340265344 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.115154 47055603929984 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.115158 46943988622208 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.123031 47384223527808 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.123709 47005912851328 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.127327 47384223527808 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.127780 47284438176640 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.128009 47005912851328 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.128274 47408641213312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.131224 47528553063296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.131797 47521348928384 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:47:23.132430 47384223527808 estimator.py:1111] Calling model_fn.
W0618 12:47:23.132559 47346441671552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.132537 47384223527808 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:47:23.133118 47005912851328 estimator.py:1111] Calling model_fn.
W0618 12:47:23.133227 47005912851328 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560883643.048369 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883643.048775 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883643.049126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.133256 47039150433152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
:::MLL 1560883643.047367 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883643.047776 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883643.048166 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:47:23.133333 47969897362304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000023-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000014-000009.tfrecord.zz_0_0
W0618 12:47:23.133913 47384223527808 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:47:23.134608 47005912851328 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:47:23.134374 47055603929984 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.134238 47039150433152 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_6_a2d8j
W0618 12:47:23.134322 47969897362304 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwb65623s
I0618 12:47:23.135218 47039150433152 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_6_a2d8j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac870707dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:47:23.135293 47969897362304 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwb65623s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba125478e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:47:23.134943 46943988622208 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:47:23.135434 47420960117632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:47:23.135629 47039150433152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:47:23.135693 47969897362304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:47:23.136124 46991911031680 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.136901 47346441671552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.139004 47829747028864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:47:23.139746 47420960117632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:47:23.140438 47039150433152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:47:23.140461 46991911031680 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site[2019-06-18 12:48:02] divide_golden_chunk finished: 3.353 seconds
[2019-06-18 12:48:02] generate golden chunk: 3.368 seconds
[2019-06-18 12:48:02] iteration time 23: 49.000 seconds
2019-06-18 12:48:03.456163: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883682.149927 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:48:06] minmax time: 3.236 seconds
2019-06-18 12:48:06.702224: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:48:06.707741: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:48:06.712526: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883686.725513 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 23}}
[2019-06-18 12:48:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=26 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:48:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-25-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=25 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=1023779856 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=2047559687 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=3071339518 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=4095119349 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=5118899180 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=6142679011 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=7166458842 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=8190238673 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=9214018504 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=10237798335 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=11261578166 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=12285357997 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=13309137828 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=14332917659 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=15356697490 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=16380477321 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=17404257152 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=18428036983 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=19451816814 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000024-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000024-000016 --seed=20475596645 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:48:19] eval finished: 12.693 seconds
[2019-06-18 12:48:19] Win rate 000024-000016 vs 000021-000015: 0.470
:::MLL 1560883699.483195 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 23}}
[2019-06-18 12:48:19] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=26 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=1023779857 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=2047559688 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=3071339519 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=4095119350 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=5118899181 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=6142679012 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=7166458843 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=8190238674 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=9214018505 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=10237798336 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=11261578167 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=12285357998 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=13309137829 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=14332917660 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=15356697491 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=16380477322 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=17404257153 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000025-000015 --seed=18428036984 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:48:48] selfplay finished: 29.434 seconds
[2019-06-18 12:48:48] selfplay mn: 29.455 seconds
[2019-06-18 12:48:48] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-26-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=26 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779857 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559688 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339519 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119350 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899181 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679012 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458843 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238674 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018505 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798336 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578167 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357998 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137829 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917660 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697491 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477322 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257153 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036984 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816815 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596646 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376477 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156308 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000025-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:48:49] train finished: 43.189 seconds
:::MLL 1560883691.932790 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.933498 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.934198 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.046819 47256543069056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883691.930745 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.931465 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.932173 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.046883 47050345309056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883691.930857 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.931745 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.932582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.047596 46966792774528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883691.942606 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.943310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.943977 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.047612 47253306778496 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.047963 47256543069056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8l1b8z_s
W0618 12:48:12.047994 47050345309056 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbimzmvtp
I0618 12:48:12.049106 47050345309056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbimzmvtp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acb0bb4be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.049109 47256543069056 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8l1b8z_s', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb0e0cde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:48:12.048792 46966792774528 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5uwzmzvs
I0618 12:48:12.049546 47050345309056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.049562 47256543069056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.048821 47253306778496 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdzbwcmxa
I0618 12:48:12.049906 46966792774528 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5uwzmzvs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab797963e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.049943 47253306778496 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdzbwcmxa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa4d26fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.050354 46966792774528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.050397 47253306778496 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.054860 47050345309056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.054927 47256543069056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.055565 46966792774528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.055644 47253306778496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.076500 47050345309056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.077091 47256543069056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.077213 46966792774528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.077721 47253306778496 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883691.939705 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.940423 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.941066 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.092344 47742951691136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883691.932478 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.933319 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.934123 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.092446 47174677754752 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
I0618 12:48:12.093517 47742951691136 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6c4e435d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:48:12.093555 47174677754752 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpkcnfrhkh
I0618 12:48:12.094643 47174677754752 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpkcnfrhkh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae7fe7f4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.094786 47742951691136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.095097 47174677754752 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883691.978089 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.978879 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.979556 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.098808 47353329030016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883691.981342 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.982090 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.982724 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.098986 47909955117952 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883692.006160 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.006677 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.007109 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.099173 47078769607552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.100111 47742951691136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.100331 47174677754752 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.099812 47353329030016 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8tone8wc
W0618 12:48:12.099966 47909955117952 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj0efhvln
I0618 12:48:12.100826 47353329030016 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8tone8wc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1196f14e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.100964 47909955117952 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj0efhvln', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9330717dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:48:12.100162 47078769607552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpr0u4y02e
I0618 12:48:12.101224 47353329030016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.101147 47078769607552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpr0u4y02e', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad1a9ed0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.101371 47909955117952 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.101537 47078769607552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.106189 47353329030016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.106240 47909955117952 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.106213 47078769607552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883692.019599 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.020030 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.020402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.108905 47309279564672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.109886 47309279564672 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpq3frh7zv
I0618 12:48:12.110871 47309279564672 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpq3frh7zv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b075563ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.111262 47309279564672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.115792 47309279564672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883692.033062 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.033484 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.033867 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.120657 47250371715968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883692.033045 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.033462 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.033839 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.121118 47848031011712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883691.973427 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.974326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.975022 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.120937 47847215408000 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.121744 47742951691136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.122243 47174677754752 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.121686 47250371715968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpy2ntazng
:::MLL 1560883691.977276 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883691.978015 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883691.978744 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.121981 47566620918656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
I0618 12:48:12.122685 47250371715968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpy2ntazng', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af99e357e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:48:12.122124 47848031011712 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpml1nkqpi
I0618 12:48:12.123097 47250371715968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.121984 47847215408000 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpg7r0g3rf
I0618 12:48:12.123115 47848031011712 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpml1nkqpi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b84c57a9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.122991 47847215408000 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpg7r0g3rf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8494dd7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.123515 47848031011712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.123389 47847215408000 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.122976 47566620918656 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnncbg6yu
I0618 12:48:12.123975 47566620918656 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnncbg6yu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4340213e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.124379 47566620918656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.125303 47353329030016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.125416 47909955117952 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.125175 47078769607552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.127761 47250371715968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.128114 47848031011712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883692.019205 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.020149 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.021003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.128305 47315799593856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883692.029806 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.030547 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.031229 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.128440 47915899298688 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.128207 47847215408000 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.128654 47050345309056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.129045 47256543069056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.129093 46966792774528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.129111 47566620918656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.129786 47253306778496 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.129442 47315799593856 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprfc74b52
W0618 12:48:12.129548 47915899298688 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplv_7lnd0
I0618 12:48:12.130559 47315799593856 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmprfc74b52', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b08da03ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.130654 47915899298688 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplv_7lnd0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9492be4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.131005 47315799593856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.131104 47915899298688 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.133264 47050345309056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:48:12.133644 47256543069056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:48:12.133722 46966792774528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:48:12.134448 47253306778496 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:48:12.134772 47309279564672 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883692.008985 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.009516 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.009967 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.136121 47480307536768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.136346 47915899298688 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.136361 47315799593856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.137169 47480307536768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpr7a4sucx
I0618 12:48:12.138174 47480307536768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpr7a4sucx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2f2773ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.138587 47480307536768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.138738 47050345309056 estimator.py:1111] Calling model_fn.
W0618 12:48:12.138855 47050345309056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:48:12.139094 47256543069056 estimator.py:1111] Calling model_fn.
I0618 12:48:12.139147 46966792774528 estimator.py:1111] Calling model_fn.
:::MLL 1560883692.020271 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.020676 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.021061 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.139234 47470853854080 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.139204 47256543069056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:48:12.139261 46966792774528 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:48:12.139901 47253306778496 estimator.py:1111] Calling model_fn.
W0618 12:48:12.140015 47253306778496 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:48:12.140291 47050345309056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:48:12.140702 46966792774528 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:48:12.140663 47256543069056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:48:12.140219 47470853854080 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpinaitxe_
I0618 12:48:12.141209 47470853854080 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpinaitxe_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2cf3f7be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.141606 47470853854080 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.141477 47253306778496 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:48:12.143202 47480307536768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.146120 47470853854080 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.146779 47250371715968 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.147055 47848031011712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.147464 47847215408000 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.148052 47566620918656 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.158021 47315799593856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.158017 47915899298688 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.162060 47480307536768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:48:12.165203 47470853854080 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883692.037052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.037539 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.037972 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.166612 47659185464192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883692.080486 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.080960 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.081389 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.167276 47391965660032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883692.038310 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.038795 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.039200 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.166926 47046235677568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
:::MLL 1560883692.080569 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883692.081044 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883692.081470 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:48:12.167415 47935623062400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000024-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000015-000009.tfrecord.zz_0_0
W0618 12:48:12.167647 47659185464192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpg1wf79ws
W0618 12:48:12.168284 47391965660032 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7jhc4nmv
I0618 12:48:12.168629 47659185464192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpg1wf79ws', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b58cd683e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:48:12.168408 47935623062400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5jfp9ky0
W0618 12:48:12.167936 47046235677568 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzghn9p1x
I0618 12:48:12.169259 47391965660032 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7jhc4nmv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1a95dd9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.169396 47935623062400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5jfp9ky0', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b992a5f3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.168933 47046235677568 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzghn9p1x', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca16c0ae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:48:12.169026 47659185464192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.169658 47391965660032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.169792 47935623062400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:48:12.169338 47046235677568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:48:12.170004 47742951691136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.170036 47174677754752 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.172401 47078769607552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.172960 47353329030016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.173400 47909955117952 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:48:12.174294 47391965660032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.173689 47659185464192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:48:12.174342 47742951691136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:48:12.174389 47935623062400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) [2019-06-18 12:48:52] divide_golden_chunk finished: 3.319 seconds
[2019-06-18 12:48:52] generate golden chunk: 3.333 seconds
[2019-06-18 12:48:52] iteration time 24: 50.124 seconds
2019-06-18 12:48:53.607339: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883732.273671 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:48:56] minmax time: 3.253 seconds
2019-06-18 12:48:56.870485: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:48:56.879673: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:48:56.884144: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883736.896943 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 24}}
[2019-06-18 12:48:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=27 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:48:56] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-26-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=26 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=1023779857 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=2047559688 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=3071339519 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=4095119350 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=5118899181 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=6142679012 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=7166458843 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=8190238674 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=9214018505 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=10237798336 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=11261578167 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=12285357998 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=13309137829 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=14332917660 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=15356697491 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=16380477322 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=17404257153 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=18428036984 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=19451816815 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000025-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000025-000016 --seed=20475596646 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:49:08] eval finished: 11.406 seconds
[2019-06-18 12:49:08] Win rate 000025-000016 vs 000021-000015: 0.480
:::MLL 1560883748.364528 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 24}}
[2019-06-18 12:49:08] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=27 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=1023779858 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=2047559689 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=3071339520 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=4095119351 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=5118899182 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=6142679013 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=7166458844 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=8190238675 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=9214018506 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=10237798337 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=11261578168 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=12285357999 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=13309137830 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=14332917661 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=15356697492 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=16380477323 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=17404257154 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000026-000015 --seed=18428036985 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:49:37] selfplay finished: 29.194 seconds
[2019-06-18 12:49:37] selfplay mn: 29.215 seconds
[2019-06-18 12:49:37] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-27-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=27 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779858 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559689 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339520 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119351 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899182 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679013 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458844 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238675 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018506 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798337 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578168 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285357999 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137830 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917661 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697492 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477323 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257154 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036985 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816816 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596647 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376478 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156309 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000026-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:49:40] train finished: 43.573 seconds
:::MLL 1560883742.126394 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.127084 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.127753 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.232506 47377023869824 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.116041 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.116944 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.117801 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.232630 47366617015168 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
I0618 12:49:02.233698 47377023869824 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b171b43ed30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:02.233772 47366617015168 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwsa52j9p
I0618 12:49:02.234850 47366617015168 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwsa52j9p', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b14aef7fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.234956 47377023869824 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.235306 47366617015168 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.240297 47377023869824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.240556 47366617015168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.262115 47377023869824 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.262498 47366617015168 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883742.151020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.151881 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.152750 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.283145 47912488244096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.158550 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.159310 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.160021 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.283331 47174842512256 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.284265 47912488244096 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_ksktrmi
W0618 12:49:02.284430 47174842512256 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnngmptah
I0618 12:49:02.285349 47912488244096 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_ksktrmi', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b93c76dee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.285504 47174842512256 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnngmptah', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae808514e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.285795 47912488244096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.285943 47174842512256 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.291136 47912488244096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.291151 47174842512256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883742.154525 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.155374 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.156200 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.291847 47809708082048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.159404 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.160137 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.160791 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.292764 47917645665152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.179687 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.180397 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.181126 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.293283 47807107724160 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.292999 47809708082048 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp13bvjsqm
I0618 12:49:02.294104 47809708082048 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp13bvjsqm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7bd940ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.294553 47809708082048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.293914 47917645665152 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpeysdtx42
W0618 12:49:02.294336 47807107724160 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5m4p8_mg
I0618 12:49:02.295090 47917645665152 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpeysdtx42', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b94fad5ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.295341 47807107724160 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5m4p8_mg', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b7b3e42ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883742.182091 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.182864 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.183568 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.295254 46979806696320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
I0618 12:49:02.295551 47917645665152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.295742 47807107724160 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.296312 46979806696320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvun5oizs
I0618 12:49:02.297538 46979806696320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvun5oizs', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aba9f46de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.297950 46979806696320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.299973 47809708082048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.300725 47807107724160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.300742 47917645665152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.302623 46979806696320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883742.199274 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.199701 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.200068 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.304191 47856529564544 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.198148 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.198578 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.198962 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.304207 47258902541184 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.305259 47856529564544 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpq8uuji_m
W0618 12:49:02.305231 47258902541184 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp04rv8_w3
I0618 12:49:02.306228 47856529564544 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpq8uuji_m', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86c0083e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.306224 47258902541184 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp04rv8_w3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb9aaf8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.306619 47258902541184 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.306624 47856529564544 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.311267 47856529564544 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.311267 47258902541184 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.312776 47912488244096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.313135 47174842512256 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.314754 47366617015168 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:02.315063 47377023869824 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:02.319377 47366617015168 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.319748 47377023869824 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.320215 47807107724160 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.321654 47809708082048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.322140 46979806696320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.322733 47917645665152 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:49:02.324814 47366617015168 estimator.py:1111] Calling model_fn.
W0618 12:49:02.324929 47366617015168 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:49:02.325202 47377023869824 estimator.py:1111] Calling model_fn.
W0618 12:49:02.325320 47377023869824 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:02.326373 47366617015168 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:02.326782 47377023869824 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:02.330196 47856529564544 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.330193 47258902541184 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883742.188498 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.189193 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.189887 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.332652 47799011099520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.183108 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.184011 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.184853 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.333004 47448778216320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.333796 47799011099520 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4zlmrv2b
W0618 12:49:02.334087 47448778216320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpyzqh2l41
I0618 12:49:02.334939 47799011099520 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4zlmrv2b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b795baa1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.335168 47448778216320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpyzqh2l41', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27d0285e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.335405 47799011099520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.335620 47448778216320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883742.232298 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.232717 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.233074 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.338598 47395716809600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.226116 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.226626 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.227065 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.338696 47458574910336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.339628 47395716809600 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz5gu3l5j
W0618 12:49:02.339705 47458574910336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwy2c4o5t
I0618 12:49:02.340616 47395716809600 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz5gu3l5j', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1b75738dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.340693 47458574910336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwy2c4o5t', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2a18161e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:02.340887 47799011099520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.340890 47448778216320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:49:02.341023 47395716809600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.341093 47458574910336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.345694 47395716809600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.345745 47458574910336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883742.246119 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.246581 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.247004 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.350418 47844002329472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.246328 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.246836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.247262 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.350471 47672447742848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.351506 47672447742848 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpe9wf3l1o
W0618 12:49:02.351476 47844002329472 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp78nqn1y1
I0618 12:49:02.352462 47844002329472 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp78nqn1y1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b83d559ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.352501 47672447742848 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpe9wf3l1o', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5be3e67e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.352858 47844002329472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.352903 47672447742848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.357529 47672447742848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.357541 47844002329472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883742.194933 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.195724 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.196445 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.358524 47227817096064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.187867 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.188747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.189620 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.358507 47087939208064 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.359610 47087939208064 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6roo7qdt
W0618 12:49:02.359670 47227817096064 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptiwomzl1
I0618 12:49:02.360850 47087939208064 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6roo7qdt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad3cc7a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.360917 47227817096064 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptiwomzl1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af45dd94dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:02.361362 47912488244096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:49:02.361282 47087939208064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.361579 47174842512256 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:49:02.361337 47227817096064 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.362618 47448778216320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.363440 47799011099520 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.364676 47395716809600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.364715 47458574910336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.365672 47912488244096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883742.274836 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.275280 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.275712 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.365786 47747008594816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
:::MLL 1560883742.275888 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883742.276326 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883742.276696 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:02.365849 47318196536192 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000025-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000016-000009.tfrecord.zz_0_0
W0618 12:49:02.365906 47174842512256 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.366060 47227817096064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.366096 47087939208064 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.366838 47747008594816 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplsgwtj5g
W0618 12:49:02.366868 47318196536192 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplo4dcz47
I0618 12:49:02.367826 47747008594816 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplsgwtj5g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6d4012de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.367842 47318196536192 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplo4dcz47', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0968e20e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:02.368228 47747008594816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:02.368240 47318196536192 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:02.368944 47807107724160 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:02.370229 46979806696320 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:49:02.370714 47912488244096 estimator.py:1111] Calling model_fn.
W0618 12:49:02.370823 47912488244096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:49:02.370992 47174842512256 estimator.py:1111] Calling model_fn.
W0618 12:49:02.371103 47174842512256 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:02.371432 47809708082048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:02.371803 47917645665152 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:02.372182 47912488244096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:02.372465 47174842512256 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:02.372956 47747008594816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.372992 47318196536192 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:02.373272 47807107724160 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.374565 46979806696320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.375748 47809708082048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.376091 47917645665152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:02.376482 47672447742848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.376514 47844002329472 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:02.377465 47258902541184 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:02.377734 47856529564544 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:49:02.378366 47807107724160 estimator.py:1111] Calling model_fn.
W0618 12:49:02.378475 47807107724160 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:49:02.379650 46979806696320 estimator.py:1111] Calling model_fn.
W0618 12:49:02.379759 46979806696320 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:02.379840 47807107724160 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:49:02.380801 47809708082048 estimator.py:1111] Calling model_fn.
W0618 12:49:02.380913 47809708082048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:02.381138 46979806696320 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:49:02.381134 47917645665152 estimator.py:1111] Calling model_fn.
W0618 12:49:02.381243 47917645665152 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks[2019-06-18 12:49:40] divide_golden_chunk finished: 3.245 seconds
[2019-06-18 12:49:40] generate golden chunk: 3.259 seconds
[2019-06-18 12:49:40] iteration time 25: 48.567 seconds
2019-06-18 12:49:42.249026: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883780.840396 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:49:45] minmax time: 3.264 seconds
2019-06-18 12:49:45.523533: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:49:45.529133: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:49:45.533771: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883785.546808 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 25}}
[2019-06-18 12:49:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000027-000016 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=28 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:49:45] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-27-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=27 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=1023779858 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=2047559689 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=3071339520 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=4095119351 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=5118899182 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=6142679013 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=7166458844 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=8190238675 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=9214018506 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=10237798337 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=11261578168 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=12285357999 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=13309137830 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=14332917661 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=15356697492 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=16380477323 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=17404257154 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=18428036985 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=19451816816 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000021-000015.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000026-000016 --seed=20475596647 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:49:57] eval finished: 11.832 seconds
[2019-06-18 12:49:57] Win rate 000026-000016 vs 000021-000015: 0.670
:::MLL 1560883797.443903 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 25}}
[2019-06-18 12:49:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=28 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=1023779859 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=2047559690 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=3071339521 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=4095119352 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=5118899183 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=6142679014 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=7166458845 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=8190238676 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=9214018507 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=10237798338 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=11261578169 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=12285358000 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=13309137831 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=14332917662 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=15356697493 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=16380477324 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=17404257155 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000027-000015 --seed=18428036986 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:50:26] selfplay finished: 29.397 seconds
[2019-06-18 12:50:26] selfplay mn: 29.417 seconds
[2019-06-18 12:50:26] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-28-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=28 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779859 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559690 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339521 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119352 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899183 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679014 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458845 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238676 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018507 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798338 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578169 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285358000 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137831 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917662 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697493 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477324 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257155 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036986 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816817 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596648 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376479 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156310 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000027-000015/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:50:28] train finished: 43.290 seconds
:::MLL 1560883790.747196 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.748093 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.748955 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.867341 47241252721536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.756725 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.757423 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.758087 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.867508 47090105684864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.746513 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.747425 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.748254 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.867465 47294178800512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.756994 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.757720 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.758418 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.867979 47278360236928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:50.868461 47241252721536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp59l23_7a
I0618 12:49:50.868668 47090105684864 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad44d9bed30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.869578 47241252721536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp59l23_7a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af77eacae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:50.868587 47294178800512 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjaciudxu
I0618 12:49:50.869697 47294178800512 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjaciudxu', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b03d1508e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.869961 47090105684864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.870017 47241252721536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.869105 47278360236928 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvmy8mwfo
I0618 12:49:50.870138 47294178800512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.870272 47278360236928 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvmy8mwfo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0022745dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.870749 47278360236928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.875301 47241252721536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.875352 47090105684864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.875554 47294178800512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.876048 47278360236928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883790.770310 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.771186 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.772003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.886867 46990442546048 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.774990 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.775712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.776399 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.886952 47165823742848 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:50.887989 46990442546048 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphig3a3pa
W0618 12:49:50.888052 47165823742848 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8e9prxp5
I0618 12:49:50.889096 46990442546048 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphig3a3pa', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abd19390dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.889186 47165823742848 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8e9prxp5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5eec1ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.889548 46990442546048 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.889640 47165823742848 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.894896 46990442546048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.894988 47165823742848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.897047 47241252721536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.897279 47090105684864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.897358 47294178800512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.898255 47278360236928 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883790.813812 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.814532 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.815167 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.915427 47788828533632 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.798334 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.799241 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.800037 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.915635 47316760105856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:50.916698 46990442546048 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.916463 47788828533632 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpzc1zq8hz
W0618 12:49:50.916652 47316760105856 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8639_5es
I0618 12:49:50.917474 47788828533632 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpzc1zq8hz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b76fcbc6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.917656 47316760105856 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8639_5es', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b091343ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:50.917504 47165823742848 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:49:50.917874 47788828533632 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.918053 47316760105856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.922840 47788828533632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.922878 47316760105856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883790.836210 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.836690 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.837134 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.932547 48001655219072 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.836229 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.836703 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.837138 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.932534 47449735537536 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.841554 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.841947 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.842267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.933087 47579771974528 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.840971 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.841398 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.841752 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.933673 47428162675584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:50.933541 48001655219072 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdogfo5u5
W0618 12:49:50.933572 47449735537536 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqpu0qcpc
I0618 12:49:50.934538 48001655219072 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdogfo5u5', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba88a31fdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.934565 47449735537536 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqpu0qcpc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b280937ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:50.934115 47579771974528 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpo1bf9780
I0618 12:49:50.935103 47579771974528 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpo1bf9780', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b464ffe7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.934940 48001655219072 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.934970 47449735537536 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.934658 47428162675584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpm26fow1a
I0618 12:49:50.935512 47579771974528 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.935626 47428162675584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpm26fow1a', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2303603e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.936031 47428162675584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.939610 48001655219072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.939618 47449735537536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.940155 47579771974528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.940642 47428162675584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.942287 47316760105856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.942336 47788828533632 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.948534 47294178800512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.949082 47241252721536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.949499 47090105684864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.949653 47278360236928 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.953024 47294178800512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:50.953548 47241252721536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:50.953971 47090105684864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:50.954137 47278360236928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883790.843172 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.844147 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.845024 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.957436 47476331643776 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
I0618 12:49:50.958392 47294178800512 estimator.py:1111] Calling model_fn.
I0618 12:49:50.958733 47241252721536 estimator.py:1111] Calling model_fn.
W0618 12:49:50.958424 48001655219072 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.958522 47294178800512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:50.958864 47241252721536 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:50.958695 47449735537536 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.959045 47579771974528 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883790.853527 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.854285 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.854970 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.958941 47071538500480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
I0618 12:49:50.959229 47090105684864 estimator.py:1111] Calling model_fn.
W0618 12:49:50.959349 47090105684864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:50.958567 47476331643776 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpx9qya8kf
I0618 12:49:50.959682 47476331643776 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpx9qya8kf', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2e3a785e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.959497 47278360236928 estimator.py:1111] Calling model_fn.
W0618 12:49:50.959775 47428162675584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.959618 47278360236928 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:49:50.960133 47476331643776 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.959996 47294178800512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:50.960323 47241252721536 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:50.960835 47090105684864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:50.960016 47071538500480 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuadjglq4
I0618 12:49:50.961110 47071538500480 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuadjglq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2acffaeb1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:49:50.961074 47278360236928 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:49:50.961548 47071538500480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.965502 47476331643776 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.966850 47071538500480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883790.872936 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.873323 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.873644 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.969448 47980838855552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
:::MLL 1560883790.874171 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.874537 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.874851 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.969604 47379017925504 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:50.969982 46990442546048 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.971070 47165823742848 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.970455 47980838855552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpd7u3cils
W0618 12:49:50.970637 47379017925504 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpo2q5aqs9
I0618 12:49:50.971460 47980838855552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpd7u3cils', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba3b1716e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.971630 47379017925504 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpo2q5aqs9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b17921ece48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:50.971861 47980838855552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:50.972034 47379017925504 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:50.974719 46990442546048 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:50.975820 47165823742848 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:50.976646 47980838855552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:50.976702 47379017925504 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:49:50.980179 46990442546048 estimator.py:1111] Calling model_fn.
W0618 12:49:50.980297 46990442546048 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:49:50.981299 47165823742848 estimator.py:1111] Calling model_fn.
W0618 12:49:50.981417 47165823742848 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:50.981752 46990442546048 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:50.982877 47165823742848 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:50.987621 47476331643776 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.989090 47071538500480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.991294 47316760105856 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.991730 47788828533632 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:50.995622 47316760105856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:50.995600 47379017925504 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.995681 47980838855552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:49:50.996090 47788828533632 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883790.907226 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.907710 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.908108 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:50.998363 47675254006656 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:50.999397 47675254006656 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplt5ida2y
I0618 12:49:51.000371 47675254006656 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplt5ida2y', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5c8b2abe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:51.000774 47675254006656 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:49:51.000810 47316760105856 estimator.py:1111] Calling model_fn.
W0618 12:49:51.000923 47316760105856 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:49:51.001310 47788828533632 estimator.py:1111] Calling model_fn.
W0618 12:49:51.001421 47788828533632 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:49:51.002310 47316760105856 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:49:51.002790 47788828533632 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883790.914858 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883790.915322 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883790.915708 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:49:51.002688 47596952150912 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000026-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000017-000010.tfrecord.zz_0_0
W0618 12:49:51.003705 47596952150912 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp2lok09pw
I0618 12:49:51.004674 47596952150912 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp2lok09pw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4a50032e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:49:51.005065 47596952150912 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:49:51.005477 47675254006656 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:51.005642 48001655219072 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:51.005849 47449735537536 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:51.006272 47579771974528 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:51.007328 47428162675584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:49:51.009626 47596952150912 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:49:51.009922 48001655219072 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:51.010147 47449735537536 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:49:51.010542 47579771974528 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return[2019-06-18 12:50:30] divide_golden_chunk finished: 3.330 seconds
[2019-06-18 12:50:30] generate golden chunk: 3.344 seconds
[2019-06-18 12:50:30] moving /lfs/lfs12/gma_akey/results/epb144/models/000027-000016.data-00000-of-00001 --> /lfs/lfs12/gma_akey/results/epb144/models/000027-000017.data-00000-of-00001
[2019-06-18 12:50:30] moving /lfs/lfs12/gma_akey/results/epb144/models/000027-000016.meta --> /lfs/lfs12/gma_akey/results/epb144/models/000027-000017.meta
[2019-06-18 12:50:30] moving /lfs/lfs12/gma_akey/results/epb144/models/000027-000016.index --> /lfs/lfs12/gma_akey/results/epb144/models/000027-000017.index
[2019-06-18 12:50:30] moving /lfs/lfs12/gma_akey/results/epb144/models/000027-000016.pb --> /lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb
[2019-06-18 12:50:30] iteration time 26: 49.405 seconds
2019-06-18 12:50:31.704830: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883830.245780 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:50:35] minmax time: 3.291 seconds
2019-06-18 12:50:35.005906: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:50:35.011358: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:50:35.016057: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883835.027679 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 26}}
[2019-06-18 12:50:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=29 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:50:35] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-28-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=28 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=1023779859 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=2047559690 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=3071339521 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=4095119352 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=5118899183 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=6142679014 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=7166458845 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=8190238676 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=9214018507 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=10237798338 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=11261578169 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=12285358000 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=13309137831 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=14332917662 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=15356697493 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=16380477324 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=17404257155 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=18428036986 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=19451816817 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000027-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000027-000017 --seed=20475596648 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:50:47] eval finished: 12.281 seconds
[2019-06-18 12:50:47] Win rate 000027-000017 vs 000026-000016: 0.360
:::MLL 1560883847.373022 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 26}}
[2019-06-18 12:50:47] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=29 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=1023779860 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=2047559691 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=3071339522 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=4095119353 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=5118899184 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=6142679015 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=7166458846 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=8190238677 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=9214018508 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=10237798339 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=11261578170 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=12285358001 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=13309137832 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=14332917663 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=15356697494 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=16380477325 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=17404257156 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000028-000016 --seed=18428036987 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:51:17] selfplay finished: 29.966 seconds
[2019-06-18 12:51:17] selfplay mn: 29.987 seconds
[2019-06-18 12:51:17] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-29-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=29 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779860 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559691 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339522 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119353 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899184 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679015 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458846 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238677 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018508 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798339 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578170 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285358001 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137832 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917663 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697494 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477325 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257156 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036987 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816818 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596649 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376480 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156311 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000028-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:51:18] train finished: 43.538 seconds
:::MLL 1560883840.239895 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.240631 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.241283 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.347476 47893888406400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.225548 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.226379 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.227243 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.347969 47046657569664 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
I0618 12:50:40.348629 47893888406400 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8f72cadd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.349877 47893888406400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.349129 47046657569664 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpui7s70ng
I0618 12:50:40.350247 47046657569664 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpui7s70ng', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aca2fe64e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.350704 47046657569664 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.355225 47893888406400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.355937 47046657569664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883840.233899 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.234619 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.235237 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.372901 47993603371904 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.229292 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.230211 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.231100 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.373106 47889936487296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.238394 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.239124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.239815 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.373425 47708512228224 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.229256 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.230098 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.230930 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.373398 47646121571200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:50:40.374041 47993603371904 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdj810s6l
W0618 12:50:40.374226 47889936487296 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmphwppll8w
I0618 12:50:40.375150 47993603371904 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdj810s6l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba6aa448e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:50:40.374508 47708512228224 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqeyfn13q
W0618 12:50:40.374541 47646121571200 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwa9sd_9r
I0618 12:50:40.375358 47889936487296 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmphwppll8w', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8e873d5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.375533 47708512228224 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqeyfn13q', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b644982ddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.375533 47646121571200 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwa9sd_9r', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b55c2bd0e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.375593 47993603371904 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.375937 47708512228224 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.375934 47646121571200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.375822 47889936487296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.376963 47893888406400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.378021 47046657569664 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.380872 47993603371904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.381050 47646121571200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.381055 47708512228224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.381122 47889936487296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883840.247297 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.248060 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.248760 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.393137 47689732322176 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.279982 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.280887 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.281694 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.393433 47215099487104 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.243896 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.244726 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.245403 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.393663 47321063940992 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.287326 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.288089 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.288769 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.393974 47183745414016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:50:40.394276 47689732322176 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp33ygbbdy
W0618 12:50:40.394546 47215099487104 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppi9srsdn
I0618 12:50:40.395395 47689732322176 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp33ygbbdy', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5fea243e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.395665 47215099487104 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppi9srsdn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af167d1edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:50:40.394730 47321063940992 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpab3v_bmt
W0618 12:50:40.395067 47183745414016 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmph84ad844
I0618 12:50:40.395815 47321063940992 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpab3v_bmt', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0a13cb3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.395847 47689732322176 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.396122 47215099487104 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.396175 47183745414016 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmph84ad844', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aea1af8ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.396250 47321063940992 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.396639 47183745414016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.400644 47708512228224 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.400635 47646121571200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.401111 47689732322176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.401504 47215099487104 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.401339 47321063940992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.401979 47183745414016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.402698 47993603371904 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.403166 47889936487296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883840.321591 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.321964 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.322285 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.415680 47305761772416 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.319602 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.320041 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.320400 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.416027 48003307885440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:50:40.416712 47305761772416 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmps22ryo55
I0618 12:50:40.417705 47305761772416 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmps22ryo55', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b0683b69e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:50:40.417025 48003307885440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpahrhkza7
I0618 12:50:40.418009 48003307885440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpahrhkza7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba8ecb38e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.418103 47305761772416 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.418408 48003307885440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.422765 47305761772416 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.422991 48003307885440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.422800 47689732322176 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.423036 47321063940992 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.423526 47215099487104 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.424613 47183745414016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.429168 47893888406400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.429530 47046657569664 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.433624 47893888406400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:50:40.433962 47046657569664 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883840.322863 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.323362 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.323768 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.434515 47884272702336 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.324752 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.325222 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.325628 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.434758 47856212669312 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.325508 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.325968 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.326366 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.435403 47867506303872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.325406 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.325864 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.326267 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.435582 47538417542016 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:50:40.435530 47884272702336 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpgokqnwmq
W0618 12:50:40.435742 47856212669312 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpm2paswit
I0618 12:50:40.436508 47884272702336 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpgokqnwmq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d35a6ee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.436727 47856212669312 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpm2paswit', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b86ad24cdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.436894 47884272702336 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.437125 47856212669312 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.436421 47867506303872 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjxogvqp9
W0618 12:50:40.436601 47538417542016 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppaytepxq
I0618 12:50:40.437404 47867506303872 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjxogvqp9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b894e4bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.437591 47538417542016 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppaytepxq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3caf13fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.437800 47867506303872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.437993 47538417542016 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.438842 47893888406400 estimator.py:1111] Calling model_fn.
W0618 12:50:40.438971 47893888406400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:50:40.439137 47046657569664 estimator.py:1111] Calling model_fn.
W0618 12:50:40.439254 47046657569664 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:50:40.440443 47893888406400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:50:40.440711 47046657569664 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:50:40.441534 47884272702336 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.441778 47856212669312 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.441787 47305761772416 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.442109 48003307885440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.442520 47867506303872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.442612 47538417542016 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.449169 47646121571200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883840.325941 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.326414 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.326787 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.448925 47407302099840 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
:::MLL 1560883840.325699 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.326143 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.326542 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.449068 47355472319360 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:50:40.449484 47708512228224 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.449966 47407302099840 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp26fko5cr
W0618 12:50:40.450043 47355472319360 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjou8i0su
I0618 12:50:40.450953 47407302099840 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp26fko5cr', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1e27fd1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.451025 47355472319360 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjou8i0su', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1216b16e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.451344 47407302099840 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:50:40.451415 47355472319360 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.452016 47993603371904 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.452637 47889936487296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.453513 47646121571200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:50:40.453826 47708512228224 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:50:40.456070 47355472319360 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.456073 47407302099840 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.456317 47993603371904 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:50:40.456974 47889936487296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:50:40.458598 47646121571200 estimator.py:1111] Calling model_fn.
W0618 12:50:40.458709 47646121571200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:50:40.458969 47708512228224 estimator.py:1111] Calling model_fn.
W0618 12:50:40.459080 47708512228224 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:50:40.460075 47646121571200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:50:40.460467 47708512228224 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:50:40.460481 47884272702336 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.461035 47856212669312 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:50:40.461380 47993603371904 estimator.py:1111] Calling model_fn.
W0618 12:50:40.461487 47993603371904 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:50:40.461533 47538417542016 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.461625 47867506303872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:50:40.462073 47889936487296 estimator.py:1111] Calling model_fn.
W0618 12:50:40.462183 47889936487296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:50:40.462853 47993603371904 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:50:40.463552 47889936487296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883840.373857 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.374286 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.374629 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.464596 47754942735232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
W0618 12:50:40.465620 47754942735232 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwebf4tyw
I0618 12:50:40.466612 47754942735232 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwebf4tyw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6f18fc3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
:::MLL 1560883840.377020 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883840.377399 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883840.377759 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:50:40.466767 47896908972928 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000027-000015.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000018-000011.tfrecord.zz_0_0
I0618 12:50:40.467016 47754942735232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.467766 47896908972928 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpomgcfom_
I0618 12:50:40.468750 47896908972928 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpomgcfom_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9026d51e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:50:40.469151 47896908972928 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:50:40.471653 47754942735232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.472067 47689732322176 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.472307 47321063940992 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.473703 47896908972928 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:50:40.475171 47215099487104 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.475176 47355472319360 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.475217 47407302099840 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:50:40.475453 47183745414016 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:50:40.476341 47689732322176 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:50:40.476633 47321063940992 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.da[2019-06-18 12:51:20] divide_golden_chunk finished: 3.317 seconds
[2019-06-18 12:51:20] generate golden chunk: 3.331 seconds
[2019-06-18 12:51:20] iteration time 27: 50.447 seconds
2019-06-18 12:51:22.184668: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883880.692816 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:51:25] minmax time: 3.246 seconds
2019-06-18 12:51:25.440978: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:51:25.446549: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:51:25.451163: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883885.464042 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 27}}
[2019-06-18 12:51:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=30 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:51:25] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-29-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=29 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=1023779860 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=2047559691 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=3071339522 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=4095119353 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=5118899184 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=6142679015 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=7166458846 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=8190238677 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=9214018508 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=10237798339 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=11261578170 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=12285358001 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=13309137832 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=14332917663 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=15356697494 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=16380477325 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=17404257156 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=18428036987 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=19451816818 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000028-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000028-000017 --seed=20475596649 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:51:36] eval finished: 11.283 seconds
[2019-06-18 12:51:36] Win rate 000028-000017 vs 000026-000016: 0.270
:::MLL 1560883896.809219 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 27}}
[2019-06-18 12:51:36] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=30 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=1023779861 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=2047559692 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=3071339523 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=4095119354 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=5118899185 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=6142679016 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=7166458847 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=8190238678 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=9214018509 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=10237798340 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=11261578171 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=12285358002 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=13309137833 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=14332917664 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=15356697495 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=16380477326 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=17404257157 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000029-000016 --seed=18428036988 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:52:06] selfplay finished: 29.722 seconds
[2019-06-18 12:52:06] selfplay mn: 29.740 seconds
[2019-06-18 12:52:06] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-30-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=30 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779861 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559692 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339523 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119354 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899185 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679016 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458847 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238678 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018509 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798340 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578171 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285358002 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137833 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917664 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697495 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477326 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257157 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036988 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816819 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596650 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376481 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156312 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000029-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:52:09] train finished: 43.907 seconds
:::MLL 1560883890.646052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.646756 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.647407 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.769510 47546931676032 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
:::MLL 1560883890.638581 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.639455 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.640276 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.769876 47544360465280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
I0618 12:51:30.770665 47546931676032 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3eaa8f5d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:51:30.770976 47544360465280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpp7gx5gml
I0618 12:51:30.771948 47546931676032 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.772209 47544360465280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpp7gx5gml', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3e114dce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.772662 47544360465280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.777213 47546931676032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.777786 47544360465280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.799069 47546931676032 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.799842 47544360465280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883890.721353 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.721809 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.722181 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.833316 47164677809024 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.834352 47164677809024 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplu4ob5kx
I0618 12:51:30.835349 47164677809024 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplu4ob5kx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ae5aa743dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.835760 47164677809024 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883890.721921 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.722349 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.722712 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.836259 47615156548480 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.837256 47615156548480 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqatq39rd
I0618 12:51:30.838228 47615156548480 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqatq39rd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e8d143e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.838629 47615156548480 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.840449 47164677809024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.843169 47615156548480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.851392 47546931676032 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883890.728167 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.728918 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.729582 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.851306 47698018825088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.852219 47544360465280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:51:30.852406 47698018825088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpf3ml70yk
:::MLL 1560883890.698451 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.699375 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.700215 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.853053 47539633419136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
I0618 12:51:30.853541 47698018825088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpf3ml70yk', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61d80e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.854005 47698018825088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.854173 47539633419136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqpv0xzmp
I0618 12:51:30.855269 47539633419136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqpv0xzmp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3cf78cce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.855718 47539633419136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.855865 47546931676032 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.856724 47544360465280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.858787 47698018825088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.859528 47164677809024 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:51:30.861233 47546931676032 estimator.py:1111] Calling model_fn.
W0618 12:51:30.861100 47539633419136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.861366 47546931676032 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:51:30.862091 47544360465280 estimator.py:1111] Calling model_fn.
W0618 12:51:30.862208 47544360465280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.862234 47615156548480 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.862857 47546931676032 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:51:30.863686 47544360465280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883890.719207 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.720124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.720952 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.863754 47530390307712 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.864745 47530390307712 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp0hnjjdep
I0618 12:51:30.865758 47530390307712 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp0hnjjdep', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3ad09dfe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.866172 47530390307712 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883890.704931 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.705598 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.706275 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.866020 47882585490304 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.867122 47882585490304 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpx808wufq
I0618 12:51:30.868201 47882585490304 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpx808wufq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8cd1161e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.868645 47882585490304 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.871031 47530390307712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.873754 47882585490304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.878290 47698018825088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.883161 47539633419136 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883890.715249 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.716161 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.717023 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.885844 47350995841920 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.886882 47350995841920 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpcv71m45b
I0618 12:51:30.887903 47350995841920 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpcv71m45b', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b110bdfce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.888303 47350995841920 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.890457 47530390307712 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.893029 47350995841920 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883890.722375 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.723135 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.723790 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.893794 47758793409408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.895602 47882585490304 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.894803 47758793409408 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpjtvrrtoo
I0618 12:51:30.895820 47758793409408 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpjtvrrtoo', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b6ffe80de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.896220 47758793409408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.901316 47758793409408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883890.746965 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.747833 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.748641 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.904127 47865616593792 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
:::MLL 1560883890.746677 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.747549 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.748363 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.904125 46932885193600 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.905313 47865616593792 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuu9opaaw
W0618 12:51:30.905353 46932885193600 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuc135mun
I0618 12:51:30.906462 47865616593792 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuu9opaaw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b88dda93e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.906462 46932885193600 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuc135mun', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aafb2898e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:51:30.906931 47164677809024 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:51:30.906928 47865616593792 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.906924 46932885193600 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.909730 47615156548480 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:51:30.911260 47164677809024 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.912292 47865616593792 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.912388 46932885193600 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.912495 47350995841920 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883890.774699 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.775155 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.775519 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.912944 47502591681408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
:::MLL 1560883890.774010 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.774483 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.774954 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.912968 47231530922880 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.914088 47615156548480 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.913947 47502591681408 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpsh7hzrht
W0618 12:51:30.913974 47231530922880 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdhsidsl9
I0618 12:51:30.914957 47502591681408 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpsh7hzrht', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b3457b0add8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.914967 47231530922880 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdhsidsl9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2af53b35be48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.915358 47502591681408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.915361 47231530922880 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.916324 47164677809024 estimator.py:1111] Calling model_fn.
W0618 12:51:30.916433 47164677809024 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.917793 47164677809024 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:51:30.919213 47615156548480 estimator.py:1111] Calling model_fn.
W0618 12:51:30.919320 47615156548480 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.919987 47231530922880 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.920043 47502591681408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.920680 47615156548480 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:51:30.921277 47758793409408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883890.819041 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.819540 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.820003 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.925324 47028666991488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
:::MLL 1560883890.820033 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.820503 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.820903 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.925723 47122904056704 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.926189 47698018825088 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:51:30.926361 47028666991488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_20uodly
I0618 12:51:30.927370 47028666991488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_20uodly', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ac5ff93de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:51:30.926706 47122904056704 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpib1qq19g
I0618 12:51:30.927690 47122904056704 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpib1qq19g', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2adbf08b5e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.927771 47028666991488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.928084 47122904056704 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.930614 47698018825088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.932509 47028666991488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.932709 47122904056704 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.932661 47539633419136 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:51:30.934284 47865616593792 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.934334 46932885193600 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:51:30.935670 47698018825088 estimator.py:1111] Calling model_fn.
W0618 12:51:30.935786 47698018825088 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.937139 47698018825088 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:51:30.937080 47539633419136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.938335 47530390307712 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883890.780889 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.781353 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.781762 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.938186 47253339779968 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.938947 47231530922880 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.939107 47502591681408 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883890.779739 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.780253 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.780754 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.938876 47445693711232 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.939289 47253339779968 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpre24m77_
I0618 12:51:30.940337 47253339779968 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpre24m77_', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afa4f1e7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:51:30.939905 47445693711232 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuqr3q4nn
I0618 12:51:30.940770 47253339779968 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.940923 47445693711232 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuqr3q4nn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b27184e9e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.941349 47445693711232 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.942322 47539633419136 estimator.py:1111] Calling model_fn.
W0618 12:51:30.942440 47539633419136 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.942677 47530390307712 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.943886 47882585490304 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:51:30.943871 47539633419136 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:51:30.945646 47253339779968 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.946130 47445693711232 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:51:30.947762 47530390307712 estimator.py:1111] Calling model_fn.
W0618 12:51:30.947871 47530390307712 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.948186 47882585490304 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:51:30.949242 47530390307712 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:51:30.951646 47028666991488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:51:30.951808 47122904056704 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:51:30.953256 47882585490304 estimator.py:1111] Calling model_fn.
W0618 12:51:30.953366 47882585490304 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:51:30.954829 47882585490304 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883890.835883 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.836313 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.836682 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.957027 48009853465472 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
:::MLL 1560883890.825341 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883890.825844 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883890.826313 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:51:30.957167 47129734509440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000028-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000019-000012.tfrecord.zz_0_0
W0618 12:51:30.958050 48009853465472 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp03lbausb
W0618 12:51:30.958156 47129734509440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp5wswtu9f
I0618 12:51:30.959054 48009853465472 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp03lbausb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2baa72d92e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.959140 47129734509440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp5wswtu9f', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2add87abce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:51:30.959457 48009853465472 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:51:30.959538 47129734509440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:51:30.960701 47350995841920 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:51:30.964082 48009853465472 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:51:30.964180 47129734509440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) i[2019-06-18 12:52:09] divide_golden_chunk finished: 3.405 seconds
[2019-06-18 12:52:09] generate golden chunk: 3.420 seconds
[2019-06-18 12:52:09] iteration time 28: 49.278 seconds
2019-06-18 12:52:11.502326: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883929.970716 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:52:14] minmax time: 3.220 seconds
2019-06-18 12:52:14.732445: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:52:14.738090: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:52:14.742788: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883934.755899 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 28}}
[2019-06-18 12:52:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=31 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:52:14] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-30-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=30 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=1023779861 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=2047559692 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=3071339523 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=4095119354 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=5118899185 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=6142679016 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=7166458847 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=8190238678 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=9214018509 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=10237798340 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=11261578171 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=12285358002 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=13309137833 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=14332917664 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=15356697495 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=16380477326 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=17404257157 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=18428036988 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=19451816819 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000029-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000029-000017 --seed=20475596650 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:52:27] eval finished: 12.540 seconds
[2019-06-18 12:52:27] Win rate 000029-000017 vs 000026-000016: 0.320
:::MLL 1560883947.362332 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 28}}
[2019-06-18 12:52:27] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=31 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=1023779862 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=2047559693 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=3071339524 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=4095119355 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=5118899186 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=6142679017 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=7166458848 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=8190238679 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=9214018510 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=10237798341 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=11261578172 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=12285358003 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=13309137834 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=14332917665 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=15356697496 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=16380477327 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=17404257158 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000030-000016 --seed=18428036989 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:52:57] selfplay finished: 30.335 seconds
[2019-06-18 12:52:57] selfplay mn: 30.355 seconds
[2019-06-18 12:52:57] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-31-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=31 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779862 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559693 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339524 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119355 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899186 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679017 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458848 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238679 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018510 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798341 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578172 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285358003 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137834 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917665 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697496 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477327 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257158 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036989 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816820 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596651 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376482 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156313 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000030-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:52:58] train finished: 43.824 seconds
:::MLL 1560883939.972232 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883939.973115 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883939.973911 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.095342 47618252325760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.096486 47618252325760 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpb44f1tji
I0618 12:52:20.097604 47618252325760 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpb44f1tji', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f459a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.098066 47618252325760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.103522 47618252325760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883939.988741 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883939.989464 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883939.990120 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.116758 47772460381056 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
I0618 12:52:20.117916 47772460381056 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b732d1e3cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.119172 47772460381056 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.124303 47772460381056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.125624 47618252325760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.146194 47772460381056 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883939.989645 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883939.990473 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883939.991216 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.146381 47964975960960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
:::MLL 1560883940.016723 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.017603 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.018429 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.146698 47281762612096 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
:::MLL 1560883939.989002 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883939.989836 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883939.990626 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.146999 47907154019200 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.147493 47964975960960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpheapuy9i
W0618 12:52:20.147747 47281762612096 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpu7j2i7e1
I0618 12:52:20.148757 47281762612096 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpu7j2i7e1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b00ed407e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.148585 47964975960960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpheapuy9i', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ffff0de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:52:20.148090 47907154019200 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmplhv2gfsz
I0618 12:52:20.149169 47281762612096 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:52:20.149046 47964975960960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:52:20.149212 47907154019200 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmplhv2gfsz', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b92897c1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.149652 47907154019200 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.154045 47281762612096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.154316 47964975960960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.154838 47907154019200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883940.016762 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.017627 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.018465 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.155139 47495669142400 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.156150 47495669142400 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp1kkhrsbx
I0618 12:52:20.157140 47495669142400 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp1kkhrsbx', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b32bb132e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.157543 47495669142400 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.162208 47495669142400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.173508 47281762612096 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.176331 47964975960960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.177355 47907154019200 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.177879 47618252325760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
:::MLL 1560883940.066227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.066712 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.067115 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.178235 47723577361280 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
:::MLL 1560883940.062616 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.063124 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.063557 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.179232 47378691687296 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.179280 47723577361280 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqdtzmkq4
I0618 12:52:20.180287 47723577361280 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqdtzmkq4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b67cb769e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.180699 47723577361280 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.180202 47378691687296 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpqlqg5fjw
I0618 12:52:20.181178 47378691687296 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpqlqg5fjw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b177eacde48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.181578 47378691687296 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.182188 47618252325760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.182396 47495669142400 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.185358 47723577361280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.186083 47378691687296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:52:20.187294 47618252325760 estimator.py:1111] Calling model_fn.
W0618 12:52:20.187405 47618252325760 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.188786 47618252325760 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883940.021999 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.022742 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.023433 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.195225 47372196893568 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.195698 47772460381056 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.196347 47372196893568 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4e242w7l
I0618 12:52:20.197506 47372196893568 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4e242w7l', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b15fb8e2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.197959 47372196893568 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.200005 47772460381056 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883940.061080 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.061485 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.061851 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.201624 47558660133760 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
:::MLL 1560883940.056914 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.057417 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.057868 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.202264 47959107015552 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.203285 47372196893568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.202660 47558660133760 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpdpraf7h7
I0618 12:52:20.203648 47558660133760 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpdpraf7h7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4165a15e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:52:20.203259 47959107015552 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprin4eqs7
I0618 12:52:20.204048 47558660133760 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:52:20.204248 47959107015552 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmprin4eqs7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9ea21fddd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:52:20.204431 47723577361280 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:52:20.204644 47959107015552 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.205045 47378691687296 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:52:20.205114 47772460381056 estimator.py:1111] Calling model_fn.
W0618 12:52:20.205224 47772460381056 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.206591 47772460381056 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883940.024790 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.025523 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.026210 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.206853 47995141272448 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.207933 47995141272448 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp_jzfn7hc
W0618 12:52:20.208678 47558660133760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:52:20.209044 47995141272448 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp_jzfn7hc', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba705eefe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:52:20.209174 47959107015552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:52:20.209487 47995141272448 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.214428 47995141272448 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883940.101561 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.102128 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.102706 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.219215 47915679273856 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
:::MLL 1560883940.105056 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.105525 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.105928 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.219444 46989244261248 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.220247 47915679273856 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp7ypi89j2
W0618 12:52:20.220441 46989244261248 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmprnaytzjn
I0618 12:52:20.221242 47915679273856 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp7ypi89j2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9485a12dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.221412 46989244261248 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmprnaytzjn', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abcd1ccae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.221643 47915679273856 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:52:20.221802 46989244261248 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.222039 47281762612096 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.224911 47372196893568 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.225622 47964975960960 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.226128 47907154019200 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.226305 47915679273856 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.226386 46989244261248 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.226343 47281762612096 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.227618 47558660133760 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.228072 47959107015552 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.229943 47964975960960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.230451 47907154019200 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.230723 47495669142400 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
I0618 12:52:20.231450 47281762612096 estimator.py:1111] Calling model_fn.
W0618 12:52:20.231559 47281762612096 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.232927 47281762612096 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:52:20.235034 47495669142400 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
I0618 12:52:20.235092 47964975960960 estimator.py:1111] Calling model_fn.
W0618 12:52:20.235203 47964975960960 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:52:20.235623 47907154019200 estimator.py:1111] Calling model_fn.
W0618 12:52:20.235734 47907154019200 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.236544 47995141272448 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.236598 47964975960960 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:52:20.237118 47907154019200 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:52:20.240139 47495669142400 estimator.py:1111] Calling model_fn.
W0618 12:52:20.240256 47495669142400 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.241615 47495669142400 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:52:20.245424 46989244261248 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:52:20.245378 47915679273856 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883940.043005 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.043882 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.044726 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.251154 47456115721088 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.251538 47723577361280 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.252126 47378691687296 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.252298 47456115721088 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp6yqfzbsd
I0618 12:52:20.253386 47456115721088 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp6yqfzbsd', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b298581ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.253850 47456115721088 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.255815 47723577361280 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.256455 47378691687296 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883940.111489 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.111955 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.112345 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.258298 46979538920320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
:::MLL 1560883940.111249 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.111705 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.112117 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.258499 46981765915520 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.259230 47456115721088 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.259312 46979538920320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpwzm6cm0d
W0618 12:52:20.259467 46981765915520 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbyipycow
I0618 12:52:20.260305 46979538920320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpwzm6cm0d', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aba8f50fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.260455 46981765915520 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbyipycow', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2abb140e3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:52:20.260701 46979538920320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:52:20.260844 46981765915520 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:52:20.260894 47723577361280 estimator.py:1111] Calling model_fn.
W0618 12:52:20.261003 47723577361280 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:52:20.261565 47378691687296 estimator.py:1111] Calling model_fn.
W0618 12:52:20.261675 47378691687296 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.262367 47723577361280 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:52:20.263042 47378691687296 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883940.048567 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883940.049321 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883940.050007 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:52:20.263002 47901165409152 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000029-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000020-000012.tfrecord.zz_0_0
W0618 12:52:20.264094 47901165409152 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp4yevbreh
I0618 12:52:20.265195 47901165409152 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp4yevbreh', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9124891dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:52:20.265369 46979538920320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.265391 46981765915520 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:52:20.265643 47901165409152 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:52:20.270845 47901165409152 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:52:20.274436 47372196893568 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.275155 47558660133760 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.275288 47959107015552 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:52:20.278762 47372196893568 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.279449 47558660133760 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.279610 47959107015552 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:52:20.280642 47456115721088 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
I0618 12:52:20.283895 47372196893568 estimator.py:1111] Calling model_fn.
W0618 12:52:20.284008 47372196893568 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:52:20.284258 47995141272448 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipu[2019-06-18 12:53:00] divide_golden_chunk finished: 3.242 seconds
[2019-06-18 12:53:00] generate golden chunk: 3.256 seconds
[2019-06-18 12:53:00] iteration time 29: 51.004 seconds
2019-06-18 12:53:02.510714: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying insert_logging
['/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9']
Reading tf_records from 1 inputs
:::MLL 1560883980.974991 epoch_start: {"value": null, "metadata": {'lineno': 648, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:53:05] minmax time: 3.236 seconds
2019-06-18 12:53:05.756276: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying freeze_requantization_ranges
2019-06-18 12:53:05.765165: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fuse_quantized_conv_and_requantize
2019-06-18 12:53:05.769886: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
:::MLL 1560883985.783287 save_model: {"value": null, "metadata": {'lineno': 483, 'file': 'ml_perf/reference_implementation.py', 'iteration': 29}}
[2019-06-18 12:53:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-train-None-%r.txt -genv HOROVOD_FUSION_THRESHOLD=134217728 -genv KMP_BLOCKTIME=0 -genv KMP_HW_SUBSET=1T -genv OMP_BIND_PROC=true -genv I_MPI_ASYNC_PROGRESS_PIN=0,1,24,25 -genv OMP_NUM_THREADS=11 \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb213 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb202 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,2 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,13 numactl -l -N 0 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,26 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb144/work_dir --export_path=/lfs/lfs12/gma_akey/results/epb144/models/000031-000017 --window_size=3120 --data_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks --training_seed=32 --freeze=True --num_inter_threads=1 --num_intra_threads=11 --dist_train=True : \
-host epb206 -env KMP_AFFINITY=granularity=fine,compact,1,37 numactl -l -N 1 python3 train.py --conv_width=32 --fc_width=64 --trunk_layers=9 --value_cost_weight=0.25 --summary_steps=64 --shuffle_buffer_size=10000 --filter_amount=0.5 --train_batch_size=8192 --lr_rates=0.32 --lr_rates=0.032 --lr_rates=0.0032 --lr_boundaries=12500 --lr_boundaries=18750 --l2_strength=0.0001 --work_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:53:05] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-eval-31-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=31 : \
-host epb131 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=1023779862 : \
-host epb215 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=2047559693 : \
-host epb217 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=3071339524 : \
-host epb133 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=4095119355 : \
-host epb203 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=5118899186 : \
-host epb200 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=6142679017 : \
-host epb171 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=7166458848 : \
-host epb134 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=8190238679 : \
-host epb219 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=9214018510 : \
-host epb121 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=10237798341 : \
-host epb207 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=11261578172 : \
-host epb201 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=12285358003 : \
-host epb176 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=13309137834 : \
-host epb173 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=14332917665 : \
-host epb132 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=15356697496 : \
-host epb178 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=16380477327 : \
-host epb205 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=17404257158 : \
-host epb204 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=18428036989 : \
-host epb175 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=19451816820 : \
-host epb174 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000030-000017.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/000030-000017 --seed=20475596651 : \
-host epb208 python3 ml_perf/execute.py --num_instance=4 -- bazel-bin/cc/eval --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/eval.flags --model=tf,/lfs/lfs12/gma_akey/resu
[2019-06-18 12:53:18] eval finished: 12.268 seconds
[2019-06-18 12:53:18] Win rate 000030-000017 vs 000026-000016: 0.460
:::MLL 1560883998.117292 epoch_stop: {"value": null, "metadata": {'lineno': 705, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 29}}
[2019-06-18 12:53:18] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-selfplay-32-%r.txt -genv LD_LIBRARY_PATH=$LD_LIBRARY_PATH:cc/tensorflow \
-host epb144 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=32 : \
-host epb131 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=1023779863 : \
-host epb215 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=2047559694 : \
-host epb217 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=3071339525 : \
-host epb133 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=4095119356 : \
-host epb203 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=5118899187 : \
-host epb200 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=6142679018 : \
-host epb171 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=7166458849 : \
-host epb134 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=8190238680 : \
-host epb219 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=9214018511 : \
-host epb121 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=10237798342 : \
-host epb207 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=11261578173 : \
-host epb201 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=12285358004 : \
-host epb176 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=13309137835 : \
-host epb173 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=14332917666 : \
-host epb132 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=15356697497 : \
-host epb178 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=16380477328 : \
-host epb205 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=17404257159 : \
-host epb204 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb144/data/holdout/000031-000016 --seed=18428036990 : \
-host epb175 python3 ml_perf/execute.py --num_instance=79 -- bazel-bin/cc/selfplay --flagfile=/lfs/lfs12/gma_akey/results/epb144/flags/selfplay.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000026-000016.pb --output_dir=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016 --holdout_dir=/lfs/lfs12/gma_akey/results/epb14
[2019-06-18 12:53:49] train finished: 43.581 seconds
:::MLL 1560883990.953521 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883990.954264 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883990.954953 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.077320 46954467267456 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883990.947257 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883990.948130 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883990.948927 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.077577 47611473404800 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
I0618 12:53:11.078483 46954467267456 estimator.py:201] Using config: {'_model_dir': '/lfs/lfs12/gma_akey/results/epb144/work_dir', '_tf_random_seed': None, '_save_summary_steps': 64, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ab4b8edcd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:53:11.078707 47611473404800 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpeiltqho9
I0618 12:53:11.079746 46954467267456 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.079869 47611473404800 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpeiltqho9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4db18bee48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.080304 47611473404800 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.085115 46954467267456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.085469 47611473404800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883990.973413 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883990.974299 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883990.975168 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.100976 47943217779584 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883990.980122 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883990.980747 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883990.981431 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.101794 47618148848512 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.102121 47943217779584 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmph7m4n3yq
I0618 12:53:11.103219 47943217779584 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmph7m4n3yq', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9aef0d6e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.103660 47943217779584 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.102873 47618148848512 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpx1xupyjw
I0618 12:53:11.103991 47618148848512 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpx1xupyjw', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4f3f6f1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.104452 47618148848512 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.106834 46954467267456 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.107329 47611473404800 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.109004 47943217779584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.109549 47618148848512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.130721 47943217779584 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.131164 47618148848512 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883991.037823 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.038298 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.038705 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.144871 47582454100864 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.145918 47582454100864 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxkfsynh9
I0618 12:53:11.146924 47582454100864 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxkfsynh9', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b46efdc8e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.147325 47582454100864 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883991.039476 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.039892 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.040254 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.147375 47680164426624 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.148368 47680164426624 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpbp3rywkv
I0618 12:53:11.149354 47680164426624 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpbp3rywkv', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b5dafd9ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.149757 47680164426624 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.151998 47582454100864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.154350 47680164426624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.157254 46954467267456 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.157903 47611473404800 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.161638 46954467267456 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:53:11.162243 47611473404800 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883991.024653 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.025560 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.026402 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.165493 47097943470976 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883991.040341 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.041087 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.041783 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.165603 47997320168320 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
I0618 12:53:11.166770 46954467267456 estimator.py:1111] Calling model_fn.
W0618 12:53:11.166881 46954467267456 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:53:11.167356 47611473404800 estimator.py:1111] Calling model_fn.
W0618 12:53:11.166585 47097943470976 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpox1wm1q2
W0618 12:53:11.167469 47611473404800 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:53:11.166656 47997320168320 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpj8j8o8du
I0618 12:53:11.167639 47097943470976 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpox1wm1q2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ad620c70e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.167708 47997320168320 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpj8j8o8du', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba787ce4e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.168066 47097943470976 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.168133 47997320168320 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.168248 46954467267456 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883991.013695 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.014474 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.015220 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.168151 47941818745728 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.168854 47611473404800 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:53:11.169203 47941818745728 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpz3aisdkp
I0618 12:53:11.170211 47941818745728 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpz3aisdkp', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b9a9ba9de48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.170617 47941818745728 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.170857 47582454100864 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.173246 47680164426624 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.173284 47097943470976 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.173300 47997320168320 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.175782 47941818745728 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883990.983227 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883990.984120 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883990.984946 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.175555 47612226687872 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883991.015151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.015888 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.016526 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.177219 47965036368768 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883991.074910 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.075302 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.075622 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.177254 47361818456960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.176705 47612226687872 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpo1kyj5i8
:::MLL 1560883991.076703 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.077079 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.077398 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.177695 47615423853440 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
I0618 12:53:11.177793 47612226687872 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpo1kyj5i8', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4dde722e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.178226 47612226687872 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.178209 47965036368768 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxhgio1li
W0618 12:53:11.178292 47361818456960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp8i7_14vm
I0618 12:53:11.179220 47965036368768 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxhgio1li', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba0038aae48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.179290 47361818456960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp8i7_14vm', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b1390f3ce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:53:11.178690 47615423853440 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpfr73qh8v
I0618 12:53:11.179616 47965036368768 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.179683 47361818456960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.179698 47615423853440 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpfr73qh8v', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b4e9d02fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.180111 47615423853440 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.181773 47618148848512 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.182211 47943217779584 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.183513 47612226687872 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.184225 47965036368768 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.184386 47361818456960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.184719 47615423853440 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883990.987861 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883990.988545 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883990.989248 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.185134 47998649688960 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.186198 47618148848512 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:53:11.186638 47943217779584 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:53:11.186195 47998649688960 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpuu3wpmg7
I0618 12:53:11.187282 47998649688960 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpuu3wpmg7', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba7d70d2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.187744 47998649688960 train.py:201] Training, steps = ?, batch = 341 -> ? examples
:::MLL 1560883991.002216 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.003130 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.003963 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.190103 47884222546816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
I0618 12:53:11.191465 47618148848512 estimator.py:1111] Calling model_fn.
W0618 12:53:11.191598 47618148848512 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
I0618 12:53:11.191924 47943217779584 estimator.py:1111] Calling model_fn.
W0618 12:53:11.192042 47943217779584 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:53:11.191156 47884222546816 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpikevr5t2
I0618 12:53:11.192174 47884222546816 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpikevr5t2', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b8d32a99dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:53:11.192846 47998649688960 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0618 12:53:11.192593 47884222546816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.193052 47618148848512 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:53:11.193496 47943217779584 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0618 12:53:11.194676 47097943470976 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.194859 47941818745728 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.194943 47997320168320 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
:::MLL 1560883991.011151 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.011893 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.012586 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.194468 47725104239488 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.195464 47725104239488 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpl6d__7r3
I0618 12:53:11.196459 47725104239488 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpl6d__7r3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b682678edd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.196870 47725104239488 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.197393 47884222546816 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.201657 47725104239488 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.203249 47361818456960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.203561 47965036368768 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.203635 47615423853440 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.204980 47612226687872 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.213827 47998649688960 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.216749 47884222546816 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.217986 47582454100864 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.219981 47680164426624 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.220972 47725104239488 deprecation.py:323] From ./preprocessing.py:144: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0618 12:53:11.222270 47582454100864 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0618 12:53:11.224269 47680164426624 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py:104: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
:::MLL 1560883991.053052 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.053469 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.053850 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.226207 47695780172672 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883991.054839 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.055254 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.055620 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.226283 47429067531136 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
I0618 12:53:11.227318 47582454100864 estimator.py:1111] Calling model_fn.
W0618 12:53:11.227428 47582454100864 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
W0618 12:53:11.227268 47695780172672 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmppwurombb
W0618 12:53:11.227298 47429067531136 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmptfyiynir
I0618 12:53:11.228261 47695780172672 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmppwurombb', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b61529f2e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.228282 47429067531136 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmptfyiynir', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b23394f3e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0618 12:53:11.228807 47582454100864 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I0618 12:53:11.228661 47695780172672 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.228677 47429067531136 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.229317 47680164426624 estimator.py:1111] Calling model_fn.
W0618 12:53:11.229424 47680164426624 deprecation.py:323] From /global/panfs01/users/gma/submission/benchmarks/minigo/implementations/tensorflow/dual_net.py:489: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
:::MLL 1560883991.121523 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.121951 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.122326 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.229832 47433058542464 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.230780 47680164426624 deprecation.py:506] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
:::MLL 1560883991.120812 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.121250 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.121649 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.230807 47258734785408 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.230834 47433058542464 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpvy_r_rta
I0618 12:53:11.231822 47433058542464 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpvy_r_rta', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b2427313e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.232218 47433058542464 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.231761 47258734785408 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpnr69clb3
I0618 12:53:11.232760 47258734785408 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpnr69clb3', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2afb90afce48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.233157 47258734785408 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.233330 47429067531136 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.233339 47695780172672 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.236842 47433058542464 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0618 12:53:11.237711 47258734785408 deprecation.py:323] From /home/gma/anaconda3/envs/minigo-dev/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
:::MLL 1560883991.105057 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.105653 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.106184 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.237936 47905850598272 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
:::MLL 1560883991.111958 global_batch_size: {"value": 8192, "metadata": {'lineno': 233, 'file': 'train.py'}}
:::MLL 1560883991.112426 opt_base_learning_rate: {"value": [0.32, 0.032, 0.0032], "metadata": {'lineno': 234, 'file': 'train.py'}}
:::MLL 1560883991.112846 opt_learning_rate_decay_boundary_steps: {"value": [12500, 18750], "metadata": {'lineno': 235, 'file': 'train.py'}}
I0618 12:53:11.238142 47971017810816 train.py:238] Training on 3120 records: /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000030-000016.tfrecord.zz_9_9 to /lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000021-000013.tfrecord.zz_0_0
W0618 12:53:11.238943 47905850598272 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmp2j5wdso4
W0618 12:53:11.239112 47971017810816 estimator.py:1760] Using temporary folder as model directory: /tmp/96737.tmpdir/tmpxml3_cb1
I0618 12:53:11.239934 47905850598272 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmp2j5wdso4', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2b923bcb7e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.240094 47971017810816 estimator.py:201] Using config: {'_model_dir': '/tmp/96737.tmpdir/tmpxml3_cb1', '_tf_random_seed': None, '_save_summary_steps': 1000000, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 11
inter_op_parallelism_threads: 1
gpu_options {
  allow_growth: true
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2ba168102e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0618 12:53:11.240334 47905850598272 train.py:201] Training, steps = ?, batch = 341 -> ? examples
I0618 12:53:11.240491 47971017810816 train.py:201] Training, steps = ?, batch = 341 -> ? examples
W0618 12:53:11.242848 47941818745728 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0618 12:53:11.243308 47097943470976 deprecation.py:323] From ./preprocessing.py:177: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions statef[2019-06-18 12:53:49] selfplay finished: 31.450 seconds
[2019-06-18 12:53:49] selfplay mn: 31.467 seconds
[2019-06-18 12:53:49] Running: mpiexec -outfile-pattern /lfs/lfs12/gma_akey/results/epb144/mpi/out-divide_golden_chunk-32-%r.txt \
-host epb144 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=32 : \
-host epb131 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=1023779863 : \
-host epb215 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=2047559694 : \
-host epb217 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=3071339525 : \
-host epb133 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=4095119356 : \
-host epb203 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=5118899187 : \
-host epb200 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=6142679018 : \
-host epb171 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=7166458849 : \
-host epb134 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=8190238680 : \
-host epb219 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=9214018511 : \
-host epb121 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=10237798342 : \
-host epb207 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=11261578173 : \
-host epb201 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=12285358004 : \
-host epb176 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=13309137835 : \
-host epb173 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=14332917666 : \
-host epb132 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=15356697497 : \
-host epb178 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=16380477328 : \
-host epb205 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=17404257159 : \
-host epb204 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=18428036990 : \
-host epb175 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=19451816821 : \
-host epb174 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=20475596652 : \
-host epb208 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=21499376483 : \
-host epb210 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/000031-000016.tfrecord.zz --out_files_number=12 --physical_cores=48 --base_dir=/lfs/lfs12/gma_akey/results/epb144 --seed=22523156314 : \
-host epb179 python3 ml_perf/divide_golden_chunk.py --read_path=/tmp/minigo/lfs/lfs12/gma_akey/results/epb144/data/selfplay/000031-000016/* --write_path=/lfs/lfs12/gma_akey/results/epb144/data/golde
[2019-06-18 12:53:52] divide_golden_chunk finished: 3.332 seconds
[2019-06-18 12:53:52] generate golden chunk: 3.347 seconds
[2019-06-18 12:53:52] iteration time 30: 51.957 seconds
:::MLL 1560884032.932403 epoch_stop: {"value": null, "metadata": {'lineno': 737, 'file': 'ml_perf/reference_implementation.py', 'epoch_num': 30}}
[2019-06-18 12:53:52] Total time: 1702.951 seconds

numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000018-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000018-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000019-000013_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000019-000013log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000020-000014_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000020-000014log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000021-000015_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000021-000015log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000022-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000022-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000023-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000023-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000024-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000024-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000025-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000025-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000026-000016_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000026-000016log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000027-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000027-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000028-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000028-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000029-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000029-000017log.txt
numactl -N 0 -l python3 produce_min_max_log.py --input_graph=/lfs/lfs12/gma_akey/results/epb144/models/000030-000017_for_min_max.pb --data_location=/lfs/lfs12/gma_akey/results/epb144/data/golden_chunks/*.zz* --num_steps=5 --batch_size=16 --random_rotation=True 2> /lfs/lfs12/gma_akey/results/epb144/models/000030-000017log.txt
:::MLL 1560884035.496761 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
I0618 12:53:55.497502 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000001-000001.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=1
I0618 12:54:22.079991 47509677065088 utils.py:86] eval finished: 26.582 seconds
I0618 12:54:22.083404 47509677065088 reference_implementation.py:563] Win rate 000001-000001 vs target: 0.010
:::MLL 1560884062.084085 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560884062.084410 eval_accuracy: {"value": 0.01, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 0}}
:::MLL 1560884062.084752 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
I0618 12:54:22.085070 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000002-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=2
I0618 12:54:46.823861 47509677065088 utils.py:86] eval finished: 24.739 seconds
I0618 12:54:46.826762 47509677065088 reference_implementation.py:563] Win rate 000002-000002 vs target: 0.110
:::MLL 1560884086.827410 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560884086.827724 eval_accuracy: {"value": 0.11, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 1}}
:::MLL 1560884086.828025 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
I0618 12:54:46.828315 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000003-000002.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=3
I0618 12:55:13.276662 47509677065088 utils.py:86] eval finished: 26.448 seconds
I0618 12:55:13.279572 47509677065088 reference_implementation.py:563] Win rate 000003-000002 vs target: 0.110
:::MLL 1560884113.280421 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560884113.280755 eval_accuracy: {"value": 0.11, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 2}}
:::MLL 1560884113.281070 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
I0618 12:55:13.281380 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000004-000003.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=4
I0618 12:55:38.736049 47509677065088 utils.py:86] eval finished: 25.454 seconds
I0618 12:55:38.738848 47509677065088 reference_implementation.py:563] Win rate 000004-000003 vs target: 0.080
:::MLL 1560884138.739491 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560884138.739852 eval_accuracy: {"value": 0.08, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 3}}
:::MLL 1560884138.740187 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
I0618 12:55:38.740486 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000005-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=5
I0618 12:56:03.574966 47509677065088 utils.py:86] eval finished: 24.834 seconds
I0618 12:56:03.577791 47509677065088 reference_implementation.py:563] Win rate 000005-000004 vs target: 0.120
:::MLL 1560884163.578432 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560884163.578746 eval_accuracy: {"value": 0.12, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 4}}
:::MLL 1560884163.579045 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
I0618 12:56:03.579345 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000006-000004.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=6
I0618 12:56:28.924800 47509677065088 utils.py:86] eval finished: 25.345 seconds
I0618 12:56:28.927748 47509677065088 reference_implementation.py:563] Win rate 000006-000004 vs target: 0.180
:::MLL 1560884188.928601 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560884188.928943 eval_accuracy: {"value": 0.18, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 5}}
:::MLL 1560884188.929260 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
I0618 12:56:28.929567 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000007-000005.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=7
I0618 12:56:53.429104 47509677065088 utils.py:86] eval finished: 24.499 seconds
I0618 12:56:53.432003 47509677065088 reference_implementation.py:563] Win rate 000007-000005 vs target: 0.100
:::MLL 1560884213.432880 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560884213.433211 eval_accuracy: {"value": 0.1, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 6}}
:::MLL 1560884213.433535 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
I0618 12:56:53.433875 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000008-000006.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=8
I0618 12:57:18.687576 47509677065088 utils.py:86] eval finished: 25.254 seconds
I0618 12:57:18.690478 47509677065088 reference_implementation.py:563] Win rate 000008-000006 vs target: 0.200
:::MLL 1560884238.691168 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560884238.691492 eval_accuracy: {"value": 0.2, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 7}}
:::MLL 1560884238.691822 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
I0618 12:57:18.692116 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000009-000007.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=9
I0618 12:57:44.083721 47509677065088 utils.py:86] eval finished: 25.391 seconds
I0618 12:57:44.086558 47509677065088 reference_implementation.py:563] Win rate 000009-000007 vs target: 0.250
:::MLL 1560884264.087466 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560884264.087809 eval_accuracy: {"value": 0.25, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 8}}
:::MLL 1560884264.088137 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
I0618 12:57:44.088449 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000010-000008.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=10
I0618 12:58:10.478323 47509677065088 utils.py:86] eval finished: 26.390 seconds
I0618 12:58:10.481246 47509677065088 reference_implementation.py:563] Win rate 000010-000008 vs target: 0.310
:::MLL 1560884290.481925 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560884290.482254 eval_accuracy: {"value": 0.31, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 9}}
:::MLL 1560884290.482583 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
I0618 12:58:10.482887 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000011-000009.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=11
I0618 12:58:37.326297 47509677065088 utils.py:86] eval finished: 26.843 seconds
I0618 12:58:37.329170 47509677065088 reference_implementation.py:563] Win rate 000011-000009 vs target: 0.230
:::MLL 1560884317.329814 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560884317.330124 eval_accuracy: {"value": 0.23, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 10}}
:::MLL 1560884317.330425 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
I0618 12:58:37.330724 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000012-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=12
I0618 12:59:03.603803 47509677065088 utils.py:86] eval finished: 26.273 seconds
I0618 12:59:03.606722 47509677065088 reference_implementation.py:563] Win rate 000012-000010 vs target: 0.220
:::MLL 1560884343.607694 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560884343.608023 eval_accuracy: {"value": 0.22, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 11}}
:::MLL 1560884343.608338 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
I0618 12:59:03.608679 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000013-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=13
I0618 12:59:28.461283 47509677065088 utils.py:86] eval finished: 24.852 seconds
I0618 12:59:28.464135 47509677065088 reference_implementation.py:563] Win rate 000013-000010 vs target: 0.270
:::MLL 1560884368.464799 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560884368.465122 eval_accuracy: {"value": 0.27, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 12}}
:::MLL 1560884368.465437 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
I0618 12:59:28.465747 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000014-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=14
I0618 12:59:53.083005 47509677065088 utils.py:86] eval finished: 24.617 seconds
I0618 12:59:53.090980 47509677065088 reference_implementation.py:563] Win rate 000014-000010 vs target: 0.200
:::MLL 1560884393.091617 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560884393.091924 eval_accuracy: {"value": 0.2, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 13}}
:::MLL 1560884393.092223 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
I0618 12:59:53.092516 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000015-000010.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=15
I0618 13:00:16.264156 47509677065088 utils.py:86] eval finished: 23.171 seconds
I0618 13:00:16.267038 47509677065088 reference_implementation.py:563] Win rate 000015-000010 vs target: 0.370
:::MLL 1560884416.267946 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560884416.268281 eval_accuracy: {"value": 0.37, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 14}}
:::MLL 1560884416.268614 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
I0618 13:00:16.268958 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000016-000011.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=16
I0618 13:00:40.281376 47509677065088 utils.py:86] eval finished: 24.012 seconds
I0618 13:00:40.284303 47509677065088 reference_implementation.py:563] Win rate 000016-000011 vs target: 0.340
:::MLL 1560884440.284969 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560884440.285291 eval_accuracy: {"value": 0.34, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 15}}
:::MLL 1560884440.285610 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
I0618 13:00:40.285913 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000017-000012.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=17
I0618 13:01:03.995653 47509677065088 utils.py:86] eval finished: 23.710 seconds
I0618 13:01:03.998546 47509677065088 reference_implementation.py:563] Win rate 000017-000012 vs target: 0.450
:::MLL 1560884463.999493 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560884463.999837 eval_accuracy: {"value": 0.45, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 16}}
:::MLL 1560884464.000163 eval_start: {"value": null, "metadata": {'lineno': 46, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
I0618 13:01:04.000493 47509677065088 utils.py:81] Running: python3 ml_perf/execute.py --num_instance=100 -- bazel-bin/cc/eval --flagfile=ml_perf/flags/9.mn/eval.flags --model=tf,/lfs/lfs12/gma_akey/results/epb144/models/000018-000013.pb --model_two=tf,/lfs/lfs12/gma_akey/results/epb144/models/target.pb --sgf_dir=/lfs/lfs12/gma_akey/results/epb144/sgf/eval/target --seed=18
I0618 13:01:28.777249 47509677065088 utils.py:86] eval finished: 24.777 seconds
I0618 13:01:28.780115 47509677065088 reference_implementation.py:563] Win rate 000018-000013 vs target: 0.500
:::MLL 1560884488.780962 eval_stop: {"value": null, "metadata": {'lineno': 48, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
:::MLL 1560884488.781288 eval_accuracy: {"value": 0.5, "metadata": {'lineno': 49, 'file': 'ml_perf/eval_models.py', 'epoch_num': 17}}
:::MLL 1560884488.781622 eval_result: {"value": null, "metadata": {'lineno': 52, 'file': 'ml_perf/eval_models.py', 'iteration': 17, 'timestamp': 885.82}}
:::MLL 1560884488.781924 run_stop: {"value": null, "metadata": {'lineno': 53, 'file': 'ml_perf/eval_models.py', 'status': 'success'}}
Model 000018-000013 beat target after 885.82s
~/submission/benchmarks/minigo/clx-8260l-2s-x32
